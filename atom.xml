<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>L</title>
  
  <subtitle>make it simple, make it happen.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://liujunming.github.io/"/>
  <updated>2023-12-30T10:09:07.056Z</updated>
  <id>http://liujunming.github.io/</id>
  
  <author>
    <name>liujunming</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Notes about ingress and egress  in network</title>
    <link href="http://liujunming.github.io/2023/12/30/Notes-about-ingress-and-egress-in-network/"/>
    <id>http://liujunming.github.io/2023/12/30/Notes-about-ingress-and-egress-in-network/</id>
    <published>2023-12-30T10:07:02.000Z</published>
    <updated>2023-12-30T10:09:07.056Z</updated>
    
    <content type="html"><![CDATA[<p>The answer from quora:</p><p>Network ingress and egress are terms used in networking to describe the direction of network traffic. In general, ingress refers to network traffic that enters a network or a device, while egress refers to network traffic that exits a network or a device. <a id="more"></a></p><p>For example, when you browse a website, the data packets that are sent from the website’s server to your browser are considered ingress traffic for your device and egress traffic for the server. Conversely, the data packets that are sent from your browser to the website’s server are considered egress traffic for your device and ingress traffic for the server.</p><p><a href="https://www.quora.com/What-are-network-ingress-and-egress" target="_blank" rel="noopener">https://www.quora.com/What-are-network-ingress-and-egress</a></p><p>The answer from chatgpt:</p><p><strong>Network ingress and egress refer to the movement of data into and out of a network</strong>. Ingress: This refers to the <strong>incoming</strong> data traffic that enters a network from an external source, such as the internet or another network. Egress: This refers to the outgoing data traffic that leaves a network to an external destination, such as the internet or another network. In networking, understanding and managing network ingress and egress is important for maintaining the security, performance, and efficiency of a network.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The answer from quora:&lt;/p&gt;
&lt;p&gt;Network ingress and egress are terms used in networking to describe the direction of network traffic. In general, ingress refers to network traffic that enters a network or a device, while egress refers to network traffic that exits a network or a device.
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Standardizing Live Migration with NVM Express</title>
    <link href="http://liujunming.github.io/2023/12/03/Notes-about-Standardizing-Live-Migration-with-NVM-Express/"/>
    <id>http://liujunming.github.io/2023/12/03/Notes-about-Standardizing-Live-Migration-with-NVM-Express/</id>
    <published>2023-12-03T12:06:55.000Z</published>
    <updated>2023-12-03T14:03:01.465Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要是mark下<a href="https://drive.google.com/file/d/1obwZNWd89MPfrZWSsj24ub0N7JHJZ6FU/view?usp=drive_link" target="_blank" rel="noopener">Standardizing Live Migration with NVM Express®</a>相关notes，相关细节可以参考原文。<a id="more"></a></p><p><img src="/images/2023/12/005.jpg" alt></p><p>slides中有如下描述：</p><blockquote><p>Host may use a new mechanism to throttle commands processing by migrating controller to slow down changes</p></blockquote><p>其对应的是:</p><blockquote><p>Support limit the BW and IOPS of a controller to allow slowing down of command processing on a migrating controller</p></blockquote><p>这是QoS的相关实现，考虑写磁盘多的workload，不限速的话，最后一轮的脏LBAs可能会很多，downtime就会有些大了。</p><p>原文考虑了本地盘与非本地盘的NVMe Live Migration。</p><p>对于本地盘的情况，需要记录脏的LBAs，在热迁移每轮迭代中，会传输脏的LBAs(类似于热迁移的脏页传输)。</p><p>对于非本地盘的情况，其实就无效考虑脏的LBAs了。</p><p>对于IPU/DPU的NVMe Live Migration，详情可以参考<a href="https://mp.weixin.qq.com/s/GnN06H864XuXU41-jFH4jA" target="_blank" rel="noopener">NVMe VFIO Live Migration for IPU/DPU Devices</a>。</p><p><img src="/images/2023/12/003.jpg" alt></p><p><img src="/images/2023/12/004.jpg" alt><br>值得注意的是，如果host上的IOMMU支持DMA脏页记录的话，就无需NVMe Device自己去记录DMA脏页了。</p><hr><p>参考资料:</p><ol><li><a href="https://nvmexpress.org/wp-content/uploads/FMS-2023-Host-Controlled-Live-Migration.pdf" target="_blank" rel="noopener">FMS 2023 Host Controlled Live Migration</a></li><li><a href="https://www.bilibili.com/video/BV19N4y1S74F/" target="_blank" rel="noopener">Standardizing Live Migration with NVM Express®</a></li><li><a href="https://www.opencompute.org/events/past-events/2023-ocp-global-summit" target="_blank" rel="noopener">2023 OCP Global Summit</a></li><li><a href="https://mp.weixin.qq.com/s/GnN06H864XuXU41-jFH4jA" target="_blank" rel="noopener">NVMe VFIO Live Migration for IPU/DPU Devices</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要是mark下&lt;a href=&quot;https://drive.google.com/file/d/1obwZNWd89MPfrZWSsj24ub0N7JHJZ6FU/view?usp=drive_link&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Standardizing Live Migration with NVM Express®&lt;/a&gt;相关notes，相关细节可以参考原文。
    
    </summary>
    
      <category term="NVMe" scheme="http://liujunming.github.io/categories/NVMe/"/>
    
    
      <category term="live migration" scheme="http://liujunming.github.io/tags/live-migration/"/>
    
      <category term="存储" scheme="http://liujunming.github.io/tags/%E5%AD%98%E5%82%A8/"/>
    
      <category term="NVMe" scheme="http://liujunming.github.io/tags/NVMe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about NVMe Namespaces</title>
    <link href="http://liujunming.github.io/2023/12/02/Notes-about-NVMe-Namespaces/"/>
    <id>http://liujunming.github.io/2023/12/02/Notes-about-NVMe-Namespaces/</id>
    <published>2023-12-02T12:20:04.000Z</published>
    <updated>2023-12-03T02:44:35.377Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下NVMe Namespaces相关notes。<a id="more"></a></p><ul><li>What is the meaning of nvme0n1 nvme0n2 nvme1n1 nvme1n2 in Linux?<ul><li>nvmeXnY: X means controller, Y means namespace</li></ul></li><li>NVMe controller<ul><li>A PCI Express function that implements the NVM Express interface</li></ul></li><li>NVMe namespace<ul><li>A namespace is a collection of logical block addresses (LBA) accessible to host software. A namespace ID (NSID) is an identifier used by a controller to provide access to a namespace. A namespace is not the physical isolation of blocks, rather the isolation of logical blocks addressable by the host software</li></ul></li><li>A NVM Express controller may support multiple namespaces that are referenced using a namespace ID</li></ul><p><img src="/images/2023/12/001.jpg" alt></p><p>无需理解LUNs。</p><p><img src="/images/2023/12/002.jpg" alt><br>无需理解vSAN。</p><hr><p>参考资料:</p><ol><li><a href="https://www.snia.org/sites/default/files/SDCEMEA/2020/4%20-%20Or%20Lapid%20Micron%20-%20Understanding%20NVMe%20namespaces%20-%20Final.pdf" target="_blank" rel="noopener">NVMe™ Namespaces:Micron Storage Solutions Engineering</a></li><li><a href="https://nvmexpress.org/resource/nvme-namespaces/" target="_blank" rel="noopener">NVMe Namespaces</a></li><li><a href="https://narasimhan-v.github.io/2020/06/12/Managing-NVMe-Namespaces.html" target="_blank" rel="noopener">Managing Nvme Namespaces</a></li><li><a href="https://unix.stackexchange.com/questions/520231/what-are-nvme-namespaces-how-do-they-work" target="_blank" rel="noopener">What are nvme namespaces? How do they work?</a></li><li><a href="https://www.flashmemorysummit.com/English/Collaterals/Proceedings/2013/20130812_PreConfD_Marks.pdf" target="_blank" rel="noopener">An NVM Express Tutorial</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下NVMe Namespaces相关notes。
    
    </summary>
    
      <category term="NVMe" scheme="http://liujunming.github.io/categories/NVMe/"/>
    
    
      <category term="存储" scheme="http://liujunming.github.io/tags/%E5%AD%98%E5%82%A8/"/>
    
      <category term="NVMe" scheme="http://liujunming.github.io/tags/NVMe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about virtio-net configuration changes</title>
    <link href="http://liujunming.github.io/2023/10/28/Notes-about-virtio-net-configuration-changes/"/>
    <id>http://liujunming.github.io/2023/10/28/Notes-about-virtio-net-configuration-changes/</id>
    <published>2023-10-28T07:15:59.000Z</published>
    <updated>2023-10-28T08:26:01.702Z</updated>
    
    <content type="html"><![CDATA[<p>参考<a href="https://docs.oasis-open.org/virtio/virtio/v1.2/csd01/virtio-v1.2-csd01.html#x1-2230004" target="_blank" rel="noopener">virtio 1.2 spec</a>，Linux kernel version <a href="https://elixir.bootlin.com/linux/v6.0/source" target="_blank" rel="noopener">v6.0</a>。<a id="more"></a></p><ul><li><em>speed</em> contains the device speed, in units of 1 MBit per second, 0 to 0x7fffffff, or 0xffffffff for unknown speed.</li><li><em>duplex</em> has the values of 0x01 for full duplex, 0x00 for half duplex and 0xff for unknown duplex state.</li></ul><p>Both <em>speed</em> and <em>duplex</em> can change, thus the driver is expected to re-read these values after receiving a configuration change notification.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_net_config</span> &#123;</span> </span><br><span class="line">        u8 mac[<span class="number">6</span>]; </span><br><span class="line">        le16 status; </span><br><span class="line">        le16 max_virtqueue_pairs; </span><br><span class="line">        le16 mtu; </span><br><span class="line">        le32 speed; </span><br><span class="line">        u8 duplex; </span><br><span class="line">        u8 rss_max_key_size; </span><br><span class="line">        le16 rss_max_indirection_table_length; </span><br><span class="line">        le32 supported_hash_types; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>Linux kernel source code:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtnet_config_changed_work</span><span class="params">(struct work_struct *work)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">virtnet_info</span> *<span class="title">vi</span> =</span></span><br><span class="line"><span class="class">        <span class="title">container_of</span>(<span class="title">work</span>, <span class="title">struct</span> <span class="title">virtnet_info</span>, <span class="title">config_work</span>);</span></span><br><span class="line">    u16 v;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (virtio_cread_feature(vi-&gt;vdev, VIRTIO_NET_F_STATUS,</span><br><span class="line">                 struct virtio_net_config, status, &amp;v) &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (v &amp; VIRTIO_NET_S_ANNOUNCE) &#123;</span><br><span class="line">        netdev_notify_peers(vi-&gt;dev);</span><br><span class="line">        virtnet_ack_link_announce(vi);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Ignore unknown (future) status bits */</span></span><br><span class="line">    v &amp;= VIRTIO_NET_S_LINK_UP;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (vi-&gt;status == v)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    vi-&gt;status = v;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (vi-&gt;status &amp; VIRTIO_NET_S_LINK_UP) &#123;</span><br><span class="line">        virtnet_update_settings(vi);</span><br><span class="line">        netif_carrier_on(vi-&gt;dev);</span><br><span class="line">        netif_tx_wake_all_queues(vi-&gt;dev);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        netif_carrier_off(vi-&gt;dev);</span><br><span class="line">        netif_tx_stop_all_queues(vi-&gt;dev);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtnet_update_settings</span><span class="params">(struct virtnet_info *vi)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    u32 speed;</span><br><span class="line">    u8 duplex;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!virtio_has_feature(vi-&gt;vdev, VIRTIO_NET_F_SPEED_DUPLEX))</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    virtio_cread_le(vi-&gt;vdev, struct virtio_net_config, speed, &amp;speed);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ethtool_validate_speed(speed))</span><br><span class="line">        vi-&gt;speed = speed;</span><br><span class="line"></span><br><span class="line">    virtio_cread_le(vi-&gt;vdev, struct virtio_net_config, duplex, &amp;duplex);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ethtool_validate_duplex(duplex))</span><br><span class="line">        vi-&gt;duplex = duplex;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考&lt;a href=&quot;https://docs.oasis-open.org/virtio/virtio/v1.2/csd01/virtio-v1.2-csd01.html#x1-2230004&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;virtio 1.2 spec&lt;/a&gt;，Linux kernel version &lt;a href=&quot;https://elixir.bootlin.com/linux/v6.0/source&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;v6.0&lt;/a&gt;。
    
    </summary>
    
      <category term="virtio" scheme="http://liujunming.github.io/categories/virtio/"/>
    
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about XDP</title>
    <link href="http://liujunming.github.io/2023/10/22/Notes-about-XDP/"/>
    <id>http://liujunming.github.io/2023/10/22/Notes-about-XDP/</id>
    <published>2023-10-22T06:14:58.000Z</published>
    <updated>2023-10-22T11:12:06.844Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下eXpress Data Path (XDP)相关notes。<a id="more"></a></p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p>XDP其实是位于网卡驱动程序里的一个快速处理数据包的HOOK点，为什么快？因为数据包处理位置非常底层，避开了很多内核skb处理开销。</p><p>XDP暴露了一个可以加载BPF程序的网络钩子。在这个钩子中，程序能够对传入的数据包进行任意修改和快速决策，避免了内核内部处理带来的额外开销。这使得XDP在性能速度方面成为最佳钩子，例如缓解DDoS攻击等。 </p><h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p><img src="/images/2023/11/016.jpg" alt></p><p><img src="/images/2023/11/015.jpg" alt></p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><img src="/images/2023/11/014.jpg" alt></p><p><img src="/images/2023/11/017.jpg" alt></p><h3 id="Introduction-to-eBPF-and-XDP"><a href="#Introduction-to-eBPF-and-XDP" class="headerlink" title="Introduction to eBPF and XDP"></a>Introduction to eBPF and XDP</h3><ul><li><a href="https://www.bilibili.com/video/BV1qq4y1r7uB/" target="_blank" rel="noopener">B站视频</a></li><li><a href="https://www.slideshare.net/lcplcp1/introduction-to-ebpf-and-xdp" target="_blank" rel="noopener">slides</a></li></ul><p>建议阅读上述资料，会对XDP有不错的认识。</p><p><img src="/images/2023/11/005.jpg" alt></p><p>以DDoS为例:</p><p><img src="/images/2023/11/006.jpg" alt></p><p><img src="/images/2023/11/007.jpg" alt></p><p><img src="/images/2023/11/008.jpg" alt></p><p><img src="/images/2023/11/009.jpg" alt></p><p>The XDP program is executed at the earliest possible moment after a packet is received from the hardware, before the kernel allocates its per-packet <code>sk_buff</code> data structure.</p><p><img src="/images/2023/11/010.jpg" alt></p><p><img src="/images/2023/11/011.jpg" alt></p><p>代码层的理解:<br><img src="/images/2023/11/001.jpg" alt></p><p><img src="/images/2023/11/002.jpg" alt></p><p><img src="/images/2023/11/003.jpg" alt></p><p><img src="/images/2023/11/004.jpg" alt></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/images/2023/11/012.jpg" alt></p><h3 id="Execution-flow-of-a-typical-XDP-program"><a href="#Execution-flow-of-a-typical-XDP-program" class="headerlink" title="Execution flow of a typical XDP program"></a>Execution flow of a typical XDP program</h3><p><img src="/images/2023/11/013.jpg" alt></p><p>详情参考<a href="https://github.com/tohojo/xdp-paper/blob/master/xdp-the-express-data-path.pdf" target="_blank" rel="noopener">xdp paper</a>3.1 The XDP Driver Hook。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>建议阅读<a href="http://arthurchiao.art/blog/xdp-paper-acm-2018-zh/" target="_blank" rel="noopener">[译] [论文] XDP (eXpress Data Path)：在操作系统内核中实现快速、可编程包处理（ACM，2018）</a>。</p><p>某种意义上来说，XDP 可以认为是一种 offload 方式：</p><ol><li>性能敏感的处理逻辑下放到网卡驱动中，以提升性能；</li><li>其他的处理逻辑仍然走内核网络栈；</li><li>如果没有用到内核 helper 函数，那整个 XDP 程序都可以 offload 到网卡（目前 Netronome smart-NICs已经支持）。</li></ol><hr><p>参考资料:</p><ol><li><a href="https://github.com/tohojo/xdp-paper/blob/master/xdp-the-express-data-path.pdf" target="_blank" rel="noopener">xdp paper</a></li><li><a href="https://github.com/tohojo/xdp-paper/blob/master/xdp-presentation.pdf" target="_blank" rel="noopener">xdp slides</a></li><li><a href="http://arthurchiao.art/blog/xdp-paper-acm-2018-zh/" target="_blank" rel="noopener">[译] [论文] XDP (eXpress Data Path)：在操作系统内核中实现快速、可编程包处理（ACM，2018）</a></li><li><a href="https://mp.weixin.qq.com/s/BqXhOlRisvNXETRj-TehUQ" target="_blank" rel="noopener">初识XDP</a></li><li><a href="https://mp.weixin.qq.com/s/qlgdIAGGv7yQXFGlGA5I8Q" target="_blank" rel="noopener">实现一个基于XDP_eBPF的学习型网桥</a></li><li><a href="https://www.youtube.com/watch?v=arq5XzodNmY" target="_blank" rel="noopener">Introduction to eBPF and XDP</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下eXpress Data Path (XDP)相关notes。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>PCI Express Max Read Request, Max Payload Size and why you care</title>
    <link href="http://liujunming.github.io/2023/10/06/PCI-Express-Max-Read-Request-Max-Payload-Size-and-why-you-care/"/>
    <id>http://liujunming.github.io/2023/10/06/PCI-Express-Max-Read-Request-Max-Payload-Size-and-why-you-care/</id>
    <published>2023-10-05T22:16:38.000Z</published>
    <updated>2023-10-06T08:26:40.127Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自:<a href="https://codywu2010.wordpress.com/2015/11/26/pci-express-max-read-request-max-payload-size-and-why-you-care/" target="_blank" rel="noopener">PCI Express Max Read Request, Max Payload Size and why you care</a><a id="more"></a></p><p>Modern high performance server is nearly all based on PCIE architecture and technologies derived from it such as Direct Media Interface (DMI) or Quick Path Interconnect (QPI).</p><p>For example below is a sample block diagram for a dual processor system:</p><p><img src="/images/2023/10/020.png" alt></p><p>A PCI Express system consists of many components, most important of which to us are:</p><ul><li>CPU</li><li>Root Complex (Root Port)</li><li>PCIE Switch</li><li>End Point</li></ul><p>Root Complex acts as the agent which helps with:</p><ul><li>Receive CPU request to initiate Memory/IO read/write towards end point</li><li>Receive End Point read/write request and either pass it to another end point or access system memory on their behalf</li></ul><p>The End point is usually of most interest to us because that’s where we put our high performance device.</p><p>It is GPU in the sample block diagram while in real time it can be a high speed Ethernet card or data collecting/processing card, or an infiniband card talking to some storage device in a large data center.</p><p>Below is a refined block diagram that amplify the interconnection of those components:</p><p><img src="/images/2023/10/021.png" alt></p><p>Based on this topology let’s talk about a typical scenario where Remote Direct Memory Access (RDMA) is used to allow a end point PCIE device to write directly to a pre-allocated system memory whenever data arrives, which offload to the maximum any involvements of CPU.</p><p>So the device will initiate a write request with data and send it along hoping root complex will help it get the data into system memory.</p><p>PCIE, different from traditional PCI or PCI-X, bases its communication traffic on the concepts of packets flying over point-to-point serial link, which is sometimes why people mention PCIE as a sort of tiny network topology.</p><p>So the RDMA device, acting as requester, sends its request package bearing the data along the link towards root complex.</p><p>The packet will arrive at intermediary PCIE switch and forward to root complex and root complex will diligently move data in the payload to system memory through its private memory controller.</p><p>Of course we would expect some overhead besides pure data payload and here goes the packet structure of PICE gen3:</p><p><img src="/images/2023/10/022.png" alt></p><p>So obviously given those additional “tax” you have to pay you would hope that you can put as large a payload as you can which would hopefully increase the effective utilization ratio.</p><p>However it does not always work and here comes to our discussion about <strong>“max payload size”</strong>.</p><p>Each device has a <strong>“max payload size supported”</strong> in its dev cap config register part indicating its capability and a “max payload size” in its dev control register part which will be programmed with actual <strong>“max playload set”</strong> it can use.</p><p>Below shows the related registers extracted from pcie base spec:</p><p><img src="/images/2023/10/018.jpg" alt></p><p><img src="/images/2023/10/019.jpg" alt></p><p>So how do we decide on what value to set within the range not above max payload supported?</p><p>The idea is it has to be equal to the minimum max payload supported along the route.</p><p>So for our data write request it would have to consider end point’s max payload supported as well as pcie switch (which is abstracted as pcie device while we do enumeration) and root complex’s root port (which is also abstracted as a device).</p><p>PCIE base spec actually described it this way without giving detailed implementation:</p><p><img src="/images/2023/10/023.png" alt></p><p>Now let’s take a look at how linux does it.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">pcie_write_mps</span><span class="params">(struct pci_dev *dev, <span class="keyword">int</span> mps)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rc;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (pcie_bus_config == PCIE_BUS_PERFORMANCE) &#123;</span><br><span class="line">        mps = <span class="number">128</span> &lt;&lt; dev-&gt;pcie_mpss;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (pci_pcie_type(dev) != PCI_EXP_TYPE_ROOT_PORT &amp;&amp;</span><br><span class="line">            dev-&gt;bus-&gt;self)</span><br><span class="line"></span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * For "Performance", the assumption is made that</span></span><br><span class="line"><span class="comment">             * downstream communication will never be larger than</span></span><br><span class="line"><span class="comment">             * the MRRS.  So, the MPS only needs to be configured</span></span><br><span class="line"><span class="comment">             * for the upstream communication.  This being the case,</span></span><br><span class="line"><span class="comment">             * walk from the top down and set the MPS of the child</span></span><br><span class="line"><span class="comment">             * to that of the parent bus.</span></span><br><span class="line"><span class="comment">             *</span></span><br><span class="line"><span class="comment">             * Configure the device MPS with the smaller of the</span></span><br><span class="line"><span class="comment">             * device MPSS or the bridge MPS (which is assumed to be</span></span><br><span class="line"><span class="comment">             * properly configured at this point to the largest</span></span><br><span class="line"><span class="comment">             * allowable MPS based on its parent bus).</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            mps = min(mps, pcie_get_mps(dev-&gt;bus-&gt;self));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    rc = pcie_set_mps(dev, mps);</span><br><span class="line">    <span class="keyword">if</span> (rc)</span><br><span class="line">        pci_err(dev, <span class="string">"Failed attempting to set the MPS\n"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>So linux follows the same idea and take the minimum of upstream device capability and downstream pci device.</p><p>The only exception is for root port which is supposed to be the top of PCI hierarchy so we can simply set by its max supported.</p><p><code>pcie_set_mps</code> does real setting of the config register and it can be seen that it is taking the min.</p><p>Now we have finished talking about <strong>max payload size</strong>, let’s turn our attention to <strong>max read request size</strong>.</p><p>It does not apply to memory write request but it applies to memory read request by that you cannot request more than that size in a single memory request.</p><p>We can imagine a slightly different use case where some application prepares a block of data to be processed by the end point device and then we notifying the device of the memory address of size and ask the device to take over.</p><p>The device will have to initiate a series of memory read request to fetch the data and process in place on the card and put the result int some preset location.</p><p>So even though packet payload can go at max to 4096 bytes the device will have to work in trickle like way if we program its max read request to be a very small value.</p><p>Here is the explanation from PCIE base spec on max read request:</p><p><img src="/images/2023/10/024.png" alt></p><p><img src="/images/2023/10/025.png" alt></p><p>So again let’s say how linux programs <strong>max read request size</strong>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">pcie_write_mrrs</span><span class="params">(struct pci_dev *dev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rc, mrrs;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * In the "safe" case, do not configure the MRRS.  There appear to be</span></span><br><span class="line"><span class="comment">     * issues with setting MRRS to 0 on a number of devices.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (pcie_bus_config != PCIE_BUS_PERFORMANCE)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * For max performance, the MRRS must be set to the largest supported</span></span><br><span class="line"><span class="comment">     * value.  However, it cannot be configured larger than the MPS the</span></span><br><span class="line"><span class="comment">     * device or the bus can support.  This should already be properly</span></span><br><span class="line"><span class="comment">     * configured by a prior call to pcie_write_mps().</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    mrrs = pcie_get_mps(dev);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * MRRS is a R/W register.  Invalid values can be written, but a</span></span><br><span class="line"><span class="comment">     * subsequent read will verify if the value is acceptable or not.</span></span><br><span class="line"><span class="comment">     * If the MRRS value provided is not acceptable (e.g., too large),</span></span><br><span class="line"><span class="comment">     * shrink the value until it is acceptable to the HW.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">while</span> (mrrs != pcie_get_readrq(dev) &amp;&amp; mrrs &gt;= <span class="number">128</span>) &#123;</span><br><span class="line">        rc = pcie_set_readrq(dev, mrrs);</span><br><span class="line">        <span class="keyword">if</span> (!rc)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">        pci_warn(dev, <span class="string">"Failed attempting to set the MRRS\n"</span>);</span><br><span class="line">        mrrs /= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (mrrs &lt; <span class="number">128</span>)</span><br><span class="line">        pci_err(dev, <span class="string">"MRRS was unable to be configured with a safe value.  If problems are experienced, try running with pci=pcie_bus_safe\n"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>pcie_set_readrq</code> does the real setting and surprisingly it uses <strong>max payload size</strong> as the ceiling even though it has not relationship with that.</p><p>We can well send a large read request but when data is returned from root complex it will be split into many small packets each with payload size less or equal to max payload size.</p><p>So above code is mainly executed in PCI bus enumeration phase.</p><p>And if we grep with this function name <code>pcie_set_readrq</code> we can see other device drivers provide overrides probably to increase the read request efficiency.</p><p>So how big an impact the two settings has on your specific device?</p><p>It’s hard to tell though you can easily find on the internet discussions talking about it.</p><p>Here is a good one <a href="http://www.xilinx.com/support/documentation/white_papers/wp350.pdf" target="_blank" rel="noopener">Understanding Performance of PCI Express Systems</a>.</p><p>And here is another good one <a href="https://billauer.co.il/blog/2011/05/pcie-pci-express-linux-max-payload-size-configuration-capabilities-tlp-lspci/" target="_blank" rel="noopener">PCI Express Max Payload size and its impact on Bandwidth</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自:&lt;a href=&quot;https://codywu2010.wordpress.com/2015/11/26/pci-express-max-read-request-max-payload-size-and-why-you-care/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PCI Express Max Read Request, Max Payload Size and why you care&lt;/a&gt;
    
    </summary>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/categories/PCI-PCIe/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about virtio-net failover</title>
    <link href="http://liujunming.github.io/2023/10/05/Notes-about-virtio-net-failover/"/>
    <id>http://liujunming.github.io/2023/10/05/Notes-about-virtio-net-failover/</id>
    <published>2023-10-05T07:03:24.000Z</published>
    <updated>2023-10-07T13:29:26.784Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要是mark下<a href="https://www.redhat.com/en/blog/virtio-net-failover-introduction" target="_blank" rel="noopener">Virtio-net failover: An introduction</a>相关notes。<a id="more"></a></p><p>Virtio-net failover is a virtualization technology that allows a virtual machine (VM) to switch from a Virtual Function I/O (VFIO) device to a virtio-net device when the VM needs to be migrated from a host to another.</p><p>On one hand, the Single Root I/O Virtualization (SR-IOV) technology allows a device like a networking card to be split into several devices (the Virtual Functions) and with the help of the VFIO technology, the kernel of the VM can directly drive these devices. This is interesting in terms of performance, because it can reach the same level as a bare metal system. In this case, the cost of the performance is that a VFIO device cannot be migrated.</p><p>On the other hand, virtio-net is a paravirtualized networking device that has good performance and can be migrated. The trade off is that performance is not as good as with VFIO devices.</p><p>Virtio-net failover tries to bring the best of both worlds: performance of a VFIO device with the migration capability of a virtio-net device.</p><h3 id="Principles"><a href="#Principles" class="headerlink" title="Principles"></a>Principles</h3><p>Virtio-net failover relies on a several blocks of technology to migrate a VM using a VFIO device:</p><ul><li>Live migration, to move the VM from one host to another</li><li>Virtio-net, to keep network connection while the migration is in progress</li><li>VFIO, to use a host hardware device</li><li>Failover, to switch from a networking device to another in a transparent way</li></ul><h3 id="Failover"><a href="#Failover" class="headerlink" title="Failover"></a>Failover</h3><p>Failover is a term that comes from the high availability (HA) domain in an attempt to provide reliability, availability and serviceability (RAS) to a system.</p><p>The principle of failover is to bind two devices together, so called the primary and the standby, in a redundant way. The system only uses the primary device, but if the primary device becomes unavailable, unusable or disconnected, the failover manager can detect the problem and disable the primary device to switch to the standby device. </p><p>The standby is used to maintain service availability. While the standby is in use, an operator can remove the dysfunctional device and replace it with a healthy one. Once the problem is corrected, the new device can be used as the new standby device while the old standby device becomes the new primary device. Alternately, the newly replaced device could be restored as the primary device and the other switched back to standby.</p><h3 id="Virtio-net-failover-operation"><a href="#Virtio-net-failover-operation" class="headerlink" title="Virtio-net failover operation"></a>Virtio-net failover operation</h3><p>Virtio-net failover plays with the failover principle to bind two devices together, but in this case, the VFIO device is chosen with caution to be the primary device and used during the regular state of operation of the system. When a migration occurs, the hypervisor triggers a primary device fault (by unplugging it), that will force the failover manager (in our case the guest kernel failover_net driver) to disable the primary device and use the standby device, the virtio-net device, that is able to survive to a VM live migration. </p><p>The hypervisor also takes the role of the operator by restoring the disabled device on the migration destination side by hotplugging a new VFIO device. In this case, failover_net driver is configured to restore the VFIO device as the primary and to keep the virtio-net as the standby as the devices are not identical.</p><p><img src="/images/2023/10/016.png" alt></p><p>To implement virtio-net failover, we need support at guest kernel level and at hypervisor level:</p><ul><li>The hypervisor detects when a migration is started and unplugs the VFIO device as it cannot be migrated, at the same time it will block the migration while the VFIO card is being unplugged.</li><li>Guest kernel needs the ability to switch transparently between  the VFIO device and the virtio-net device.</li><li>On normal operation, VFIO is used for its performance, but when the hypervisor asks to unplug the card, the kernel unplugs it and switches the networking traffic from the VFIO device to the virtio-net device.</li><li>While the migration is processed, the VM is not stopped and all the networking traffic that usually crosses the VFIO device is redirected to the virtio-net device. There is no service interruption,</li><li>At the end of the migration, on the destination side, the hypervisor plugs in a VFIO device, and the traffic switches back from the virtio-net device to the VFIO device.</li></ul><p><img src="/images/2023/10/017.png" alt></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Virtio-net failover allows a VM hypervisor to migrate a VM with a VFIO device without interrupting the network connection. To reach this goal we need collaboration between the hypervisor and the guest kernel — the hypervisor unplugs the card and the guest kernel switches the network connection to the virtio-net device, and then they restore the original state on the destination host.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要是mark下&lt;a href=&quot;https://www.redhat.com/en/blog/virtio-net-failover-introduction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Virtio-net failover: An introduction&lt;/a&gt;相关notes。
    
    </summary>
    
      <category term="live migration" scheme="http://liujunming.github.io/categories/live-migration/"/>
    
    
      <category term="live migration" scheme="http://liujunming.github.io/tags/live-migration/"/>
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
      <category term="VFIO" scheme="http://liujunming.github.io/tags/VFIO/"/>
    
  </entry>
  
  <entry>
    <title>基于E810网卡的VF热迁移</title>
    <link href="http://liujunming.github.io/2023/10/05/%E5%9F%BA%E4%BA%8EE810%E7%BD%91%E5%8D%A1%E7%9A%84VF%E7%83%AD%E8%BF%81%E7%A7%BB/"/>
    <id>http://liujunming.github.io/2023/10/05/基于E810网卡的VF热迁移/</id>
    <published>2023-10-05T06:34:15.000Z</published>
    <updated>2023-10-05T06:51:02.097Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自: <a href="https://mp.weixin.qq.com/s/GRxfeN7Vlr_NM2_kRw_5uQ" target="_blank" rel="noopener">基于E810网卡的VF热迁移–依托第四代Xeon可扩展处理器的加速案例</a><a id="more"></a></p><p>Intel E810网卡对VF透传设备的热迁移支持，使高性能数据面和灵活的运维得以兼顾，并且热迁移依托第四代志强可扩展处理器可以得到显著加速。</p><p><img src="/images/2023/10/001.png" alt></p><p><img src="/images/2023/10/002.png" alt></p><p><img src="/images/2023/10/003.png" alt></p><p><img src="/images/2023/10/004.png" alt></p><p><img src="/images/2023/10/005.png" alt></p><p><img src="/images/2023/10/006.png" alt></p><p><img src="/images/2023/10/007.png" alt></p><p><img src="/images/2023/10/008.png" alt></p><p>从slides里可以看出，对于Device State，改动的是e810 driver中增加的live migration支持(e810网卡协议本身支持live migration)，然后VFIO framework去调用e810 driver提供的接口，即可获取到Device State。</p><p><img src="/images/2023/10/009.png" alt></p><p><img src="/images/2023/10/010.png" alt></p><p><img src="/images/2023/10/011.png" alt></p><p><img src="/images/2023/10/012.png" alt></p><p><img src="/images/2023/10/013.png" alt></p><p><img src="/images/2023/10/014.png" alt></p><p><img src="/images/2023/10/015.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自: &lt;a href=&quot;https://mp.weixin.qq.com/s/GRxfeN7Vlr_NM2_kRw_5uQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;基于E810网卡的VF热迁移–依托第四代Xeon可扩展处理器的加速案例&lt;/a&gt;
    
    </summary>
    
      <category term="live migration" scheme="http://liujunming.github.io/categories/live-migration/"/>
    
    
      <category term="live migration" scheme="http://liujunming.github.io/tags/live-migration/"/>
    
      <category term="VFIO" scheme="http://liujunming.github.io/tags/VFIO/"/>
    
  </entry>
  
  <entry>
    <title>AMD虚拟化支持TLBi</title>
    <link href="http://liujunming.github.io/2023/09/24/AMD%E8%99%9A%E6%8B%9F%E5%8C%96%E6%94%AF%E6%8C%81TLBi/"/>
    <id>http://liujunming.github.io/2023/09/24/AMD虚拟化支持TLBi/</id>
    <published>2023-09-24T05:40:24.000Z</published>
    <updated>2023-09-24T06:48:01.927Z</updated>
    
    <content type="html"><![CDATA[<p>本文转自<a href="https://github.com/ChinaLinuxKernel/CLK/blob/master/CLK2021/3-1%20AMD%E6%9E%B6%E6%9E%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5.pdf" target="_blank" rel="noopener">CLK2021 AMD架构虚拟机性能探索与实践</a>。<a id="more"></a></p><p><img src="/images/2023/09/001.jpg" alt></p><p><img src="/images/2023/09/002.jpg" alt></p><p><img src="/images/2023/09/003.jpg" alt></p><p><img src="/images/2023/09/004.jpg" alt></p><p><img src="/images/2023/09/005.jpg" alt></p><p><img src="/images/2023/09/006.jpg" alt></p><p><img src="/images/2023/09/007.jpg" alt></p><p><img src="/images/2023/09/008.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转自&lt;a href=&quot;https://github.com/ChinaLinuxKernel/CLK/blob/master/CLK2021/3-1%20AMD%E6%9E%B6%E6%9E%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CLK2021 AMD架构虚拟机性能探索与实践&lt;/a&gt;。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="AMD" scheme="http://liujunming.github.io/tags/AMD/"/>
    
  </entry>
  
  <entry>
    <title>Intel FRED feature</title>
    <link href="http://liujunming.github.io/2023/09/10/Intel-FRED-feature/"/>
    <id>http://liujunming.github.io/2023/09/10/Intel-FRED-feature/</id>
    <published>2023-09-10T08:40:11.000Z</published>
    <updated>2023-09-10T09:13:22.119Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Intel的FRED(Flexible Return and Event Delivery) feature。<a id="more"></a></p><p>FRED has the capability of helping system performance and response time.</p><p>Intel engineers summed up FRED as:</p><blockquote><p>The Intel flexible return and event delivery (FRED) architecture defines simple new transitions that change privilege level (ring transitions).  The FRED architecture was designed with the following goals:<br>1) Improve overall performance and response time by replacing event delivery through the interrupt descriptor table (IDT event delivery) and event return by<br>the IRET instruction with lower latency transitions.<br>2) Improve software robustness by ensuring that event delivery establishes the full supervisor context and that event return establishes the full user context.</p></blockquote><blockquote><p>The new transitions defined by the FRED architecture are FRED event delivery and, for returning from events, two FRED return instructions. FRED event delivery can effect a transition from ring 3 to ring 0, but it is used also to deliver events incident to ring 0(ring0 -&gt; ring0之间也可以用FRED). One FRED instruction (ERETU) effects a return from ring 0 to ring 3, while the other (ERETS) returns while remaining in ring 0.</p></blockquote><blockquote><p>In addition to these transitions, the FRED architecture defines a new instruction (LKGS) for managing the state of the GS segment register. The LKGS instruction can be used by 64-bit operating systems that do not use the new FRED transitions.</p></blockquote><p>Simply put, FRED is basically about lower-latency transitions between CPU privilege levels.</p><p>点到为止，按需再细看吧。</p><hr><p>参考资料:</p><ol><li><a href="https://www.phoronix.com/news/Intel-FRED-Linux-Patches" target="_blank" rel="noopener">Intel Sends Out Initial Linux Kernel Patches For FRED</a></li><li><a href="https://cdrdv2.intel.com/v1/dl/getContent/678938" target="_blank" rel="noopener">FRED spec</a></li><li><a href="https://lore.kernel.org/lkml/20221220063658.19271-1-xin3.li@intel.com/" target="_blank" rel="noopener">RFC patch</a></li><li><a href="https://www.eejournal.com/article/we-interrupt-this-program/" target="_blank" rel="noopener">Intel and AMD Contemplate Different Replacements for x86 Interrupt Handling</a></li><li><a href="https://www.zdnet.com/article/linus-torvalds-on-how-amd-and-intel-are-changing-how-processor-interrupts-are-handled/" target="_blank" rel="noopener">Linus Torvalds on how AMD and Intel are changing how processor interrupts are handled</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Intel的FRED(Flexible Return and Event Delivery) feature。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
  <entry>
    <title>Understand Weak Symbols by Examples</title>
    <link href="http://liujunming.github.io/2023/09/03/Understand-Weak-Symbols-by-Examples/"/>
    <id>http://liujunming.github.io/2023/09/03/Understand-Weak-Symbols-by-Examples/</id>
    <published>2023-09-03T09:12:53.000Z</published>
    <updated>2023-09-03T09:21:03.797Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自<a href="http://winfred-lu.blogspot.com/2009/11/understand-weak-symbols-by-examples.html" target="_blank" rel="noopener">Understand Weak Symbols by Examples</a>。</p><p>Wikipedia defines the weak symbols: </p><blockquote><p>In computing, a weak symbol is a symbol definition in an object file or dynamic library that may be overridden by other symbol definitions, its value will be zero if no definition found by loader.</p></blockquote><p>In other words, we can define a symbol that doesn’t need to be resolved at link time. It is a very well-known feature and used a lot in Linux Kernel, Glibc, and so on.</p><a id="more"></a><p>Take a look at the example, we are not able to compile it due to the ‘undefined reference’ error.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cat err.c</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        f();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ gcc err.c</span><br><span class="line">/tmp/ccYx7WNg.o: In function `main':</span><br><span class="line">err.c:(.text+<span class="number">0x12</span>): undefined reference to `f'</span><br><span class="line">collect2: ld returned <span class="number">1</span> <span class="built_in">exit</span> status</span><br></pre></td></tr></table></figure></p><p>Try to declare ‘f’ as an weak symbol, and we can compile it without error.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat weak.c</span><br><span class="line"><span class="keyword">void</span> __attribute__((weak)) f();</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (f)</span><br><span class="line">            f();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">$ gcc weak.c</span><br></pre></td></tr></table></figure></p><p>Note that the function ‘f’ is called inside an if statement. If not calling ‘f’ this way, we will get a ‘Segmentation fault’ error. In the weak.c example, ‘f’ is actually not invoked. It is because ‘f’ is an un-defined weak symbol and therefore will be zero when the loader cannot find it.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ ./a.out</span><br><span class="line">$ nm a.out</span><br><span class="line">...</span><br><span class="line">w f</span><br><span class="line"><span class="number">08048324</span> T main</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>Let’s define the function ‘f’ in another file, and link the objects together. This time, ‘f’ will be correctly called. (Note that puts is the optimization of printf by gcc)</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ cat f.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"hello from f\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ gcc -c weak.c f.c</span><br><span class="line">$ gcc -o weak weak.o f.o</span><br><span class="line">$ ./weak</span><br><span class="line">hello from f</span><br><span class="line"></span><br><span class="line">$ nm weak.o</span><br><span class="line">w f</span><br><span class="line"><span class="number">00000000</span> T main</span><br><span class="line">$ nm f.o</span><br><span class="line"><span class="number">00000000</span> T f</span><br><span class="line">U <span class="built_in">puts</span></span><br><span class="line">$ nm weak</span><br><span class="line">...</span><br><span class="line"><span class="number">08048384</span> T f</span><br><span class="line"><span class="number">08048354</span> T main</span><br><span class="line">U <span class="built_in">puts</span>@@GLIBC_2<span class="number">.0</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>We may even override the original weak symbol (type ‘W’) with a strong symbol (type ‘T’).<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">$ cat orig.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">void</span> __attribute__((weak)) f()</span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"original f..\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        f();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">$ gcc orig.c</span><br><span class="line">$ ./a.out</span><br><span class="line">original f..</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ cat ovrd.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"overridden f!\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line">$ gcc -c orig.c ovrd.c</span><br><span class="line">$ gcc -o ovrd orig.o ovrd.o</span><br><span class="line">$ ./ovrd</span><br><span class="line">overridden f!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ nm orig.o</span><br><span class="line"><span class="number">00000000</span> W f</span><br><span class="line"><span class="number">00000014</span> T main</span><br><span class="line">U <span class="built_in">puts</span></span><br><span class="line">$ nm ovrd.o</span><br><span class="line"><span class="number">00000000</span> T f</span><br><span class="line">U <span class="built_in">puts</span></span><br><span class="line">$ nm ovrd</span><br><span class="line">...</span><br><span class="line"><span class="number">0804838</span>c T f</span><br><span class="line"><span class="number">08048368</span> T main</span><br><span class="line">U <span class="built_in">puts</span>@@GLIBC_2<span class="number">.0</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>And of course, we can also override a weak object (type ‘V’) with a strong object (type ‘D’).<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">$ cat orig-obj.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">int</span> __attribute__((weak)) x = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> __attribute__((weak)) y = <span class="number">1</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"x = %d, y = %d\n"</span>, x, y);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">$ gcc orig-obj.c</span><br><span class="line">$ ./a.out</span><br><span class="line">x = <span class="number">1</span>, y = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ cat ovrd-obj.c</span><br><span class="line"><span class="keyword">int</span> x = <span class="number">2</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">&#125;</span><br><span class="line">$ gcc -c orig-obj.c ovrd-obj.c</span><br><span class="line">$ gcc -o ovrd-obj orig-obj.o ovrd-obj.o</span><br><span class="line">$ ./ovrd-obj</span><br><span class="line">x = <span class="number">2</span>, y = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ nm orig-obj.o</span><br><span class="line"><span class="number">00000000</span> T main</span><br><span class="line">U <span class="built_in">printf</span></span><br><span class="line"><span class="number">00000000</span> V x</span><br><span class="line"><span class="number">00000004</span> V y</span><br><span class="line">$ nm ovrd-obj.o</span><br><span class="line"><span class="number">00000000</span> T f</span><br><span class="line"><span class="number">00000000</span> D x</span><br><span class="line">$ nm ovrd-obj</span><br><span class="line">...</span><br><span class="line"><span class="number">08048394</span> T f</span><br><span class="line"><span class="number">08048354</span> T main</span><br><span class="line">U <span class="built_in">printf</span>@@GLIBC_2<span class="number">.0</span></span><br><span class="line"><span class="number">080495</span>c8 D x</span><br><span class="line"><span class="number">080495</span>c4 V y</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>What if there are multiple symbols? Linker’s symbol rules tell us that:</p><ol><li>Multiple strong symbols are not allowed</li><li>Given a strong symbol and multiple weak symbols –&gt; choose the strong symbol</li><li>Given multiple weak symbols –&gt; choose any of those weak symbols</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">$ cat mul.c</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        f();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">$ cat s1.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"1st strong f from %s\n"</span>, __FILE__);</span><br><span class="line">&#125;</span><br><span class="line">$ cat s2.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"2nd strong f from %s\n"</span>, __FILE__);</span><br><span class="line">&#125;</span><br><span class="line">$ cat w1.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">void</span> __attribute__((weak)) f(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"1st weak f from %s\n"</span>, __FILE__);</span><br><span class="line">&#125;</span><br><span class="line">$ cat w2.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">void</span> __attribute__((weak)) f(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"2nd weak f from %s\n"</span>, __FILE__);</span><br><span class="line">&#125;</span><br><span class="line">$ gcc -c mul.c s1.c s2.c w1.c w2.c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ gcc -o test1 mul.o s1.o s2.o</span><br><span class="line">s2.o: In function `f':</span><br><span class="line">s2.c:(.text+<span class="number">0x0</span>): multiple definition of `f'</span><br><span class="line">s1.o:s1.c:(.text+<span class="number">0x0</span>): first defined here</span><br><span class="line">collect2: ld returned <span class="number">1</span> <span class="built_in">exit</span> status</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ gcc -o test2 mul.o s1.o w1.o w2.o</span><br><span class="line">$ ./test2</span><br><span class="line"><span class="number">1</span>st strong f from s1.c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ gcc -o test3<span class="number">-1</span> mul.o w1.o w2.o</span><br><span class="line">$ ./test3<span class="number">-1</span></span><br><span class="line"><span class="number">1</span>st weak f from w1.c</span><br><span class="line">$ gcc -o test3<span class="number">-2</span> mul.o w2.o w1.o</span><br><span class="line">$ ./test3<span class="number">-2</span></span><br><span class="line"><span class="number">2</span>nd weak f from w2.c</span><br></pre></td></tr></table></figure><p>Hope these examples help!</p><p>References:</p><ol><li><a href="http://en.wikipedia.org/wiki/Weak_symbol" target="_blank" rel="noopener">Wikipedia, “Weak Symbol”</a></li><li><a href="http://gcc.gnu.org/onlinedocs/gcc-3.2/gcc/Function-Attributes.html" target="_blank" rel="noopener">gcc manual, “Declaring Attributes of Functions”</a></li><li><a href="http://sourceware.org/binutils/docs/binutils/nm.html" target="_blank" rel="noopener">binutil Document, “nm”</a></li><li><a href="http://www.slideshare.net/satpalparmar/linkers-and-loaders-presentation" target="_blank" rel="noopener">Sandeep Grover, “Linkers &amp; Loaders - A Programmers Perspective”</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自&lt;a href=&quot;http://winfred-lu.blogspot.com/2009/11/understand-weak-symbols-by-examples.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Understand Weak Symbols by Examples&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Wikipedia defines the weak symbols: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In computing, a weak symbol is a symbol definition in an object file or dynamic library that may be overridden by other symbol definitions, its value will be zero if no definition found by loader.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, we can define a symbol that doesn’t need to be resolved at link time. It is a very well-known feature and used a lot in Linux Kernel, Glibc, and so on.&lt;/p&gt;
    
    </summary>
    
      <category term="C语言" scheme="http://liujunming.github.io/categories/C%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="C语言" scheme="http://liujunming.github.io/tags/C%E8%AF%AD%E8%A8%80/"/>
    
  </entry>
  
  <entry>
    <title>每周分享第36期</title>
    <link href="http://liujunming.github.io/2023/09/03/%E6%AF%8F%E5%91%A8%E5%88%86%E4%BA%AB%E7%AC%AC36%E6%9C%9F/"/>
    <id>http://liujunming.github.io/2023/09/03/每周分享第36期/</id>
    <published>2023-09-03T04:39:26.000Z</published>
    <updated>2023-09-03T05:13:08.469Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Live-migration-of-virtual-machines-over-CXL"><a href="#Live-migration-of-virtual-machines-over-CXL" class="headerlink" title="Live migration of virtual machines over CXL"></a>Live migration of virtual machines over CXL</h3><p><a href="https://lwn.net/Articles/931528/" target="_blank" rel="noopener">https://lwn.net/Articles/931528/</a><br><a id="more"></a></p><h3 id="spot-instance"><a href="#spot-instance" class="headerlink" title="spot instance"></a>spot instance</h3><p>竞价实例（Spot Instance）：节省80-90％的云计算成本</p><p>竞价实例是云中的闲置计算能力，它是云供应商出售其计算能力的一种方式之一—另外两种是按需实例和预留实例（包年包月实例）。就服务器本身而言，这三者之间没有区别，不同之处在于商业模式。按需实例是根据使用时长来收费的，用户只需要在使用的时候才付费。预留实例允许用户以“月”或者“年”为单位来购买。竞价实例允许用户通过使用使用云中当前闲置的服务器资源来节省高达90％的云计算成本，云供应商希望通过以极低的价格出售这些位于云中闲置的服务器，将这些空闲资源利用起来以带来收益。</p><p>关于竞价实例（Spot Instance），您应该知道什么：</p><p>1.竞价实例很便宜</p><p>和按需实例对比，竞价实例通常仅是其价格的10-20％。和预留实例对比，竞价实例通常仅是其价格的30-60％。竞价实例提供了大量节省云资源费用的可能性。</p><p>2.竞价实例可能随时会被终止</p><p>使用竞价实例的风险是，云供应商可以在几乎没有警告（通常会提前几分钟通知）的情况下终止这些实例。如果您的应用需要保证可用性，一致性或数据一致中的任何一个，那么当您使用竞价实例时，您需要专门的管理配置工具去保证这些。云供应商不会为竞价实例提供SLA，您的应用需要去处理这些随时可能发生的中断。</p><p><a href="https://cloud.tencent.com/developer/article/1544459" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1544459</a></p><h3 id="利用-chrt-命令查询与修改进程调度器"><a href="#利用-chrt-命令查询与修改进程调度器" class="headerlink" title="利用 chrt 命令查询与修改进程调度器"></a>利用 chrt 命令查询与修改进程调度器</h3><p>chrt 命令是 linux 提供的一个底层应用指令，它可以在运行时设置进程的某些属性，还可以更改调度策略和调度优先级。</p><p><a href="https://cloud.tencent.com/developer/article/2118807" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/2118807</a></p><h3 id="万字干货分享-阿里云-CIPU-技术解析"><a href="#万字干货分享-阿里云-CIPU-技术解析" class="headerlink" title="万字干货分享 | 阿里云 CIPU 技术解析"></a>万字干货分享 | 阿里云 CIPU 技术解析</h3><p><a href="https://mp.weixin.qq.com/s/wtLX0q9BnQDghmBvCL5uGQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/wtLX0q9BnQDghmBvCL5uGQ</a></p><h3 id="揭秘！CIPU-最新秘密武器——弹性-RDMA-的技术解析与实践"><a href="#揭秘！CIPU-最新秘密武器——弹性-RDMA-的技术解析与实践" class="headerlink" title="揭秘！CIPU 最新秘密武器——弹性 RDMA 的技术解析与实践"></a>揭秘！CIPU 最新秘密武器——弹性 RDMA 的技术解析与实践</h3><p><a href="https://mp.weixin.qq.com/s/yWVOA60Kp6MROOFxK4kSdw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/yWVOA60Kp6MROOFxK4kSdw</a></p><h3 id="Future-Generation-Xeon"><a href="#Future-Generation-Xeon" class="headerlink" title="Future-Generation Xeon"></a>Future-Generation Xeon</h3><p><a href="https://mp.weixin.qq.com/s/ZdcR3Q2fiX2UjxrW4ez6_g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ZdcR3Q2fiX2UjxrW4ez6_g</a></p><h3 id="仅-8670-行代码，Linux-内核第一版-v0-01-开源代码解读"><a href="#仅-8670-行代码，Linux-内核第一版-v0-01-开源代码解读" class="headerlink" title="仅 8670 行代码，Linux 内核第一版 (v0.01) 开源代码解读"></a>仅 8670 行代码，Linux 内核第一版 (v0.01) 开源代码解读</h3><p><a href="https://mp.weixin.qq.com/s/TX_DTkiLsUOADoVyX8x_TQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/TX_DTkiLsUOADoVyX8x_TQ</a><br><a href="https://seiya.me/blog/reading-linux-v0.01" target="_blank" rel="noopener">https://seiya.me/blog/reading-linux-v0.01</a></p><h3 id="sycl"><a href="#sycl" class="headerlink" title="sycl"></a>sycl</h3><p><a href="https://oneapi-src.github.io/SYCLomatic/dev_guide/compare-prog-models.html" target="_blank" rel="noopener">CUDA and SYCL Programming Model Comparison</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Live-migration-of-virtual-machines-over-CXL&quot;&gt;&lt;a href=&quot;#Live-migration-of-virtual-machines-over-CXL&quot; class=&quot;headerlink&quot; title=&quot;Live migration of virtual machines over CXL&quot;&gt;&lt;/a&gt;Live migration of virtual machines over CXL&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://lwn.net/Articles/931528/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://lwn.net/Articles/931528/&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="经验" scheme="http://liujunming.github.io/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="经验" scheme="http://liujunming.github.io/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Paravirtualized ticket spinlocks</title>
    <link href="http://liujunming.github.io/2023/08/27/Notes-about-Paravirtualized-ticket-spinlocks/"/>
    <id>http://liujunming.github.io/2023/08/27/Notes-about-Paravirtualized-ticket-spinlocks/</id>
    <published>2023-08-27T06:01:48.000Z</published>
    <updated>2023-08-27T09:20:28.580Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下kvm中的Paravirtualized ticket spinlocks相关notes。<br>参考内核版本为v5.0，主要内容转载自<a href="http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/10/01/kvm-performance-2" target="_blank" rel="noopener">kvm performance optimization technologies, part two</a>。<a id="more"></a></p><p>在kvm中，也会将Paravirtualized ticket spinlocks称为PV unhalt。</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Now, suppose that vCPU A grabs a spinlock, and before it finishes, is preempted by the scheduler. And then suppose vCPU B tries to grab the spinlock. Now B, instead of spinning for the short period of time that A needed the spinlock for, will be spinning until vCPU is scheduled again — which may be anywhere from several milliseconds to hundreds of milliseconds, depending on how busy the system is. B is now using the cpu but accomplishing nothing. It’s burning up its VM’s share of CPU time, and keeping other VMs with useful work to do from running. Worse yet, it may even be that the reason A is not running is that the hypervisor’s scheduler is trying to give priority to B — so B is actively keeping A from finishing the work that it needed to do with the spinlock.</p><p>The situation gets even worse with a more advanced form of spinlock called a ticketlock. Ticketlocks have a lot of advantages for large systems, including reduced cacheline bouncing and more predictable wait time. (See this <a href="https://lwn.net/Articles/267968/" target="_blank" rel="noopener">LWN article</a> for a complete description.) The key attribute for this discussion is that ticketlocks essentially make a first-come first-served queue: if A has the lock, then B tries to grab it, and then C, B is guaranteed to get the lock before C. So now, if C is spinning waiting for the lock, it must wait for both A and B to finish before it can get the lock.</p><p>The result is that on a moderately loaded system, the vast majority of the cpu cycles are actually spent waiting for ticketlocks rather than doing any useful work. This is called a “ticketlock storm”. </p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>The PV unhalt feature is used to set the <code>pv_lock_ops</code> to rewrite the native spinlock’s function so it can be more optimizated.</p><p>Though the total implementation of pv spinlock is related with the spinlock implementation such as ticketlock and queued spinlock, the basic idea behind the pv spinlock is the same. That is <strong>instead of spining while the vCPU can’t get the spinlock, it will execute halt instruction and let the other vCPU got scheduled. When the vCPU can get the spinlock, allows a vCPU to kick the target vCPU out of halt state.</strong></p><p>When the time spent waiting for a lock reaches a given threshold, kvm is notified via a hypercall that a vCPU is currently blocked by a held lock. KVM then halts the waiting vCPU until the lock is detected to be available.</p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><h3 id="kvm-side"><a href="#kvm-side" class="headerlink" title="kvm side"></a>kvm side</h3><p>kvm should expose the <code>KVM_FEATURE_PV_UNHALT</code> to the guest.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> __do_cpuid_ent(struct kvm_cpuid_entry2 *entry, u32 function,</span><br><span class="line">                 u32 index, <span class="keyword">int</span> *nent, <span class="keyword">int</span> maxnent)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> KVM_CPUID_FEATURES:</span><br><span class="line">        entry-&gt;eax = (<span class="number">1</span> &lt;&lt; KVM_FEATURE_CLOCKSOURCE) |</span><br><span class="line">                 ...</span><br><span class="line">                 (<span class="number">1</span> &lt;&lt; KVM_FEATURE_PV_UNHALT) |</span><br><span class="line">                 ...</span><br></pre></td></tr></table></figure></p><h3 id="guest-side"><a href="#guest-side" class="headerlink" title="guest side"></a>guest side</h3><p>When the guest startup, <code>kvm_spinlock_init</code> is used to initialize the pv spinlock.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> __<span class="function">init <span class="title">kvm_spinlock_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!kvm_para_available())</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="comment">/* Does host kernel support KVM_FEATURE_PV_UNHALT? */</span></span><br><span class="line">    <span class="keyword">if</span> (!kvm_para_has_feature(KVM_FEATURE_PV_UNHALT))</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (kvm_para_has_hint(KVM_HINTS_REALTIME))</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Don't use the pvqspinlock code if there is only 1 vCPU. */</span></span><br><span class="line">    <span class="keyword">if</span> (num_possible_cpus() == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    __pv_init_lock_hash();</span><br><span class="line">    pv_ops.lock.queued_spin_lock_slowpath = __pv_queued_spin_lock_slowpath;</span><br><span class="line">    pv_ops.lock.queued_spin_unlock =</span><br><span class="line">        PV_CALLEE_SAVE(__pv_queued_spin_unlock);</span><br><span class="line">    pv_ops.lock.wait = kvm_wait;</span><br><span class="line">    pv_ops.lock.kick = kvm_kick_cpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (kvm_para_has_feature(KVM_FEATURE_STEAL_TIME)) &#123;</span><br><span class="line">        pv_ops.lock.vcpu_is_preempted =</span><br><span class="line">            PV_CALLEE_SAVE(__kvm_vcpu_is_preempted);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>最值得关注的函数是<code>kvm_wait</code>和<code>kvm_kick_cpu</code>，会在下面进行详细的介绍。</p><h2 id="halt-when-vCPU-is-blocked-by-a-held-lock"><a href="#halt-when-vCPU-is-blocked-by-a-held-lock" class="headerlink" title="halt when vCPU is blocked by a held lock"></a>halt when vCPU is blocked by a held lock</h2><h3 id="guest-side-1"><a href="#guest-side-1" class="headerlink" title="guest side"></a>guest side</h3><p>When the vCPU can’t get the spinlock, it will call wait callback.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> __<span class="function">always_inline <span class="keyword">void</span> <span class="title">pv_wait</span><span class="params">(u8 *ptr, u8 val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PVOP_VCALL2(lock.wait, ptr, val);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Then it will execute the halt instruction in <code>kvm_wait</code>.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_wait</span><span class="params">(u8 *ptr, u8 val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (in_nmi())</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    local_irq_save(flags);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (READ_ONCE(*ptr) != val)</span><br><span class="line">        <span class="keyword">goto</span> out;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * halt until it's our turn and kicked. Note that we do safe halt</span></span><br><span class="line"><span class="comment">     * for irq enabled case to avoid hang when lock info is overwritten</span></span><br><span class="line"><span class="comment">     * in irq spinlock slowpath and no spurious interrupt occur to save us.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (arch_irqs_disabled_flags(flags))</span><br><span class="line">        halt();</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        safe_halt();</span><br><span class="line"></span><br><span class="line">out:</span><br><span class="line">    local_irq_restore(flags);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="kvm-side-1"><a href="#kvm-side-1" class="headerlink" title="kvm side"></a>kvm side</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">handle_halt</span><br><span class="line">└── kvm_emulate_halt</span><br><span class="line">    └── kvm_vcpu_halt</span><br></pre></td></tr></table></figure><p>When the guest execute halt instruction, the <code>kvm_emulate_halt</code>-&gt;<code>kvm_vcpu_halt</code> will be called. This will set the <code>vcpu-&gt;arch.mp_state</code> to <code>KVM_MP_STATE_HALTED</code>. Then <code>vcpu_block</code> will be called to block this vCPU.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">vcpu_run</span><span class="params">(struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> r;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kvm</span> *<span class="title">kvm</span> = <span class="title">vcpu</span>-&gt;<span class="title">kvm</span>;</span></span><br><span class="line"></span><br><span class="line">    vcpu-&gt;srcu_idx = srcu_read_lock(&amp;kvm-&gt;srcu);</span><br><span class="line">    vcpu-&gt;arch.l1tf_flush_l1d = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">if</span> (kvm_vcpu_running(vcpu)) &#123;</span><br><span class="line">            r = vcpu_enter_guest(vcpu);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            r = vcpu_block(kvm, vcpu);</span><br><span class="line">        &#125;</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">vcpu_block</span><span class="params">(struct kvm *kvm, struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!kvm_arch_vcpu_runnable(vcpu) &amp;&amp;</span><br><span class="line">        (!kvm_x86_ops-&gt;pre_block || kvm_x86_ops-&gt;pre_block(vcpu) == <span class="number">0</span>)) &#123;</span><br><span class="line">        srcu_read_unlock(&amp;kvm-&gt;srcu, vcpu-&gt;srcu_idx);</span><br><span class="line">        kvm_vcpu_block(vcpu);</span><br><span class="line">        vcpu-&gt;srcu_idx = srcu_read_lock(&amp;kvm-&gt;srcu);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (kvm_x86_ops-&gt;post_block)</span><br><span class="line">            kvm_x86_ops-&gt;post_block(vcpu);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!kvm_check_request(KVM_REQ_UNHALT, vcpu))</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    kvm_apic_accept_events(vcpu);</span><br><span class="line">    <span class="keyword">switch</span>(vcpu-&gt;arch.mp_state) &#123;</span><br><span class="line">    <span class="keyword">case</span> KVM_MP_STATE_HALTED:</span><br><span class="line">        vcpu-&gt;arch.pv.pv_unhalted = <span class="literal">false</span>;</span><br><span class="line">        vcpu-&gt;arch.mp_state =</span><br><span class="line">            KVM_MP_STATE_RUNNABLE;</span><br><span class="line">        <span class="comment">/* fall through */</span></span><br><span class="line">    <span class="keyword">case</span> KVM_MP_STATE_RUNNABLE:</span><br><span class="line">        vcpu-&gt;arch.apf.halted = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> KVM_MP_STATE_INIT_RECEIVED:</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">return</span> -EINTR;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="kick-the-halted-vCPU-until-the-lock-is-detected-to-be-available"><a href="#kick-the-halted-vCPU-until-the-lock-is-detected-to-be-available" class="headerlink" title="kick the halted vCPU until the lock is detected to be available"></a>kick the halted vCPU until the lock is detected to be available</h2><h3 id="guest-side-2"><a href="#guest-side-2" class="headerlink" title="guest side"></a>guest side</h3><p>When the halted vCPU can get the spinlock, the <code>kick</code> callback will be called by <code>pv_kick</code> by a running vCPU. The <code>kvm_kick_cpu</code> will be called and this trigger a <code>KVM_HC_KICK_CPU</code> hypercall.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> __<span class="function">always_inline <span class="keyword">void</span> <span class="title">pv_kick</span><span class="params">(<span class="keyword">int</span> cpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PVOP_VCALL1(lock.kick, cpu);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Kick a cpu by its apicid. Used to wake up a halted vcpu */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_kick_cpu</span><span class="params">(<span class="keyword">int</span> cpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> apicid;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    apicid = per_cpu(x86_cpu_to_apicid, cpu);</span><br><span class="line">    kvm_hypercall2(KVM_HC_KICK_CPU, flags, apicid);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="kvm-side-2"><a href="#kvm-side-2" class="headerlink" title="kvm side"></a>kvm side</h3><p>When the guest trigger <code>KVM_HC_KICK_CPU</code> hypercall, <code>kvm_pv_kick_cpu_op</code> will be called.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kvm_emulate_hypercall</span><span class="params">(struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> KVM_HC_KICK_CPU:</span><br><span class="line">        kvm_pv_kick_cpu_op(vcpu-&gt;kvm, a0, a1);</span><br><span class="line">        ret = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>The <code>kvm_pv_kick_cpu_op</code> will send an interrupt to the lapic.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * kvm_pv_kick_cpu_op:  Kick a vcpu.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @apicid - apicid of vcpu to be kicked.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_pv_kick_cpu_op</span><span class="params">(struct kvm *kvm, <span class="keyword">unsigned</span> <span class="keyword">long</span> flags, <span class="keyword">int</span> apicid)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kvm_lapic_irq</span> <span class="title">lapic_irq</span>;</span></span><br><span class="line"></span><br><span class="line">    lapic_irq.shorthand = <span class="number">0</span>;</span><br><span class="line">    lapic_irq.dest_mode = <span class="number">0</span>;</span><br><span class="line">    lapic_irq.level = <span class="number">0</span>;</span><br><span class="line">    lapic_irq.dest_id = apicid;</span><br><span class="line">    lapic_irq.msi_redir_hint = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    lapic_irq.delivery_mode = APIC_DM_REMRD;</span><br><span class="line">    kvm_irq_delivery_to_apic(kvm, <span class="literal">NULL</span>, &amp;lapic_irq, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kvm_irq_delivery_to_apic</span><br><span class="line">└── kvm_apic_set_irq</span><br><span class="line">    └── __apic_accept_irq</span><br></pre></td></tr></table></figure><p>Then in <code>__apic_accept_irq</code> it will kick the blocked vCPU.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Add a pending IRQ into lapic.</span></span><br><span class="line"><span class="comment"> * Return 1 if successfully added and 0 if discarded.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> __apic_accept_irq(struct kvm_lapic *apic, <span class="keyword">int</span> delivery_mode,</span><br><span class="line">                 <span class="keyword">int</span> <span class="built_in">vector</span>, <span class="keyword">int</span> level, <span class="keyword">int</span> trig_mode,</span><br><span class="line">                 struct dest_map *dest_map)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> APIC_DM_REMRD:</span><br><span class="line">        result = <span class="number">1</span>;</span><br><span class="line">        vcpu-&gt;arch.pv.pv_unhalted = <span class="number">1</span>;</span><br><span class="line">        kvm_make_request(KVM_REQ_EVENT, vcpu);</span><br><span class="line">        kvm_vcpu_kick(vcpu);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>For the halted vCPU, then <code>kvm_vcpu_block</code> returns, it will set <code>vcpu-&gt;arch.mp_state</code> to <code>KVM_MP_STATE_RUNNABLE</code> and let the halted vCPU enter Non-root mode to get the spinlock.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">vcpu_block</span><span class="params">(struct kvm *kvm, struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!kvm_arch_vcpu_runnable(vcpu) &amp;&amp;</span><br><span class="line">        (!kvm_x86_ops-&gt;pre_block || kvm_x86_ops-&gt;pre_block(vcpu) == <span class="number">0</span>)) &#123;</span><br><span class="line">        srcu_read_unlock(&amp;kvm-&gt;srcu, vcpu-&gt;srcu_idx);</span><br><span class="line">        kvm_vcpu_block(vcpu);</span><br><span class="line">        vcpu-&gt;srcu_idx = srcu_read_lock(&amp;kvm-&gt;srcu);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (kvm_x86_ops-&gt;post_block)</span><br><span class="line">            kvm_x86_ops-&gt;post_block(vcpu);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 此时kvm_check_request(KVM_REQ_UNHALT, vcpu)为true</span></span><br><span class="line">        <span class="comment">// 因为__apic_accept_irq调用了kvm_make_request(KVM_REQ_EVENT, vcpu)</span></span><br><span class="line">        <span class="keyword">if</span> (!kvm_check_request(KVM_REQ_UNHALT, vcpu))</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    kvm_apic_accept_events(vcpu);</span><br><span class="line">    <span class="keyword">switch</span>(vcpu-&gt;arch.mp_state) &#123;</span><br><span class="line">    <span class="keyword">case</span> KVM_MP_STATE_HALTED:</span><br><span class="line">        vcpu-&gt;arch.pv.pv_unhalted = <span class="literal">false</span>;</span><br><span class="line">        vcpu-&gt;arch.mp_state =</span><br><span class="line">            KVM_MP_STATE_RUNNABLE;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><hr><p>参考资料:</p><ol><li><a href="http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/10/01/kvm-performance-2" target="_blank" rel="noopener">kvm performance optimization technologies, part two</a></li><li><a href="https://lore.kernel.org/kvm/20120323080503.14568.43092.sendpatchset@codeblue/" target="_blank" rel="noopener">kvm : Paravirt-spinlock support for KVM guests</a></li><li><a href="https://people.cs.pitt.edu/~ouyang/files/paper/vee13-pmtlock-paper.pdf" target="_blank" rel="noopener">Preemptable Ticket Spinlocks: Improving Consolidated Performance in the Cloud</a></li><li><a href="https://wiki.xenproject.org/wiki/Benchmarking_the_new_PV_ticketlock_implementation" target="_blank" rel="noopener">Benchmarking the new PV ticketlock implementation</a></li><li><a href="https://www.researchgate.net/publication/200014431_Lock-holder_preemption_on_Xen" target="_blank" rel="noopener">How to deal with lock-holder preemption</a></li><li>Towards scalable multiprocessor virtual machines. In Proceedings of the 3rd conference on Virtual Machine Research And Technology Symposium - Volume 3</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下kvm中的Paravirtualized ticket spinlocks相关notes。&lt;br&gt;参考内核版本为v5.0，主要内容转载自&lt;a href=&quot;http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/10/01/kvm-performance-2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kvm performance optimization technologies, part two&lt;/a&gt;。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
      <category term="Concurrency" scheme="http://liujunming.github.io/tags/Concurrency/"/>
    
  </entry>
  
  <entry>
    <title>Notes about PV sched yield</title>
    <link href="http://liujunming.github.io/2023/08/26/Notes-about-PV-sched-yield/"/>
    <id>http://liujunming.github.io/2023/08/26/Notes-about-PV-sched-yield/</id>
    <published>2023-08-26T10:08:30.000Z</published>
    <updated>2023-08-27T11:42:54.428Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下kvm中的PV sched yield相关notes，参考内核版本是v6.0。<a id="more"></a></p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Idea:<br>When sending a call-function IPI-many to vCPUs, yield(by hypercall) if any of the IPI target vCPU was preempted, yield to(让步于) the first preempted target vCPU which we found.</p><p>如果IPI的source vCPU不yield to the preempted target vCPU的话，source vCPU在Non-root mode下依然会busy waiting(参考<code>smp_call_function_many_cond</code>函数)，直到preempted target vCPU被调度到Non-root mode后才结束；还不如直接yiled source vCPU，yield to the preempted target vCPU。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">smp_call_function_many_cond</span><span class="params">(<span class="keyword">const</span> struct cpumask *mask,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">smp_call_func_t</span> func, <span class="keyword">void</span> *info,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">unsigned</span> <span class="keyword">int</span> scf_flags,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">smp_cond_func_t</span> cond_func)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (run_remote &amp;&amp; wait) &#123;</span><br><span class="line">        <span class="comment">// 按顺序等各个cpu修改csd的flag，不然就死等</span></span><br><span class="line">        for_each_cpu(cpu, cfd-&gt;cpumask) &#123;</span><br><span class="line">            <span class="keyword">call_single_data_t</span> *csd;</span><br><span class="line"></span><br><span class="line">            csd = &amp;per_cpu_ptr(cfd-&gt;pcpu, cpu)-&gt;csd;</span><br><span class="line">            csd_lock_wait(csd);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>下图阐述了IPI target vCPUs are good yield candidates的原因。<br><img src="/images/2023/08/014.jpg" alt><br>详情建议阅读<a href="https://lore.kernel.org/kvm/1563457031-21189-2-git-send-email-pbonzini@redhat.com/" target="_blank" rel="noopener">KVM: Boost vCPUs that are delivering interrupts</a>。</p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><h3 id="kvm-side"><a href="#kvm-side" class="headerlink" title="kvm side"></a>kvm side</h3><p>export this feature to the guest<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> __do_cpuid_func(struct kvm_cpuid_array *<span class="built_in">array</span>, u32 function)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> KVM_CPUID_FEATURES:</span><br><span class="line">        entry-&gt;eax = (<span class="number">1</span> &lt;&lt; KVM_FEATURE_CLOCKSOURCE) |</span><br><span class="line">                  ...</span><br><span class="line">                 (<span class="number">1</span> &lt;&lt; KVM_FEATURE_PV_SCHED_YIELD) |</span><br></pre></td></tr></table></figure></p><h3 id="guest-side"><a href="#guest-side" class="headerlink" title="guest side"></a>guest side</h3><p>When the guest startup it will replace the <code>smp_ops.send_call_func_ipi</code> with <code>kvm_smp_send_call_func_ipi</code> if the PV sched yield feature supported.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">init <span class="title">kvm_guest_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (pv_sched_yield_supported()) &#123;</span><br><span class="line">        smp_ops.send_call_func_ipi = kvm_smp_send_call_func_ipi;</span><br><span class="line">        pr_info(<span class="string">"setup PV sched yield\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">bool</span> <span class="title">pv_sched_yield_supported</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (kvm_para_has_feature(KVM_FEATURE_PV_SCHED_YIELD) &amp;&amp;</span><br><span class="line">        !kvm_para_has_hint(KVM_HINTS_REALTIME) &amp;&amp;</span><br><span class="line">        kvm_para_has_feature(KVM_FEATURE_STEAL_TIME) &amp;&amp;</span><br><span class="line">        !boot_cpu_has(X86_FEATURE_MWAIT) &amp;&amp;</span><br><span class="line">        (num_possible_cpus() != <span class="number">1</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="yield-to-the-preempted-target-vCPU"><a href="#yield-to-the-preempted-target-vCPU" class="headerlink" title="yield to the preempted target vCPU"></a>yield to the preempted target vCPU</h2><h3 id="guest-side-1"><a href="#guest-side-1" class="headerlink" title="guest side"></a>guest side</h3><p>When the guest send call func IPI, the current vcpu will call <code>native_send_call_func_ipi</code> to send IPI to the target vcpu. If the target vCPU is preempted, it will issue a hypercall <code>KVM_HC_SCHED_YIELD</code>. </p><p>We just select the first preempted target vCPU which we found since the state of target vCPUs can change underneath and to avoid race conditions.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_smp_send_call_func_ipi</span><span class="params">(<span class="keyword">const</span> struct cpumask *mask)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> cpu;</span><br><span class="line"></span><br><span class="line">    native_send_call_func_ipi(mask);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Make sure other vCPUs get a chance to run if they need to. */</span></span><br><span class="line">    for_each_cpu(cpu, mask) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!idle_cpu(cpu) &amp;&amp; vcpu_is_preempted(cpu)) &#123;</span><br><span class="line">            kvm_hypercall1(KVM_HC_SCHED_YIELD, per_cpu(x86_cpu_to_apicid, cpu));</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="kvm-side-1"><a href="#kvm-side-1" class="headerlink" title="kvm side"></a>kvm side</h3><p>kvm needs to implement the hypercall handler to process the yield hypercall.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kvm_emulate_hypercall</span><span class="params">(struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> KVM_HC_SCHED_YIELD:</span><br><span class="line">        <span class="keyword">if</span> (!guest_pv_has(vcpu, KVM_FEATURE_PV_SCHED_YIELD))</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">        kvm_sched_yield(vcpu, a0);</span><br><span class="line">        ret = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Find the target vcpu and yield to it.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_sched_yield</span><span class="params">(struct kvm_vcpu *vcpu, <span class="keyword">unsigned</span> <span class="keyword">long</span> dest_id)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kvm_vcpu</span> *<span class="title">target</span> = <span class="title">NULL</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kvm_apic_map</span> *<span class="title">map</span>;</span></span><br><span class="line"></span><br><span class="line">    vcpu-&gt;stat.directed_yield_attempted++;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (single_task_running())</span><br><span class="line">        <span class="keyword">goto</span> no_yield;</span><br><span class="line"></span><br><span class="line">    rcu_read_lock();</span><br><span class="line">    <span class="built_in">map</span> = rcu_dereference(vcpu-&gt;kvm-&gt;arch.apic_map);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (likely(<span class="built_in">map</span>) &amp;&amp; dest_id &lt;= <span class="built_in">map</span>-&gt;max_apic_id &amp;&amp; <span class="built_in">map</span>-&gt;phys_map[dest_id])</span><br><span class="line">        target = <span class="built_in">map</span>-&gt;phys_map[dest_id]-&gt;vcpu;</span><br><span class="line"></span><br><span class="line">    rcu_read_unlock();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!target || !READ_ONCE(target-&gt;ready))</span><br><span class="line">        <span class="keyword">goto</span> no_yield;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Ignore requests to yield to self */</span></span><br><span class="line">    <span class="keyword">if</span> (vcpu == target)</span><br><span class="line">        <span class="keyword">goto</span> no_yield;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (kvm_vcpu_yield_to(target) &lt;= <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">goto</span> no_yield;</span><br><span class="line"></span><br><span class="line">    vcpu-&gt;stat.directed_yield_successful++;</span><br><span class="line"></span><br><span class="line">no_yield:</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>上述代码的第26行<code>kvm_vcpu_yield_to(target)</code>，<code>target</code>就是目标vCPU，当前代码的执行上下文是IPI的source vCPU thread，执行完<code>kvm_vcpu_yield_to</code>后，即可yield to 目标vCPU。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kvm_vcpu_yield_to</span><span class="params">(struct kvm_vcpu *target)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">pid</span> *<span class="title">pid</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">task</span> = <span class="title">NULL</span>;</span></span><br><span class="line">    <span class="keyword">int</span> ret = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    rcu_read_lock();</span><br><span class="line">    pid = rcu_dereference(target-&gt;pid);</span><br><span class="line">    <span class="keyword">if</span> (pid)</span><br><span class="line">        task = get_pid_task(pid, PIDTYPE_PID);</span><br><span class="line">    rcu_read_unlock();</span><br><span class="line">    <span class="keyword">if</span> (!task)</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    ret = yield_to(task, <span class="number">1</span>);</span><br><span class="line">    put_task_struct(task);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再看下<code>yield_to</code>函数:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return:</span></span><br><span class="line"><span class="comment"> *  true (&gt;0) if we indeed boosted the target task.</span></span><br><span class="line"><span class="comment"> *  false (0) if we failed to boost the target.</span></span><br><span class="line"><span class="comment"> *  -ESRCH if there's no task to yield to.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> __<span class="function">sched <span class="title">yield_to</span><span class="params">(struct task_struct *p, <span class="keyword">bool</span> preempt)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// yield_to_task主动放弃CPU并执行指定的task_struct</span></span><br><span class="line">    yielded = curr-&gt;sched_class-&gt;yield_to_task(rq, p, preempt);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><hr><p>参考资料:</p><ol><li><a href="http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/09/10/kvm-performance-1" target="_blank" rel="noopener">kvm performance optimization technologies, part one</a></li><li><a href="https://lore.kernel.org/kvm/1560255830-8656-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: Yield to IPI target if necessary</a></li><li><a href="https://static.sched.com/hosted_files/kvmforum2020/6e/KVM%20Latency%20and%20Scalability%20Performance%20Tuning.pdf" target="_blank" rel="noopener">KVM Latency and Scalability Performance Tuning</a></li><li><a href="https://zhuanlan.zhihu.com/p/442921692" target="_blank" rel="noopener">进程管理：一文读懂Linux内核中的任务间调度策略</a></li><li><a href="https://cloud.tencent.com/developer/article/1648811" target="_blank" rel="noopener">从一个softlock问题来谈谈Kernel IPI的实现</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下kvm中的PV sched yield相关notes，参考内核版本是v6.0。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
      <category term="调度" scheme="http://liujunming.github.io/tags/%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>Notes about PV EOI</title>
    <link href="http://liujunming.github.io/2023/08/26/Notes-about-PV-EOI/"/>
    <id>http://liujunming.github.io/2023/08/26/Notes-about-PV-EOI/</id>
    <published>2023-08-26T05:35:07.000Z</published>
    <updated>2023-08-26T05:46:46.058Z</updated>
    
    <content type="html"><![CDATA[<p>本文参考内核版本为v5.0。主要内容转载自:<a href="http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/09/10/kvm-performance-1" target="_blank" rel="noopener">kvm performance optimization technologies, part one</a></p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>PV EOI is an old pv optimization. The idea behind pv eoi is to avoid the EOI write in APIC. This exit is expensive. PV EOI uses a shared memory. The VMM set a flag in this shared memory before injecting the interrupt, when the guest process the interrupt and write an EOI, if it finds this flag it will clear it and just return.<a id="more"></a></p><p><img src="/images/2023/08/013.jpeg" alt></p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p><img src="/images/2023/08/pv-eoi-init.svg" alt></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> KVM_PV_EOI_BIT 0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> KVM_PV_EOI_MASK (0x1 &lt;&lt; KVM_PV_EOI_BIT)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> KVM_PV_EOI_ENABLED KVM_PV_EOI_MASK</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> KVM_PV_EOI_DISABLED 0x0</span></span><br></pre></td></tr></table></figure><p>Linux guest:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="title">DEFINE_PER_CPU_DECRYPTED</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">long</span>, kvm_apic_eoi)</span> </span>= KVM_PV_EOI_DISABLED;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_guest_cpu_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (kvm_para_has_feature(KVM_FEATURE_PV_EOI)) &#123;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">long</span> pa;</span><br><span class="line">        __this_cpu_write(kvm_apic_eoi, <span class="number">0</span>);</span><br><span class="line">        pa = slow_virt_to_phys(this_cpu_ptr(&amp;kvm_apic_eoi))</span><br><span class="line">            | KVM_MSR_ENABLED;</span><br><span class="line">        wrmsrl(MSR_KVM_PV_EOI_EN, pa);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>kvm:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kvm_lapic_enable_pv_eoi</span><span class="params">(struct kvm_vcpu *vcpu, u64 data, <span class="keyword">unsigned</span> <span class="keyword">long</span> len)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    u64 addr = data &amp; ~KVM_MSR_ENABLED;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">gfn_to_hva_cache</span> *<span class="title">ghc</span> = &amp;<span class="title">vcpu</span>-&gt;<span class="title">arch</span>.<span class="title">pv_eoi</span>.<span class="title">data</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> new_len;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!IS_ALIGNED(addr, <span class="number">4</span>))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    vcpu-&gt;arch.pv_eoi.msr_val = data;</span><br><span class="line">    <span class="keyword">if</span> (!pv_eoi_enabled(vcpu))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (addr == ghc-&gt;gpa &amp;&amp; len &lt;= ghc-&gt;len)</span><br><span class="line">        new_len = ghc-&gt;len;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        new_len = len;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> kvm_gfn_to_hva_cache_init(vcpu-&gt;kvm, ghc, addr, new_len);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Linux guest:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">init <span class="title">kvm_guest_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (kvm_para_has_feature(KVM_FEATURE_PV_EOI))</span><br><span class="line">        apic_set_eoi_write(kvm_guest_apic_eoi_write);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> notrace <span class="keyword">void</span> <span class="title">kvm_guest_apic_eoi_write</span><span class="params">(u32 reg, u32 val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * This relies on __test_and_clear_bit to modify the memory</span></span><br><span class="line"><span class="comment">     * in a way that is atomic with respect to the local CPU.</span></span><br><span class="line"><span class="comment">     * The hypervisor only accesses this memory from the local CPU so</span></span><br><span class="line"><span class="comment">     * there's no need for lock or memory barriers.</span></span><br><span class="line"><span class="comment">     * An optimization barrier is implied in apic write.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (__test_and_clear_bit(KVM_PV_EOI_BIT, this_cpu_ptr(&amp;kvm_apic_eoi)))</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    apic-&gt;native_eoi_write(APIC_EOI, APIC_EOI_ACK);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="interrupt-injection-before-vmentry"><a href="#interrupt-injection-before-vmentry" class="headerlink" title="interrupt injection before vmentry"></a>interrupt injection before vmentry</h2><p>The <code>apic_sync_pv_eoi_to_guest</code> will be called when vmentry.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * apic_sync_pv_eoi_to_guest - called before vmentry</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Detect whether it's safe to enable PV EOI and</span></span><br><span class="line"><span class="comment"> * if yes do so.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">apic_sync_pv_eoi_to_guest</span><span class="params">(struct kvm_vcpu *vcpu,</span></span></span><br><span class="line"><span class="function"><span class="params">                    struct kvm_lapic *apic)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!pv_eoi_enabled(vcpu) ||</span><br><span class="line">        <span class="comment">/* IRR set or many bits in ISR: could be nested. */</span></span><br><span class="line">        apic-&gt;irr_pending ||</span><br><span class="line">        <span class="comment">/* Cache not set: could be safe but we don't bother. */</span></span><br><span class="line">        apic-&gt;highest_isr_cache == <span class="number">-1</span> ||</span><br><span class="line">        <span class="comment">/* Need EOI to update ioapic. */</span></span><br><span class="line">        kvm_ioapic_handles_vector(apic, apic-&gt;highest_isr_cache)) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * PV EOI was disabled by apic_sync_pv_eoi_from_guest</span></span><br><span class="line"><span class="comment">         * so we need not do anything here.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    pv_eoi_set_pending(apic-&gt;vcpu);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>pv_eoi_set_pending</code> will set the <code>KVM_PV_EOI_ENABLED</code> flag in shared memory.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">pv_eoi_set_pending</span><span class="params">(struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (pv_eoi_put_user(vcpu, KVM_PV_EOI_ENABLED) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        apic_debug(<span class="string">"Can't set EOI MSR value: 0x%llx\n"</span>,</span><br><span class="line">               (<span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span>)vcpu-&gt;arch.pv_eoi.msr_val);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    __set_bit(KVM_APIC_PV_EOI_PENDING, &amp;vcpu-&gt;arch.apic_attention);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">pv_eoi_put_user</span><span class="params">(struct kvm_vcpu *vcpu, u8 val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> kvm_write_guest_cached(vcpu-&gt;kvm, &amp;vcpu-&gt;arch.pv_eoi.data, &amp;val,</span><br><span class="line">                      <span class="keyword">sizeof</span>(val));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="apic-sync-pv-eoi-from-guest-after-vmexit"><a href="#apic-sync-pv-eoi-from-guest-after-vmexit" class="headerlink" title="apic_sync_pv_eoi_from_guest after vmexit"></a>apic_sync_pv_eoi_from_guest after vmexit</h2><p>The <code>apic_sync_pv_eoi_from_guest</code> will be called when vmexit or cancel interrupt.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * apic_sync_pv_eoi_from_guest - called on vmexit or cancel interrupt</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Detect whether guest triggered PV EOI since the</span></span><br><span class="line"><span class="comment"> * last entry. If yes, set EOI on guests's behalf.</span></span><br><span class="line"><span class="comment"> * Clear PV EOI in guest memory in any case.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">apic_sync_pv_eoi_from_guest</span><span class="params">(struct kvm_vcpu *vcpu,</span></span></span><br><span class="line"><span class="function"><span class="params">                    struct kvm_lapic *apic)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">bool</span> pending;</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">vector</span>;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * PV EOI state is derived from KVM_APIC_PV_EOI_PENDING in host</span></span><br><span class="line"><span class="comment">     * and KVM_PV_EOI_ENABLED in guest memory as follows:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * KVM_APIC_PV_EOI_PENDING is unset:</span></span><br><span class="line"><span class="comment">     *  -&gt; host disabled PV EOI.</span></span><br><span class="line"><span class="comment">     * KVM_APIC_PV_EOI_PENDING is set, KVM_PV_EOI_ENABLED is set:</span></span><br><span class="line"><span class="comment">     *  -&gt; host enabled PV EOI, guest did not execute EOI yet.</span></span><br><span class="line"><span class="comment">     * KVM_APIC_PV_EOI_PENDING is set, KVM_PV_EOI_ENABLED is unset:</span></span><br><span class="line"><span class="comment">     *  -&gt; host enabled PV EOI, guest executed EOI.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    BUG_ON(!pv_eoi_enabled(vcpu));</span><br><span class="line">    pending = pv_eoi_get_pending(vcpu);</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Clear pending bit in any case: it will be set again on vmentry.</span></span><br><span class="line"><span class="comment">     * While this might not be ideal from performance point of view,</span></span><br><span class="line"><span class="comment">     * this makes sure pv eoi is only enabled when we know it's safe.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    pv_eoi_clr_pending(vcpu);</span><br><span class="line">    <span class="keyword">if</span> (pending)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">vector</span> = apic_set_eoi(apic);</span><br><span class="line">    trace_kvm_pv_eoi(apic, <span class="built_in">vector</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>pv_eoi_get_pending</code> will get the status of the shared flag. If it is still pending, it means the no guest trigger the EOI write, nothing to do. If the guest trigger the EOI here will call <code>apic_set_eoi</code> set the EOI of APIC on guests’s behalf.</p><p>Note the <code>apic-&gt;irr_pending</code> will always be true with virtual interrupt delivery enabled. So pv eoi today I think is little used as the APICv is very common.</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="/images/2023/08/pv-eoi-full-pic.drawio.svg" alt></p><hr><p>参考资料:</p><ol><li><a href="http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/09/10/kvm-performance-1" target="_blank" rel="noopener">http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/09/10/kvm-performance-1</a></li><li><a href="https://lwn.net/Articles/502176/" target="_blank" rel="noopener">https://lwn.net/Articles/502176/</a></li><li><a href="https://lore.kernel.org/kvm/cover.1337695416.git.mst@redhat.com/" target="_blank" rel="noopener">https://lore.kernel.org/kvm/cover.1337695416.git.mst@redhat.com/</a></li><li><a href="https://www.kernel.org/doc/Documentation/virtual/kvm/msr.txt" target="_blank" rel="noopener">https://www.kernel.org/doc/Documentation/virtual/kvm/msr.txt</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文参考内核版本为v5.0。主要内容转载自:&lt;a href=&quot;http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/09/10/kvm-performance-1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kvm performance optimization technologies, part one&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;p&gt;PV EOI is an old pv optimization. The idea behind pv eoi is to avoid the EOI write in APIC. This exit is expensive. PV EOI uses a shared memory. The VMM set a flag in this shared memory before injecting the interrupt, when the guest process the interrupt and write an EOI, if it finds this flag it will clear it and just return.
    
    </summary>
    
      <category term="中断" scheme="http://liujunming.github.io/categories/%E4%B8%AD%E6%96%AD/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
      <category term="中断" scheme="http://liujunming.github.io/tags/%E4%B8%AD%E6%96%AD/"/>
    
  </entry>
  
  <entry>
    <title>Notes about pvpanic</title>
    <link href="http://liujunming.github.io/2023/08/13/Notes-about-pvpanic/"/>
    <id>http://liujunming.github.io/2023/08/13/Notes-about-pvpanic/</id>
    <published>2023-08-13T12:36:43.000Z</published>
    <updated>2023-08-13T12:44:44.733Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下pvpanic相关notes。<a id="more"></a></p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>pvpanic, which is a paravirtualized device emulated by QEMU and used by the guest OS to report to the VMM when it experiences a panic/crash. This mechanism allows a guest OS kernel to signal the hypervisor when it panics, before any crash dump is collected.</p><h3 id="pvpanic-device"><a href="#pvpanic-device" class="headerlink" title="pvpanic device"></a>pvpanic device</h3><p>pvpanic device is a simulated device, through which a guest panic event is sent to qemu, and a QMP event is generated. This allows management apps (e.g. libvirt) to be notified and respond to the event.</p><p>The management app has the option of waiting for GUEST_PANICKED events, and/or polling for guest-panicked RunState, to learn when the pvpanic device has fired a panic event.</p><p>The pvpanic device can be implemented as an ISA device (using IOPORT) or as a PCI device.</p><h3 id="crash-kexec-post-notifiers"><a href="#crash-kexec-post-notifiers" class="headerlink" title="crash_kexec_post_notifiers"></a>crash_kexec_post_notifiers</h3><p>During initialization, the pvpanic module registers a callback with the <code>panic_notifier_list</code> notifier chain. When the kernel panics, the value of <code>crash_kexec_post_notifiers</code> determines whether or not the callbacks registered in the panic_notifier_list are invoked before kexec’ing into the capture kernel which will collect the crash dump. The <code>panic()</code> code in <code>kernel/panic.c</code> is extensively commented and worth a look if you are interested in the details.</p><hr><p>参考资料:</p><ol><li><a href="https://github.com/qemu/qemu/blob/master/docs/specs/pvpanic.txt" target="_blank" rel="noopener">docs/specs/pvpanic.txt</a></li><li><a href="https://blogs.oracle.com/linux/post/an-introduction-to-pvpanic" target="_blank" rel="noopener">An introduction to pvpanic</a></li><li><a href="https://cloud.tencent.com/developer/news/345830" target="_blank" rel="noopener">PVPanic的实现原理以及应用</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下pvpanic相关notes。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>盘点内存虚拟化探索之路</title>
    <link href="http://liujunming.github.io/2023/08/13/%E7%9B%98%E7%82%B9%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8E%A2%E7%B4%A2%E4%B9%8B%E8%B7%AF/"/>
    <id>http://liujunming.github.io/2023/08/13/盘点内存虚拟化探索之路/</id>
    <published>2023-08-13T02:29:45.000Z</published>
    <updated>2023-08-13T03:17:30.112Z</updated>
    
    <content type="html"><![CDATA[<p>本文内容转载自:<a href="https://mp.weixin.qq.com/s/f_bgSfz4nzG50izBYYzdLA" target="_blank" rel="noopener">致敬 hacker ｜盘点内存虚拟化探索之路</a>。<a id="more"></a></p><h2 id="云与虚拟化"><a href="#云与虚拟化" class="headerlink" title="云与虚拟化"></a>云与虚拟化</h2><p>云计算是通过 Internet 服务的方式提供动态可伸缩资源的计算模式，经过多年的发展已成为企业 IT 技术的重要支撑。虚拟化是云计算的核心技术之一，将一台计算机抽象为多台逻辑计算机，即虚拟机，每个虚拟机是一个单独安全的环境，可运行不同的操作系统且互不影响。</p><p>虚拟化技术给资源使用和调度带来了极大便利，云计算系统可以根据负载情况及时进行资源调度，在提升资源利用率的同时保证应用和服务不会因资源不足而影响服务质量。然而虚拟化也是有代价的，对资源的抽象带来了性能损失，这也是虚拟化一直致力解决的问题。</p><p>虚拟化的资源抽象可以简单划分为三部分：CPU 虚拟化、内存虚拟化和设备虚拟化。其中设备虚拟化已经可以实现网络、存储等设备直通虚拟机，没有性能损失；CPU 虚拟化在硬件特性的支持下，执行普通指令性能与裸机相同；而内存虚拟化相比裸机，仍然存在较大差异，是当下值得关注的问题。</p><h2 id="内存虚拟化"><a href="#内存虚拟化" class="headerlink" title="内存虚拟化"></a>内存虚拟化</h2><h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><p>说到内存虚拟化，就不得不提虚拟内存的概念。早期的操作系统只有物理地址且空间有限，进程使用内存时必须小心翼翼以避免覆盖其他进程的内存。为避免此问题，虚拟内存的概念被抽象出来，保证每个进程都有一块连续的、独立的虚拟内存空间。进程直接通过 VA（Virtual Address）使用内存，CPU 访存时发出的 VA 由硬件 MMU（Memory Management Unit）拦截并转换为 PA（Physical Address），VA 到 PA 的映射使用页表进行管理，MMU 在转换时会自动查询页表。</p><p><img src="/images/2023/08/001.png" alt></p><h3 id="内存虚拟化-1"><a href="#内存虚拟化-1" class="headerlink" title="内存虚拟化"></a>内存虚拟化</h3><p>与虚拟内存的概念类似，一台主机上的每个虚拟机认为自己独占整个物理地址空间，因而需要对内存再做一次抽象，即内存虚拟化，保证每个虚拟机都有独立的地址空间。这样一来，在虚拟机和物理机中均有 VA 和 PA 的概念，即 GVA（Guest  Virtual Address）和 GPA（Guest Physical Address），以及 HVA（Host Virtual Address）和 HPA（Host Physical Address）。虚拟机内的程序使用的是GVA，最终需要转换成 HPA。两个 VA 到 PA（ GVA 到 GPA 以及 HVA 到 HPA）的映射同样使用页表管理，GPA 到 HVA 一般是几段连续的线性映射，由虚拟机的管理程序 VMM（Virtual Machine Monitor）进行管理。</p><p><img src="/images/2023/08/002.png" alt></p><p>进程访存需要从 VA 转换成 PA，在引入内存虚拟化后，转换路径发生了很大的变化。原本只需要将 VA 转换为 PA，虚拟化后转换过程变成 GVA -&gt; GPA -&gt; HVA -&gt; HPA 。路径变得更长更复杂之后，对于访存的安全和性能都带来了挑战，这两点也是内存虚拟化需要达到的目标：1）安全 ，即地址转换的合法性，虚拟机不能访问不属于自己的内存；2）性能，即地址转换的高效性，包括转换关系建立的开销低，以及转换过程本身的开销低。</p><h2 id="经典方案"><a href="#经典方案" class="headerlink" title="经典方案"></a>经典方案</h2><p>为达成内存虚拟化的目标，已经有很多虚拟化方案被提出，SPT（Shadow Page Table）和 EPT（Extended Page Table）是两种典型的方案，也是大家最熟悉的方案。我们先以此为切入点，看看他们是如何工作的，然后再讨论其他的虚拟化方案。</p><h3 id="SPT"><a href="#SPT" class="headerlink" title="SPT"></a>SPT</h3><p>由于最初的硬件只支持一层页表转换，直接用来转换虚拟机或物理机上的 VA 到 PA 都无法完成 GVA 到 HPA 的转换。因此 SPT 建立了一条捷径，即影子页表，直接管理 GVA 到 HPA 的映射，如下图所示。每一个影子页表实例对应虚拟机内一个进程，影子页表的建立需要 VMM 查询虚拟机内进程的页表。</p><p><img src="/images/2023/08/003.png" alt></p><p>由于影子页表管理的是 GVA 到 HPA 的直接映射，SPT 地址转换路径与物理机路径相当，直接查询一层页表就可以完成地址转换。在使用 4 级页表时，转换过程如下图所示。</p><p><img src="/images/2023/08/004.png" alt></p><p><strong>优势</strong>：SPT 地址转换过程的开销低，与物理机相当。</p><p><strong>劣势</strong>：</p><ol><li>地址转换关系的建立开销很大，为保证地址转换的合法性，所有的转换关系建立，即虚拟机进程的页表修改，都会被拦截之后陷出到特权的 VMM 中代为执行；</li><li>影子页表本身需要占用内存，且一个影子页表只对应虚拟机内一个进程，整体会占用较多内存资源。</li></ol><h3 id="EPT"><a href="#EPT" class="headerlink" title="EPT"></a>EPT</h3><p>后来的硬件针对虚拟化增加了嵌套页表的支持，使得硬件可以自动完成两层页表转换。EPT 即是基于硬件支持的方案，在管理 GVA 到 GPA 的虚拟机页表基础上，新增扩展页表管理 GPA 到 HPA 的映射，如下图所示。这两层页表相互独立，两层映射关系转换都由硬件自动完成。</p><p><img src="/images/2023/08/005.png" alt></p><p>由于虚拟机内各级页表（gL4, gL3, gL2, gL1）内容只是 GPA，查询下一级时必须先经扩展页表（nL4, nL3, nL2, nL1）转换为 HPA，使得整个转换路径很长。在两层页表均为 4 级时，转换过程如下图所示。</p><p><img src="/images/2023/08/006.png" alt></p><p><strong>优势</strong>：地址转换关系的建立开销低，独立的 EPT 页表的存在保证了地址转换的合法性，因此虚拟机的页表可以自行修改而无需 VMM 的干预。</p><p><strong>劣势</strong>：转换过程的开销很大，最坏情况下需要 24（4 + 4 + 4 * 4）次硬件查表转换。</p><p>两种经典的方案在安全上都有坚实的保证，但在性能上各有缺陷。SPT 为保证地址转换的合法性在建立转换关系时付出了很大代价，而 EPT 虽然消除了建立转换关系的开销，转换路径却更长了。</p><h2 id="其他探索"><a href="#其他探索" class="headerlink" title="其他探索"></a>其他探索</h2><p>业界和学术界关于内存虚拟化还有很多的探索，基本思想与 SPT 或 EPT 类似，可以据此分为三类来看：1）一层页表方案。与 SPT 类似，使用一层页表直接管理 GVA 到 HPA 的映射；2）两层页表方案。与 EPT 类似，使用两层独立页表分别管理 GVA 到 GPA 以及 GPA 到 HPA 的映射；3）混合方案。结合前两类方案，进行动态的选择。</p><h3 id="Direct-Paging"><a href="#Direct-Paging" class="headerlink" title="Direct Paging"></a>Direct Paging</h3><p>一层页表方案，这是 Xen 在早期硬件仅支持一层页表时的半虚拟化方案。相比于 SPT 最大的区别是，没有单独维护 GVA 到 GPA 的虚拟机页表，虚拟机知道自己处于虚拟化环境，即知道自己的页表内容是 HPA。虚拟机修改页表也需要陷出，但是采用主动陷出的方式，可以 batch 化，而 SPT 则是被动拦截陷出；读取页表时只能拿到 HPA，需要查一张 M2P（Machine to Physical）表才能得到 GPA。</p><p><img src="/images/2023/08/007.png" alt></p><p>Direct Paging 同样使用一层页表管理 GVA 到 HPA 映射，地址转换的路径与 SPT 是相同的。在使用 4 级页表时，最坏只需 4 次查表。</p><p><strong>优势</strong>：地址转换过程的开销低，与物理机相当。</p><p><strong>劣势</strong>：</p><ol><li>地址转换关系的建立开销很大，所有页表修改都需要主动陷出；</li><li>需要虚拟机做半虚拟化的适配，虚拟机需要感知自己的页表管理的是 GVA 到 HPA 的映射。</li></ol><h3 id="Direct-Segment"><a href="#Direct-Segment" class="headerlink" title="Direct Segment"></a>Direct Segment</h3><p>两层页表方案，这是学术界基于新硬件的方案。GVA 到 GPA 的映射管理与 EPT 相同，同样采用多级页表。但 GPA 到 HPA 的映射采用分段机制， GPA 转换为 HPA 时只需要通过硬件加上一个偏移即可。</p><p><img src="/images/2023/08/008.png" alt></p><p>GPA 虽然不等于 HPA，但二者的映射关系十分简单，只需要 Direct Segment 硬件添加一个偏移，整个转换路径与物理机的路径相比差别很小，仅多了几次硬件偏移。虚拟机使用 4 级页表时，转换路径如下图所示，其中 DS 表示 GPA 到 HPA 转换的硬件支持。</p><p><img src="/images/2023/08/009.png" alt></p><p><strong>优势</strong>：地址转换关系的建立开销低，同时转换过程的开销也很低。</p><p><strong>劣势</strong>：</p><ol><li>需要硬件支持 GPA 到 HPA 分段映射，现有的硬件不具备这样的功能；</li><li>需要分配大段连续的内存，即主机不能有太多内存碎片。</li></ol><h3 id="Flat-EPT"><a href="#Flat-EPT" class="headerlink" title="Flat EPT"></a>Flat EPT</h3><p>两层页表方案，这也是学术界提出的基于新硬件的方案。整体与 EPT 非常相似，唯一的区别在于 EPT 管理 GPA 到 HPA 的使用多级页表，一般是 4 级，每级 512 项；而 Flat EPT 使用仅有一级的扁平页表，表项远不止 512。</p><p><img src="/images/2023/08/010.png" alt></p><p>与 EPT 相同，虚拟机内各级页表的内容也是 GPA，查询下一级时需要先经过扁平扩展页表（nL4）转换为 HPA。由于扁平扩展页表只有一级，转换路径相比 EPT 缩短了非常多。在虚拟机内使用4级页表时，转换路径如下图所示，最坏只需 9（4 + 1 + 4 * 1）次查表。</p><p><img src="/images/2023/08/011.png" alt></p><p><strong>优势</strong>：地址转换关系的建立开销低，同时转换过程的开销也较低。相比于 Direct Segment 对内存分配要求很低，只需要少量连续内存用作扁平扩展页表即可（8G规格虚拟机只需要 16M）。</p><p><strong>劣势</strong>：需要硬件支持扁平扩展页表，当前的硬件只支持表项为 512 的多级扩展页表。</p><h3 id="Mix-SPT-and-EPT"><a href="#Mix-SPT-and-EPT" class="headerlink" title="Mix SPT and EPT"></a>Mix SPT and EPT</h3><p>混合方案，这是学术界较早提出的方案，简单而言就是动态的分时切换 SPT 与 EPT。在虚拟机运行时监控和采集 TLB miss 与 Page Fault 的数据，在二者达到设定的阈值时进行 SPT 与 EPT 之间的切换，如下图所示：</p><ul><li>TLB miss 率高于阈值 T1，Page Fault 频率低于阈值 T2 时，从 EPT 切换到 SPT</li><li>TLB miss 率低于阈值 T1，Page Fault 频率高于阈值 T2 时，从 SPT 切换到 EPT</li></ul><p><img src="/images/2023/08/012.png" alt></p><p><strong>优势</strong>：有机会充分利用SPT与EPT的优势，达到更好的性能。</p><p><strong>劣势</strong>：</p><ol><li>页表切换阈值的设定很困难，硬件配置都可能影响阈值；</li><li>SPT与EPT的切换也是有代价的，主要是SPT的销毁与重建。</li></ol><h3 id="TPT"><a href="#TPT" class="headerlink" title="TPT"></a>TPT</h3><p>值得一提的是，ATC’23的paper<a href="https://www.usenix.org/system/files/atc23-bergman.pdf" target="_blank" rel="noopener">Translation Pass-Through for Near-Native Paging Performance in VMs</a>也是本topic的工作，可以仔细阅读论文中的Related Work一节，了解更多相关工作。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一层页表显著的优势是地址转换过程开销低，与物理机相同，需要解决的问题是减少地址转换建立的开销。一个可能的方向是放弃一些安全性，让页表的修改更轻量；另一个更实际的方向是在合适的场景使用，即针对页表修改不频繁的负载使用。</p><p>两层页表的优势是地址转换建立的开销小，虚拟机可以独立修改页表，需要考虑的问题是缩短转换路径。这个方向其实可行性很高，但是依赖新硬件的支持，短期不太可能出现符合要求的新硬件。</p><p>混合页表的设计初衷是希望充分利用两类页表的优势，但是做好动态的模式切换是非常困难的，负载的差异甚至硬件的差异都可能影响切换的效果。或许针对已知负载做定向的调优是一个可行的方向。</p><p>长远来看，如果有新硬件的加持，两层页表（尤其是Flat EPT）是比较完善的方案，地址转换可以很高效，也不需要在安全和通用性上做一些牺牲。但是短期来看，新硬件为时尚早，在一层页表方案上做进一步的探索和优化，是更加实际的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文内容转载自:&lt;a href=&quot;https://mp.weixin.qq.com/s/f_bgSfz4nzG50izBYYzdLA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;致敬 hacker ｜盘点内存虚拟化探索之路&lt;/a&gt;。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="内存管理" scheme="http://liujunming.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Interrupt Request Lines (IRQs)</title>
    <link href="http://liujunming.github.io/2023/08/12/Notes-about-Interrupt-Request-Lines-IRQs/"/>
    <id>http://liujunming.github.io/2023/08/12/Notes-about-Interrupt-Request-Lines-IRQs/</id>
    <published>2023-08-12T04:02:00.000Z</published>
    <updated>2023-08-12T04:12:46.496Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下IRQs相关notes。<a id="more"></a></p><p>An interrupt request (IRQ) is a hardware signal sent to the processor instructing it to suspend its current activity and handle some external event, such as a keyboard input or a mouse movement. In x86 based computer systems, IRQs are numbered from 0 to 15. Newer computers, including x86-64 systems, provide more than these 16 interrupts (usually 24). Some interrupts are reserved for specific purposes, such as the keyboard and the real-time clock; others have common uses but may be reassigned; and some are left available for extra devices that may be added to the system.</p><p>Here is a list of the IRQs and their common purposes in the x86 system:<br><img src="/images/2023/07/003.jpeg" alt></p><p>In Linux, IRQ mappings are stored in the /proc/interrupts file:<br><img src="/images/2023/07/004.jpeg" alt><br>In the picture above, you can see the names of the drivers that are using each IRQ. For example, the keyborad is using IRQ 1, the mouse is using IRQ 12.</p><p>File ‘/proc/interrupts’ is the procfs Linux interface to the interrupt subsystem, and it presents a table about the number of interrupts on every CPU core in the system in the following form:</p><ul><li>First column: interrupt number</li><li>CPUx columns: interrupt counters for every CPU core in the system</li><li>Next column: interrupt type:<ul><li>IO-APIC-edge — edge-triggered interrupt for the I/O APIC controller</li><li>IO-APIC-fasteoi — level-triggered interrupt for the I/O APIC controller</li><li>PCI-MSI-edge — MSI interrupt</li><li>XT-PIC-XT-PIC — interrupt for the PIC controller</li></ul></li><li>Last column: device (driver) associated with this interrupt</li></ul><hr><p>参考资料:</p><ol><li><a href="https://geek-university.com/irq-interrupt-request/" target="_blank" rel="noopener">IRQ (Interrupt Request)</a></li><li><a href="http://bucarotechelp.com/computers/architecture/90032101.asp" target="_blank" rel="noopener">Interrupt Request Lines (IRQs) by Stephen Bucaro</a></li><li><a href="https://habr.com/en/articles/501660/" target="_blank" rel="noopener">External Interrupts in the x86 system. Part 2. Linux kernel boot options</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下IRQs相关notes。
    
    </summary>
    
      <category term="中断" scheme="http://liujunming.github.io/categories/%E4%B8%AD%E6%96%AD/"/>
    
    
      <category term="中断" scheme="http://liujunming.github.io/tags/%E4%B8%AD%E6%96%AD/"/>
    
  </entry>
  
  <entry>
    <title>每周分享第35期</title>
    <link href="http://liujunming.github.io/2023/08/12/%E6%AF%8F%E5%91%A8%E5%88%86%E4%BA%AB%E7%AC%AC35%E6%9C%9F/"/>
    <id>http://liujunming.github.io/2023/08/12/每周分享第35期/</id>
    <published>2023-08-11T23:31:57.000Z</published>
    <updated>2023-08-12T01:51:53.163Z</updated>
    
    <content type="html"><![CDATA[<h3 id="chrome-CCFRank"><a href="#chrome-CCFRank" class="headerlink" title="chrome CCFRank"></a>chrome CCFRank</h3><p><a href="https://chrome.google.com/webstore/detail/ccfrank/pfcajmbenomfbjnbjhgbnbdjmiklnkie" target="_blank" rel="noopener">https://chrome.google.com/webstore/detail/ccfrank/pfcajmbenomfbjnbjhgbnbdjmiklnkie</a><br>在dblp、Google学术、Connected Papers和WoS的搜索结果中显示中国计算机学会推荐的会议和期刊排名。<a id="more"></a></p><h3 id="Zotero论文管理"><a href="#Zotero论文管理" class="headerlink" title="Zotero论文管理"></a>Zotero论文管理</h3><p><a href="https://cloud.tencent.com/developer/article/1894275" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1894275</a><br><a href="https://www.zotero.org/" target="_blank" rel="noopener">https://www.zotero.org/</a></p><h3 id="Remote-Procedure-Calls"><a href="#Remote-Procedure-Calls" class="headerlink" title="Remote Procedure Calls"></a>Remote Procedure Calls</h3><p><a href="https://people.cs.rutgers.edu/~pxk/417/notes/rpc.html" target="_blank" rel="noopener">https://people.cs.rutgers.edu/~pxk/417/notes/rpc.html</a></p><h3 id="华为天才少年大模型创业-李博杰"><a href="#华为天才少年大模型创业-李博杰" class="headerlink" title="华为天才少年大模型创业 - 李博杰"></a>华为天才少年大模型创业 - 李博杰</h3><p><a href="https://mp.weixin.qq.com/s/XVHbQngpq36WtZSRRVlA9g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/XVHbQngpq36WtZSRRVlA9g</a></p><h3 id="李博杰面试经历分享"><a href="#李博杰面试经历分享" class="headerlink" title="李博杰面试经历分享"></a>李博杰面试经历分享</h3><p><a href="https://mp.weixin.qq.com/s/1Oozg1kcVoyYjf9F0ssAUQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/1Oozg1kcVoyYjf9F0ssAUQ</a></p><h3 id="High-Bandwidth-Memory-HBM"><a href="#High-Bandwidth-Memory-HBM" class="headerlink" title="High-Bandwidth Memory (HBM)"></a>High-Bandwidth Memory (HBM)</h3><p><a href="https://www.amd.com/system/files/documents/high-bandwidth-memory-hbm.pdf" target="_blank" rel="noopener">https://www.amd.com/system/files/documents/high-bandwidth-memory-hbm.pdf</a></p><h3 id="Linux-之父“开炮”！曾喊-AMD-真香，今炮轰-AMD：怒批-fTPM-“愚蠢”、“破玩意儿”"><a href="#Linux-之父“开炮”！曾喊-AMD-真香，今炮轰-AMD：怒批-fTPM-“愚蠢”、“破玩意儿”" class="headerlink" title="Linux 之父“开炮”！曾喊 AMD 真香，今炮轰 AMD：怒批 fTPM “愚蠢”、“破玩意儿”"></a>Linux 之父“开炮”！曾喊 AMD 真香，今炮轰 AMD：怒批 fTPM “愚蠢”、“破玩意儿”</h3><p><a href="https://mp.weixin.qq.com/s/f5as7KGXCN3NJ5yAYcOAxg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/f5as7KGXCN3NJ5yAYcOAxg</a></p><h3 id="阿里造“神龙”"><a href="#阿里造“神龙”" class="headerlink" title="阿里造“神龙”"></a>阿里造“神龙”</h3><p><a href="https://mp.weixin.qq.com/s/Jp0CeqxyB6hlIeGyiw6Gnw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Jp0CeqxyB6hlIeGyiw6Gnw</a></p><h3 id="vmtouch命令"><a href="#vmtouch命令" class="headerlink" title="vmtouch命令"></a>vmtouch命令</h3><p><a href="https://www.cnblogs.com/coldplayerest/archive/2012/02/28/2371881.html" target="_blank" rel="noopener">https://www.cnblogs.com/coldplayerest/archive/2012/02/28/2371881.html</a></p><h3 id="ASAN-Address-Sanitizer"><a href="#ASAN-Address-Sanitizer" class="headerlink" title="ASAN(Address Sanitizer)"></a>ASAN(Address Sanitizer)</h3><p>ASan，即Address Sanitizer，是一个适用于c/c++程序的动态内存错误检测器，它由一个编译器检测模块（LLVM pass）和一个替换malloc函数的运行时库组成，在性能及检测内存错误方面都优于Valgrind。</p><p><a href="https://mp.weixin.qq.com/s/aGq2NFjIb7OZbv1lsV6UXA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/aGq2NFjIb7OZbv1lsV6UXA</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;chrome-CCFRank&quot;&gt;&lt;a href=&quot;#chrome-CCFRank&quot; class=&quot;headerlink&quot; title=&quot;chrome CCFRank&quot;&gt;&lt;/a&gt;chrome CCFRank&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://chrome.google.com/webstore/detail/ccfrank/pfcajmbenomfbjnbjhgbnbdjmiklnkie&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://chrome.google.com/webstore/detail/ccfrank/pfcajmbenomfbjnbjhgbnbdjmiklnkie&lt;/a&gt;&lt;br&gt;在dblp、Google学术、Connected Papers和WoS的搜索结果中显示中国计算机学会推荐的会议和期刊排名。
    
    </summary>
    
      <category term="经验" scheme="http://liujunming.github.io/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="经验" scheme="http://liujunming.github.io/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>Linux kernel SRCU usage</title>
    <link href="http://liujunming.github.io/2023/08/06/Linux-kernel-SRCU-usage/"/>
    <id>http://liujunming.github.io/2023/08/06/Linux-kernel-SRCU-usage/</id>
    <published>2023-08-06T01:56:41.000Z</published>
    <updated>2023-08-05T14:35:31.543Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Linux kernel中SRCU相关API的使用方法。<a id="more"></a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li>Read-copy update (RCU)是一种在读多写少场景下可替代读写锁的高性能同步机制，RCU的读端不加锁，因此开销很低，不会被阻塞，执行的时间确定。这种设计决定了RCU写端不能阻塞读端，因此RCU写端的开销很高，因为它必须保留临界区数据直到没有读者访问，然后回收临界区数据</li><li>RCU要求访问临界区的读者不能睡眠或者被阻塞，原因是睡眠意味者上下文切换，进程的cpu被抢占，是不允许出现在处于临界区的读者身上的，因为会影响宽限期的检查。</li><li>在许多场景下我们又要求进程是可睡眠的，比如实时系统，高优先级的进程可以抢占低优先级进程的cpu，因此低优先级的进程必须让出cpu，低优先级进程如果拿了RCU的读锁，此时就会睡眠，会破坏RCU宽限期的检查。</li></ul><p>一个<strong>可以睡眠的RCU同步进制</strong>就被提了出来。</p><h2 id="SRCU-Implementation-Strategy"><a href="#SRCU-Implementation-Strategy" class="headerlink" title="SRCU Implementation Strategy"></a>SRCU Implementation Strategy</h2><p>将宽限期的检查隔离到一个子系统中，这样即使一个读者的睡眠时间无限延长，那么也只有处于这个子系统中的写者受到影响。</p><h2 id="SRCU-API-and-Usage"><a href="#SRCU-API-and-Usage" class="headerlink" title="SRCU API and Usage"></a>SRCU API and Usage</h2><p><a href="https://www.kernel.org/doc/Documentation/RCU/lockdep.txt" target="_blank" rel="noopener">Documentation/RCU/lockdep.txt</a>可以查询相关API的使用信息。</p><p>The SRCU API is shown in below. The following sections describe how to use it.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int init_srcu_struct(struct srcu_struct *sp);</span><br><span class="line">void cleanup_srcu_struct(struct srcu_struct *sp);</span><br><span class="line">int srcu_read_lock(struct srcu_struct *sp);</span><br><span class="line">void srcu_read_unlock(struct srcu_struct *sp, int idx);</span><br><span class="line">void synchronize_srcu(struct srcu_struct *sp);</span><br></pre></td></tr></table></figure></p><p>一个<code>struct srcu_struct</code>代表一个逻辑SRCU子系统。</p><h3 id="Initialization-and-Cleanup"><a href="#Initialization-and-Cleanup" class="headerlink" title="Initialization and Cleanup"></a>Initialization and Cleanup</h3><p>Each subsystem using SRCU must create an <code>struct srcu_struct</code>, either by declaring a variable of this type or by dynamically allocating the memory, for example, via <code>kmalloc()</code>. Once this structure is in place, it must be initialized via <code>init_srcu_struct()</code>, which returns zero for success or an error code for failure (for example, upon memory exhaustion).</p><p>If the <code>struct srcu_struct</code> is dynamically allocated, then <code>cleanup_srcu_struct()</code> must be called before it is freed. Similarly, if the struct <code>srcu_struct</code> is a variable declared within a Linux kernel module, then <code>cleanup_srcu_struct()</code> must be called before the module is unloaded. Either way, the caller must take care to ensure that all SRCU read-side critical sections have completed (and that no more will commence) before calling <code>cleanup_srcu_struct()</code>. </p><h3 id="Read-Side-Primitives"><a href="#Read-Side-Primitives" class="headerlink" title="Read-Side Primitives"></a>Read-Side Primitives</h3><p>The read-side <code>srcu_read_lock()</code> and <code>srcu_read_unlock()</code> primitives are used as shown:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">idx = srcu_read_lock(&amp;ss);</span><br><span class="line"><span class="comment">/* read-side critical section. */</span></span><br><span class="line">srcu_read_unlock(&amp;ss, idx);</span><br></pre></td></tr></table></figure></p><p>The <code>ss</code> variable is the <code>struct srcu_struct</code> whose initialization was described above, and the <code>idx</code> variable is an integer that in effect tells <code>srcu_read_unlock()</code> the grace period during which the corresponding <code>srcu_read_lock()</code> started.</p><h3 id="Update-Side-Primitives"><a href="#Update-Side-Primitives" class="headerlink" title="Update-Side Primitives"></a>Update-Side Primitives</h3><p>The <code>synchronize_srcu()</code> primitives may be used as shown below:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">list_del_rcu(p);</span><br><span class="line">synchronize_srcu(&amp;ss);</span><br><span class="line">kfree(p);</span><br></pre></td></tr></table></figure><p>As one might expect by analogy with Classic RCU, this primitive blocks until after the completion of all SRCU read-side critical sections that started before the <code>synchronize_srcu()</code> started, as shown in Table 1.</p><p><img src="/images/2023/07/002.jpg" alt></p><p>Here, CPU 1 need only wait for the completion of CPU 0’s SRCU read-side critical section. It need not wait for the completion of CPU 2’s SRCU read-side critical section, because CPU 2 did not start this critical section until <em>after</em> CPU 1 began executing <code>synchronize_srcu()</code>. Finally, CPU 1’s <code>synchronize_srcu()</code> need not wait for CPU 3’s SRCU read-side critical section, because CPU 3 is using <code>s2</code> rather than <code>s1</code> as its <code>struct srcu_struct</code>. CPU 3’s SRCU read-side critical section is thus related to a different set of grace periods than those of CPUs 0 and 2.</p><h3 id="MISC-API"><a href="#MISC-API" class="headerlink" title="MISC API"></a>MISC API</h3><ul><li>synchronize_srcu_expedited</li></ul><p>Wait for an SRCU grace period to elapse, but be more aggressive about spinning rather than blocking when waiting.</p><ul><li>srcu_dereference_check</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing</span></span><br><span class="line"><span class="comment"> * @p: the pointer to fetch and protect for later dereferencing</span></span><br><span class="line"><span class="comment"> * @ssp: pointer to the srcu_struct, which is used to check that we</span></span><br><span class="line"><span class="comment"> *  really are in an SRCU read-side critical section.</span></span><br><span class="line"><span class="comment"> * @c: condition to check for update-side use</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * If PROVE_RCU is enabled, invoking this outside of an RCU read-side</span></span><br><span class="line"><span class="comment"> * critical section will result in an RCU-lockdep splat, unless @c evaluates</span></span><br><span class="line"><span class="comment"> * to 1.  The @c argument will normally be a logical expression containing</span></span><br><span class="line"><span class="comment"> * lockdep_is_held() calls.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> srcu_dereference_check(p, ssp, c) \</span></span><br><span class="line">    __rcu_dereference_check((p), (c) || srcu_read_lock_held(ssp), __rcu)</span><br></pre></td></tr></table></figure><p>readers/updaters均可能会调用该函数。</p><hr><p>参考资料:</p><ol><li><a href="https://blog.csdn.net/huang987246510/article/details/102762067" target="_blank" rel="noopener">SRCU的简单实现</a></li><li><a href="https://blog.csdn.net/huang987246510/article/details/103039355" target="_blank" rel="noopener">SRCU的内核简单实现</a></li><li><a href="https://lwn.net/Articles/202847/" target="_blank" rel="noopener">Sleepable RCU</a></li><li><a href="https://linuxtv.org/downloads/v4l-dvb-internals/device-drivers/API-synchronize-srcu-expedited.html" target="_blank" rel="noopener">synchronize_srcu_expedited</a></li><li><a href="https://linuxtv.org/downloads/v4l-dvb-internals/device-drivers/API-synchronize-srcu.html" target="_blank" rel="noopener">synchronize_srcu</a></li><li><a href="https://docs.kernel.org/core-api/kernel-api.html#c.srcu_dereference_check" target="_blank" rel="noopener">srcu_dereference_check</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Linux kernel中SRCU相关API的使用方法。
    
    </summary>
    
      <category term="Kernel" scheme="http://liujunming.github.io/categories/Kernel/"/>
    
    
      <category term="Kernel" scheme="http://liujunming.github.io/tags/Kernel/"/>
    
      <category term="Concurrency" scheme="http://liujunming.github.io/tags/Concurrency/"/>
    
  </entry>
  
</feed>
