<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>L</title>
  
  <subtitle>make it simple, make it happen.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://liujunming.github.io/"/>
  <updated>2025-01-05T04:26:17.211Z</updated>
  <id>http://liujunming.github.io/</id>
  
  <author>
    <name>liujunming</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Notes about DRAM components</title>
    <link href="http://liujunming.github.io/2025/01/05/DRAM-components/"/>
    <id>http://liujunming.github.io/2025/01/05/DRAM-components/</id>
    <published>2025-01-05T00:52:40.000Z</published>
    <updated>2025-01-05T04:26:17.211Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下DRAM components相关notes。<br><img src="/images/2025/01/018.png" alt><br><a id="more"></a><br>In modern cloud servers, a CPU(socket) has several memory controllers. Each controller communicates with DIMMs through high-speed memory channels. Usually, a memory channel is shared by several DIMM slots. A DIMM has several ranks, and each is composed of sevaral DRAM chips. For typical DDR4 DIMMs, a rank is composed of 16 chips for data bits and 2 additional chips for ECC bits. <strong>A chip consists of multiple banks, which enables the access parallesim</strong>. A DRAM bank is structured as a two-dimensional cell array indexed by rows and columns. At the micro-level, a cell can store multiple bits of data, and the number of data bits stored in a cell is called the data width of a chip, which is usually denoted as x4, x8 or x16,etc.</p><ul><li>socket</li><li>memory controller</li><li>channel</li><li>DIMM(Dual In-Line Memory Module)</li><li>rank</li><li>chip</li><li>bank</li><li>cell (row, column)</li></ul><hr><p>参考资料:</p><ol><li>Predicting DRAM-Caused Node Unavailability in Hyper-Scale Clouds(DSN’22)</li><li><a href="https://info.support.huawei.com/compute/docs/zh-cn/kunpeng-knowledge/typical-scenarios-1/zh-cn_topic_0000001137649751.html" target="_blank" rel="noopener">内存结构</a></li><li><a href="https://info.support.huawei.com/compute/docs/zh-cn/kunpeng-knowledge/typical-scenarios-1/zh-cn_topic_0000001090907934.html" target="_blank" rel="noopener">内存基本概念</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下DRAM components相关notes。&lt;br&gt;&lt;img src=&quot;/images/2025/01/018.png&quot; alt&gt;&lt;br&gt;
    
    </summary>
    
      <category term="体系结构" scheme="http://liujunming.github.io/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="体系结构" scheme="http://liujunming.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Memory Scrubbing</title>
    <link href="http://liujunming.github.io/2025/01/04/Notes-about-Memory-Scrubbing/"/>
    <id>http://liujunming.github.io/2025/01/04/Notes-about-Memory-Scrubbing/</id>
    <published>2025-01-04T11:38:43.000Z</published>
    <updated>2025-01-04T13:26:49.114Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Memory Scrubbing相关notes。<a id="more"></a></p><h2 id="What"><a href="#What" class="headerlink" title="What"></a>What</h2><p>Memory scrubbing refers to the process of correcting or ‘scrubbing’ erroneously flipped bits in memory as a result of transient faults such as those caused by physical phenomena. Scrubbing is considered a RAS feature.</p><h2 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h2><p>Memory scrubbing将错误纠正后回写，可以防止内存条上的单bit错误逐渐累积形成多bit不可纠正错误。These actions provide software with early visibility for possible preventive measures such as page off-lining based on the rate of error corrections.</p><h2 id="When"><a href="#When" class="headerlink" title="When"></a>When</h2><ul><li>Patrol scrubbing proactively searches the system memory(由硬件而非软件来做), repairing correctable errors. It prevents accumulation of single-bit errors.</li><li>Demand scrubbing is the ability to write corrected data back to the memory once a correctable error is detected on a read transaction.</li></ul><h2 id="How"><a href="#How" class="headerlink" title="How"></a>How</h2><p><strong>Patrol Scrubbing consists in reading memory, checking it against ECC for errors, and overwriting with the corrected memory words when an error is discovered</strong>. </p><p>Patrol scrubbing is done using a hardware engine, on either the platform or on the memory device, which generates requests to memory addresses on the memory device. The engine generates memory requests at a predefined frequency. Given enough time, it will eventually access every memory address. The frequency in which patrol scrub generates requests produces no noticeable impact on the memory device’s quality of service.</p><p>By generating read requests to memory addresses, the patrol scrubber allows the hardware an opportunity to run ECC on a memory address and correct any correctable errors before they can become uncorrectable errors. <u>Optionally, if an uncorrectable error is discovered, the patrol scrubber can trigger a hardware interrupt and notify the software layer of its memory address</u>.</p><hr><p>参考资料:</p><ol><li><a href="https://www.intel.com/content/www/us/en/quality/reliability-availability-serviceability-xeon-paper.html" target="_blank" rel="noopener">4th Gen Intel® Xeon® Scalable Processors: Reliability, Availability, and Serviceability (RAS) Technical Paper</a></li><li><a href="https://en.wikichip.org/wiki/memory_scrubbing" target="_blank" rel="noopener">https://en.wikichip.org/wiki/memory_scrubbing</a></li><li><a href="https://community.intel.com/t5/Server-Products/Uncorrectable-Memory-Error-amp-Patrol-Scrub/m-p/545123" target="_blank" rel="noopener">Uncorrectable Memory Error &amp; Patrol Scrub</a></li><li><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/pmem-RAS.html" target="_blank" rel="noopener">Reliability, Availability, and Serviceability (RAS)</a></li><li><a href="https://uefi.org/htmlspecs/ACPI_Spec_6_4_html/05_ACPI_Software_Programming_Model/ACPI_Software_Programming_Model.html" target="_blank" rel="noopener">ACPI Software Programming Model</a></li><li><a href="https://info.support.huawei.com/compute/docs/zh-cn/kunpeng-knowledge/typical-scenarios-1/zh-cn_topic_0000001108627660.html" target="_blank" rel="noopener">Demand Scrubbing/Patrol Scrubbing（内存巡检）</a></li><li><a href="https://www.cnblogs.com/xyjk1002-rejuvenation/p/16479297.html" target="_blank" rel="noopener">内存错误和服务器内存RAS功能-DELL篇-1</a></li><li><a href="https://superuser.com/questions/372422/can-linux-scrub-memory" target="_blank" rel="noopener">Can Linux scrub memory?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Memory Scrubbing相关notes。
    
    </summary>
    
      <category term="RAS" scheme="http://liujunming.github.io/categories/RAS/"/>
    
    
      <category term="RAS" scheme="http://liujunming.github.io/tags/RAS/"/>
    
  </entry>
  
  <entry>
    <title>Notes about SDM MCA</title>
    <link href="http://liujunming.github.io/2025/01/04/Notes-about-SDM-MCA/"/>
    <id>http://liujunming.github.io/2025/01/04/Notes-about-SDM-MCA/</id>
    <published>2025-01-04T03:35:29.000Z</published>
    <updated>2025-01-04T06:38:01.401Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下SDM中MCA相关notes。<a id="more"></a></p><h2 id="1-Architecture"><a href="#1-Architecture" class="headerlink" title="1. Architecture"></a>1. Architecture</h2><ul><li>processors implement a machine-check architecture that provides a mechanism for detecting and reporting hardware (machine) errors, such as: system bus errors, ECC errors, parity errors, cache errors, and TLB errors. It consists of a set of model-specific registers (MSRs) that are used to set up machine checking and additional banks of MSRs used for recording errors that are detected.</li><li>the processor can report information on corrected machine-check errors and deliver a programmable interrupt for software to respond to MC errors, referred to as corrected machine-check error interrupt (CMCI).</li><li>Intel 64 processors support for software recovery from certain uncorrected recoverable machine check errors.</li></ul><h2 id="2-MSRs"><a href="#2-MSRs" class="headerlink" title="2. MSRs"></a>2. MSRs</h2><p><img src="/images/2025/01/005.png" alt></p><h3 id="2-1-Machine-Check-Global-Control-MSRs"><a href="#2-1-Machine-Check-Global-Control-MSRs" class="headerlink" title="2.1 Machine-Check Global Control MSRs"></a>2.1 Machine-Check Global Control MSRs</h3><h4 id="2-1-1-IA32-MCG-CAP-MSR"><a href="#2-1-1-IA32-MCG-CAP-MSR" class="headerlink" title="2.1.1 IA32_MCG_CAP MSR"></a>2.1.1 IA32_MCG_CAP MSR</h4><p>The IA32_MCG_CAP MSR is a read-only register that provides information about the machine-check architecture of the processor.</p><p><img src="/images/2025/01/006.png" alt></p><p>深入了解各个field后，其实就可以对MCA整体架构有个全局的认识了。</p><h4 id="2-1-2-IA32-MCG-STATUS-MSR"><a href="#2-1-2-IA32-MCG-STATUS-MSR" class="headerlink" title="2.1.2 IA32_MCG_STATUS MSR"></a>2.1.2 IA32_MCG_STATUS MSR</h4><p>The IA32_MCG_STATUS MSR describes the current state of the processor after a machine-check exception has occurred.</p><p><img src="/images/2025/01/007.png" alt></p><h4 id="2-1-3-IA32-MCG-CTL-MSR"><a href="#2-1-3-IA32-MCG-CTL-MSR" class="headerlink" title="2.1.3 IA32_MCG_CTL MSR"></a>2.1.3 IA32_MCG_CTL MSR</h4><p>IA32_MCG_CTL controls the reporting of machine-check exceptions.</p><h4 id="2-1-4-IA32-MCG-EXT-CTL-MSR"><a href="#2-1-4-IA32-MCG-EXT-CTL-MSR" class="headerlink" title="2.1.4 IA32_MCG_EXT_CTL MSR"></a>2.1.4 IA32_MCG_EXT_CTL MSR</h4><p>IA32_MCG_EXT_CTL.LMCE_EN (bit 0) allows the processor to signal some MCEs to only a single logical processor in the system.</p><p><img src="/images/2025/01/008.png" alt></p><h4 id="2-1-5-Enabling-Local-Machine-Check"><a href="#2-1-5-Enabling-Local-Machine-Check" class="headerlink" title="2.1.5 Enabling Local Machine Check"></a>2.1.5 Enabling Local Machine Check</h4><p>When system software has enabled LMCE, then hardware will determine if a particular error can be delivered only to a single logical processor. Software should make no assumptions about the type of error that hardware can choose to deliver as LMCE.</p><h3 id="2-2-Error-Reporting-Register-Banks"><a href="#2-2-Error-Reporting-Register-Banks" class="headerlink" title="2.2 Error-Reporting Register Banks"></a>2.2 Error-Reporting Register Banks</h3><h4 id="2-2-1-IA32-MCi-CTL-MSRs"><a href="#2-2-1-IA32-MCi-CTL-MSRs" class="headerlink" title="2.2.1 IA32_MCi_CTL MSRs"></a>2.2.1 IA32_MCi_CTL MSRs</h4><p><img src="/images/2025/01/009.png" alt></p><h4 id="2-2-2-IA32-MCi-STATUS-MSRs"><a href="#2-2-2-IA32-MCi-STATUS-MSRs" class="headerlink" title="2.2.2 IA32_MCi_STATUS MSRs"></a>2.2.2 IA32_MCi_STATUS MSRs</h4><p><img src="/images/2025/01/010.png" alt></p><p><img src="/images/2025/01/011.png" alt></p><h4 id="2-2-3-IA32-MCi-ADDR-MSRs"><a href="#2-2-3-IA32-MCi-ADDR-MSRs" class="headerlink" title="2.2.3 IA32_MCi_ADDR MSRs"></a>2.2.3 IA32_MCi_ADDR MSRs</h4><p><img src="/images/2025/01/012.png" alt></p><h4 id="2-2-4-IA32-MCi-MISC-MSRs"><a href="#2-2-4-IA32-MCi-MISC-MSRs" class="headerlink" title="2.2.4 IA32_MCi_MISC MSRs"></a>2.2.4 IA32_MCi_MISC MSRs</h4><p><img src="/images/2025/01/013.png" alt></p><h4 id="2-2-5-IA32-MCi-CTL2-MSRs"><a href="#2-2-5-IA32-MCi-CTL2-MSRs" class="headerlink" title="2.2.5 IA32_MCi_CTL2 MSRs"></a>2.2.5 IA32_MCi_CTL2 MSRs</h4><p><img src="/images/2025/01/014.png" alt></p><h2 id="3-Enhanced-Cache-Error-reporting"><a href="#3-Enhanced-Cache-Error-reporting" class="headerlink" title="3. Enhanced Cache Error reporting"></a>3. Enhanced Cache Error reporting</h2><ul><li>In earlier Intel processors, cache status was based on the number of correction events that occurred in a cache.</li><li>In “threshold-based error status”, cache status is based on the number of lines (ECC blocks) in a cache that incur repeated corrections.</li><li>A processor that supports enhanced cache error reporting contains hardware that tracks the operating status of certain caches and provides an indicator of their “health”.<ul><li>The hardware reports a “green” status when the number of lines that incur repeated corrections is at or below a pre-defined threshold</li><li>a “yellow” status when the number of affected lines exceeds the threshold. Yellow status means that the cache reporting the event is operating correctly, but you should schedule the system for servicing within a few weeks.</li></ul></li></ul><h2 id="4-Corrected-Machine-Check-Error-Interrupt"><a href="#4-Corrected-Machine-Check-Error-Interrupt" class="headerlink" title="4. Corrected Machine Check Error Interrupt"></a>4. Corrected Machine Check Error Interrupt</h2><p>待另择篇幅整理</p><h2 id="5-Recovery-of-Uncorrected-Recoverable-UCR-Errors"><a href="#5-Recovery-of-Uncorrected-Recoverable-UCR-Errors" class="headerlink" title="5. Recovery of Uncorrected Recoverable(UCR) Errors"></a>5. Recovery of Uncorrected Recoverable(UCR) Errors</h2><p>Recovery of uncorrected recoverable machine check errors is an enhancement in machine-check architecture. <strong>This allow system software to perform recovery action on certain class of uncorrected errors and continue execution.</strong></p><h3 id="5-1-Detection-of-Software-Error-Recovery-Support"><a href="#5-1-Detection-of-Software-Error-Recovery-Support" class="headerlink" title="5.1 Detection of Software Error Recovery Support"></a>5.1 Detection of Software Error Recovery Support</h3><p>The new class of architectural MCA errors from which system software can attempt recovery is called <u><strong>Uncorrected Recoverable (UCR)</strong></u> Errors. <u>UCR errors are uncorrected errors that have been detected and signaled but have not corrupted the processor context</u>. For certain UCR errors, this means that once system software has performed a certain recovery action, it is possible to continue execution on this processor. UCR error reporting provides an error containment mechanism for data poisoning. The machine check handler will use the error log information from the error reporting registers to analyze and implement specific error recovery actions for UCR errors.</p><h3 id="5-2-UCR-Error-Reporting-and-Logging"><a href="#5-2-UCR-Error-Reporting-and-Logging" class="headerlink" title="5.2 UCR Error Reporting and Logging"></a>5.2 UCR Error Reporting and Logging</h3><p>IA32_MCi_STATUS MSR is used for reporting UCR errors and existing corrected or uncorrected errors.<br>When IA32_MCG_CAP[24] is set, a UCR error is indicated by the following bit settings in the IA32_MCi_STATUS register:</p><ul><li>Valid (bit 63) = 1</li><li>UC(bit61)=1</li><li>PCC(bit57)=0</li></ul><p>In addition, the IA32_MCi_STATUS register bit fields, bits 56:55, are defined (see Figure 16-6) to provide additional information to help system software to properly identify the necessary recovery action for the UCR error:</p><ul><li>S (Signaling) flag, bit 56</li><li>AR (Action Required) flag, bit 55 </li></ul><h3 id="5-3-UCR-Error-Classification"><a href="#5-3-UCR-Error-Classification" class="headerlink" title="5.3 UCR Error Classification"></a>5.3 UCR Error Classification</h3><ul><li><u>Uncorrected no action required (UCNA)</u> - is a UCR error that is not signaled via a machine check exception and, instead, is reported to system software as a corrected machine check error. </li><li><u>Software recoverable action optional (SRAO)</u> - a UCR error is signaled either via a machine check exception or CMCI. System software recovery action is optional and not required to continue execution from this machine check exception.</li><li><u>Software recoverable action required (SRAR)</u> - a UCR error that requires system software to take a recovery action on this processor before scheduling another stream of execution on this processor. </li></ul><p><img src="/images/2025/01/015.png" alt></p><h3 id="5-4-UCR-Error-Overwrite-Rules"><a href="#5-4-UCR-Error-Overwrite-Rules" class="headerlink" title="5.4 UCR Error Overwrite Rules"></a>5.4 UCR Error Overwrite Rules</h3><p>In general, the overwrite rules are as follows:</p><ul><li>UCR errors will overwrite corrected errors.</li><li>Uncorrected (PCC=1) errors overwrite UCR (PCC=0) errors.</li><li>UCR errors are not written over previous UCR errors.</li><li>Corrected errors do not write over previous UCR errors.</li></ul><h2 id="6-Interpreting-the-MCA-Error-Codes"><a href="#6-Interpreting-the-MCA-Error-Codes" class="headerlink" title="6. Interpreting the MCA Error Codes"></a>6. Interpreting the MCA Error Codes</h2><p>When the processor detects a machine-check error condition, it writes a 16-bit error code to the MCA error code field of one of the IA32_MCi_STATUS registers and sets the VAL (valid) flag in that register. The processor may also write a 16-bit model-specific error code in the IA32_MCi_STATUS register depending on the implementation of the machine-check architecture of the processor.</p><h3 id="6-1-Simple-Error-Codes"><a href="#6-1-Simple-Error-Codes" class="headerlink" title="6.1 Simple Error Codes"></a>6.1 Simple Error Codes</h3><p>Simple error codes indicate global error information.</p><p><img src="/images/2025/01/016.png" alt></p><h3 id="6-2-Compound-Error-Codes"><a href="#6-2-Compound-Error-Codes" class="headerlink" title="6.2 Compound Error Codes"></a>6.2 Compound Error Codes</h3><p>Compound error codes describe errors related to the TLBs, memory, caches, bus and interconnect logic, and internal timer. <strong>A set of sub-fields is common to all of compound errors. These sub-fields describe the type of access, level in the cache hierarchy, and type of request</strong>.</p><p><img src="/images/2025/01/017.png" alt></p><ul><li>Transaction Type (TT) Sub-Field</li><li>Level (LL) Sub-Field</li><li>Request (RRRR) Sub-Field</li><li>Bus and Interconnect Errors</li><li>Memory Controller and Extended Memory Errors</li></ul><h3 id="6-3-Architecturally-Defined-UCR-Errors"><a href="#6-3-Architecturally-Defined-UCR-Errors" class="headerlink" title="6.3 Architecturally Defined UCR Errors"></a>6.3 Architecturally Defined UCR Errors</h3><ul><li>Architecturally Defined SRAO Errors</li><li>Architecturally Defined SRAR Errors</li></ul><h3 id="6-4-Multiple-MCA-Errors"><a href="#6-4-Multiple-MCA-Errors" class="headerlink" title="6.4 Multiple MCA Errors"></a>6.4 Multiple MCA Errors</h3><p>When multiple MCA errors are detected within a certain detection window, the processor may aggregate the reporting of these errors together as a single event, i.e., a single machine exception condition. If this occurs, system software <u>may find multiple MCA errors logged in different MC banks on one logical processor</u> or <u>find multiple MCA errors logged across different processors for a single machine check broadcast event</u>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下SDM中MCA相关notes。
    
    </summary>
    
      <category term="RAS" scheme="http://liujunming.github.io/categories/RAS/"/>
    
    
      <category term="SDM" scheme="http://liujunming.github.io/tags/SDM/"/>
    
      <category term="RAS" scheme="http://liujunming.github.io/tags/RAS/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Device Memory TCP</title>
    <link href="http://liujunming.github.io/2025/01/01/Notes-about-Device-Memory-TCP/"/>
    <id>http://liujunming.github.io/2025/01/01/Notes-about-Device-Memory-TCP/</id>
    <published>2025-01-01T11:10:46.000Z</published>
    <updated>2025-01-01T12:04:42.997Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Device Memory TCP相关notes。<a id="more"></a></p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Device memory TCP is a proposal for transferring data to and/or from device memory efficiently, without bouncing the data to a host memory buffer.</p><h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p><img src="/images/2025/01/001.png" alt></p><p><img src="/images/2025/01/002.png" alt></p><p><img src="/images/2025/01/003.png" alt></p><p>A large amount of data transfers have device memory as the source and/or destination. Accelerators drastically increased the volume of such transfers. Some examples include:</p><ul><li>ML accelerators transferring large amounts of training data from storage into GPU/TPU memory. In some cases ML training setup time can be as long as 50% of TPU compute time, improving data transfer throughput &amp; efficiency can help improving GPU/TPU utilization.</li><li>Distributed training, where ML accelerators, such as GPUs on different hosts, exchange data among them.</li><li>Distributed raw block storage applications transfer large amounts of data with remote SSDs, much of this data does not require host processing.</li></ul><p>Today, the majority of the Device-to-Device data transfers the network are implemented as the following low level operations: Device-to-Host copy, Host-to-Host network transfer, and Host-to-Device copy.</p><p>The implementation is suboptimal, especially for bulk data transfers, and can put significant strains on system resources, such as host memory bandwidth, PCIe bandwidth, etc.</p><h2 id="Proposal"><a href="#Proposal" class="headerlink" title="Proposal"></a>Proposal</h2><p><img src="/images/2025/01/004.png" alt></p><p>We attempt to optimize this use case by implementing socket APIs that enable the user to:</p><ol><li>send device memory across the network directly, and</li><li>receive incoming network packets directly into device memory.</li></ol><p>Packet payloads go directly from the NIC to device memory for receive and from device memory to NIC for transmit. Packet headers go to/from host memory and are processed by the TCP/IP stack normally.</p><p>The NIC must support header split to achieve this. i.e. the capability to split incoming packets into a header + payload and to put each into a separate buffer. Device Memory works by using device memory for the packet payload, and host memory for the packet headers.</p><h2 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h2><ul><li>Alleviate host memory bandwidth pressure, compared to existing network-transfer + device-copy semantics.</li><li>Alleviate PCIe BW pressure, by limiting data transfer to the lowest level of the PCIe tree, compared to traditional path which sends data through the root complex.</li></ul><hr><p>参考资料:</p><ol><li><a href="https://docs.kernel.org/networking/devmem.html" target="_blank" rel="noopener">docs.kernel:Device Memory TCP</a></li><li><a href="https://netdevconf.org/0x17/sessions/talk/device-memory-tcp.html" target="_blank" rel="noopener">netdevconf:Device Memory TCP</a></li><li><a href="https://lore.kernel.org/netdev/20240831004313.3713467-1-almasrymina@google.com/" target="_blank" rel="noopener">[PATCH net-next v24 00/13] Device Memory TCP</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Device Memory TCP相关notes。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about AMD Processor Hierarchy</title>
    <link href="http://liujunming.github.io/2024/12/22/Notes-about-AMD-Processor-Hierarchy/"/>
    <id>http://liujunming.github.io/2024/12/22/Notes-about-AMD-Processor-Hierarchy/</id>
    <published>2024-12-22T10:14:50.000Z</published>
    <updated>2024-12-22T11:05:21.491Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/2024/12/008.jpg" alt><a id="more"></a></p><p>This is a simplified configuration of an EPYC Rome node with two sockets. Each socket contains eight <strong>Core Complex Dies</strong> (CCDs, each enclosed in a green box) and one I/O die (IOD, enclosed in a yellow box). The infinity sign (♾) represents the Infinity Fabric. Each CCD contains two <strong>Core Complexes</strong> (CCXs). Each CCX has 4 cores and 16 MB of L3 cache. Thus, there are 64 cores per socket and 128 cores per node.</p><p>The Rome processor hierarchy is as follows:</p><ul><li>Core: A CPU core has private L1I, L1D, and L2 caches, which are shared by two hyperthreads on the core.</li><li>CCX: A core complex includes four cores and a common L3 cache of 16 MB. Different CCXs do not share L3.</li><li>CCD: A core complex die includes two CCXs and an Infinity Link to the I/O die (IOD). The CCDs connect to memory, I/O, and each other through the IOD.</li><li>Socket: A socket includes eight CCDs (total of 64 cores), a common centralized I/O die (includes eight unified memory controllers and eight IO x16 PCIe 4.0 lanes—total of 128 lanes), and a link to the network interface controller (NIC).</li><li>Node: A node includes two sockets and a network interface controller (NIC).</li></ul><hr><p>参考资料:</p><ol><li><a href="https://www.nas.nasa.gov/hecc/support/kb/amd-rome-processors_658.html" target="_blank" rel="noopener">AMD Rome Processors</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/2024/12/008.jpg&quot; alt&gt;
    
    </summary>
    
      <category term="AMD" scheme="http://liujunming.github.io/categories/AMD/"/>
    
    
      <category term="AMD" scheme="http://liujunming.github.io/tags/AMD/"/>
    
  </entry>
  
  <entry>
    <title>Notes about FUSE filesystem</title>
    <link href="http://liujunming.github.io/2024/12/21/Notes-about-FUSE-filesystem/"/>
    <id>http://liujunming.github.io/2024/12/21/Notes-about-FUSE-filesystem/</id>
    <published>2024-12-21T11:07:07.000Z</published>
    <updated>2024-12-22T00:31:42.645Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p><img src="/images/2024/12/005.png" alt><a id="more"></a></p><h2 id="tutorial"><a href="#tutorial" class="headerlink" title="tutorial"></a>tutorial</h2><p><img src="/images/2024/12/007.png" alt></p><p>very nice tutorial: <a href="https://maastaar.net/fuse/linux/filesystem/c/2016/05/21/writing-a-simple-filesystem-using-fuse/" target="_blank" rel="noopener">Writing a Simple Filesystem Using FUSE in C</a></p><h3 id="Making-a-call-into-a-FUSE-file-system"><a href="#Making-a-call-into-a-FUSE-file-system" class="headerlink" title="Making a call into a FUSE file system"></a>Making a call into a FUSE file system</h3><p><img src="/images/2024/12/006.gif" alt></p><ol><li>A program, such as ls, mkdir makes a call to a file system routine. For example, open(“/test/fuse/file1.txt”). This call gets sent to the kernel.</li><li>If this file is in a FUSE volume, the kernel passes it on to the FUSE kernel module, which then passes it on to the implementation of that file system.</li><li>The implementation of open then refers to the actual data structures that represent the file system and returns a file handle. It is open’s job to take a concrete view of data (bits stored on a hard drive) and present an abstract view (a hierarchically organized file system).</li><li>The kernel returns the result of the open function to the program that originally made the call.</li></ol><p>Cited From <a href="https://www.cs.cmu.edu/~fp/courses/15213-s07/lectures/15-filesys/index.html" target="_blank" rel="noopener">File Systems and FUSE</a>.</p><h3 id="simple-fuse-example"><a href="#simple-fuse-example" class="headerlink" title="simple fuse example"></a>simple fuse example</h3><ul><li><a href="https://github.com/JulesWang/helloworld-fuse/tree/master" target="_blank" rel="noopener">helloworld-fuse</a></li><li><a href="https://github.com/libfuse/libfuse/blob/master/example/hello.c" target="_blank" rel="noopener">libfuse/example/hello.c</a></li></ul><h3 id="辅助资料"><a href="#辅助资料" class="headerlink" title="辅助资料"></a>辅助资料</h3><ul><li><a href="https://www.cs.hmc.edu/~geoff/classes/hmc.cs135.201109/homework/fuse/fuse_doc.html" target="_blank" rel="noopener">CS135 FUSE Documentation</a></li><li><a href="https://www.cs.nmsu.edu/~pfeiffer/fuse-tutorial/" target="_blank" rel="noopener">Writing a FUSE Filesystem: a Tutorial</a></li><li><a href="https://github.com/osxfuse/fuse/blob/master/doc/how-fuse-works" target="_blank" rel="noopener">How Fuse-1.3 Works</a></li><li><a href="https://www.bilibili.com/video/BV1NS4y1L7Me/" target="_blank" rel="noopener">linux内核开发第38讲：linux基于fuse实现自定义文件系统整体架构</a></li></ul><h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><p>FAST’17 paper: <a href="https://www.usenix.org/system/files/conference/fast17/fast17-vangoor.pdf" target="_blank" rel="noopener">To FUSE or Not to FUSE: Performance of User-Space File Systems</a>，<a href="https://www.usenix.org/sites/default/files/conference/protected-files/fast17_slides_vangoor.pdf" target="_blank" rel="noopener">slides</a>也非常硬核!</p><h3 id="辅助资料-1"><a href="#辅助资料-1" class="headerlink" title="辅助资料"></a>辅助资料</h3><ul><li><a href="https://georgesims21.github.io/fuse/" target="_blank" rel="noopener">George’s Blog FUSE</a></li><li><a href="https://www.bilibili.com/video/BV1r24y157gm/" target="_blank" rel="noopener">FUSE 文件系统浅析 - 张老师</a></li><li><a href="https://zhuanlan.zhihu.com/p/143256077" target="_blank" rel="noopener">用户态文件系统 - FUSE</a></li><li><a href="https://www.kernel.org/doc/html/next/filesystems/fuse.html" target="_blank" rel="noopener">kernel doc fuse</a></li></ul><h2 id="Manual"><a href="#Manual" class="headerlink" title="Manual"></a>Manual</h2><ul><li><a href="https://man7.org/linux/man-pages/man4/fuse.4.html" target="_blank" rel="noopener">fuse(4)</a></li><li><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/uapi/linux/fuse.h" target="_blank" rel="noopener">include/uapi/linux/fuse.h</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/2024/12/005.png&quot; alt&gt;
    
    </summary>
    
      <category term="文件系统" scheme="http://liujunming.github.io/categories/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="文件系统" scheme="http://liujunming.github.io/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Linux Transmit Packet Steering(XPS) technology</title>
    <link href="http://liujunming.github.io/2024/12/21/Notes-about-Linux-Transmit-Packet-Steering-XPS-technology/"/>
    <id>http://liujunming.github.io/2024/12/21/Notes-about-Linux-Transmit-Packet-Steering-XPS-technology/</id>
    <published>2024-12-21T00:07:27.000Z</published>
    <updated>2024-12-21T05:01:50.936Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Linux XPS(Transmit Packet Steering)相关notes。<a id="more"></a></p><h2 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h2><blockquote><p>The Linux network stack maps each core C to a different Tx queue Q, such that Q’s memory is allocated from C’s node. Additionally, memory allocations of packets transmitted via Q are likewise fulfilled using the same node. Cores can then transmit simultaneously through their individual queues in an uncoordinated, NU(D)MA-friendly manner while avoiding synchronization overheads. When a thread T that executes on C issues a system call to open a socket file descriptor S, the network stack associates Q with S, saving Q’s identifier in the socket data structure. After that, whenever T transmits through S, the network stack checks that T still runs on C. If it does not, the network stack updates S to point to the queue of T ’s new core. (The actual modification happens after Q is drained from any outstanding packets that originated from S, to avoid out-of-order transmissions.)</p></blockquote><h2 id="2-Optimization"><a href="#2-Optimization" class="headerlink" title="2. Optimization"></a>2. Optimization</h2><h3 id="2-1-reduce-contention"><a href="#2-1-reduce-contention" class="headerlink" title="2.1 reduce contention"></a>2.1 reduce contention</h3><p>contention on the device queue lock is significantly reduced since fewer CPUs contend for the same queue(contention can be eliminated completely if each CPU has its own transmit queue).</p><h3 id="2-2-reduce-cache-miss-rate-on-transmit-completion"><a href="#2-2-reduce-cache-miss-rate-on-transmit-completion" class="headerlink" title="2.2 reduce cache miss rate on transmit completion"></a>2.2 reduce cache miss rate on transmit completion</h3><p>cache miss rate on transmit completion is reduced, in particular for data cache lines that hold the <code>sk_buff</code> structures.</p><p>网卡发完包后，会给CPU发送中断；接着linux内核协议栈就会调用<code>kfree_skb</code>，此时就会访问到<code>sk_buff</code> structures。如果发送数据包的core与调用<code>kfree_skb</code>的core一样，那么<code>sk_buff</code> structures的cache miss rate就会降低。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kfree_skb</span><br><span class="line">└── kfree_skb_reason</span><br><span class="line">    └── skb_unref</span><br><span class="line">        └── skb-&gt;users</span><br></pre></td></tr></table></figure><h3 id="2-3-DMA-Buffer-NUMA-Affinity"><a href="#2-3-DMA-Buffer-NUMA-Affinity" class="headerlink" title="2.3 DMA Buffer NUMA Affinity"></a>2.3 DMA Buffer NUMA Affinity</h3><p>网卡发包时，DMA本node的内存即可，无需跨numa node，可以提升DMA的性能。详情可以参考<a href="/2024/11/17/%E8%BD%AC%E8%BD%BD-Linux-NUMA-Optimization-1/#3-2-1-DMA-Buffer-NUMA-Affinity">DMA Buffer NUMA Affinity</a>。</p><hr><p>参考资料:</p><ol><li>IOctopus: Outsmarting Nonuniform DMA(ASPLOS’20)</li><li><a href="https://www.kernel.org/doc/Documentation/networking/scaling.txt" target="_blank" rel="noopener">Scaling in the Linux Networking Stack</a></li><li><a href="https://zhuanlan.zhihu.com/p/148756667" target="_blank" rel="noopener">Linux网络栈的性能缩放</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Linux XPS(Transmit Packet Steering)相关notes。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about network RFS and aRFS</title>
    <link href="http://liujunming.github.io/2024/12/08/Notes-about-network-RFS-and-aRFS/"/>
    <id>http://liujunming.github.io/2024/12/08/Notes-about-network-RFS-and-aRFS/</id>
    <published>2024-12-08T04:49:12.000Z</published>
    <updated>2024-12-08T13:24:24.082Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下network的RFS(Receive Flow Steering)和aRFS(Accelerated Receive Flow Steering)相关notes。<a id="more"></a></p><h3 id="RFS"><a href="#RFS" class="headerlink" title="RFS"></a>RFS</h3><p><a href="/2024/05/05/Notes-about-RSS-Receive-Side-Scaling/">RSS</a>/<a href="/2024/12/01/Notes-about-Linux-Receive-Packet-Steering-RPS-technology/">RPS</a>很好地保证了数据包处理的负载均衡，可以将处理任务合理的分配到所有的 CPU 上。</p><p>但是，有时候我们还需要考虑其他的因素。比如，网卡收到了属于一个运行在 CPU0 上的进程的数据包，那么这些数据包被 CPU0 处理会比其他 CPU 处理更高效。</p><p>原因很简单直观，数据在 CPU 内传递比跨 CPU 传递要更节省时间。因此，我们<strong>希望数据包尽量能够被其所属的进程所在的CPU处理，至少能够被同属一个 NUMA域的CPU处理</strong>。</p><p>RFS 机制就是为了实现这一点。使用 hash 函数根据包头信息计算得到一个 hash 值，然后作为索引查表。RFS 所查找的匹配表（<code>rps_sock_flow_table</code>）中存储的是数据包所属进程所在的 CPU。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hash value] : [CPU id]</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>如果能查找到有效的CPU，就将数据包入队到CPU对应的backlog队列中；如果查找不到，那么就直接按照 RPS 机制转发。</p><p>与 RPS 预先配置好的 CPU 列表不同，<code>rps_sock_flow</code>表是动态更新的。如果有数据包的收发操作，如 <code>inet_recvmsg()</code>, <code>inet_sendmsg()</code>, <code>inet_sendpage()</code>, <code>tcp_splice_read()</code> 等操作，则会插入新的值。类似的情况还发生在进程被调度到新的 CPU 的时候。这时候就需要更新匹配表中的值。如果原来的 CPU 队列上还有未处理完的数据包，那么就会发生乱序。</p><p>为了避免乱序，RFS 使用了另一个表 —— <code>rps_dev_flow</code> 表，每个网卡队列对应一个该表。该表的索引依旧是包头的 hash 值，每个表项对应两个字段：1) 现在的 CPU（也就是该数据包所属流已经把数据包放在其队列上等待其内核处理的 CPU）号。2) 当该流最后一个数据包到达后，该 CPU 的 backlog 队列的尾计数器值(用来判断原CPU 队列上有没有未处理完的包)。</p><p>当进程切换 CPU 时，先判断原 CPU 队列上有没有未处理完的包，如果有就不切换；如果没有，就切换。</p><p><img src="/images/2024/12/003.png" alt></p><h3 id="aRFS"><a href="#aRFS" class="headerlink" title="aRFS"></a>aRFS</h3><p>Accelerated RFS 之于 RFS 相当于 RSS 之于 RPS。Accelerated RFS 在硬件上就可以选择正确的队列，随后触发该数据包所属流所在的 CPU 的中断。由此可见，如果想要在硬件上实现队列选择，我们需要一个从流到硬件队列的对应关系。</p><p><strong>aRFS允许网卡在选择队列时，直接将数据包放入应用程序所在CPU对应的队列</strong>。</p><ol><li>维护规则: 内核自动维护socket五元组、socket应用程序所在的CPU和CPU对应的接收队列的映射关系<ul><li>socket五元组 -&gt; CPU(从流到 CPU 的映射关系，记录在 <code>rps_dev_flow</code> 表中)</li><li>CPU -&gt; RX queue(CPU 和硬件队列的关系，通过 <code>/proc/irq/&lt;irq_num&gt;/smp_affinity</code> 进行配置)</li></ul></li><li>下发规则: 内核根据上述映射关系，在用户态接收数据时，将五元组与CPU对应的规则下发到网卡 </li><li>匹配规则: 网卡接收到的所有报文会根据aRFS规则进行匹配并转发到相应的接收队列</li></ol><p><img src="/images/2024/12/004.png" alt></p><p>每当<code>rps_dev_flow</code>表中的条目被更新，网络协议栈就会调用驱动中的<code>ndo_rx_flow_steer</code>函数来更新流到硬件队列的对应关系。</p><p>Modern NICs support aRFS by (1) providing the OS with an API that allows it to associate networking flows with Rx queues, and by (2) steering incoming packets accordingly. When the OS migrates thread T away from  core C, the OS updates the NIC regarding thread T ’s new queue using the aRFS API. The actual update is delayed until the original queue is drained from packets of socket file descriptor S(flow在old core上的排空), to avoid out-of-order receives.</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>理解aRFS或许更为关键</li><li>aRFS允许网卡在选择队列时，直接将数据包放入应用程序所在CPU对应的队列</li></ul><hr><p>参考资料:</p><ol><li><a href="https://borispis.github.io/files/2020-ioctopus.pdf" target="_blank" rel="noopener">IOctopus: Outsmarting Nonuniform DMA</a></li><li><a href="https://www.kernel.org/doc/Documentation/networking/scaling.txt" target="_blank" rel="noopener">Scaling in the Linux Networking Stack</a></li><li><a href="https://blog.csdn.net/dog250/article/details/80025959" target="_blank" rel="noopener">Linux RPS/RFS 实现原理浅析</a></li><li><a href="https://garycplin.blogspot.com/2017/06/linux-network-scaling-receives-packets.html" target="_blank" rel="noopener">Linux Network Scaling: Receiving Packets</a></li><li><a href="https://blog.csdn.net/weixin_45485072/article/details/133248630" target="_blank" rel="noopener">Understanding Host Network Stack Overheads论文阅读笔记</a></li><li><a href="https://blog.luckyoung.org/2023/23-02-13_network-parameters/" target="_blank" rel="noopener">网络参数 RSS、RPS、RFS、aRFS 学习总结</a></li><li><a href="https://arthurchiao.art/blog/linux-net-stack-implementation-rx-zh/#684-arfs-hardware-accelerated-rfs" target="_blank" rel="noopener">Linux 网络栈接收数据（RX）：原理及内核实现（2022）</a></li><li><a href="https://zhuanlan.zhihu.com/p/148756667" target="_blank" rel="noopener">Linux网络栈的性能缩放</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下network的RFS(Receive Flow Steering)和aRFS(Accelerated Receive Flow Steering)相关notes。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Linux Receive Packet Steering(RPS) technology</title>
    <link href="http://liujunming.github.io/2024/12/01/Notes-about-Linux-Receive-Packet-Steering-RPS-technology/"/>
    <id>http://liujunming.github.io/2024/12/01/Notes-about-Linux-Receive-Packet-Steering-RPS-technology/</id>
    <published>2024-11-30T16:56:52.000Z</published>
    <updated>2024-12-01T08:59:55.237Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Linux RPS(Receive Packet Steering)相关notes。<a id="more"></a></p><h3 id="Prerequisite"><a href="#Prerequisite" class="headerlink" title="Prerequisite"></a>Prerequisite</h3><p><a href="/2024/05/05/Notes-about-RSS-Receive-Side-Scaling/">RSS(Receive Side Scaling)</a></p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p>Receive Packet Steering (RPS) is logically a software implementation of RSS.</p><h3 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h3><p>RPS has some advantages over RSS: </p><ol><li>it can be used with any NIC</li><li>software filters can easily be added to hash over new protocols</li><li>it does not increase hardware device interrupt rate (although it does IPIs)</li></ol><p>在没有RSS功能的网卡中，RPS还是有价值的。</p><h3 id="How"><a href="#How" class="headerlink" title="How"></a>How</h3><p><img src="/images/2024/12/001.png" alt></p><p>RPS其实就是一个<strong>软件对CPU负载重分发</strong>的机制。其使能的作用点在CPU开始处理软中断，即下面的地方：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">netif_rx_internal</span><br><span class="line">netif_receive_skb_internal</span><br></pre></td></tr></table></figure></p><p><img src="/images/2024/12/002.png" alt></p><p>Whereas RSS selects the queue and hence CPU that will run the hardware interrupt handler, RPS selects the CPU to perform protocol processing above the interrupt handler. This is accomplished by placing the packet on the desired CPU backlog queue and waking up the CPU for processing.(RSS选择队列，从而选择了运行硬件中断处理程序的CPU；而RPS在中断处理程序之上选择CPU执行协议处理。这是通过将数据包放置在所需的CPU积压队列中并唤醒CPU进行处理来实现的。)</p><hr><p>参考资料:</p><ol><li><a href="https://blog.csdn.net/dog250/article/details/80025959" target="_blank" rel="noopener">Linux RPS/RFS 实现原理浅析</a></li><li><a href="https://www.kernel.org/doc/Documentation/networking/scaling.txt" target="_blank" rel="noopener">Scaling in the Linux Networking Stack</a></li><li><a href="https://zhuanlan.zhihu.com/p/148756667" target="_blank" rel="noopener">Linux网络栈的性能缩放</a></li><li><a href="https://garycplin.blogspot.com/2017/06/linux-network-scaling-receives-packets.html" target="_blank" rel="noopener">Linux Network Scaling: Receiving Packets</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Linux RPS(Receive Packet Steering)相关notes。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>virtio-net RSS Inner Header Hash</title>
    <link href="http://liujunming.github.io/2024/11/24/virtio-net-Inner-Header-Hash/"/>
    <id>http://liujunming.github.io/2024/11/24/virtio-net-Inner-Header-Hash/</id>
    <published>2024-11-24T02:03:40.000Z</published>
    <updated>2024-11-24T06:16:48.781Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下virtio-net RSS Inner Header Hash的相关notes。<a id="more"></a></p><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><p><a href="/2024/11/23/Notes-about-virtio-net-RSS-featute/">virtio-net RSS feature</a></p><p>需要理解网络<a href="https://www.wikiwand.com/en/articles/Tunneling_protocol" target="_blank" rel="noopener">Tunnel协议</a>，清楚Outer Header与Inner Header的概念。<br><img src="/images/2024/11/021.png" alt></p><h2 id="distribute-different-flows"><a href="#distribute-different-flows" class="headerlink" title="distribute different flows"></a>distribute different flows</h2><p>传统隧道协议由于在外头部中缺少足够的熵，导致收包时报文汇聚到单个队列上，无法发挥多队列收包的优势。</p><p>For legacy systems, they may lack entropy fields which modern protocols have in the outer header, resulting in multiple flows with the same outer header but different inner headers being directed to the same receive queue. This results in poor receive performance.</p><p>To address this limitation, inner header hash can be used to enable the device to advertise the capability to calculate the hash for the inner packet, regaining better receive performance.</p><blockquote><p>Legacy tunneling protocols, lacking the outer header entropy, can use RSS with the inner header hash to distribute flows with identical outer but different inner headers across various queues, improving performance.</p></blockquote><h2 id="identify-same-flow"><a href="#identify-same-flow" class="headerlink" title="identify same flow"></a>identify same flow</h2><blockquote><p>Identify an inner flow distributed across multiple outer tunnels.</p></blockquote><p>现代隧道协议在某些场景需要通过将同一条流接收在同一个队列上以获得性能收益，而外头部不容易做到。</p><p>Currently, a received encapsulated packet has an outer and an inner header, but the virtio device is unable to calculate the hash for the inner header. The same flow can traverse through different tunnels, resulting in the encapsulated packets being spread across multiple receive queues (refer to the figure below). However, in certain scenarios, we may need to direct these encapsulated packets of the same flow to a single receive queue. This facilitates the processing of the flow by the same CPU to improve performance (warm caches, less locking, etc.).</p><pre><code>client1                    client2   |        +-------+         |   +-------&gt;|tunnels|&lt;--------+            +-------+               |  |               v  v       +-----------------+       | monitoring host |       +-----------------+</code></pre><p>To achieve this, the device can calculate a symmetric hash based on the inner headers of the same flow.</p><h3 id="symmetric-hash"><a href="#symmetric-hash" class="headerlink" title="symmetric hash"></a>symmetric hash</h3><blockquote><p>symmetric hash确保同一个五元组(无论方向)哈希到同一个桶中，即当源IP和目标IP、源端口和目标端口互换时，哈希值仍然能保持一致。</p></blockquote><p><img src="/images/2024/11/022.png" alt></p><p><img src="/images/2024/11/023.png" alt></p><p><a href="https://lore.kernel.org/virtio-dev/e573702a-9a2e-d210-f13a-f0b241442991@linux.alibaba.com/" target="_blank" rel="noopener">https://lore.kernel.org/virtio-dev/e573702a-9a2e-d210-f13a-f0b241442991@linux.alibaba.com/</a></p><h2 id="Spec描述"><a href="#Spec描述" class="headerlink" title="Spec描述"></a>Spec描述</h2><p>VIRTIO_NET_F_HASH_TUNNEL</p><p><a href="https://docs.oasis-open.org/virtio/virtio/v1.3/csd01/virtio-v1.3-csd01.html#x1-2620004" target="_blank" rel="noopener">5.1.6.4.4 Inner Header Hash</a></p><blockquote><p>5.1.6.4.4.1 Encapsulated packet<br>Multiple tunneling protocols allow encapsulating an inner, payload packet in an outer, encapsulated packet. The encapsulated packet thus contains an outer header and an inner header, and the device calculates the hash over either the inner header or the outer header.<br>If VIRTIO_NET_F_HASH_TUNNEL is negotiated and a received encapsulated packet’s outer header matches one of the encapsulation types enabled in enabled_tunnel_types, then the device uses the inner header for hash calculations (only a single level of encapsulation is currently supported).<br>If VIRTIO_NET_F_HASH_TUNNEL is negotiated and a received packet’s (outer) header does not match any encapsulation types enabled in enabled_tunnel_types, then the device uses the outer header for hash calculations.</p></blockquote><hr><p>参考资料:</p><ol><li><a href="https://networkdirection.net/articles/routingandswitching/gretunnels/" target="_blank" rel="noopener">GRE Tunnels</a></li><li><a href="https://lore.kernel.org/virtio-dev/20230703152711.106008-1-hengqi@linux.alibaba.com/" target="_blank" rel="noopener">[PATCH v21] virtio-net: support inner header hash</a></li><li><a href="https://developer.aliyun.com/article/1257786" target="_blank" rel="noopener">高性能网络 SIG 月度动态：联合 IBM 就 SMC v2.1 协议升级达成一致，ANCK 率先完成支持</a></li><li><a href="https://developer.aliyun.com/article/1305988" target="_blank" rel="noopener">高性能网络 SIG 月度动态：ANCK 首次支持 SMCv2.1，virtio 规范支持隧道报文内头部哈希</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下virtio-net RSS Inner Header Hash的相关notes。
    
    </summary>
    
      <category term="virtio" scheme="http://liujunming.github.io/categories/virtio/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about virtio-net RSS feature</title>
    <link href="http://liujunming.github.io/2024/11/23/Notes-about-virtio-net-RSS-featute/"/>
    <id>http://liujunming.github.io/2024/11/23/Notes-about-virtio-net-RSS-featute/</id>
    <published>2024-11-23T10:33:03.000Z</published>
    <updated>2024-11-24T00:25:05.878Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下virtio-net中<a href="/2024/05/05/Notes-about-RSS-Receive-Side-Scaling/">RSS(Receive Side Scaling)</a>的具体实现。<a id="more"></a></p><h2 id="Spec描述"><a href="#Spec描述" class="headerlink" title="Spec描述"></a>Spec描述</h2><p>VIRTIO_NET_F_RSS</p><p><img src="/images/2024/11/020.png" alt></p><p><a href="https://docs.oasis-open.org/virtio/virtio/v1.3/csd01/virtio-v1.3-csd01.html#x1-2570003" target="_blank" rel="noopener">5.1.6.4.3 Hash calculation for incoming packets</a></p><p><a href="https://docs.oasis-open.org/virtio/virtio/v1.3/csd01/virtio-v1.3-csd01.html#x1-2580001" target="_blank" rel="noopener">5.1.6.4.3.1 Supported/enabled hash types</a></p><p>RSS需要通过ctrl q去下发配置参数，所以VIRTIO_NET_F_RSS Requires VIRTIO_NET_F_CTRL_VQ，需要ctrl q。<br><a href="https://docs.oasis-open.org/virtio/virtio/v1.3/csd01/virtio-v1.3-csd01.html#x1-2890007" target="_blank" rel="noopener">5.1.6.5.7 Receive-side scaling (RSS)</a></p><h2 id="struct-virtio-net-rss-config"><a href="#struct-virtio-net-rss-config" class="headerlink" title="struct virtio_net_rss_config"></a>struct virtio_net_rss_config</h2><p>研究明白<code>struct virtio_net_rss_config</code>即可理解virtio-net RSS的实现细节。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rss_rq_id</span> &#123;</span> </span><br><span class="line">   le16 vq_index_1_16: <span class="number">15</span>; <span class="comment">/* Bits 1 to 16 of the virtqueue index */</span> </span><br><span class="line">   le16 reserved: <span class="number">1</span>; <span class="comment">/* Set to zero */</span> </span><br><span class="line">&#125;; </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_net_rss_config</span> &#123;</span> </span><br><span class="line">    le32 hash_types; </span><br><span class="line">    le16 indirection_table_mask; </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">rss_rq_id</span> <span class="title">unclassified_queue</span>;</span> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">rss_rq_id</span> <span class="title">indirection_table</span>[<span class="title">indirection_table_length</span>];</span> </span><br><span class="line">    le16 max_tx_vq; </span><br><span class="line">    u8 hash_key_length; </span><br><span class="line">    u8 hash_key_data[hash_key_length]; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="hash-types"><a href="#hash-types" class="headerlink" title="hash_types"></a>hash_types</h3><p>通过hash_types，比如可以选择(Source IP address,Destination IP address,Source TCP port,Destination TCP port)这个四元组作为RSS Input Fields，也可以选择(Source IP address,Destination IP address)这个二元组作为RSS Input Fields。<br><img src="/images/2024/11/016.png" alt></p><h3 id="indirection-table-mask"><a href="#indirection-table-mask" class="headerlink" title="indirection_table_mask"></a>indirection_table_mask</h3><p><img src="/images/2024/11/017.png" alt><br>indirection_table_mask就是上图中的LSB。例如indirection_table_mask为0x111，那么RSS Redirection Table的size就是8。</p><h3 id="hash-key-length和hash-key-data"><a href="#hash-key-length和hash-key-data" class="headerlink" title="hash_key_length和hash_key_data"></a>hash_key_length和hash_key_data</h3><p><img src="/images/2024/11/018.png" alt></p><p>hash_key_length和hash_key_data就代表上图中的Hash Key。</p><h3 id="struct-rss-rq-id"><a href="#struct-rss-rq-id" class="headerlink" title="struct rss_rq_id"></a>struct rss_rq_id</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rss_rq_id</span> &#123;</span> </span><br><span class="line">   le16 vq_index_1_16: <span class="number">15</span>; <span class="comment">/* Bits 1 to 16 of the virtqueue index */</span> </span><br><span class="line">   le16 reserved: <span class="number">1</span>; <span class="comment">/* Set to zero */</span> </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>rss_rq_id is a receive virtqueue id.vq_index_1_16 consists of bits 1 to 16 of a virtqueue index. For example, a vq_index_1_16 value of 3 corresponds to virtqueue index 6, which maps to receiveq4.</p><p><img src="/images/2024/11/019.png" alt></p><table><thead><tr><th>vq_id</th><th>vq</th></tr></thead><tbody><tr><td>0</td><td>rxq1</td></tr><tr><td>1</td><td>txq1</td></tr><tr><td>2</td><td>rxq2</td></tr><tr><td>3</td><td>txq2</td></tr><tr><td>4</td><td>rxq3</td></tr><tr><td>5</td><td>txq3</td></tr><tr><td>6</td><td>rxq4</td></tr><tr><td>7</td><td>txq4</td></tr></tbody></table><p>如果vq_index_1_16为3，那么rss_rq_id就是6(0x110)，对应于rxq4。</p><h3 id="unclassified-queue"><a href="#unclassified-queue" class="headerlink" title="unclassified_queue"></a>unclassified_queue</h3><p>Field unclassified_queue specifies the receive virtqueue id in which to place unclassified packets.</p><h3 id="indirection-table"><a href="#indirection-table" class="headerlink" title="indirection_table"></a>indirection_table</h3><p>Field indirection_table is an array of receive virtqueues ids.</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>The device MUST determine the destination queue for a network packet as follows:</p><ol><li>Calculate the hash of the packet.</li><li>If the device did not calculate the hash for the specific packet, the device directs the packet to the receiveq specified by <code>unclassified_queue</code> of <code>virtio_net_rss_config</code> structure.</li><li>Apply <code>indirection_table_mask</code>to the calculated hash and use the result as the index in the indirection table to get the destination receive virtqueue id.</li><li>If the destination receive queue is being reset, the device MUST drop the packet.</li></ol><hr><p>参考资料:</p><ol><li><a href="https://docs.oasis-open.org/virtio/virtio/v1.3/csd01/virtio-v1.3-csd01.html" target="_blank" rel="noopener">VIRTIO 1.3 spec</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下virtio-net中&lt;a href=&quot;/2024/05/05/Notes-about-RSS-Receive-Side-Scaling/&quot;&gt;RSS(Receive Side Scaling)&lt;/a&gt;的具体实现。
    
    </summary>
    
      <category term="virtio" scheme="http://liujunming.github.io/categories/virtio/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about NUMA</title>
    <link href="http://liujunming.github.io/2024/11/17/%E8%BD%AC%E8%BD%BD-Linux-NUMA-Optimization-1/"/>
    <id>http://liujunming.github.io/2024/11/17/转载-Linux-NUMA-Optimization-1/</id>
    <published>2024-11-17T00:37:04.000Z</published>
    <updated>2024-11-17T08:26:21.697Z</updated>
    
    <content type="html"><![CDATA[<p>本文内容主要转载自:<a href="https://oliveryang.net/2016/02/linux-numa-optimization-1/" target="_blank" rel="noopener">https://oliveryang.net/2016/02/linux-numa-optimization-1/</a><a id="more"></a></p><h2 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h2><p>理解NUMA的概念首先要熟悉多处理器计算机系统的几个重要概念。</p><h3 id="1-1-SMP-vs-AMP"><a href="#1-1-SMP-vs-AMP" class="headerlink" title="1.1 SMP vs. AMP"></a>1.1 SMP vs. AMP</h3><p><a href="https://www.wikiwand.com/en/articles/Symmetric_multiprocessing" target="_blank" rel="noopener">SMP(Symmetric Multiprocessing)</a>， 即对称多处理器架构，是目前最常见的多处理器计算机架构。<br><a href="https://en.wikipedia.org/wiki/Asymmetric_multiprocessing" target="_blank" rel="noopener">AMP(Asymmetric Multiprocessing)</a>， 即非对称多处理器架构，则是与SMP相对的概念。</p><p>那么两者之间的主要区别是什么呢？ 总结下来有这么几点，</p><ol><li>SMP的多个处理器都是同构的，使用相同架构的CPU；而AMP的多个处理器则可能是异构的。</li><li>SMP的多个处理器共享同一内存地址空间；而AMP的每个处理器则拥有自己独立的地址空间。</li><li>SMP的多个处理器操通常共享一个操作系统的实例；而AMP的每个处理器可以有或者没有运行操作系统， 运行操作系统的CPU也是在运行多个独立的实例。</li><li>SMP的多处理器之间可以通过共享内存来协同通信；而AMP则需要提供一种处理器间的通信机制。</li></ol><p>SMP和AMP的深入介绍很多经典文章书籍可参考，此处不再赘述。现今主流的x86多处理器服务器都是SMP架构的， 而很多嵌入式系统则是AMP架构的。</p><h3 id="1-2-NUMA-vs-UMA"><a href="#1-2-NUMA-vs-UMA" class="headerlink" title="1.2 NUMA vs. UMA"></a>1.2 NUMA vs. UMA</h3><p><a href="https://en.wikipedia.org/wiki/Non-uniform_memory_access" target="_blank" rel="noopener">NUMA(Non-Uniform Memory Access)</a> 非均匀内存访问架构是指多处理器系统中，内存的访问时间是依赖于处理器和内存之间的相对位置的。 这种设计里存在和处理器相对近的内存，通常被称作本地内存；还有和处理器相对远的内存， 通常被称为非本地内存。</p><p><a href="https://en.wikipedia.org/wiki/Uniform_memory_access" target="_blank" rel="noopener">UMA(Uniform Memory Access)</a> 均匀内存访问架构则是与NUMA相反，所以处理器对共享内存的访问距离和时间是相同的。</p><p>由此可知，不论是NUMA还是UMA都是SMP架构的一种设计和实现上的选择。</p><p>阅读文档时，也常常能看到<strong>ccNUMA(Cache Coherent NUMA)</strong>，即缓存一致性NUMA架构。 这种架构主要是在NUMA架构之上保证了多处理器之间的缓存一致性。降低了系统程序的编写难度。</p><p>x86多处理器发展历史上，早期的多核和多处理器系统都是UMA架构的。这种架构下， 多个CPU通过同一个北桥(North Bridge)芯片与内存链接。北桥芯片里集成了内存控制器(Memory Controller)，</p><p>下图是一个典型的早期 x86 UMA 系统，四路处理器通过 FSB (前端系统总线) 和主板上的内存控制器芯片 (MCH) 相连，DRAM 是以 UMA 方式组织的，延迟并无访问差异，<br><img src="/images/2024/11/011.png" alt></p><p>在 UMA 架构下，CPU 和内存控制器之间的前端总线 (FSB) 在系统 CPU 数量不断增加的前提下， 成为了系统性能的瓶颈。因此，AMD 在引入 64 位 x86 架构时，实现了 NUMA 架构。之后， Intel 也推出了 x64 的 Nehalem 架构，x86 终于全面进入到 NUMA 时代。x86 NUMA 目前的实现属于 ccNUMA。</p><p>从 Nehalem 架构开始，x86 开始转向 NUMA 架构，内存控制器芯片被集成到处理器内部，多个处理器通过 QPI 链路相连，从此 DRAM 有了远近之分。 而 Sandybridge 架构则更近一步，将片外的 IOH 芯片也集成到了处理器内部，至此，内存控制器和 PCIe Root Complex 全部在处理器内部了。 下图就是一个典型的 x86 的 NUMA 架构：</p><p><img src="/images/2024/11/012.png" alt></p><h2 id="2-NUMA-Hierarchy"><a href="#2-NUMA-Hierarchy" class="headerlink" title="2. NUMA Hierarchy"></a>2. NUMA Hierarchy</h2><p>NUMA Hierarchy就是NUMA的层级结构。一个Intel x86 NUMA系统就是由多个NUMA Node组成。</p><h3 id="2-1-NUMA-Node内部"><a href="#2-1-NUMA-Node内部" class="headerlink" title="2.1 NUMA Node内部"></a>2.1 NUMA Node内部</h3><p>一个NUMA Node内部是由一个<strong>物理CPU</strong>和它所有的<strong>本地内存(Local Memory)</strong>组成的。广义得讲， 一个NUMA Node内部还包含<strong>本地IO资源</strong>，对大多数Intel x86 NUMA平台来说，主要是PCIe总线资源。 ACPI规范就是这么抽象一个NUMA Node的。</p><h4 id="2-1-1-物理CPU"><a href="#2-1-1-物理CPU" class="headerlink" title="2.1.1 物理CPU"></a>2.1.1 物理CPU</h4><p>一个CPU Socket里可以由多个CPU Core和一个Uncore部分组成。每个CPU Core内部又可以由两个CPU Thread组成。 每个CPU thread都是一个操作系统可见的逻辑CPU。对大多数操作系统来说，一个八核HT打开的CPU会被识别为16个CPU。 下面就说一说这里面相关的概念，</p><ul><li><p>Socket<br>一个Socket对应一个物理CPU。 这个词大概是从CPU在主板上的物理连接方式上来的。处理器通过主板的Socket来插到主板上。 尤其是有了多核(Multi-core)系统以后，Multi-socket系统被用来指明系统到底存在多少个物理CPU。</p></li><li><p>Core<br>CPU的运算核心。 x86的核包含了CPU运算的基本部件，如逻辑运算单元(ALU), 浮点运算单元(FPU), L1和L2缓存。 一个Socket里可以有多个Core。如今的多核时代，即使是Single Socket的系统， 也是逻辑上的SMP系统。但是，一个物理CPU的系统不存在非本地内存，因此相当于UMA系统。</p></li><li><p>Uncore<br>Intel x86物理CPU里没有放在Core里的部件都被叫做Uncore。Uncore里集成了过去x86 UMA架构时代北桥芯片的基本功能。 在Nehalem时代，内存控制器被集成到CPU里，叫做iMC(Integrated Memory Controller)。 而PCIe Root Complex还做为独立部件在IO Hub芯片里。到了SandyBridge时代，PCIe Root Complex也被集成到了CPU里。 现今的Uncore部分，除了iMC，PCIe Root Complex，还有QPI(QuickPath Interconnect)控制器， L3缓存，CBox(负责缓存一致性)，及其它外设控制器。</p></li><li><p>Threads<br>这里特指CPU的多线程技术。在Intel x86架构下，CPU的多线程技术被称作超线程(Hyper-Threading)技术。 Intel的超线程技术在一个处理器Core内部引入了额外的硬件设计模拟了两个逻辑处理器(Logical Processor)， 每个逻辑处理器都有独立的处理器状态，但共享Core内部的计算资源，如ALU，FPU，L1，L2缓存。 这样在最小的硬件投入下提高了CPU在多线程软件工作负载下的性能，提高了硬件使用效率。 x86的超线程技术出现早于NUMA架构。</p></li></ul><p>以下图为例，1 个 x86 CPU Socket 有 4 个物理 Core，每个 Core 有两个 HT (Hyper Thread)，L1 L2 Cache 被两个 HT 共享， 而 L3 Cache 则在 Socket 内，被所有 4 个 Core 共享，<br><img src="/images/2024/11/013.jpg" alt></p><h4 id="2-1-2-本地内存"><a href="#2-1-2-本地内存" class="headerlink" title="2.1.2 本地内存"></a>2.1.2 本地内存</h4><p>在Intel x86平台上，所谓本地内存，就是CPU可以经过Uncore部件里的iMC访问到的内存。而那些非本地的， 远程内存(Remote Memory)，则需要经过QPI的链路到该内存所在的本地CPU的iMC来访问。 曾经在Intel IvyBridge的NUMA平台上做的内存访问性能测试显示，远程内存访问的延时是本地内存的一倍。</p><p>可以假设，操作系统应该尽量利用本地内存的低访问延迟特性来优化应用和系统的性能。</p><h4 id="2-1-3-本地IO资源"><a href="#2-1-3-本地IO资源" class="headerlink" title="2.1.3 本地IO资源"></a>2.1.3 本地IO资源</h4><p>如前所述，Intel自从SandyBridge处理器开始，已经把PCIe Root Complex集成到CPU里了。 正因为如此，从CPU直接引出PCIe Root Port的PCIe 3.0的链路可以直接与PCIe Switch或者PCIe Endpoint相连。 一个PCIe Endpoint就是一个PCIe外设。这就意味着，对某个PCIe外设来说，如果它直接与哪个CPU相连， 它就属于哪个CPU所在的NUMA Node。</p><p>与本地内存一样，所谓本地IO资源，就是CPU可以经过Uncore部件里的PCIe Root Complex直接访问到的IO资源。 如果是非本地IO资源，则需要经过QPI链路到该IO资源所属的CPU，再通过该CPU PCIe Root Complex访问。 如果同一个NUMA Node内的CPU和内存和另外一个NUMA Node的IO资源发生互操作，因为要跨越QPI链路， 会存在额外的访问延迟问题。</p><p>其它体系结构里，为降低外设访问延迟，也有将IB(Infiniband)总线集成到CPU里的。 这样IB设备也属于NUMA Node的一部分了。</p><p>可以假设，操作系统如果是NUMA Aware的话，应该会尽量针对本地IO资源低延迟的优点进行优化。</p><h3 id="2-2-NUMA-Node互联"><a href="#2-2-NUMA-Node互联" class="headerlink" title="2.2 NUMA Node互联"></a>2.2 NUMA Node互联</h3><p>在Intel x86上，NUMA Node之间的互联是通过<a href="https://en.wikipedia.org/wiki/Intel_QuickPath_Interconnect" target="_blank" rel="noopener">QPI(QuickPath Interconnect)</a> Link的。 CPU的Uncore部分有QPI的控制器来控制CPU到QPI的数据访问。</p><p>不借助第三方的 Node Controller，2 或 4 个 NUMA Node (取决于具体架构)可以通过 QPI(QuickPath Interconnect) 总线互联起来， 构成一个NUMA系统。例如，<a href="https://www.doit.com.cn/p/118059.html" target="_blank" rel="noopener">SGI UV计算机系统</a>， 它就是借助自家的 SGI NUMAlink® 互联技术来达到 4 到 256 个 CPU socket 扩展的能力的。这是一个 SMP 系统， 所以支持运行一个 Linux 操作系统实例去管理系统。</p><p>下图就是一个利用 QPI Switch 互联的 8 NUMA Node 的 x86 系统，</p><p><img src="/images/2024/11/014.png" alt></p><h2 id="3-NUMA-Affinity"><a href="#3-NUMA-Affinity" class="headerlink" title="3. NUMA Affinity"></a>3. NUMA Affinity</h2><p>NUMA Affinity(亲和性)是和NUMA Hierarchy(层级结构)直接相关的。对系统软件来说， 以下两个概念至关重要，</p><h3 id="3-1-CPU-NUMA-Affinity"><a href="#3-1-CPU-NUMA-Affinity" class="headerlink" title="3.1 CPU NUMA Affinity"></a>3.1 CPU NUMA Affinity</h3><p>CPU NUMA的亲和性是指从CPU角度看，哪些内存访问更快，有更低的延迟。如前所述， 和该CPU直接相连的本地内存是更快的。操作系统如果可以根据任务所在CPU去分配本地内存， 就是基于CPU NUMA亲和性的考虑。因此，CPU NUMA亲和性就是要尽量让任务运行在本地的NUMA Node里。</p><h3 id="3-2-Device-NUMA-Affinity"><a href="#3-2-Device-NUMA-Affinity" class="headerlink" title="3.2 Device NUMA Affinity"></a>3.2 Device NUMA Affinity</h3><p><img src="/images/2024/11/015.png" alt></p><p>设备NUMA亲和性是指从PCIe外设的角度看，如果和CPU和内存相关的IO活动都发生在外设所属的NUMA Node， 将会有更低延迟。这里有两种设备NUMA亲和性的问题，</p><h4 id="3-2-1-DMA-Buffer-NUMA-Affinity"><a href="#3-2-1-DMA-Buffer-NUMA-Affinity" class="headerlink" title="3.2.1 DMA Buffer NUMA Affinity"></a>3.2.1 DMA Buffer NUMA Affinity</h4><p>大部分PCIe设备支持DMA功能的。也就是说，设备可以直接把数据写入到位于内存中的DMA缓冲区。 显然，如果DMA缓冲区在PCIe外设所属的NUMA Node里分配，那么将会有最低的延迟。 否则，外设的DMA操作要跨越QPI链接去读写另外一个NUMA Node里的DMA缓冲区。 因此，操作系统如果可以根据PCIe设备所属的NUMA node分配DMA缓冲区， 将会有最好的DMA操作的性能。</p><h4 id="3-2-2-Interrupt-NUMA-Affinity"><a href="#3-2-2-Interrupt-NUMA-Affinity" class="headerlink" title="3.2.2 Interrupt NUMA Affinity"></a>3.2.2 Interrupt NUMA Affinity</h4><p>设备DMA操作完成后，需要在CPU上触发中断来通知驱动程序的中断处理例程(ISR)来读写DMA缓冲区。 很多时候，ISR触发下半部机制(SoftIRQ)来进入到协议栈相关(Network，Storage)的代码路径来传送数据。 对大部分操作系统来说，硬件中断(HardIRQ)和下半部机制的代码在同一个CPU上发生。 因此，DMA缓冲区的读写操作发生的位置和设备硬件中断(HardIRQ)密切相关。假设操作系统可以把设备的硬件中断绑定到自己所属的NUMA node， 那之后中断处理函数和协议栈代码对DMA缓冲区的读写将会有更低的延迟。</p><h2 id="4-Firmware接口"><a href="#4-Firmware接口" class="headerlink" title="4. Firmware接口"></a>4. Firmware接口</h2><p>由于NUMA的亲和性对应用的性能非常重要，那么硬件平台就需要给操作系统提供接口机制来感知硬件的NUMA层级结构。 在x86平台，ACPI规范提供了以下接口来让操作系统检测系统的NUMA层级结构。</p><p>ACPI 5.0a规范的第17章是有关NUMA的章节。ACPI规范里，NUMA Node被第9章定义的Module Device所描述。 ACPI规范里用<strong>Proximity Domain</strong>对NUMA Node做了抽象，两者的概念大多时候等同。</p><ul><li><p><strong>SRAT(System Resource Affinity Table)</strong><br>主要描述了系统boot时的CPU和内存都属于哪个Proximity Domain(NUMA Node)。 这个表格里的信息时静态的，如果是启动后热插拔，需要用OSPM的_PXM方法去获得相关信息。</p></li><li><p><strong>SLIT(System Locality Information Table)</strong><br>提供CPU和内存之间的位置远近信息。在SRAT表格里，只能告诉给定的CPU和内存是否在一个NUMA Node。 对某个CPU来说，不在本NUMA Node里的内存，即远程内存们是否都是一样的访问延迟取决于NUMA的拓扑有多复杂(QPI的跳数)。 总之，对于不能简单用远近来描述的NUMA系统(QPI存在0，1，2等不同跳数)， 需要SLIT表格给出进一步的说明。同样的，这个表格也是静态表格，热插拔需要使用OSPM的_SLI方法。</p></li><li><p><strong>DSDT(Differentiated System Description Table)</strong><br>从Device NUMA角度看，这个表格给出了系统boot时的外设都属于哪个Proximity Domain(NUMA Node)。</p></li></ul><p>ACPI规范OSPM(Operating System-directed configuration and Power Management) 和OSPM各种方法就是操作系统里的ACPI驱动和ACPI firmware之间的一个互动的接口。 x86启动OS后，没有ACPI之前，firmware(BIOS)的代码是无法被执行了，除非通过SMI中断处理程序。 但有了ACPI，BIOS提前把ACPI的一些静态表格和AML的bytecode代码装载到内存， 然后ACPI驱动就会加载AML的解释器，这样OS就可以通过ACPI驱动调用预先装载的AML代码。 AML(ACPI Machine Language)是和Java类似的一种虚拟机解释型语言，所以不同操作系统的ACPI驱动， 只要有相同的虚拟机解释器，就可以直接从操作系统调用ACPI写好的AML的代码了。 所以，前文所述的所有热插拔的OSPM方法，其实就是对应ACPI firmware的AML的一段函数代码而已。 (关于ACPI的简单介绍，这里给出两篇延伸阅读：<a href="http://rdist.root.org/2008/10/17/all-about-acpi/" target="_blank" rel="noopener">1</a> 和<a href="https://www.usenix.org/legacy/events/usenix02/tech/freenix/full_papers/watanabe/watanabe_html/index.html" target="_blank" rel="noopener">2</a>。)</p><p>至此，x86 NUMA平台所需的一些硬件知识基本就覆盖到了。需要说明的是， 虽然本文以Intel平台为例，但AMD平台的差异也只是CPU总线和内部结构的差异而已。 其它方面的NUMA概念AMD也是类似的。</p><hr><p>参考资料:</p><ol><li>IOctopus: outsmarting nonuniform DMA(ASPLOS’20)</li><li><a href="https://blog.csdn.net/qq_20817327/article/details/105925071" target="_blank" rel="noopener">NUMA架构详解</a></li><li><a href="https://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/" target="_blank" rel="noopener">The MySQL “swap insanity” problem and the effects of the NUMA architecture</a></li><li><a href="https://frankdenneman.nl/2016/07/08/numa-deep-dive-part-2-system-architecture/" target="_blank" rel="noopener">NUMA Deep Dive Part 2: System Architecture</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文内容主要转载自:&lt;a href=&quot;https://oliveryang.net/2016/02/linux-numa-optimization-1/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://oliveryang.net/2016/02/linux-numa-optimization-1/&lt;/a&gt;
    
    </summary>
    
      <category term="体系结构" scheme="http://liujunming.github.io/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="体系结构" scheme="http://liujunming.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Notes about AMD IOMMU IRTCache机制</title>
    <link href="http://liujunming.github.io/2024/11/10/Notes-about-AMD-IOMMU-IRTCache/"/>
    <id>http://liujunming.github.io/2024/11/10/Notes-about-AMD-IOMMU-IRTCache/</id>
    <published>2024-11-10T10:52:35.000Z</published>
    <updated>2024-11-10T11:52:37.336Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下AMD IOMMU IRTCache机制的相关notes。<a id="more"></a></p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>在没有IRTCache机制之前，设备的MSI data到IRTE(Interrupt Remapping Table Entry)的映射，需要硬件从内存中读取Interrupt Remapping Table来获取IRTE。<br><img src="/images/2024/11/009.png" alt></p><p>在引入IRTCache机制之后，IOMMU硬件中就会缓存设备MSI data到IRTE的映射了,这样就可以避免IOMMU硬件从内存中读取IRTE。</p><h3 id="How"><a href="#How" class="headerlink" title="How"></a>How</h3><p>For IOMMU AVIC, the IOMMU driver needs to keep track of vcpu scheduling changes, and updates interrupt remapping table entry (IRTE) accordingly. The IRTE is normally cached by the hardware, which requires the IOMMU driver to issue IOMMU IRT invalidation command and wait for completion everytime it updates the table.</p><p>Enabling IOMMU AVIC on a large scale system with lots of vcpus and VFIO pass-through devices running interrupt-intensive workload, it could result in high IRT invalidation rate. In such case, the overhead from IRT invalidation could outweigh the benefit of IRTE caching.</p><p>Therefore, introduce a new AMD IOMMU driver option “amd_iommu=irtcachedis” to allow disabling IRTE caching, and avoid the need for IRTE invalidation.</p><p><img src="/images/2024/11/008.png" alt></p><p><img src="/images/2024/11/010.png" alt></p><hr><p>参考资料:</p><ol><li><a href="https://lore.kernel.org/lkml/20230530141137.14376-1-suravee.suthikulpanit@amd.com/" target="_blank" rel="noopener">[PATCH v3 0/5] iommu/amd: AVIC Interrupt Remapping Improvements</a></li><li>AMD I/O Virtualization Technology (IOMMU) Specification, 48882</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下AMD IOMMU IRTCache机制的相关notes。
    
    </summary>
    
      <category term="IOMMU" scheme="http://liujunming.github.io/categories/IOMMU/"/>
    
    
      <category term="AMD" scheme="http://liujunming.github.io/tags/AMD/"/>
    
      <category term="IOMMU" scheme="http://liujunming.github.io/tags/IOMMU/"/>
    
  </entry>
  
  <entry>
    <title>Notes about PCIe flow control机制</title>
    <link href="http://liujunming.github.io/2024/11/10/Notes-about-PCIe-credit%E6%9C%BA%E5%88%B6/"/>
    <id>http://liujunming.github.io/2024/11/10/Notes-about-PCIe-credit机制/</id>
    <published>2024-11-10T02:16:57.000Z</published>
    <updated>2024-11-10T07:12:32.928Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下PCIe flow control机制的相关notes。<a id="more"></a></p><p>The receiver of each port reports the size of its Flow Control buffers <strong>in units called credits</strong>.<br>在一条链路的两端设备分别向对方通知其自己可以使用的缓冲区大小或数量。这里通知的空间大小就是信用（credit）。</p><p><img src="/images/2024/11/007.png" alt></p><p>A定期的告诉B，我这里还有地方，来吧，来吧~。B因此知道A是有空余空间接收的。同样，B也是采用同样的方式告知A。流控信用会定期在两者间发送，这叫做更新流控信用（Update FC）。</p><p>The data link layer has a Flow Control (FC) mechanism, which makes sure that a TLP is transmitted only when the link partner has enough buffer space to accept it.</p><p>The Flow Control mechanism uses a credit‐based mechanism that allows the transmitting port to be aware of buffer space available at the receiving port. As part of its initialization, each receiver reports the size of its buffers to the transmitter on the other end of the Link, and then <strong>during run‐time it regularly updates the number of credits available using Flow Control DLLPs</strong>. Technically, of course, DLLPs are overhead because they don’t convey any data payload, but they are kept small to minimize their impact on performance.</p><hr><p>参考资料:</p><ol><li>PCI Express Technology(Mike Jackson, Ravi Budruk)</li><li><a href="https://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-2" target="_blank" rel="noopener">Down to the TLP: How PCI express devices talk (Part II)</a></li><li><a href="https://www.slideshare.net/slideshow/pciexpressbasicsbackgroundpdf/252660914#38" target="_blank" rel="noopener">PCI Express Basics Background</a></li><li><a href="https://mp.weixin.qq.com/s/WkRTqLOpqynHtOiaaOTplw" target="_blank" rel="noopener">Credit timeout &amp; Completion timeout</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下PCIe flow control机制的相关notes。
    
    </summary>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/categories/PCI-PCIe/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about PCIe prefetchable bar</title>
    <link href="http://liujunming.github.io/2024/11/03/Notes-about-PCIe-prefetchable-bar/"/>
    <id>http://liujunming.github.io/2024/11/03/Notes-about-PCIe-prefetchable-bar/</id>
    <published>2024-11-03T09:21:24.000Z</published>
    <updated>2024-11-03T09:43:15.866Z</updated>
    
    <content type="html"><![CDATA[<p>When a base address register is marked as <strong>Prefetchable</strong>, it means that:the region does not have read side effects (reading from that memory range doesn’t change any state), and it is allowed for the CPU to cache loads from that memory region and read it in bursts (typically cache line sized).<a id="more"></a> Hardware is also allowed to merge repeated stores to the same address into one store of the latest value. If you are using paging and want maximum performance, you should map prefetchable MMIO regions as WT (write-through) instead of UC (uncacheable). On x86, frame buffers are the exception, they should be almost always be mapped WC (write-combining).</p><p><img src="/images/2024/11/006.png" alt></p><hr><p>参考资料:</p><ol><li><a href="https://wiki.osdev.org/PCI" target="_blank" rel="noopener">wiki.osdev.org/PCI</a></li><li><a href="https://blog.csdn.net/redseazhaojianertao/article/details/79943494" target="_blank" rel="noopener">PCIE的prefetchable和nonprefetchable的理解</a></li><li>Intel SDM Vol3</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;When a base address register is marked as &lt;strong&gt;Prefetchable&lt;/strong&gt;, it means that:the region does not have read side effects (reading from that memory range doesn’t change any state), and it is allowed for the CPU to cache loads from that memory region and read it in bursts (typically cache line sized).
    
    </summary>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/categories/PCI-PCIe/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about RDMA Direct WQE与Inline data机制</title>
    <link href="http://liujunming.github.io/2024/11/03/Notes-about-RDMA-Inline-data%E6%9C%BA%E5%88%B6/"/>
    <id>http://liujunming.github.io/2024/11/03/Notes-about-RDMA-Inline-data机制/</id>
    <published>2024-11-03T03:27:55.000Z</published>
    <updated>2024-11-03T09:20:09.475Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下RDMA Direct WQE与Inline data机制，主要内容转载自<a href="https://zhuanlan.zhihu.com/p/567720023" target="_blank" rel="noopener">知乎:RDMA 高级</a>。<a id="more"></a></p><h2 id="Normal-flow"><a href="#Normal-flow" class="headerlink" title="Normal flow"></a>Normal flow</h2><p>以发包为例:<br><img src="/images/2024/11/001.jpg" alt></p><ol><li>填充要发送的数据</li><li>填充WQE描述符</li><li>敲doorbell通知硬件有数据要发送</li><li>硬件通过DMA读取WQE</li><li>硬件通过DMA读取要发送的数据</li></ol><h2 id="Direct-WQE"><a href="#Direct-WQE" class="headerlink" title="Direct WQE"></a>Direct WQE</h2><p>以发包为例:<br><img src="/images/2024/11/002.jpg" alt><br>与Normal flow相比，Direct WQE先将WQE写入MMIO bar中，再写doorbell通知硬件有数据要发送。这样RNIC就无需通过DMA来读取WQE了。</p><p>需要将MMIO页以write combining方式映射，这里的MMIO页属于<a href="/2024/10/20/Notes-about-RDMA-Device-Memory/">RDMA Device Memory</a>。</p><p><img src="/images/2024/11/003.png" alt></p><h2 id="Inline-Send"><a href="#Inline-Send" class="headerlink" title="Inline-Send"></a>Inline-Send</h2><p><img src="/images/2024/11/004.jpg" alt><br><code>ibv_post_send</code>时带上<code>IBV_SEND_INLINE</code>标识，如果要发送的数据小于128字节则填WQE时会将这部分数据直接append在WQE的后面。这样硬件DMA WQE时就顺便将data也读出来了，这样就省去了单独DMA data的操作。</p><h2 id="Inline-Receive"><a href="#Inline-Receive" class="headerlink" title="Inline-Receive"></a>Inline-Receive</h2><p><img src="/images/2024/11/005.png" alt><br>与发送类似，如果接收的是一个小数据，则没有必要将其放入RQ的receive buffer中，而是可以直接将其放入CQE中。这可以省去硬件将数据DMA至RQ SGE list的过程。使用<code>ibv_exp_create_qp</code>创建QP时指定<code>max_inl_recv</code>即可开启此功能。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Direct WQE与Inline data机制的目标都是减少RDMA数据面上的PCIe TLP交互次数。</p><hr><p>参考资料:</p><ol><li><a href="https://zhuanlan.zhihu.com/p/567720023" target="_blank" rel="noopener">RDMA 高级</a></li><li><a href="https://docs.nvidia.com/networking/display/mlnxofedv461000/optimized+memory+access#src-12013520_OptimizedMemoryAccess-Inline-Receive" target="_blank" rel="noopener">Inline-Receive</a></li><li><a href="https://lore.kernel.org/all/1622194379-59868-5-git-send-email-liweihang@huawei.com/" target="_blank" rel="noopener">[rdma-core,4/4] libhns: Add support for direct wqe</a></li><li>Design Guidelines for High Performance RDMA Systems(ATC’16)</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下RDMA Direct WQE与Inline data机制，主要内容转载自&lt;a href=&quot;https://zhuanlan.zhihu.com/p/567720023&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;知乎:RDMA 高级&lt;/a&gt;。
    
    </summary>
    
      <category term="RDMA" scheme="http://liujunming.github.io/categories/RDMA/"/>
    
    
      <category term="RDMA" scheme="http://liujunming.github.io/tags/RDMA/"/>
    
  </entry>
  
  <entry>
    <title>Notes about NVF</title>
    <link href="http://liujunming.github.io/2024/10/27/Notes-about-NVF/"/>
    <id>http://liujunming.github.io/2024/10/27/Notes-about-NVF/</id>
    <published>2024-10-27T08:55:46.000Z</published>
    <updated>2024-10-27T10:10:02.468Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下NVF(Network Function Virtualization)相关notes。<a id="more"></a></p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><img src="/images/2024/10/021.jpg" alt></p><p><img src="/images/2024/10/022.jpg" alt></p><p><img src="/images/2024/10/023.jpg" alt></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Network Function Virtualization is a network architecture for virtualizing the entire class of network functions (NFs) on commodity off-the-shelf(现成的) general-purpose hardware.</p><p><img src="/images/2024/10/020.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://www.usenix.org/conference/nsdi18/presentation/zhang-kai" target="_blank" rel="noopener">G-NET: Effective GPU Sharing in NFV Systems</a></li><li><a href="https://dianshenseu.github.io/files/NFV.pdf" target="_blank" rel="noopener">NFV实验平台的技术方案及搭建过程介绍</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下NVF(Network Function Virtualization)相关notes。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about RDMA ODP feature</title>
    <link href="http://liujunming.github.io/2024/10/20/Notes-about-RDMA-ODP-feature/"/>
    <id>http://liujunming.github.io/2024/10/20/Notes-about-RDMA-ODP-feature/</id>
    <published>2024-10-20T08:27:30.000Z</published>
    <updated>2024-10-20T11:42:27.410Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下RDMA ODP(On-Demand-Paging) feature相关notes。<a id="more"></a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>On-Demand-Paging (ODP) is a technique to alleviate much of the shortcomings of memory registration. Applications no longer need to pin down the underlying physical pages of the address space, and track the validity of the mappings. Rather, the HCA requests the latest translations from the OS when pages are not present, and the OS invalidates translations which are no longer valid due to either non-present pages or mapping changes.</p><p><img src="/images/2024/10/017.jpg" alt></p><h2 id="Synchronizing-between-CPU-and-RNIC-page-tables"><a href="#Synchronizing-between-CPU-and-RNIC-page-tables" class="headerlink" title="Synchronizing between CPU and RNIC page tables"></a>Synchronizing between CPU and RNIC page tables</h2><p><img src="/images/2024/10/018.jpg" alt></p><h3 id="Faulting"><a href="#Faulting" class="headerlink" title="Faulting"></a>Faulting</h3><p>When an RDMA request accesses data on invalid virtual pages, (1a) the RNIC stalls the QP and raises an RNIC page fault interrupt. (1b) The driver requests the OS kernel for virtual-to-physical mappings via <code>hmm_range_fault</code>. The OS kernel triggers CPU page faults on these virtual pages and fills the CPU page table if necessary. (1c) The driver updates the mappings on the RNIC page table and (1d) resumes the QP.</p><h3 id="Invalidation"><a href="#Invalidation" class="headerlink" title="Invalidation"></a>Invalidation</h3><p>When the OS kernel tries to unmap virtual pages in scenarios like swapping out or page migration, (2a)it notifies the RNIC driver to invalidate virtual pages via <code>mmu_interval_notifier</code>. (2b) The RNIC driver erases the virtual-to-physical mapping from the RNIC page table. (2c) The driver notifies the kernel that the physical pages are no longer used by the RNIC. Then, the OS kernel modifies the CPU page table and reuses the physical pages.</p><p>ODP MR(Memory Region) relies on faulting and invalidation flows to synchronize CPU and RNIC page tables. </p><h3 id="Advising"><a href="#Advising" class="headerlink" title="Advising"></a>Advising</h3><p>An application can proactively request the RNIC driver to populate a range in the RNIC page table. The RNIC driver completes advising by steps (3a) – (3b), which are identical to steps (1b) – (1c).</p><h2 id="Related-code"><a href="#Related-code" class="headerlink" title="Related code"></a>Related code</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> ib_odp_general_cap_bits &#123;</span><br><span class="line">IB_ODP_SUPPORT= <span class="number">1</span> &lt;&lt; <span class="number">0</span>,</span><br><span class="line">IB_ODP_SUPPORT_IMPLICIT = <span class="number">1</span> &lt;&lt; <span class="number">1</span>,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> ib_odp_transport_cap_bits &#123;</span><br><span class="line">IB_ODP_SUPPORT_SEND= <span class="number">1</span> &lt;&lt; <span class="number">0</span>,</span><br><span class="line">IB_ODP_SUPPORT_RECV= <span class="number">1</span> &lt;&lt; <span class="number">1</span>,</span><br><span class="line">IB_ODP_SUPPORT_WRITE= <span class="number">1</span> &lt;&lt; <span class="number">2</span>,</span><br><span class="line">IB_ODP_SUPPORT_READ= <span class="number">1</span> &lt;&lt; <span class="number">3</span>,</span><br><span class="line">IB_ODP_SUPPORT_ATOMIC= <span class="number">1</span> &lt;&lt; <span class="number">4</span>,</span><br><span class="line">IB_ODP_SUPPORT_SRQ_RECV= <span class="number">1</span> &lt;&lt; <span class="number">5</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><hr><p>参考资料:</p><ol><li><a href="https://docs.nvidia.com/networking/display/mlnxofedv461000/optimized+memory+access" target="_blank" rel="noopener">Optimized Memory Access</a></li><li>TeRM: Extending RDMA-Attached Memory with SSD(FAST’24)</li><li><a href="https://dlsvr04.asus.com.cn/pub/ASUS/mb/accessory/PEM-FDR/Manual/Mellanox_OFED_Linux_User_Manual_v2_3-1_0_1.pdf" target="_blank" rel="noopener">Mellanox OFED for Linux User Manual</a></li><li><a href="https://lore.kernel.org/linux-rdma/1418310266-9584-1-git-send-email-haggaie@mellanox.com/" target="_blank" rel="noopener">[PATCH v3 00/17] On demand paging</a></li><li><a href="https://lore.kernel.org/linux-rdma/cover.1699503619.git.matsuda-daisuke@fujitsu.com/" target="_blank" rel="noopener">[PATCH for-next v7 0/7] On-Demand Paging on SoftRoCE</a></li><li><a href="https://cloud.tencent.com/developer/article/2428026" target="_blank" rel="noopener">RDMA - ODP按需分页设计原理-优点-源码浅析</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下RDMA ODP(On-Demand-Paging) feature相关notes。
    
    </summary>
    
      <category term="RDMA" scheme="http://liujunming.github.io/categories/RDMA/"/>
    
    
      <category term="RDMA" scheme="http://liujunming.github.io/tags/RDMA/"/>
    
  </entry>
  
  <entry>
    <title>Notes about RDMA Device Memory</title>
    <link href="http://liujunming.github.io/2024/10/20/Notes-about-RDMA-Device-Memory/"/>
    <id>http://liujunming.github.io/2024/10/20/Notes-about-RDMA-Device-Memory/</id>
    <published>2024-10-20T00:29:55.000Z</published>
    <updated>2024-10-20T08:16:54.452Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下RDMA Device Memory相关notes。<a id="more"></a></p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Device Memory is a verbs API that allows using on-chip memory, located on the device, as a data buffer for send/receive and RDMA operations. The device memory can be mapped and accessed directly by user and kernel applications, and can be allocated in various sizes, registered as memory regions with local and remote access keys for performing the send/ receive and RDMA operations. Using the device memory to store packets for transmission can significantly reduce transmission latency compared to the host memory.</p><p><img src="/images/2024/10/014.jpg" alt></p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><img src="/images/2024/10/015.jpg" alt></p><p>staging buffer: 暂存缓冲区</p><h3 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h3><p><img src="/images/2024/10/016.jpg" alt></p><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>可以类比于NVMe的<a href="/2024/06/30/深入理解NVMe-CMB机制/">CMB</a>，RDMA Device Memory以mmio的形式expose给host，目的是让RDMA直接使用Device Memory，无需DMA到host的内存，减少了PCIe TLP的交互。</p><h3 id="相关paper"><a href="#相关paper" class="headerlink" title="相关paper"></a>相关paper</h3><p>Sherman(SIGMOD’22) is the first RDMA-based system that leverages on-chip memory of commodity RDMA NICs.</p><hr><p>参考资料:</p><ol><li><a href="https://docs.nvidia.com/networking/display/rdmacore50/device+memory" target="_blank" rel="noopener">Device Memory</a></li><li><a href="https://www.openfabrics.org/images/2018workshop/presentations/304_LLiss_OnDeviceMemory.pdf" target="_blank" rel="noopener">On-device memory usage for RDMA transactions</a></li><li><a href="http://lastweek.io/notes/source_code/rdma/" target="_blank" rel="noopener">On DPDK and RDMA Related Software</a></li><li><a href="https://www.man7.org/linux/man-pages/man3/ibv_alloc_dm.3.html" target="_blank" rel="noopener">ibv_alloc_dm(3)</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下RDMA Device Memory相关notes。
    
    </summary>
    
      <category term="RDMA" scheme="http://liujunming.github.io/categories/RDMA/"/>
    
    
      <category term="RDMA" scheme="http://liujunming.github.io/tags/RDMA/"/>
    
  </entry>
  
  <entry>
    <title>Notes about RDMA SRQ/XRC/DCT技术</title>
    <link href="http://liujunming.github.io/2024/10/19/Notes-about-RDMA-SRQ-XRC-DCT%E6%8A%80%E6%9C%AF/"/>
    <id>http://liujunming.github.io/2024/10/19/Notes-about-RDMA-SRQ-XRC-DCT技术/</id>
    <published>2024-10-19T02:47:47.000Z</published>
    <updated>2024-10-22T23:48:39.056Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下RDMA SRQ(Shared Receive Queue)/XRC(eXtended Reliable Connection)/DCT(Dynamically Connected Transport)技术相关notes。<a id="more"></a></p><h2 id="1-SRQ"><a href="#1-SRQ" class="headerlink" title="1. SRQ"></a>1. SRQ</h2><h3 id="1-1-为什么需要SRQ"><a href="#1-1-为什么需要SRQ" class="headerlink" title="1.1 为什么需要SRQ"></a>1.1 为什么需要SRQ</h3><p><img src="/images/2024/10/007.webp" alt></p><p>在没有SRQ的情况下，因为RC/UC/UD的接收方不知道对端什么时候会发送过来多少数据，所以必须做好最坏的打算，做好突发性收到大量数据的准备，也就是向RQ中下发足量的的接收WQE；另外RC服务类型可以利用流控机制来抑制发送方，也就是告诉对端”我这边RQ WQE不够了”，这样发送端就会暂时放缓或停止发送数据。</p><p>但是第一种方法由于是为最坏情况准备的，大部分时候有大量的RQ WQE处于空闲状态未被使用，这对内存是一种极大地浪费(主要是WQE指向的用于存放数据的内存空间)；第二种方法虽然不用下发那么多RQ WQE了，但是流控是有代价的，即会增加通信时延。</p><p>而SRQ通过允许很多QP共享接收WQE(本身其实不是很大)以及<strong>用于存放数据的内存空间</strong>(这可是很大一块内存)来解决上面的问题。当任何一个QP收到消息后，硬件会从SRQ中取出一个WQE，根据其内容存放接收到的数据，然后硬件通过Completion Queue来返回接收任务的完成信息给对应的上层用户。</p><p><img src="/images/2024/10/008.webp" alt></p><h3 id="1-2-SRQ-Limit"><a href="#1-2-SRQ-Limit" class="headerlink" title="1.2 SRQ Limit"></a>1.2 SRQ Limit</h3><p>SRQ可以设置一个阈值，当队列中剩余的WQE数量小于阈值时，这个SRQ就会上报一个异步事件。提醒用户“队列中的WQE快用完了，请下发更多WQE以防没有地方接收新的数据”。这个阈值就被称为SRQ Limit，这个上报的事件就被称为SRQ Limit Reached。</p><h2 id="2-XRC"><a href="#2-XRC" class="headerlink" title="2. XRC"></a>2. XRC</h2><h3 id="2-1-为什么需要XRC"><a href="#2-1-为什么需要XRC" class="headerlink" title="2.1 为什么需要XRC"></a>2.1 为什么需要XRC</h3><p>当前的计算节点一般都有多核，因此可以运行多进程。在这样的计算节点组成的集群中，如果想用RC连接建立full mesh的全连接拓扑时，每个节点就需要建立N*p*p个QP(这里假设集群有N个节点，每个节点上有p个进程，需要让任何2个进程都连通)。当集群扩张，N和p同时增长时，一个节点所需的RC QP资源将变得不可接受。</p><p>XRC的思想是<strong>当一个进程想与某个远程节点的p个进程通信时不需要跟各个进程建立p个连接而只需要跟对端节点建立一个连接</strong>，连接上传输的报文携带了对端目的进程号(XRC SRQ)，报文到达连接对端(XRC TGT QP)时根据进程号分发至各个进程对应的XRC SRQ。这样源端进程只需要创建一个源端连接(XRC INI QP)就能跟对端所有进程通信了，这样所需总的QP数量就会除以p。</p><h3 id="2-2-核心概念"><a href="#2-2-核心概念" class="headerlink" title="2.2 核心概念"></a>2.2 核心概念</h3><p><img src="/images/2024/10/009.webp" alt></p><p>上图中XRC下标xyz的含义:x代表发起端的node号，y代表发起端的进程号，z代表接收端的node号。</p><ul><li>XRC INI QP</li></ul><p>XRC发起端QP，是XRC操作的源端队列，用于发出XRC操作，但它没有接收XRC操作的功能，对比常规RC QP来说可以认为它是只有SQ没有RQ。XRC操作在对端由XRC TGT QP处理。</p><ul><li>XRC TGT QP</li></ul><p>XRC接收端QP，它处理XRC操作将其分发至报文SRQ number对应的SRQ。XRC TGT QP只能接收XRC操作，但它没有发出XRC操作的功能，对比常规RC QP来说可以认为它是只有RQ没有SQ。XRC操作在对端由XRC INI QP发出。</p><ul><li>XRC SRQ</li></ul><p>接收缓冲区(receive WQE)被放在XRC SRQ中以接收XRC请求，XRC请求中携带了XRC SRQ number，所以XRC TGT QP收到报文后会从报文指定的XRC SRQ中取receive WQE来存放XRC请求。</p><ul><li>XRC domain</li></ul><p>用于关联XRC TGT QP和XRC SRQ，XRC报文只能指定与XRC TGT QP在同一domain内的XRC SRQ，否则报文会被丢弃。这起到了隔离资源的作用，防止攻击报文随意指定XRC SRQ。</p><p>XRC INI QP和XRC TGT QP是一一对应的，host2上的每个进程在远端节点host0上都有自己对应的XRC TGT QP。<strong>XRC的共享体现在一个XRC TGT QP可以分发至多个XRC SRQ</strong>。一个进程一般只有一个XRC SRQ，它可以接收多个XRC TGT QP来的包。</p><h2 id="3-DCT"><a href="#3-DCT" class="headerlink" title="3. DCT"></a>3. DCT</h2><p>Dynamically Connected transport (DCT) service is an extension to transport services to enable a higher degree of scalability while maintaining high performance for <strong>sparse traffic</strong>. Utilization of DCT reduces the total number of QPs required system wide by <em>having Reliable type QPs dynamically connect and disconnect from any remote node</em>. <strong>DCT connections only stay connected while they are active</strong>. This results in smaller memory footprint, less overhead to set connections and higher on-chip cache utilization and hence increased performance. </p><h3 id="3-1-为什么需要DCT"><a href="#3-1-为什么需要DCT" class="headerlink" title="3.1 为什么需要DCT"></a>3.1 为什么需要DCT</h3><p><img src="/images/2024/10/011.jpg" alt></p><p><img src="/images/2024/10/010.webp" alt></p><p>UD虽然扩展性很好，但是不支持read/write单边语义。RC虽然支持read/write单边语义，但是扩展性不好。DCT的初衷就是融合2者的优点，保持RC的read/write单边语义和可靠连接特性，同时像UD一样<strong>用一个QP去跟多个远端通信，保持良好的可扩展性</strong>。DCT一般用于sparse traffic场景。</p><p><img src="/images/2024/10/012.jpg" alt></p><p>想用RC连接建立full mesh的全连接拓扑时:</p><ul><li>在RC机制下，每个节点就需要建立N*p*p个QP</li><li>在XRC机制下，每个节点就需要建立N*p个QP</li><li>在DCT机制下，每个节点就需要建立p(可能p+n)个QP</li></ul><h3 id="3-2-什么是DCT"><a href="#3-2-什么是DCT" class="headerlink" title="3.2 什么是DCT"></a>3.2 什么是DCT</h3><p><img src="/images/2024/10/013.jpg" alt></p><ul><li>Dynamic Connectivity</li><li>Each DC Initiator can be used to reach any remote DC Target</li></ul><p>DCT具有非对称的API：DC在发送侧的部分称为DC initiator(DCI)，在接收侧的部分称为DC target(DCT)。DCI和DCT不过是特殊类型的QP，它们依然遵循基本的QP操作，比如post send/receive。</p><p>DC意味着临时连接，在DCI上发送的每个send-WR都携带了目的地址信息，如果DCI当前连接的对端不是send-WR里携带的对端(node地址不一样)，则它会首先断开当前的连接，再连接到send-WR里携带的对端。只要后续的send-WR里携带的都是当前已连接对端，则都可以复用当前已建立的连接。如果DCI在一段指定的时间内都没有发送操作则也会断开当前连接。注意DCT每次临时建立的是一个RC可靠连接。</p><h3 id="3-3-思考"><a href="#3-3-思考" class="headerlink" title="3.3 思考"></a>3.3 思考</h3><p>DCT preserves their core connection-oriented design, but dynamically creates and destroys one-to-one connections. This provides software the illusion of using one QP to communicate with multiple remote machines, but at a prohibitively large performance cost for our workloads: DCT requires three additional network messages when the target machine of a DCT queue pair changes: a disconnect packet to the current machine, and a two-way handshake with the next machine to establish a connection[FaSST, OSDI’16].</p><p>所以DCT在<strong>sparse traffic</strong>场景中，性能才高。</p><h3 id="3-4-XRC-vs-DCT"><a href="#3-4-XRC-vs-DCT" class="headerlink" title="3.4 XRC vs DCT"></a>3.4 XRC vs DCT</h3><ul><li>XRC: 发起端进程与不同node通信时，需要与不同node都建立XRC连接</li><li>DCT: 发起端进程与不同node通信时，只需建立一个连接；当发起端进程需要与新node通信时，先与原先的node断连，再与新node建连，从而达到只用一个连接的目标</li></ul><h3 id="3-5-学术论文"><a href="#3-5-学术论文" class="headerlink" title="3.5 学术论文"></a>3.5 学术论文</h3><p>KRCORE: a microsecond-scale RDMA control plane for elastic computing(ATC’22)<br><img src="/images/2024/10/019.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://zhuanlan.zhihu.com/p/567720023" target="_blank" rel="noopener">RDMA 高级</a></li><li><a href="https://zhuanlan.zhihu.com/p/279904125" target="_blank" rel="noopener">Savir专栏:11. RDMA之Shared Receive Queue</a></li><li><a href="https://docs.nvidia.com/networking/display/mlnxofedv543100/advanced+transport" target="_blank" rel="noopener">Advanced Transport</a></li><li><a href="https://www.openfabrics.org/images/eventpresos/workshops2014/DevWorkshop/presos/Monday/pdf/05_DC_Verbs.pdf" target="_blank" rel="noopener">Dynamically Connected Transport</a></li><li><a href="https://www.usenix.org/system/files/conference/osdi16/osdi16-kalia.pdf" target="_blank" rel="noopener">FaSST: Fast, Scalable and Simple Distributed Transactions with Two-Sided (RDMA) Datagram RPCs</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下RDMA SRQ(Shared Receive Queue)/XRC(eXtended Reliable Connection)/DCT(Dynamically Connected Transport)技术相关notes。
    
    </summary>
    
      <category term="RDMA" scheme="http://liujunming.github.io/categories/RDMA/"/>
    
    
      <category term="RDMA" scheme="http://liujunming.github.io/tags/RDMA/"/>
    
  </entry>
  
</feed>
