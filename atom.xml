<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>L</title>
  
  <subtitle>make it simple, make it happen.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://liujunming.github.io/"/>
  <updated>2023-04-22T09:30:38.240Z</updated>
  <id>http://liujunming.github.io/</id>
  
  <author>
    <name>liujunming</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Linux IOMMU bypass method</title>
    <link href="http://liujunming.github.io/2023/04/22/Linux-IOMMU-bypass-method/"/>
    <id>http://liujunming.github.io/2023/04/22/Linux-IOMMU-bypass-method/</id>
    <published>2023-04-22T08:45:06.000Z</published>
    <updated>2023-04-22T09:30:38.240Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/2023/04/01.jpg" alt><br><a id="more"></a><br><img src="/images/2023/04/03.jpg" alt></p><p><img src="/images/2023/04/02.jpg" alt><br>将AT字段设置为10b即可bypass IOMMU。</p><p><a href="/2019/11/24/Introduction-to-PCIe-Address-Translation-Services/">ATC</a>的深入理解：如果设备在ATC中找到对应的映射entry后，会将TLP AT字段设置为10b，并将TLP中的address字段设置为翻译后的地址。</p><hr><p>参考资料:</p><ol><li><a href="https://pdfs.semanticscholar.org/b450/50db1fb770a07bc60c66d3532ee4d1949ccb.pdf" target="_blank" rel="noopener">Thunderclap:Exploring Vulnerabilities in Operating System IOMMU Protection via DMA from Untrustworthy Peripherals</a></li><li>PCIe spec</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/2023/04/01.jpg&quot; alt&gt;&lt;br&gt;
    
    </summary>
    
      <category term="IOMMU" scheme="http://liujunming.github.io/categories/IOMMU/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
      <category term="IOMMU" scheme="http://liujunming.github.io/tags/IOMMU/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Root Complex</title>
    <link href="http://liujunming.github.io/2023/02/12/Notes-about-root-complex/"/>
    <id>http://liujunming.github.io/2023/02/12/Notes-about-root-complex/</id>
    <published>2023-02-12T09:36:29.000Z</published>
    <updated>2023-02-12T10:19:59.731Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Root Complex(RC)相关笔记。<br><img src="/images/2023/02/06.png" alt></p><a id="more"></a><p>The Root Complex is an entity that includes a Host Bridge and one or more root ports.<br><img src="/images/2023/02/07.png" alt></p><p>当CPU读写pcie设备的MMIO BAR时，RC的Host Bridge将processor transactions转换为TLP。因此当host bridge发现CPU访问的物理地址区间是MMIO时，会让目标EP(End Point)所属的root port发送memory read/write TLP，经过路由，最终TLP会下发到目标EP。</p><hr><p>参考资料:</p><ol><li><a href="http://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-1/" target="_blank" rel="noopener">Down to the TLP: How PCI express devices talk</a></li><li><a href="https://astralvx.com/introduction-to-pcie/" target="_blank" rel="noopener">Introduction to PCIe</a></li><li><a href="https://zhuanlan.zhihu.com/p/32786076" target="_blank" rel="noopener">使用Xilinx IP核进行PCIE开发学习笔记</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Root Complex(RC)相关笔记。&lt;br&gt;&lt;img src=&quot;/images/2023/02/06.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/categories/PCI-PCIe/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about vsock</title>
    <link href="http://liujunming.github.io/2023/02/11/Notes-about-vsock/"/>
    <id>http://liujunming.github.io/2023/02/11/Notes-about-vsock/</id>
    <published>2023-02-11T04:59:37.000Z</published>
    <updated>2023-02-11T06:11:05.414Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录vsock相关Notes。<a id="more"></a></p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p>VM Sockets(vsock) is a fast and efficient communication mechanism between guest virtual machines and their host. 说白了，就是允许guest与host利用socket进行通信(不依赖于虚拟机的网卡)，借助于网卡，guest与host也是可以进行socket通信的，但此时就不是vsock了。使用vsock进行socket编程时，需要使用新的socket address family AF_VSOCK。</p><h3 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h3><p><img src="/images/2023/02/01.jpg" alt><br><img src="/images/2023/02/02.jpg" alt><br><img src="/images/2023/02/03.jpg" alt></p><h3 id="How"><a href="#How" class="headerlink" title="How"></a>How</h3><p><img src="/images/2023/02/04.jpg" alt><br>There are several layers here.</p><ul><li>application, use &lt;cid,port&gt; as a socket address</li><li>socket layer, support for socket API</li><li>AF_VSOCK address family, implement the vsock core</li><li>transport, trasnport the data between guest and host.</li></ul><p>The transport layer is the mostly needed to talk as the other three just need to implement standand interfaces in kernel.</p><p>Transport as its name indicated, is used to transport the data between guest and host just like the networking card transport data between local and remote socket. There are two kinds of transports according to data’s flow direction.</p><ul><li>G2H: guest-&gt;host transport, they run in the guest and the guest vsock networking protocol uses this to communication with the host.</li><li>H2G: host-&gt;guest transport, they run in the host and the host vsock networing protocol uses this to communiction with the guest.</li></ul><p>Usually H2G transport is implemented as a device emulation, and G2H transport is implemented as the emulated device’s driver. For example, in VMware the H2G transport is a emulated vmci PCI device and the G2H is vmci device driver. In qemu the H2G transport is a emulated vhost-vsock device and the G2H transport is the vosck device’s driver.</p><p>Following picture shows the virtio(in guest) and vhost(in host) transport.<br><img src="/images/2023/02/05.jpg" alt></p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>可以参考 <a href="https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6" target="_blank" rel="noopener">https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6</a><br>在qemu-kvm + Linux guest环境中搭建vsock环境。</p><hr><p>参考资料:</p><ol><li><a href="https://vmsplice.net/~stefan/stefanha-kvm-forum-2015.pdf" target="_blank" rel="noopener">virtio-vsock Zero-configuration host/guest communication</a></li><li><a href="https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6" target="_blank" rel="noopener">https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6</a></li><li><a href="https://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/04/18/vsock-internals" target="_blank" rel="noopener">Linux vsock internals</a></li><li><a href="https://static.sched.com/hosted_files/devconfcz2020a/b1/DevConf.CZ_2020_vsock_v1.1.pdf" target="_blank" rel="noopener">VSOCK: VM ↔ host socket with minimal configuration</a></li><li><a href="https://www.man7.org/linux/man-pages/man7/vsock.7.html" target="_blank" rel="noopener">man vsock</a></li><li><a href="https://iaguozhi.github.io/blogs/vsock.html" target="_blank" rel="noopener">vsock 介绍与使用</a></li><li><a href="https://lwn.net/Articles/556550/" target="_blank" rel="noopener">Introduce VM Sockets virtio transport</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录vsock相关Notes。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Intel Hyper-Threading Technology</title>
    <link href="http://liujunming.github.io/2023/01/07/Notes-about-Intel-Hyper-Threading-Technology/"/>
    <id>http://liujunming.github.io/2023/01/07/Notes-about-Intel-Hyper-Threading-Technology/</id>
    <published>2023-01-07T05:33:43.000Z</published>
    <updated>2023-01-07T06:52:51.063Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录下作者对intel 超线程(Hyper-Threading)技术的理解。 <a id="more"></a> </p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/images/2023/01/01.jpg" alt><br><img src="/images/2023/01/02.jpg" alt><br>根据sdm的描述，同一个core上的两个超线程其实是共享execution engine的。</p><p><img src="/images/2023/01/03.jpg" alt><br>每个超线程拥有独立的通用寄存器。每个超线程的具体资源状态需要查询spec，本文不在此赘述。</p><h3 id="Execution-Engine"><a href="#Execution-Engine" class="headerlink" title="Execution Engine"></a>Execution Engine</h3><p><img src="/images/2023/01/04.jpg" alt><br>Execution Engine涉及到具体的微架构。接下来将以Ice Lake Client microarchitecture为例来介绍下Execution Engine。</p><p><img src="/images/2023/01/05.jpg" alt><br><img src="/images/2023/01/06.jpg" alt></p><p>Execution Unit是需要额外关注的。由上图可知，在一个Execution Engine内拥有4个ALU，1个Slow Int。</p><ul><li>同一个core上的两个超线程想同时执行<code>add</code>指令，这理论上是可行的，因为Execution Engine中有四个ALU Execution Unit(ALU可运行<code>add</code>指令)。</li><li>同一个core上的两个超线程想同时执行<code>mul</code>指令，这理论上是不可行的，因为Execution Engine中只有一个Slow Int Execution Unit(Slow Int可运行<code>mul</code>指令)。</li></ul><hr><p>参考资料:</p><ol><li><a href="https://cdrdv2.intel.com/v1/dl/getContent/671488" target="_blank" rel="noopener">Intel® 64 and IA-32 Architectures Optimization Reference Manual</a></li><li><a href="https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-lipp.pdf" target="_blank" rel="noopener">Meltdown: Reading Kernel Memory from User Space</a></li><li>Intel SDM Vol3</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录下作者对intel 超线程(Hyper-Threading)技术的理解。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="体系结构" scheme="http://liujunming.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
  <entry>
    <title>Notes about signal in Linux</title>
    <link href="http://liujunming.github.io/2022/12/18/Notes-about-signal-in-Linux/"/>
    <id>http://liujunming.github.io/2022/12/18/Notes-about-signal-in-Linux/</id>
    <published>2022-12-18T06:38:23.000Z</published>
    <updated>2022-12-18T08:21:07.581Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Linux的signal相关notes。<a id="more"></a><br><img src="/images/2022/12/05.jpg" alt></p><h3 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h3><p><a href="https://blog.csdn.net/w903414/article/details/109802539" target="_blank" rel="noopener">一篇文章彻底搞定信号</a></p><h4 id="信号是什么"><a href="#信号是什么" class="headerlink" title="信号是什么"></a>信号是什么</h4><p>例：</p><ol><li>输入命令，在Shell下启动一个前台进程。</li><li>用户按下Ctrl-C，键盘输入产生一个硬件中断。</li><li>如果CPU当前正在执行这个进程的代码，则该进程的用户空间代码暂停执行， CPU从用户态切换到内核态处理硬件中断。</li><li>终端驱动程序将Ctrl-C解释成一个<code>SIGINT</code>信号，记在该进程的PCB中（也可以说发送了一个<code>SIGINT</code>信号给该进程）。</li><li>当某个时刻要从内核返回到该进程的用户空间代码继续执行之前，首先处理PCB中记录的信号，发现有一个<code>SIGINT</code>信号待处理，而这个信号的默认处理动作是终止进程，所以直接终止进程而不再返回它的用户空间代码执行。</li></ol><p>在这个例子中，由Ctrl-C产生的硬件中断就是一个信号。Ctrl+C产生的信号只能发送给前台进程，命令后加&amp;就可放到后台运行。Shell可同时运行一个前台进程和任意多个后台进程，只有前台进程才能接受到像CTRL+C这种控制键产生的信号。</p><h4 id="信号的种类"><a href="#信号的种类" class="headerlink" title="信号的种类"></a>信号的种类</h4><h4 id="信号的产生"><a href="#信号的产生" class="headerlink" title="信号的产生"></a>信号的产生</h4><ul><li>硬件产生</li><li>软件产生</li></ul><h4 id="信号的注册"><a href="#信号的注册" class="headerlink" title="信号的注册"></a>信号的注册</h4><p>信号注册实际上是一个位图和一个sigqueue队列。<br><img src="/images/2022/12/06.png" alt></p><h4 id="信号的注销"><a href="#信号的注销" class="headerlink" title="信号的注销"></a>信号的注销</h4><h4 id="信号阻塞"><a href="#信号阻塞" class="headerlink" title="信号阻塞"></a>信号阻塞</h4><p><img src="/images/2022/12/07.png" alt></p><h4 id="信号未决"><a href="#信号未决" class="headerlink" title="信号未决"></a>信号未决</h4><p>实际执行信号的处理动作称为信号递达（Delivery），信号从产生到递达之间的状态，称为信号未决（Pending）。进程可以选择阻塞（Block）某个信号。被阻塞的信号产生时将保持在未决状态，直到进程解除对此信号的阻塞，才执行递达的动作。注意，阻塞和忽略是不同的，只要信号被阻塞就不会递达，而忽略是在递达之后可选的一种处理动作。</p><h4 id="信号的处理方式"><a href="#信号的处理方式" class="headerlink" title="信号的处理方式"></a>信号的处理方式</h4><p><img src="/images/2022/12/08.png" alt></p><p>每个信号都有两个标志位分别表示阻塞和未决，还有一个函数指针表示处理动作。</p><h4 id="信号的捕捉"><a href="#信号的捕捉" class="headerlink" title="信号的捕捉"></a>信号的捕捉</h4><p>条件: 如果信号的处理动作是用户自定义函数，在信号递达时就调用这个函数，这就称为信号捕捉。</p><p>流程:<br><img src="/images/2022/12/09.png" alt></p><p>内核态返回用户态会调用<code>do_signal</code>函数，两种情况：</p><ol><li>无信号：<code>sys_return</code>函数，返回用户态</li><li>有信号：先处理信号，信号返回，再调用<code>do_signal</code>函数 </li></ol><p>例：</p><ol><li>程序注册了<code>SIGQUIT</code>信号的处理函数sighandler。</li><li>当前正在执行main函数，这时发生中断或异常切换到内核态。</li><li>在中断处理完毕后要返回用户态的main函数之前检查到有信号SIGQUIT递达。</li><li>内核决定返回用户态后不是恢复main函数的上下文继续执行，而是执行sighandler函数， <strong>sighandler和main函数之间不存在调用和被调用的关系，是两个独立的控制流程。</strong></li><li>sighandler函数返回后自动执行特殊的系统调用sig_return再次进入内核态。</li><li>如果没有新的信号要递达，这次再返回用户态就是恢复main函数的上下文继续执行了。</li></ol><h4 id="常用信号集操作函数"><a href="#常用信号集操作函数" class="headerlink" title="常用信号集操作函数"></a>常用信号集操作函数</h4><h4 id="SIGCHLD信号"><a href="#SIGCHLD信号" class="headerlink" title="SIGCHLD信号"></a>SIGCHLD信号</h4><h3 id="SIGKILL-vs-SIGTERM"><a href="#SIGKILL-vs-SIGTERM" class="headerlink" title="SIGKILL vs SIGTERM"></a>SIGKILL vs SIGTERM</h3><p>Though both of these signals are used for killing a process, there are some differences between the two:</p><ul><li><code>SIGTERM</code> gracefully kills the process whereas <code>SIGKILL</code> kills the process immediately.</li><li><code>SIGTERM</code> signal can be handled, ignored, and blocked, but <code>SIGKILL</code> cannot be handled or blocked.</li><li><code>SIGTERM</code> doesn’t kill the child processes. <code>SIGKILL</code> kills the child processes as well.</li></ul><p><img src="https://linuxhandbook.com/content/images/2022/04/sigterm-vs-sigkill-tip.webp" alt></p><hr><p>参考资料:</p><ol><li><a href="https://www.man7.org/linux/man-pages/man7/signal.7.html" target="_blank" rel="noopener">man signal</a></li><li><a href="https://www-uxsup.csx.cam.ac.uk/courses/moved.Building/signals.pdf" target="_blank" rel="noopener">A list of signals and what they mean</a></li><li><a href="https://linuxhandbook.com/sigterm-vs-sigkill/#:~:text=Though%20both%20of%20these%20signals%20are%20used%20for,blocked%2C%20but%20SIGKILL%20cannot%20be%20handled%20or%20blocked." target="_blank" rel="noopener">SIGTERM vs SIGKILL: What’s the Difference?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Linux的signal相关notes。
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>深入解析virtio-blk resize原理</title>
    <link href="http://liujunming.github.io/2022/12/17/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90virtio-blk-resize%E5%8E%9F%E7%90%86/"/>
    <id>http://liujunming.github.io/2022/12/17/深入解析virtio-blk-resize原理/</id>
    <published>2022-12-17T07:05:05.000Z</published>
    <updated>2022-12-18T03:12:28.554Z</updated>
    
    <content type="html"><![CDATA[<p>本文将结合virtio spec、qemu与Linux kernel源码深入解析virtio-blk resize的原理。<a id="more"></a> </p><p>本文参考的virtio spec是<a href="https://ozlabs.org/~rusty/virtio-spec/virtio-0.9.5.pdf" target="_blank" rel="noopener">0.9.5</a>，qemu版本为<a href="https://gitlab.com/qemu-project/qemu/-/tree/v2.6.0" target="_blank" rel="noopener">v2.6.0</a>，Linux kernel版本为<a href="https://elixir.bootlin.com/linux/v4.19/source" target="_blank" rel="noopener">v4.19</a>。</p><h2 id="1-overview"><a href="#1-overview" class="headerlink" title="1. overview"></a>1. overview</h2><p>virtio-blk后端设备resize后，通过msi-x的configuration vector给guest发送中断，guest收到中断后，handler会读取virtio header中的capacity field来完成resize操作。</p><h2 id="2-基础知识"><a href="#2-基础知识" class="headerlink" title="2. 基础知识"></a>2. 基础知识</h2><p>virtio header中有configuration vector这个field。guest配置MSI-x table时，会配置好configuration vector。<br><img src="/images/2022/12/03.jpg" alt></p><p>当后端设备配置发生变化时，会触发configuration vector对应的中断。<br><img src="/images/2022/12/04.jpg" alt></p><p>对于virtio-blk设备，virtio header中的capacity存放了size信息。当resize时，capacity会发生变化。<br><img src="/images/2022/12/02.jpg" alt><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk_config</span> &#123;</span></span><br><span class="line"><span class="comment">/* The capacity (in 512-byte sectors). */</span></span><br><span class="line">__u64 capacity;</span><br><span class="line"><span class="comment">/* The maximum segment size (if VIRTIO_BLK_F_SIZE_MAX) */</span></span><br><span class="line">__u32 size_max;</span><br><span class="line"><span class="comment">/* The maximum number of segments (if VIRTIO_BLK_F_SEG_MAX) */</span></span><br><span class="line">__u32 seg_max;</span><br><span class="line"><span class="comment">/* geometry of the device (if VIRTIO_BLK_F_GEOMETRY) */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk_geometry</span> &#123;</span></span><br><span class="line">__u16 cylinders;</span><br><span class="line">__u8 heads;</span><br><span class="line">__u8 sectors;</span><br><span class="line">&#125; geometry;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* block size of device (if VIRTIO_BLK_F_BLK_SIZE) */</span></span><br><span class="line">__u32 blk_size;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* the next 4 entries are guarded by VIRTIO_BLK_F_TOPOLOGY  */</span></span><br><span class="line"><span class="comment">/* exponent for physical block per logical block. */</span></span><br><span class="line">__u8 physical_block_exp;</span><br><span class="line"><span class="comment">/* alignment offset in logical blocks. */</span></span><br><span class="line">__u8 alignment_offset;</span><br><span class="line"><span class="comment">/* minimum I/O size without performance penalty in logical blocks. */</span></span><br><span class="line">__u16 min_io_size;</span><br><span class="line"><span class="comment">/* optimal sustained I/O size in logical blocks. */</span></span><br><span class="line">__u32 opt_io_size;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* writeback mode (if VIRTIO_BLK_F_CONFIG_WCE) */</span></span><br><span class="line">__u8 wce;</span><br><span class="line">__u8 unused;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* number of vqs, only available when VIRTIO_BLK_F_MQ is set */</span></span><br><span class="line">__u16 num_queues;</span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure></p><h2 id="3-virtio-blk后端设备resize"><a href="#3-virtio-blk后端设备resize" class="headerlink" title="3. virtio-blk后端设备resize"></a>3. virtio-blk后端设备resize</h2><p>首先需要完成virtio-blk后端设备的resize，比如virtio-blk后端设备是一个文件，那么需要将这个文件resize！virtio-blk后端设备的形式较多，不在本文描述范围之内。</p><h2 id="4-QEMU发送configuration-vector中断"><a href="#4-QEMU发送configuration-vector中断" class="headerlink" title="4. QEMU发送configuration vector中断"></a>4. QEMU发送configuration vector中断</h2><h3 id="4-1-hmp-block-resize命令"><a href="#4-1-hmp-block-resize命令" class="headerlink" title="4.1 hmp block_resize命令"></a>4.1 hmp block_resize命令</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hmp_block_resize</span><br><span class="line">└── qmp_block_resize</span><br><span class="line">    └── bdrv_truncate</span><br><span class="line">        └── blk_dev_resize_cb</span><br><span class="line">            └── virtio_blk_resize[resize_cb]</span><br></pre></td></tr></table></figure><p>hmp <code>block_resize</code>命令的函数调用链如上所示，最终会调用到<code>virtio_blk_resize</code>函数。</p><h3 id="4-2-virtio-blk-resize发送configuration-vector中断"><a href="#4-2-virtio-blk-resize发送configuration-vector中断" class="headerlink" title="4.2 virtio_blk_resize发送configuration vector中断"></a>4.2 virtio_blk_resize发送configuration vector中断</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">virtio_blk_resize</span><br><span class="line">└── virtio_notify_config</span><br><span class="line">    └── virtio_notify_vector(vdev, vdev-&gt;config_vector)</span><br><span class="line">        └── virtio_pci_notify</span><br><span class="line">            └── msix_notify</span><br><span class="line">                ├── msix_get_message</span><br><span class="line">                └── msi_send_message</span><br></pre></td></tr></table></figure><p>最终qemu会调用<code>msi_send_message</code>往guest注入configuration vector中断(本质上是模拟memory write TLP)。</p><h2 id="5-guest处理configuration-vector中断"><a href="#5-guest处理configuration-vector中断" class="headerlink" title="5. guest处理configuration vector中断"></a>5. guest处理configuration vector中断</h2><h3 id="5-1-guest注册中断"><a href="#5-1-guest注册中断" class="headerlink" title="5.1 guest注册中断"></a>5.1 guest注册中断</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">vp_request_msix_vectors</span><span class="params">(struct virtio_device *vdev, <span class="keyword">int</span> nvectors,</span></span></span><br><span class="line"><span class="function"><span class="params">   <span class="keyword">bool</span> per_vq_vectors, struct irq_affinity *desc)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">err = request_irq(pci_irq_vector(vp_dev-&gt;pci_dev, v),</span><br><span class="line">vp_config_changed, <span class="number">0</span>, vp_dev-&gt;msix_names[v],</span><br><span class="line">vp_dev);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Handle a configuration change: Tell driver if it wants to know. */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> irqreturn_t <span class="title">vp_config_changed</span><span class="params">(<span class="keyword">int</span> irq, <span class="keyword">void</span> *opaque)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_pci_device</span> *<span class="title">vp_dev</span> = <span class="title">opaque</span>;</span></span><br><span class="line"></span><br><span class="line">virtio_config_changed(&amp;vp_dev-&gt;vdev);</span><br><span class="line"><span class="keyword">return</span> IRQ_HANDLED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">virtio_config_changed</span><span class="params">(struct virtio_device *dev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line"></span><br><span class="line">spin_lock_irqsave(&amp;dev-&gt;config_lock, flags);</span><br><span class="line">__virtio_config_changed(dev);</span><br><span class="line">spin_unlock_irqrestore(&amp;dev-&gt;config_lock, flags);</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL_GPL(virtio_config_changed);</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __virtio_config_changed(struct virtio_device *dev)</span><br><span class="line">&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_driver</span> *<span class="title">drv</span> = <span class="title">drv_to_virtio</span>(<span class="title">dev</span>-&gt;<span class="title">dev</span>.<span class="title">driver</span>);</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!dev-&gt;config_enabled)</span><br><span class="line">dev-&gt;config_change_pending = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (drv &amp;&amp; drv-&gt;config_changed)</span><br><span class="line">drv-&gt;config_changed(dev); <span class="comment">//for virtio-blk, it's virtblk_config_changed</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">virtio_driver</span> <span class="title">virtio_blk</span> = &#123;</span></span><br><span class="line">...</span><br><span class="line">.config_changed= virtblk_config_changed,</span><br><span class="line">...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtblk_config_changed</span><span class="params">(struct virtio_device *vdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk</span> *<span class="title">vblk</span> = <span class="title">vdev</span>-&gt;<span class="title">priv</span>;</span></span><br><span class="line"></span><br><span class="line">queue_work(virtblk_wq, &amp;vblk-&gt;config_work);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">virtblk_probe</span><span class="params">(struct virtio_device *vdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">INIT_WORK(&amp;vblk-&gt;config_work, virtblk_config_changed_work);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-2-中断handler处理resize"><a href="#5-2-中断handler处理resize" class="headerlink" title="5.2 中断handler处理resize"></a>5.2 中断handler处理resize</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">virtblk_config_changed_work</span><br><span class="line">└── virtblk_update_capacity</span><br><span class="line">    └── virtio_cread</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* The queue's logical block size must be set before calling this */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtblk_update_capacity</span><span class="params">(struct virtio_blk *vblk, <span class="keyword">bool</span> resize)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_device</span> *<span class="title">vdev</span> = <span class="title">vblk</span>-&gt;<span class="title">vdev</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">request_queue</span> *<span class="title">q</span> = <span class="title">vblk</span>-&gt;<span class="title">disk</span>-&gt;<span class="title">queue</span>;</span></span><br><span class="line"><span class="keyword">char</span> cap_str_2[<span class="number">10</span>], cap_str_10[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> nblocks;</span><br><span class="line">u64 capacity;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Host must always specify the capacity. */</span></span><br><span class="line">virtio_cread(vdev, struct virtio_blk_config, capacity, &amp;capacity);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>virtio_cread(vdev, struct virtio_blk_config, capacity, &amp;capacity)</code>其实就是读virtio header中的capacity field，此时会发生VM Exit trap到qemu中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Config space accessors. */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> virtio_cread(vdev, structname, member, ptr)\</span></span><br><span class="line"><span class="keyword">do</span> &#123;\</span><br><span class="line"><span class="comment">/* Must match the member's type, and be integer */</span>\</span><br><span class="line"><span class="keyword">if</span> (!typecheck(typeof((((structname*)<span class="number">0</span>)-&gt;member)), *(ptr))) \</span><br><span class="line">(*ptr) = <span class="number">1</span>;\</span><br><span class="line">\</span><br><span class="line"><span class="keyword">switch</span> (<span class="keyword">sizeof</span>(*ptr)) &#123;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">1</span>:\</span><br><span class="line">*(ptr) = virtio_cread8(vdev,\</span><br><span class="line">       offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">2</span>:\</span><br><span class="line">*(ptr) = virtio_cread16(vdev,\</span><br><span class="line">offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">4</span>:\</span><br><span class="line">*(ptr) = virtio_cread32(vdev,\</span><br><span class="line">offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">8</span>:\</span><br><span class="line">*(ptr) = virtio_cread64(vdev,\</span><br><span class="line">offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">default</span>:\</span><br><span class="line">BUG();\</span><br><span class="line">&#125;\</span><br><span class="line">&#125; <span class="keyword">while</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> u64 <span class="title">virtio_cread64</span><span class="params">(struct virtio_device *vdev,</span></span></span><br><span class="line"><span class="function"><span class="params"> <span class="keyword">unsigned</span> <span class="keyword">int</span> offset)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">u64 ret;</span><br><span class="line">__virtio_cread_many(vdev, offset, &amp;ret, <span class="number">1</span>, <span class="keyword">sizeof</span>(ret));</span><br><span class="line"><span class="keyword">return</span> virtio64_to_cpu(vdev, (__force __virtio64)ret);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Read @count fields, @bytes each. */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span> __virtio_cread_many(struct virtio_device *vdev,</span><br><span class="line">       <span class="keyword">unsigned</span> <span class="keyword">int</span> offset,</span><br><span class="line">       <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> count, <span class="keyword">size_t</span> bytes)</span><br><span class="line">&#123;</span><br><span class="line">u32 old, gen = vdev-&gt;config-&gt;generation ?</span><br><span class="line">vdev-&gt;config-&gt;generation(vdev) : <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"></span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">old = gen;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; count; i++)</span><br><span class="line">vdev-&gt;config-&gt;get(vdev, offset + bytes * i,</span><br><span class="line">  buf + i * bytes, bytes);</span><br><span class="line"></span><br><span class="line">gen = vdev-&gt;config-&gt;generation ?</span><br><span class="line">vdev-&gt;config-&gt;generation(vdev) : <span class="number">0</span>;</span><br><span class="line">&#125; <span class="keyword">while</span> (gen != old);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="6-qemu完成virtio-header中capacity-field的模拟"><a href="#6-qemu完成virtio-header中capacity-field的模拟" class="headerlink" title="6. qemu完成virtio header中capacity field的模拟"></a>6. qemu完成virtio header中capacity field的模拟</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">uint32_t</span> virtio_config_readb(VirtIODevice *vdev, <span class="keyword">uint32_t</span> addr)</span><br><span class="line">&#123;</span><br><span class="line">    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);</span><br><span class="line">    <span class="keyword">uint8_t</span> val;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (addr + <span class="keyword">sizeof</span>(val) &gt; vdev-&gt;config_len) &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">uint32_t</span>)<span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    k-&gt;get_config(vdev, vdev-&gt;config);<span class="comment">//对应到virtio_blk_update_config</span></span><br><span class="line"></span><br><span class="line">    val = ldub_p(vdev-&gt;config + addr);</span><br><span class="line">    <span class="keyword">return</span> val;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* coalesce internal state, copy to pci i/o region 0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtio_blk_update_config</span><span class="params">(VirtIODevice *vdev, <span class="keyword">uint8_t</span> *config)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    VirtIOBlock *s = VIRTIO_BLK(vdev);</span><br><span class="line">    BlockConf *conf = &amp;s-&gt;conf.conf;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk_config</span> <span class="title">blkcfg</span>;</span></span><br><span class="line">    <span class="keyword">uint64_t</span> capacity;</span><br><span class="line">    <span class="keyword">int</span> blk_size = conf-&gt;logical_block_size;</span><br><span class="line"></span><br><span class="line">    blk_get_geometry(s-&gt;blk, &amp;capacity);</span><br><span class="line">    <span class="built_in">memset</span>(&amp;blkcfg, <span class="number">0</span>, <span class="keyword">sizeof</span>(blkcfg));</span><br><span class="line">    virtio_stq_p(vdev, &amp;blkcfg.capacity, capacity);</span><br><span class="line">    virtio_stl_p(vdev, &amp;blkcfg.seg_max, <span class="number">128</span> - <span class="number">2</span>);</span><br><span class="line">    virtio_stw_p(vdev, &amp;blkcfg.geometry.cylinders, conf-&gt;cyls);</span><br><span class="line">    virtio_stl_p(vdev, &amp;blkcfg.blk_size, blk_size);</span><br><span class="line">    virtio_stw_p(vdev, &amp;blkcfg.min_io_size, conf-&gt;min_io_size / blk_size);</span><br><span class="line">    virtio_stw_p(vdev, &amp;blkcfg.opt_io_size, conf-&gt;opt_io_size / blk_size);</span><br><span class="line">    blkcfg.geometry.heads = conf-&gt;heads;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * We must ensure that the block device capacity is a multiple of</span></span><br><span class="line"><span class="comment">     * the logical block size. If that is not the case, let's use</span></span><br><span class="line"><span class="comment">     * sector_mask to adopt the geometry to have a correct picture.</span></span><br><span class="line"><span class="comment">     * For those devices where the capacity is ok for the given geometry</span></span><br><span class="line"><span class="comment">     * we don't touch the sector value of the geometry, since some devices</span></span><br><span class="line"><span class="comment">     * (like s390 dasd) need a specific value. Here the capacity is already</span></span><br><span class="line"><span class="comment">     * cyls*heads*secs*blk_size and the sector value is not block size</span></span><br><span class="line"><span class="comment">     * divided by 512 - instead it is the amount of blk_size blocks</span></span><br><span class="line"><span class="comment">     * per track (cylinder).</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (blk_getlength(s-&gt;blk) /  conf-&gt;heads / conf-&gt;secs % blk_size) &#123;</span><br><span class="line">        blkcfg.geometry.sectors = conf-&gt;secs &amp; ~s-&gt;sector_mask;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        blkcfg.geometry.sectors = conf-&gt;secs;</span><br><span class="line">    &#125;</span><br><span class="line">    blkcfg.size_max = <span class="number">0</span>;</span><br><span class="line">    blkcfg.physical_block_exp = get_physical_block_exp(conf);</span><br><span class="line">    blkcfg.alignment_offset = <span class="number">0</span>;</span><br><span class="line">    blkcfg.wce = blk_enable_write_cache(s-&gt;blk);</span><br><span class="line">    <span class="built_in">memcpy</span>(config, &amp;blkcfg, <span class="keyword">sizeof</span>(struct virtio_blk_config));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>参考资料:</p><ol><li><a href="http://m.blog.chinaunix.net/uid-29718549-id-4390132.html" target="_blank" rel="noopener">qemu block_resize(动态修改磁盘大小)实现简记</a></li><li><a href="https://blog.frehi.be/2022/08/01/online-resizing-block-devices-and-file-systems/" target="_blank" rel="noopener">Online resizing block devices and file systems</a></li><li><a href="https://serverfault.com/a/743106" target="_blank" rel="noopener">Is online disk resize possible with KVM?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将结合virtio spec、qemu与Linux kernel源码深入解析virtio-blk resize的原理。
    
    </summary>
    
      <category term="virtio" scheme="http://liujunming.github.io/categories/virtio/"/>
    
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Intel turbo boost</title>
    <link href="http://liujunming.github.io/2022/12/03/Notes-about-Intel-turbo-boost/"/>
    <id>http://liujunming.github.io/2022/12/03/Notes-about-Intel-turbo-boost/</id>
    <published>2022-12-03T11:08:59.000Z</published>
    <updated>2022-12-03T11:38:55.483Z</updated>
    
    <content type="html"><![CDATA[<p>Intel turbo boost的中文翻译为”睿频加速”，一般情况下turbo(睿频)指的就是Intel turbo boost。本文将记录turbo相关notes。<a id="more"></a> </p><p><img src="/images/2022/12/01.jpg" alt></p><p>CPUs don’t always need to run at their maximum frequency. Some programs are more dependent on memory to run smoothly, while others are CPU-intensive. Intel Turbo Boost Technology is an energy-efficient solution to this imbalance: it lets the CPU run at its base clock speed when handling light workloads, then jump to a higher clock speed for heavy workloads.</p><p>Running at a lower clock rate (the number of cycles executed by the processor every second) allows the processor to use less power, which can reduce heat and positively impact battery life in laptops. But when more speed is needed, Intel Turbo Boost Technology dynamically increases the clock rate to compensate.</p><p>Intel Turbo Boost Technology can potentially increase CPU speeds up to the Max Turbo Frequency while staying within safe temperature and power limits. This can increase performance in both single-threaded and multithreaded applications (programs that utilize several processor cores).</p><hr><p>参考资料:</p><ol><li><a href="https://www.intel.com/content/www/us/en/support/articles/000030893/processors.html" target="_blank" rel="noopener">What Is Intel® Turbo Boost Technology and How Does It Work?</a></li><li><a href="https://www.intel.com/content/www/us/en/gaming/resources/turbo-boost.htm" target="_blank" rel="noopener">What Is Intel® Turbo Boost Technology?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Intel turbo boost的中文翻译为”睿频加速”，一般情况下turbo(睿频)指的就是Intel turbo boost。本文将记录turbo相关notes。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
  <entry>
    <title>How to use IO poll in Linux NVMe driver</title>
    <link href="http://liujunming.github.io/2022/11/29/How-to-use-IO-poll-in-Linux-NVMe-driver/"/>
    <id>http://liujunming.github.io/2022/11/29/How-to-use-IO-poll-in-Linux-NVMe-driver/</id>
    <published>2022-11-29T15:09:37.000Z</published>
    <updated>2022-11-29T15:35:56.810Z</updated>
    
    <content type="html"><![CDATA[<p>使用NVMe driver的<code>poll_queues</code>参数即可开启IO queue的poll。<a id="more"></a> </p><h3 id="内核源码"><a href="#内核源码" class="headerlink" title="内核源码"></a>内核源码</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//https://elixir.bootlin.com/linux/v6.0/source/drivers/nvme/host/pci.c</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> poll_queues;</span><br><span class="line">module_param_cb(poll_queues, &amp;io_queue_count_ops, &amp;poll_queues, <span class="number">0644</span>);</span><br><span class="line">MODULE_PARM_DESC(poll_queues, <span class="string">"Number of queues to use for polled IO."</span>);</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nvme_setup_io_queues</span><span class="params">(struct nvme_dev *dev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">dev-&gt;nr_poll_queues = poll_queues;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>当只有一个IO queue时，设置<code>poll_queues</code>为1后，发现依然有中断。其实这是符合预取的。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nvme_setup_irqs</span><span class="params">(struct nvme_dev *dev, <span class="keyword">unsigned</span> <span class="keyword">int</span> nr_io_queues)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pci_dev</span> *<span class="title">pdev</span> = <span class="title">to_pci_dev</span>(<span class="title">dev</span>-&gt;<span class="title">dev</span>);</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">irq_affinity</span> <span class="title">affd</span> = &#123;</span></span><br><span class="line">.pre_vectors= <span class="number">1</span>,</span><br><span class="line">.calc_sets= nvme_calc_irq_sets,</span><br><span class="line">.priv= dev,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> irq_queues, poll_queues;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Poll queues don't need interrupts, but we need at least one I/O queue</span></span><br><span class="line"><span class="comment"> * left over for non-polled I/O.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">poll_queues = min(dev-&gt;nr_poll_queues, nr_io_queues - <span class="number">1</span>);</span><br><span class="line">dev-&gt;io_queues[HCTX_TYPE_POLL] = poll_queues;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Initialize for the single interrupt case, will be updated in</span></span><br><span class="line"><span class="comment"> * nvme_calc_irq_sets().</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">dev-&gt;io_queues[HCTX_TYPE_DEFAULT] = <span class="number">1</span>;</span><br><span class="line">dev-&gt;io_queues[HCTX_TYPE_READ] = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * We need interrupts for the admin queue and each non-polled I/O queue,</span></span><br><span class="line"><span class="comment"> * but some Apple controllers require all queues to use the first</span></span><br><span class="line"><span class="comment"> * vector.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">irq_queues = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span> (!(dev-&gt;ctrl.quirks &amp; NVME_QUIRK_SINGLE_VECTOR))</span><br><span class="line">irq_queues += (nr_io_queues - poll_queues);</span><br><span class="line"><span class="keyword">return</span> pci_alloc_irq_vectors_affinity(pdev, <span class="number">1</span>, irq_queues,</span><br><span class="line">      PCI_IRQ_ALL_TYPES | PCI_IRQ_AFFINITY, &amp;affd);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>由上述代码可知，driver至少留一个IO queue使用interrupt而非poll。</p><p>因此，当只有一个IO queue时，即使driver参数设置了<code>poll_queues</code>为1，其实是不生效的(<code>nvme_setup_irqs</code>中的<code>poll_queues</code>变量为0)，这个唯一的IO queue使用的依然是interrupt而非poll。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用NVMe driver的&lt;code&gt;poll_queues&lt;/code&gt;参数即可开启IO queue的poll。
    
    </summary>
    
      <category term="存储" scheme="http://liujunming.github.io/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="http://liujunming.github.io/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Notes about sysctl</title>
    <link href="http://liujunming.github.io/2022/11/27/Notes-about-sysctl/"/>
    <id>http://liujunming.github.io/2022/11/27/Notes-about-sysctl/</id>
    <published>2022-11-27T07:28:45.000Z</published>
    <updated>2022-11-27T11:15:38.702Z</updated>
    
    <content type="html"><![CDATA[<p><code>sysctl</code>的用法可参考<code>man sysctl</code>。<a id="more"></a><br>本文主要转载自<a href="https://cloud.tencent.com/developer/article/1657639" target="_blank" rel="noopener">Linux 下的 Sysctl 命令</a>。</p><p>作为一个 Linux 系统管理员，有时候你需要修改默认的内核行为。例如，你可能想要启用 SysRq 或者增加 Kernel 能够接受的连接数量。 内核参数可以在构建内核的时候，在系统启动时，或者在运行时进行设置。</p><p>本文讲解如何使用<code>sysct</code>l命令在运行时进行查看并且修改内核参数。</p><h3 id="1-使用sysctl查看-Kernel-参数"><a href="#1-使用sysctl查看-Kernel-参数" class="headerlink" title="1. 使用sysctl查看 Kernel 参数"></a>1. 使用sysctl查看 Kernel 参数</h3><p>想要查看所有的当前内核参数，运行<code>sysctl</code> 命令加上<code>-a</code>选项：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -a</span><br></pre></td></tr></table></figure></p><p>这将会输出一个很大的列表，看起来像下面这样，每行包含一个参数和对应的值：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">abi.vsyscall32 = 1</span><br><span class="line">debug.exception-trace = 1</span><br><span class="line">debug.kprobes-optimization = 1</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>所有用户可以查看当前的内核参数；仅仅 root 用户可以修改它们的值。</p><p>通过将参数名传递给<code>sysctl</code>,你可以检查单个参数的取值。例如，想要检查当前的 swappiness 取值，你可以输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl vm.swappiness</span><br></pre></td></tr></table></figure></p><p>输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vm.swappiness = 60</span><br></pre></td></tr></table></figure></p><p>Swappiness 是一个内核属性，它定义了系统多长时间会使用swap space。</p><p>这个<code>sysctl</code>命令将会从<code>/proc/sys</code>目录下读取信息。 <code>/proc/sys</code>是一个虚拟目录，它包含文件对象，可以被用来查看或者设置当前的内核参数。</p><p>你也可以通过显示合适的文件，来查看参数值。唯一的不同就是文件如何被展示。例如，<code>sysctl vm.swappiness</code>和<code>cat /proc/sys/vm/swappiness</code>都将给出同样的输出。当使用<code>sysctl</code>时，目录中的斜杠将会被点所替代，并且<code>proc.sys</code>部分被去掉了。</p><h3 id="2-使用sysctl来修改内核参数"><a href="#2-使用sysctl来修改内核参数" class="headerlink" title="2. 使用sysctl来修改内核参数"></a>2. 使用sysctl来修改内核参数</h3><p>想要在系统运行时设置一个内核参数，按照下面的格式运行<code>sysctl</code>命令加上参数名和取值：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w parameter=value</span><br></pre></td></tr></table></figure><p>如果这个取值包含空格或者特殊符号，使用双引号包裹取值。你还可以在同一个命令中传递多个<code>parameter=value</code> 键值对。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在生产系统中修改内核设置必须非常小心，这可能会使得内核不稳当，并且你需要重启系统。</span><br></pre></td></tr></table></figure><p>例如，想要允许 IPV4 包转发，你需要运行：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv4.ip_forward=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>这个修改立即生效，但是它不是持久化的。在系统重启后，默认值会被重新加载。</p><p>想要永久修改一个参数，你需要修改设置到文件<code>/etc/sysctl.conf</code> ：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv4.ip_forward=<span class="number">1</span> &gt;&gt; <span class="regexp">/etc/</span>sysctl.conf</span><br></pre></td></tr></table></figure><p>另外修改参数的方式就是使用<code>echo</code>命令将设置写入到<code>/proc/sys</code>目录下的文件中。例如，不使用上面的命令，你还可以用：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="number">1</span> &gt; <span class="regexp">/proc/</span>sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><p>这个<code>-p</code>选项允许你从一个配置文件中加载设置：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -p /etc/sysctl.d/file_name.conf</span><br></pre></td></tr></table></figure><p>如果没有给出文件，那么 <code>sysctl</code> 从 <code>/etc/sysctl.conf</code>文件中读取。</p><h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h3><p><code>sysctl</code> 命令允许你查看并且修改 Linux 内核参数。</p><hr><p>参考资料:</p><ol><li><a href="https://linux.die.net/man/8/sysctl" target="_blank" rel="noopener">man sysctl</a></li><li><a href="https://cloud.tencent.com/developer/article/1657639" target="_blank" rel="noopener">Linux 下的 Sysctl 命令</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;sysctl&lt;/code&gt;的用法可参考&lt;code&gt;man sysctl&lt;/code&gt;。
    
    </summary>
    
      <category term="工具" scheme="http://liujunming.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://liujunming.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Linux Hungtask机制</title>
    <link href="http://liujunming.github.io/2022/11/27/Linux-Hungtask%E6%9C%BA%E5%88%B6/"/>
    <id>http://liujunming.github.io/2022/11/27/Linux-Hungtask机制/</id>
    <published>2022-11-27T03:36:29.000Z</published>
    <updated>2022-11-27T06:33:40.495Z</updated>
    
    <content type="html"><![CDATA[<p>本文将总结Linux的Hungtask机制。<a id="more"></a><br>本文参考的内核源码版本为<a href="https://elixir.bootlin.com/linux/v4.0/source" target="_blank" rel="noopener">v4.0</a>。</p><h3 id="1-现象"><a href="#1-现象" class="headerlink" title="1. 现象"></a>1. 现象</h3><p>内核日志会看到如下信息:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INFO: task filebench:7143 blocked for more than 120 seconds.</span><br><span class="line">21794 Oct 24 13:21:33 localhost kernel: &quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.</span><br></pre></td></tr></table></figure></p><h3 id="2-背景知识"><a href="#2-背景知识" class="headerlink" title="2. 背景知识"></a>2. 背景知识</h3><p>长期以来，处于D状态(<code>TASK_UNINTERRUPTIBLE</code>状态)的进程都是让人比较烦恼的问题，处于D状态的进程不能接收信号，kill不掉。在一些场景下，常见的进程长期处于D状态，用户对此无能为力，也不知道原因，只能重启恢复。<br>其实进程长期处于D状态肯定是不正常的，内核中设计D状态的目的是为了让进程等待IO完成，正常情况下IO应该会顺利完成，然后唤醒相应的D状态进程，即使在异常情况下(比如磁盘离或损坏、磁阵链路断开等)，IO处理也是有超时机制的，原理上不会存在永久处于D状态的进程。但是因为内核代码流程中可能存在一些bug，或者用户内核模块中的相关机制不合理，可能导致进程长期处于D状态，无法唤醒，类似于死锁状态。<br>针对这种情况，内核中提供了hung task机制用于检测系统中是否存在处于D状态超过120s(时长可以设置)的进程，如果存在，则打印相关警告和进程堆栈。如果配置了<code>hung_task_panic</code>，则直接发起panic，结合kdump可以搜集到vmcore。从内核的角度看，如果有进程处于D状态的时间超过了120s，那肯定已经出现异常了，以此机制来收集相关的异常信息，用于分析定位问题。</p><h3 id="3-基本原理"><a href="#3-基本原理" class="headerlink" title="3. 基本原理"></a>3. 基本原理</h3><p>创建一个内核线程(khungtaskd)，定期(120s)唤醒后，遍历系统中的所有进程，检查是否存在处于D状态超过120s(时长可以设置)的进程，如果存在，则打印相关警告和进程堆栈。如果配置了hung_task_panic（proc或内核启动参数），则直接发起panic。</p><h3 id="4-源码解析"><a href="#4-源码解析" class="headerlink" title="4. 源码解析"></a>4. 源码解析</h3><p><a href="https://elixir.bootlin.com/linux/v4.0/source/kernel/hung_task.c" target="_blank" rel="noopener">kernel/hung_task.c</a><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hung_task_init</span><br><span class="line">└── watchdog</span><br><span class="line">    └── check_hung_uninterruptible_tasks</span><br><span class="line">        └── check_hung_task</span><br></pre></td></tr></table></figure></p><h4 id="4-1-初始化"><a href="#4-1-初始化" class="headerlink" title="4.1 初始化"></a>4.1 初始化</h4><p>初始化一个内核线程来检测系统中是否存在D状态超过120s的进程。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> __<span class="function">init <span class="title">hung_task_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">/*注册panic通知链，在panic时执行相关操作。*/</span></span><br><span class="line">atomic_notifier_chain_register(&amp;panic_notifier_list, &amp;panic_block);</span><br><span class="line"><span class="comment">/*创建内核线程khungtaskd，执行函数为watchdog*/</span></span><br><span class="line">watchdog_task = kthread_run(watchdog, <span class="literal">NULL</span>, <span class="string">"khungtaskd"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-2-watchdog"><a href="#4-2-watchdog" class="headerlink" title="4.2 watchdog"></a>4.2 watchdog</h4><p>khungtaskd内核线程的处理函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * kthread which checks for tasks stuck in D state</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">watchdog</span><span class="params">(<span class="keyword">void</span> *dummy)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">/*设置当前khungtaskd内核线程的nice为0，即普通优先级，为了不影响业务运行*/</span></span><br><span class="line">set_user_nice(current, <span class="number">0</span>);</span><br><span class="line"><span class="comment">/*死循环进行检测*/</span></span><br><span class="line"><span class="keyword">for</span> ( ; ; ) &#123;</span><br><span class="line"><span class="comment">/*进程处于D状态的时间上限可通过sysctl/proc控制，默认为120s*/</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> timeout = sysctl_hung_task_timeout_secs;</span><br><span class="line"><span class="comment">/*检测线程(khungtaskd)sleep 120s(默认)后，再次唤醒。*/</span></span><br><span class="line"><span class="keyword">while</span> (schedule_timeout_interruptible(timeout_jiffies(timeout)))</span><br><span class="line">timeout = sysctl_hung_task_timeout_secs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (atomic_xchg(&amp;reset_hung_task, <span class="number">0</span>))</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line"><span class="comment">/*醒来后执行实际的检测操作*/</span></span><br><span class="line">check_hung_uninterruptible_tasks(timeout);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-3-check-hung-uninterruptible-tasks"><a href="#4-3-check-hung-uninterruptible-tasks" class="headerlink" title="4.3 check_hung_uninterruptible_tasks"></a>4.3 check_hung_uninterruptible_tasks</h4><p>遍历系统中的所有进程，检测是否有处于D状态超过120s的进程，如果有则打印警告或panic。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Check whether a TASK_UNINTERRUPTIBLE does not get woken up for</span></span><br><span class="line"><span class="comment"> * a really long time (120 seconds). If that happens, print out</span></span><br><span class="line"><span class="comment"> * a warning.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">check_hung_uninterruptible_tasks</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">long</span> timeout)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">/*hung task检测是检查的最大进程数，默认为最大的进程号*/</span></span><br><span class="line"><span class="keyword">int</span> max_count = sysctl_hung_task_check_count;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 每次遍历进程数的上限，默认为1024，这样做的目的是为了:</span></span><br><span class="line"><span class="comment"> * 1、防止rcu_read_lock的占用时间太长。</span></span><br><span class="line"><span class="comment"> * 2、hung task的watchdog占用CPU时间太长。如果没开内核抢占，则如果内核线程不主动调度的话，是不能发生进程切换的</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 如果系统中的进程数比较多，那么就可能检测不到部分D状态进程了?不会，因为这里只是会调度一次，调度回来后，会继续遍历后面的进程</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> batch_count = HUNG_TASK_BATCHING;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">g</span>, *<span class="title">t</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * If the system crashed already then all bets are off,</span></span><br><span class="line"><span class="comment"> * do not report extra hung tasks:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">/*如果系统已经处于crash状态了，就不再报hung task了。*/</span></span><br><span class="line"><span class="keyword">if</span> (test_taint(TAINT_DIE) || did_panic)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">rcu_read_lock();</span><br><span class="line"><span class="comment">/*遍历系统中的所有进程*/</span></span><br><span class="line">do_each_thread(g, t) &#123;</span><br><span class="line"><span class="keyword">if</span> (!max_count--)</span><br><span class="line"><span class="keyword">goto</span> unlock;</span><br><span class="line"><span class="comment">/*如果每次检测的进程数量超过1024了，则需要发起调度，结束rcu优雅周期*/</span></span><br><span class="line"><span class="keyword">if</span> (!--batch_count) &#123;</span><br><span class="line">batch_count = HUNG_TASK_BATCHING;</span><br><span class="line"><span class="comment">/*释放rcu，并主动调度，调度回来后检查相应进程是否还在，如果不在了，则退出遍历，否则继续*/</span></span><br><span class="line"><span class="keyword">if</span> (!rcu_lock_break(g, t))</span><br><span class="line"><span class="keyword">goto</span> unlock;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* use "==" to skip the TASK_KILLABLE tasks waiting on NFS */</span></span><br><span class="line"><span class="comment">/*检测进程状态是否为D*/</span></span><br><span class="line"><span class="keyword">if</span> (t-&gt;state == TASK_UNINTERRUPTIBLE)</span><br><span class="line"><span class="comment">/*检测进程处于D状态的时间是否超过120s。*/</span></span><br><span class="line">check_hung_task(t, timeout);</span><br><span class="line">&#125; while_each_thread(g, t);</span><br><span class="line"> unlock:</span><br><span class="line">rcu_read_unlock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-4-check-hung-task"><a href="#4-4-check-hung-task" class="headerlink" title="4.4 check_hung_task"></a>4.4 check_hung_task</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">check_hung_task</span><span class="params">(struct task_struct *t, <span class="keyword">unsigned</span> <span class="keyword">long</span> timeout)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">/*进程上下文切换计数，以此来判断该进程是否发生过调度*/</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> switch_count = t-&gt;nvcsw + t-&gt;nivcsw;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Ensure the task is not frozen.</span></span><br><span class="line"><span class="comment"> * Also, skip vfork and any other user process that freezer should skip.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (unlikely(t-&gt;flags &amp; (PF_FROZEN | PF_FREEZER_SKIP)))</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * When a freshly created task is scheduled once, changes its state to</span></span><br><span class="line"><span class="comment"> * TASK_UNINTERRUPTIBLE without having ever been switched out once, it</span></span><br><span class="line"><span class="comment"> * musn't be checked.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (unlikely(!switch_count))</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 如果当前switch_count等于last_switch_count，则说明在khungtaskd进程被唤醒期间，该进程没有发生过调度。</span></span><br><span class="line"><span class="comment"> * 也就是说，该进程一直处于D状态，因为last_switch_count只在这里更新，其它地方不会。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (switch_count != t-&gt;last_switch_count) </span><br><span class="line"><span class="comment">/* 更新last_switch_count计数，只在这里更新，该计数专用于hung task的检测。*/</span></span><br><span class="line">t-&gt;last_switch_count = switch_count;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">trace_sched_process_hang(t);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * hung task错误打印次数限制，防止dos攻击。默认为10次，由于是全局变量，</span></span><br><span class="line"><span class="comment"> * 表示系统运行期间最多打印10次，超过后就不打印了。该参数应该可以</span></span><br><span class="line"><span class="comment"> * 通过sysctl修改</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (!sysctl_hung_task_warnings)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (sysctl_hung_task_warnings &gt; <span class="number">0</span>)</span><br><span class="line">sysctl_hung_task_warnings--;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Ok, the task did not get scheduled for more than 2 minutes,</span></span><br><span class="line"><span class="comment"> * complain:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">/*如下就是我们平常常见的hung task打印了*/</span></span><br><span class="line">pr_err(<span class="string">"INFO: task %s:%d blocked for more than %ld seconds.\n"</span>,</span><br><span class="line">t-&gt;comm, t-&gt;pid, timeout);</span><br><span class="line">pr_err(<span class="string">"      %s %s %.*s\n"</span>,</span><br><span class="line">print_tainted(), init_utsname()-&gt;release,</span><br><span class="line">(<span class="keyword">int</span>)<span class="built_in">strcspn</span>(init_utsname()-&gt;version, <span class="string">" "</span>),</span><br><span class="line">init_utsname()-&gt;version);</span><br><span class="line">pr_err(<span class="string">"\"echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs\""</span></span><br><span class="line"><span class="string">" disables this message.\n"</span>);</span><br><span class="line"><span class="comment">/*打印堆栈*/</span></span><br><span class="line">sched_show_task(t);</span><br><span class="line"><span class="comment">/*如果开启了debug_lock，则打印锁的占用情况*/</span></span><br><span class="line">debug_show_held_locks(t);</span><br><span class="line"></span><br><span class="line">touch_nmi_watchdog();</span><br><span class="line"><span class="comment">/*检测是否配置了/proc/sys/kernel/hung_task_panic，如果配置则直接触发panic*/</span></span><br><span class="line"><span class="keyword">if</span> (sysctl_hung_task_panic) &#123;</span><br><span class="line"><span class="comment">/*打印所有CPU的堆栈*/</span></span><br><span class="line">trigger_all_cpu_backtrace();</span><br><span class="line"><span class="comment">/*触发panic，如果配置了kdump就有用了*/</span></span><br><span class="line">panic(<span class="string">"hung_task: blocked tasks"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-Hungtask定位思路"><a href="#5-Hungtask定位思路" class="headerlink" title="5. Hungtask定位思路"></a>5. Hungtask定位思路</h3><p><img src="/images/2022/11/14.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://mp.weixin.qq.com/s/Jpex9c0_GBZsxB4J21ojxA" target="_blank" rel="noopener">Hungtask原理及分析</a></li><li><a href="https://zhuanlan.zhihu.com/p/463433198" target="_blank" rel="noopener">内核Hungtask原理和定位思路总结</a></li><li><a href="https://blog.csdn.net/weixin_33921089/article/details/86390346" target="_blank" rel="noopener">hung task机制</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将总结Linux的Hungtask机制。
    
    </summary>
    
      <category term="Kernel" scheme="http://liujunming.github.io/categories/Kernel/"/>
    
    
      <category term="Kernel" scheme="http://liujunming.github.io/tags/Kernel/"/>
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Notes about linux进程D状态</title>
    <link href="http://liujunming.github.io/2022/11/26/Notes-about-%E8%BF%9B%E7%A8%8BD%E7%8A%B6%E6%80%81/"/>
    <id>http://liujunming.github.io/2022/11/26/Notes-about-进程D状态/</id>
    <published>2022-11-26T08:50:19.000Z</published>
    <updated>2022-11-27T03:37:43.130Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录进程D状态相关笔记。</p><a id="more"></a> <h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>man ps中的描述:<br><img src="/images/2022/11/11.jpg" alt></p><p>Linux kernel中的宏定义: <a href="https://elixir.bootlin.com/linux/v6.0/source/include/linux/sched.h#L86" target="_blank" rel="noopener">TASK_UNINTERRUPTIBLE</a></p><h3 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h3><p><img src="/images/2022/11/12.jpg" alt><br><img src="/images/2022/11/13.jpg" alt></p><h3 id="资料推荐"><a href="#资料推荐" class="headerlink" title="资料推荐"></a>资料推荐</h3><p>强烈推荐<a href="/pdf/炫技！bug 排查大曝光，涉及Linux 内核的那种.pdf">炫技！bug 排查大曝光，涉及Linux 内核的那种</a>一文，会收获颇丰!</p><hr><p>参考资料:</p><ol><li><a href="https://www.man7.org/linux/man-pages/man1/ps.1.html" target="_blank" rel="noopener">man ps</a></li><li><a href="https://www.cnblogs.com/embedded-linux/p/7043569.html" target="_blank" rel="noopener">linux进程D状态</a></li><li><a href="https://mp.weixin.qq.com/s/5OOqJRhBRhdih7Pb0f5e5A" target="_blank" rel="noopener">炫技！bug 排查大曝光，涉及Linux 内核的那种</a></li><li><a href="https://www.zouhl.com/posts/linux%E4%B8%8B%E5%B8%B8%E8%A7%81%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90-d%E7%8A%B6%E6%80%81%E5%92%8Cz%E7%8A%B6%E6%80%81/" target="_blank" rel="noopener">Linux下常见的系统问题分析 D状态和Z状态</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录进程D状态相关笔记。&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>利用bpftrace打印内核函数调用栈</title>
    <link href="http://liujunming.github.io/2022/11/20/%E5%88%A9%E7%94%A8bpftrace%E6%89%93%E5%8D%B0%E5%86%85%E6%A0%B8%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%A0%88/"/>
    <id>http://liujunming.github.io/2022/11/20/利用bpftrace打印内核函数调用栈/</id>
    <published>2022-11-20T08:30:23.000Z</published>
    <updated>2022-11-20T08:39:58.395Z</updated>
    
    <content type="html"><![CDATA[<p>本文将以<code>vp_notify</code>函数为例，介绍下如何利用bpftrace打印内核函数调用栈。<a id="more"></a> </p><ul><li><p>确定目标内核函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bpftrace -l &apos;kprobe:*&apos; | grep vp_notify</span><br><span class="line">kprobe:vp_notify</span><br></pre></td></tr></table></figure></li><li><p><code>kstack</code>: Stack Traces, Kernel</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ bpftrace -e &apos;kprobe:vp_notify &#123; @[kstack] = count(); &#125;&apos;</span><br><span class="line">Attaching 1 probe...</span><br><span class="line">^C</span><br></pre></td></tr></table></figure></li></ul><p><a href="https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md#7-kstack-stack-traces-kernel" target="_blank" rel="noopener">https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md#7-kstack-stack-traces-kernel</a></p><p><a href="https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md#2-count-count" target="_blank" rel="noopener">count()</a>的含义</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将以&lt;code&gt;vp_notify&lt;/code&gt;函数为例，介绍下如何利用bpftrace打印内核函数调用栈。
    
    </summary>
    
      <category term="工具" scheme="http://liujunming.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://liujunming.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="debug" scheme="http://liujunming.github.io/tags/debug/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Intel TME and MKTME technology</title>
    <link href="http://liujunming.github.io/2022/11/19/Notes-about-TME-and-MKTME/"/>
    <id>http://liujunming.github.io/2022/11/19/Notes-about-TME-and-MKTME/</id>
    <published>2022-11-19T07:52:04.000Z</published>
    <updated>2022-11-19T11:08:50.049Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录Intel的TME(Total Memory Encryption)和MKTME(Multi-Key Total Memory Encryption)技术。<a id="more"></a> </p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>Total Memory Encryption (TME) is a  x86 instruction set extension proposed by Intel for a full physical memory encryption for DRAM and NVRAM with a single ephemeral key. TME can be further extended with the Multi-Key Total Memory Encryption (MKTME) extension which builds on TME and adds support multiple encryption keys.</p><h3 id="TME"><a href="#TME" class="headerlink" title="TME"></a>TME</h3><p>普通RAM里面储存的数据，在掉电之后，一般都以为是彻底消失了。但在一些复杂的离线攻击下，这些数据仍然是能被恢复出来并导致泄密。TME可以对抗这种攻击。</p><p>Total Memory Encryption (TME) – as name would imply is a capability to encrypt entirety of physical memory of a system. This capability is typically enabled in very early stages of boot process with small change to BIOS and once configured and locked will encrypt all the data on external memory buses of an SOC using NIST standard AES-XTS algorithm with 128-bit keys. The encryption key used for TME uses hardware random number generator implemented in Intel SOC and the keys are not accessible by software or using external interfaces to Intel SOC. TME capability is intended to provide protections of AES-XTS to external memory buses and DIMMs. The architecture is flexible and will support additional memory protections schemes in future. This capability when enabled is intended to support (unmodified) existing system and application software. Overall performance impact of this capability is likely to be relatively small and is highly dependent on workload.</p><p>Inside the chip itself (e.g., registers and caches) the data remains in plain text. This is done in order to maintain compatibility with all existing software and I/O models. An AES-XTS encryption engine is physically located directly on the data paths to external memory buses ensuring all data entering and leaving the chip is encrypted. Note that there is one exception for a specially defined <a href="/2022/11/19/Notes-about-TME-and-MKTME/#Exclusion-range">exclusion range</a>.</p><p><img src="/images/2022/11/07.png" alt></p><p><img src="/images/2022/11/08.png" alt></p><p>TME的最大缺点是只能使用一把平台密钥来加密内存，不支持在系统里划分出多个基于加密密钥构建的加密内存domain；但MKTME就支持使用多把密钥，进而实现per进程/容器/VM粒度的加密内存domain。</p><h3 id="MKTME"><a href="#MKTME" class="headerlink" title="MKTME"></a>MKTME</h3><p>Multi-Key Total Memory Encryption (MKTME) builds on TME and adds support for multiple encryption keys. The SOC implementation will support a fixed number of encryption keys, and software can configure SOC to use a subset of available keys. Software manages the use of keys and can use each of the available key for encrypting any page of the memory. Thus, MKTME allows page granular encryption of memory. By default MKTME uses TME encryption key unless explicitly specified by software. In addition to supporting CPU generated ephemeral key (not accessible by software or using external interfaces to SOC), MKTME also supports software provided keys. Software provided keys are particularly useful when used with non-volatile memory or when combined with attestation mechanisms and/or used with key provisioning services. In virtualization scenario, we anticipate VMM or hypervisor to manage use of keys to transparently support legacy operating systems without any changes. An OS may be enabled to take additional advantage of MKTME capability both in native or virtualized environment. When properly enabled, MKTME is available to each guest OS in virtualized environment, and guest OS can take advantage of MKTME in same was as native OS.</p><p>MKTME是在TME架构的基础上，实现了<strong>以页为粒度、支持使用多把密钥对内存进行加密的功能，同时还允许由软件设置AES-XTS加解密引擎所使用的密钥</strong>。</p><p>下图是将MKTME用在虚拟化场景中的一个示例图：<br><img src="/images/2022/11/09.png" alt><br>在这个示例中：</p><ul><li>Hypervisor使用KeyID 0 (即TME定义的平台密钥)来访问自己的加密内存</li><li>VM1和VM2都可以使用KeyID 0来访问自己的加密内存</li><li>VM1使用KeyID 1来访问自己的私有加密内存</li><li>VM2使用KeyID 2来访问自己的私有加密内存</li><li>VM1和VM2可以使用KeyID 3来访问两个VM共享的加密内存</li></ul><p>KeyID字段被包含在PTE中，且位于物理地址字段的高位，就像是物理地址字段的一部分（即通过减少一部分物理地址宽度来实现），这个特性叫做<strong>物理地址位超卖</strong>（oversubscribing）。该特性使物理地址具有了别名，即具有相同物理地址的页可以有不同的KeyID。<br><img src="/images/2022/11/10.png" alt></p><p>KeyID信息是不会出现在处理器外部的（比如内存总线上）。物理地址位超卖不会影响cache和TLB的行为，因为KeyID仅被当做成物理地址的一部分来处理；但物理地址位超卖会影响大多数的页表类型：Host普通IA页表、EPT和IOMMU页表。</p><ul><li><p>IA paging<br>MKTME会影响Host侧的IA paging（含每一级页表），即在物理地址字段的高位中包含KeyID字段；CR3寄存器也受此影响，也包含了KeyID。</p></li><li><p>EPT paging<br>MKTME会影响EPT paging（含每一级页表），因为EPT用于将GPA映射到HPA，而HPA必须要包含KeyID。</p></li><li><p>IOMMU paging<br>MKTME会影响IOMMU paging（含每一级页表），因为EPT用于将GPA映射到HPA(虚拟化场景下)，而HPA必须要包含KeyID。</p></li><li><p>其他物理地址<br>其他的物理地址结构（如VMCS指针、物理地址位图等）也都需要包含KeyID。</p></li></ul><p>虽然例子中Hypervisor使用的是KeyID 0，但Hypervisor具有特权，可以使用任意KeyID访问自己的加密内存，也能管理和设置每个VM所能使用的KeyID。</p><p>MKTME支持的密钥数量总是固定的，而具体数量由特定的处理器实现来决定。软件可以通过配置只使用其中的部分密钥，这组密钥被称为可用密钥。软件负责管理可用密钥，并可以使用可用密钥对任意一个内存页进行加密。</p><p>在软件不进行任何显式配置的情况下，MKTME引擎默认使用TME的平台密钥进行内存加密。<strong>MKTME也允许使用软件提供的密钥或处理器RNG生成的密钥</strong>。 在虚拟化场景中，Hypervisor负责管理每个VM所使用的密钥，并透明地对Guest OS实施加密保护（在这个场景中，可以将MKTME视为TME虚拟化技术）。</p><p>总而言之，MKTME希望在系统层面能够创建<strong>多个独立的加密内存domain</strong>。 这对用户来说也更加安全。</p><h3 id="安全威胁模型分析"><a href="#安全威胁模型分析" class="headerlink" title="安全威胁模型分析"></a>安全威胁模型分析</h3><p><strong>TME和MKTME的安全性依赖于特权软件（OS和Hypervisor），这点与传统虚拟化技术的安全边界完全一致。</strong> 假设在攻击者拥有特权的情况下，攻击者能将所有物理页的加密模式都改为非加密模式。事实上只要攻击者拥有特权，就已经能够访问任意内存了，只不过需要使用正确的KeyID来访问per进程/容器/VM实例的加密内存，比如在访问VM实例内的数据前需要在EPT PTE中找出正确的KeyID，然后建立一个使用该KeyID的PTE映射来访问该物理页。</p><p>此外，TME和MKTME没有对数据提供完整性保护，因此软件使用错误的KeyID访问加密内存、直接篡改加密内存中的内容都是可行的。</p><p>由于软件和处理器接口无法访问到TME平台密钥以及MKTME中由处理器硬件自生成的密钥，因此密钥本身是存储安全的；但由软件提供的MKTME密钥可能会因调用者考虑不周而遭到泄露，这个难题需要软件设计者自己来解决。</p><p>由于cache中的数据是明文的，因此TME和MKTME无法抵御像L1TF这种利用处理器speculative execution侧信道漏洞的攻击方式来间接probe cache中的明文数据的这种攻击方式。</p><p>综上所述，<strong>由于特权软件仍有足够的权限来降低TME和MKTME的安全性，因此TME/MKTME技术目前还不属于机密计算的范畴，即无法做到哪怕在被攻破的OS/VMM环境里也能够保护租户机密数据的强度。</strong> TME和MKTME防范的攻击路径是从恶意VM实例到Hypervisor。更具体来说，只要攻击者无法跨域安全域（指从guest ring0到host ring0）且在软件采用了正确配置的情况下，TME和MKTME就能够抵御恶意VM实例对Host或其他VM实例的数据泄露攻击；但前提是租户必须信任CSP和Intel CPU。</p><p>目前Intel TDX(使用到了MKTME技术)做到了在被攻破的OS/VMM环境里也能够保护租户机密数据的强度，前提是租户必须信任Intel CPU。</p><h3 id="Exclusion-range"><a href="#Exclusion-range" class="headerlink" title="Exclusion range"></a>Exclusion range</h3><p>A single exclusion range is supported (for both TME/MKTME for <code>KeyID 0</code> only) for special use cases such as BIOS memory ranges that are not generally available to the operating system. Once the physical addresses are set, no memory encryption is applied to this range.</p><hr><p>参考资料:</p><ol><li><a href="https://developer.aliyun.com/article/767096" target="_blank" rel="noopener">Intel TME和MKTME技术解析</a></li><li><a href="https://en.wikichip.org/wiki/x86/tme" target="_blank" rel="noopener">wikichip:Total Memory Encryption</a></li><li><a href="https://www.linux-kvm.org/images/d/d7/Mktme_kvm_forum_2018.pdf" target="_blank" rel="noopener">Protect Data of Virtual Machines with MKTME on KVM</a></li><li><a href="https://firmwaresecurity.com/2017/12/14/intel-total-memory-encryption/" target="_blank" rel="noopener">Intel Total Memory Encryption (TME) and Multi-Key Total Memory Encryption (MKTME)</a></li><li><a href="https://lwn.net/Articles/787852/" target="_blank" rel="noopener">Intel MKTME enabling</a></li><li><a href="https://zhuanlan.zhihu.com/p/429055957" target="_blank" rel="noopener">对抗内存物理读取攻击的利器：Intel TME和AMD SME</a></li><li><a href="https://www.tomshardware.com/news/intel-mktme-amd-memory-encryption,39467.html" target="_blank" rel="noopener">Intel Follows AMD’s Lead on Full Memory Encryption</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录Intel的TME(Total Memory Encryption)和MKTME(Multi-Key Total Memory Encryption)技术。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="Security" scheme="http://liujunming.github.io/tags/Security/"/>
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
  <entry>
    <title>Notes about KVM coalesced MMIO/PIO</title>
    <link href="http://liujunming.github.io/2022/11/19/Notes-about-KVM-coalesced-MMIO-PIO/"/>
    <id>http://liujunming.github.io/2022/11/19/Notes-about-KVM-coalesced-MMIO-PIO/</id>
    <published>2022-11-19T03:06:45.000Z</published>
    <updated>2022-11-19T07:13:35.487Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下KVM coalesced MMIO/PIO相关notes。<a id="more"></a> </p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><a href="https://elixir.bootlin.com/linux/v6.0/source/virt/kvm" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/v6.0/source/virt/kvm</a><br><img src="/images/2022/11/06.jpg" alt><br>在KVM源码中经常看到coalesced MMIO，本文将一探究竟。当然本文只侧重于high level层面，不涉及源码中的细节。</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><blockquote><p>When kernel has to send MMIO writes to userspace, it stores them in memory until it has to pass the hand to userspace for another reason. This avoids to have too many context switches on operations that can wait.</p></blockquote><blockquote><p>Coalesced I/O is used if one or more write accesses to a hardware register can be deferred until a read or a write to another hardware register on the same device.  This last access will cause a vmexit and userspace will process accesses from the ring buffer before emulating it. That will avoid exiting to userspace on repeated writes.</p></blockquote><ul><li><p>Without KVM coalesced MMIO/PIO</p><ul><li>可deferred的MMIO/PIO write导致Non-root mode VM Exit -&gt; KVM -&gt; QEMU(处理可deferred的MMIO/PIO write) -&gt; KVM -&gt; 返回到Non-root mode</li></ul></li><li><p>With KVM coalesced MMIO/PIO</p><ul><li>可deferred的MMIO/PIO write导致Non-root mode VM Exit -&gt; KVM(将可deferred的MMIO/PIO write记录到ring buffer) -&gt;  返回到Non-root mode</li><li>不可deferred的MMIO/PIO导致Non-root mode VM Exit -&gt; KVM -&gt; QEMU(先处理完ring buffer中记录的可deferred的MMIO/PIO write，再处理这次不可deferred的MMIO/PIO) -&gt; KVM -&gt; 返回到Non-root mode</li></ul></li></ul><p>从上述的对比可知，KVM coalesced MMIO/PIO可以在KVM中记录可deferred的MMIO/PIO write，不用退出的qemu来处理，可以将这些请求dealy到下一次不可deferred的MMIO/PIO来处理。That will avoid exiting to userspace on repeated writes.</p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">4.116 KVM_(UN)REGISTER_COALESCED_MMIO</span><br><span class="line"></span><br><span class="line">Capability: KVM_CAP_COALESCED_MMIO (for coalesced mmio)</span><br><span class="line">    KVM_CAP_COALESCED_PIO (for coalesced pio)</span><br><span class="line">Architectures: all</span><br><span class="line">Type: vm ioctl</span><br><span class="line">Parameters: struct kvm_coalesced_mmio_zone</span><br><span class="line">Returns: 0 on success, &lt; 0 on error</span><br><span class="line"></span><br><span class="line">Coalesced I/O is a performance optimization that defers hardware</span><br><span class="line">register write emulation so that userspace exits are avoided.  It is</span><br><span class="line">typically used to reduce the overhead of emulating frequently accessed</span><br><span class="line">hardware registers.</span><br><span class="line"></span><br><span class="line">When a hardware register is configured for coalesced I/O, write accesses</span><br><span class="line">do not exit to userspace and their value is recorded in a ring buffer</span><br><span class="line">that is shared between kernel and userspace.</span><br><span class="line"></span><br><span class="line">Coalesced I/O is used if one or more write accesses to a hardware</span><br><span class="line">register can be deferred until a read or a write to another hardware</span><br><span class="line">register on the same device.  This last access will cause a vmexit and</span><br><span class="line">userspace will process accesses from the ring buffer before emulating</span><br><span class="line">it. That will avoid exiting to userspace on repeated writes.</span><br><span class="line"></span><br><span class="line">Coalesced pio is based on coalesced mmio. There is little difference</span><br><span class="line">between coalesced mmio and pio except that coalesced pio records accesses</span><br><span class="line">to I/O ports.</span><br></pre></td></tr></table></figure><h3 id="QEMU-example"><a href="#QEMU-example" class="headerlink" title="QEMU example"></a>QEMU example</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// https://gitlab.com/qemu-project/qemu/-/blob/stable-6.0/hw/net/e1000.c#L1631-L1647</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">e1000_mmio_setup(E1000State *d)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint32_t</span> excluded_regs[] = &#123;</span><br><span class="line">        E1000_MDIC, E1000_ICR, E1000_ICS, E1000_IMS,</span><br><span class="line">        E1000_IMC, E1000_TCTL, E1000_TDT, PNPMMIO_SIZE</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    memory_region_init_io(&amp;d-&gt;mmio, OBJECT(d), &amp;e1000_mmio_ops, d,</span><br><span class="line">                          <span class="string">"e1000-mmio"</span>, PNPMMIO_SIZE);</span><br><span class="line">    memory_region_add_coalescing(&amp;d-&gt;mmio, <span class="number">0</span>, excluded_regs[<span class="number">0</span>]);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; excluded_regs[i] != PNPMMIO_SIZE; i++)</span><br><span class="line">        memory_region_add_coalescing(&amp;d-&gt;mmio, excluded_regs[i] + <span class="number">4</span>,</span><br><span class="line">                                     excluded_regs[i+<span class="number">1</span>] - excluded_regs[i] - <span class="number">4</span>);</span><br><span class="line">    memory_region_init_io(&amp;d-&gt;io, OBJECT(d), &amp;e1000_io_ops, d, <span class="string">"e1000-io"</span>, IOPORT_SIZE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>本case的<code>memory_region_add_coalescing</code>注册了coalesced MMIO region。对于细节，需要结合e1000的spec与qemu、kvm相关代码了，在此不再描述。</p><hr><p>参考资料:</p><ol><li><a href="https://lore.kernel.org/kvm/1212156357946-git-send-email-Laurent.Vivier@bull.net/" target="_blank" rel="noopener">kvm: Batch writes to MMIO</a></li><li><a href="https://www.kernel.org/doc/Documentation/virtual/kvm/api.txt" target="_blank" rel="noopener">Documentation/virtual/kvm/api.txt</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下KVM coalesced MMIO/PIO相关notes。
    
    </summary>
    
      <category term="QEMU&amp;&amp;KVM" scheme="http://liujunming.github.io/categories/QEMU-KVM/"/>
    
    
      <category term="QEMU&amp;&amp;KVM" scheme="http://liujunming.github.io/tags/QEMU-KVM/"/>
    
  </entry>
  
  <entry>
    <title>Comparing VIRTIO, NVMe, and io_uring queue designs</title>
    <link href="http://liujunming.github.io/2022/11/13/Comparing-VIRTIO-NVMe-and-io-uring-queue-designs/"/>
    <id>http://liujunming.github.io/2022/11/13/Comparing-VIRTIO-NVMe-and-io-uring-queue-designs/</id>
    <published>2022-11-13T13:11:13.000Z</published>
    <updated>2022-11-13T13:19:55.638Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.vmsplice.net/2022/06/comparing-virtio-nvme-and-iouring-queue.html" target="_blank" rel="noopener">http://blog.vmsplice.net/2022/06/comparing-virtio-nvme-and-iouring-queue.html</a><br>深度好文，强烈推荐！<a id="more"></a> </p><h3 id="Ring-buffer-basics"><a href="#Ring-buffer-basics" class="headerlink" title="Ring buffer basics"></a>Ring buffer basics</h3><p>A ring buffer is a circular array where new elements are produced on one side and consumed on the other side. Often terms such as head and tail are used to <strong>describe the array indices at which the next element is accessed</strong>. When the end of the array is reached, one moves back to the start of the array. The empty and full conditions are special states that must be checked to avoid underflow and overflow.</p><p>VIRTIO, NVMe, and io_uring all use single producer, single consumer shared memory ring buffers. This allows a CPU and an I/O device or two CPUs to communicate across a region of memory to which both sides have access.</p><p><a href="https://mp.weixin.qq.com/s/pjuHWagzhONS3eOmF6xkXQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/pjuHWagzhONS3eOmF6xkXQ</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.vmsplice.net/2022/06/comparing-virtio-nvme-and-iouring-queue.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://blog.vmsplice.net/2022/06/comparing-virtio-nvme-and-iouring-queue.html&lt;/a&gt;&lt;br&gt;深度好文，强烈推荐！
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Notes about KVM dedicated vCPUs hint</title>
    <link href="http://liujunming.github.io/2022/11/13/Notes-about-KVM-dedicated-vCPUs-hint/"/>
    <id>http://liujunming.github.io/2022/11/13/Notes-about-KVM-dedicated-vCPUs-hint/</id>
    <published>2022-11-13T02:44:24.000Z</published>
    <updated>2022-11-13T03:08:40.720Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下KVM中的dedicated vCPUs hint KVM_HINTS_DEDICATED。<a id="more"></a> </p><p>This feature introduces dedicated vCPUs(vCPU pinning, and there is no vCPU over-commitment) hint KVM_HINTS_DEDICATED, it has two users now:</p><ol><li><p>Waiman Long mentioned that:<br> Generally speaking, unfair lock performs well for VMs with a small number of vCPUs. Native qspinlock may perform better than pvqspinlock if there is vCPU pinning and there is no vCPU over-commitment.</p></li><li><p>vCPUs are very unlikely to get preempted when they are the only task running on a CPU. PV TLB flush is slower than the native flush in that case.</p></li></ol><p><img src="/images/2022/11/05.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://static.sched.com/hosted_files/kvmforum2019/e3/Boosting%20Dedicated%20Instances%20by%20KVM%20Tax%20Cut.pdf" target="_blank" rel="noopener">Boosting Dedicated InstanceviaKVMTaxCut</a></li><li><a href="https://lore.kernel.org/kvm/1518483942-14741-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: Introduce dedicated vCPUs hint KVM_HINTS_DEDICATED</a></li><li><a href="https://lore.kernel.org/qemu-devel/1518083060-5881-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">target-i386: adds PV_DEDICATED hint CPUID feature bit</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下KVM中的dedicated vCPUs hint KVM_HINTS_DEDICATED。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
  </entry>
  
  <entry>
    <title>Notes about io_uring</title>
    <link href="http://liujunming.github.io/2022/11/12/Notes-about-io-uring/"/>
    <id>http://liujunming.github.io/2022/11/12/Notes-about-io-uring/</id>
    <published>2022-11-12T05:13:37.000Z</published>
    <updated>2022-11-13T01:24:51.868Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录io_uring相关笔记。<a id="more"></a> </p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>The native Linux AIO framework suffers from various limitations, which io_uring aims to overcome:</p><ul><li>It does not support buffered I/O, only direct I/O is supported.</li><li>It has non-deterministic behavior which may block under various circumstances.</li><li>It has a sub-optimal API, which requires at least two system calls per I/O, one to submit a request, and one to wait for its completion.<ul><li>Each submission needs to copy 64 + 8 bytes of data, and each completion needs to copy 32 bytes.</li></ul></li></ul><h3 id="Communication-channel"><a href="#Communication-channel" class="headerlink" title="Communication channel"></a>Communication channel</h3><p><img src="/images/2022/11/01.jpg" alt></p><p>An io_uring instance has two rings, a submission queue (SQ) and a completion queue (CQ), shared between the kernel and the application. The queues are single producer, single consumer, and power of two in size.</p><p>The queues provide a lock-less access interface, coordinated with memory barriers.</p><p>The application creates one or more SQ entries (SQE), and then updates the SQ tail. The kernel consumes the SQEs , and updates the SQ head.</p><p>The kernel creates CQ entries (CQE) for one or more completed requests, and updates the CQ tail. The application consumes the CQEs and updates the CQ head.</p><p>Completion events may arrive in any order but they are always associated with specific SQEs.</p><h3 id="System-call"><a href="#System-call" class="headerlink" title="System call"></a>System call</h3><p><img src="/images/2022/11/02.jpg" alt></p><h3 id="默认流程"><a href="#默认流程" class="headerlink" title="默认流程"></a>默认流程</h3><p>默认情形下，提交任务的流程，以及获取结果的方式:</p><ol><li>把sqe放入sqring</li><li>调用<code>io_uring_enter</code>通知内核</li><li><strong>可以轮询cqring等待结果</strong>或者通过带<code>IORING_ENTER_GETEVENTS</code>和<code>min_complete</code>参数的<code>io_uring_enter</code>阻塞等待指定数目的任务完成，再去cqring中检查结果</li></ol><h3 id="Submission-Queue-Polling"><a href="#Submission-Queue-Polling" class="headerlink" title="Submission Queue Polling"></a>Submission Queue Polling</h3><p>如果在调用<code>io_uring_setup</code> 时设置了 <code>IORING_SETUP_SQPOLL</code> 的 flag，内核会额外启动一个内核线程，我们称作 SQ 线程。这个内核线程可以运行在某个指定的 core 上（通过 <code>sq_thread_cpu</code> 配置）。这个内核线程会不停的 Poll SQ，除非在一段时间内没有 Poll 到任何请求（通过 <code>sq_thread_idle</code> 配置），才会被挂起。</p><p><img src="/images/2022/11/04.jpeg" alt></p><p>当程序在用户态设置完 SQE，并通过修改 SQ 的 tail 完成一次插入时，如果此时 SQ 线程处于唤醒状态，那么可以立刻捕获到这次提交，这样就避免了用户程序调用<code>io_uring_enter</code>这个系统调用。如果 SQ 线程处于休眠状态，则需要通过调用<code>io_uring_enter</code>，并使用<code>IORING_SQ_NEED_WAKEUP</code> 参数，来唤醒 SQ 线程。用户态可以通过 sqring 的 flags 变量获取 SQ 线程的状态。</p><h3 id="io-polling"><a href="#io-polling" class="headerlink" title="io polling"></a>io polling</h3><p>在默认情况下，当设备处理完IO请求后，设备会发送中断通知内核往cqring添加cqe，并更新cqring的tail指针。用户态程序会轮询cqring获取新的cqe。</p><p>但是对于IO low latency或者high IOPS的场景，使用中断并不合适，应该使用polling(refers to performing IO without relying on hardware interrupts to signal a completion event)。此时因为没有中断通知，内核就不会往 cqring中填充cqe，因此用户态程序就不能去轮询cqring了。此时，用户态程序必须调用<code>io_uring_enter</code> with <code>IORING_ENTER_GETEVENTS</code> set and <code>min_complete</code> set to 0来下发轮询任务给内核，内核会轮询检查是否有结果产生，如果有，则将结果放入cqring。 </p><p>Tips:搞清楚内核什么时候更新cqring，分为如下两种case:</p><ol><li><p>硬件中断通知内核</p></li><li><p>用户态程序调用<code>io_uring_enter</code>来下发polling任务给内核</p></li></ol><h3 id="liburing"><a href="#liburing" class="headerlink" title="liburing"></a>liburing</h3><p>为了简化使用io_uring， liburing 库应用而生。用户无需了解诸多 io_uring 细节便可以使用起来，如无需关心 memory barrier，以及 ring buffer 的管理等。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/images/2022/11/03.jpg" alt></p><p>io_uring 主要通过用户态与内核态共享内存的途径，来摒弃使用系统调用来提交 I/O 操作和获取 I/O 操作的结果，从而避免了上下文切换的情况。另外，由于用户态进程与内核态线程通过共享内存的方式通信，从而避免了内存拷贝的过程，提升了 I/O 操作的性能。</p><p>所以，io_uring 主要通过两个优化点来提升 I/O 操作的性能：</p><ul><li>摒弃使用系统调用来提交 I/O 操作和获取 I/O 操作结果</li><li>减少用户态与内核态之间的内存拷贝</li></ul><hr><p>参考资料:</p><ol><li><a href="https://blogs.oracle.com/linux/post/an-introduction-to-the-io-uring-asynchronous-io-framework" target="_blank" rel="noopener">An Introduction to the io_uring Asynchronous I/O Framework</a></li><li><a href="https://unixism.net/loti/what_is_io_uring.html" target="_blank" rel="noopener">What is io_uring?</a></li><li><a href="https://kernel.dk/io_uring.pdf" target="_blank" rel="noopener">Efficient IO with io_uring</a></li><li><a href="https://zhuanlan.zhihu.com/p/62682475" target="_blank" rel="noopener">AIO 的新归宿：io_uring</a></li><li><a href="https://kernel.dk/axboe-kr2022.pdf" target="_blank" rel="noopener">What’s new with io_uring</a></li><li><a href="https://mp.weixin.qq.com/s/4hXwPhCOJFjUjMJqzjKWgg" target="_blank" rel="noopener">io_uring 新异步 IO 机制，性能提升超 150%，堪比 SPDK</a></li><li><a href="https://zhuanlan.zhihu.com/p/361955546" target="_blank" rel="noopener">浅析开源项目之io_uring</a></li><li><a href="https://mp.weixin.qq.com/s/fzvkGpvxFXYEWMCWcfTb-w" target="_blank" rel="noopener">下一代异步 IO io_uring 技术解密</a></li><li><a href="Submission Queue Polling[¶](https://unixism.net/loti/tutorial/sq_poll.html#submission-queue-polling">Submission Queue Polling</a>)</li><li><a href="https://www.jianshu.com/p/32a3c72da1c1" target="_blank" rel="noopener">io_uring</a></li><li><a href="https://mp.weixin.qq.com/s/1wZpFhwJR-LNkQm-QzFxRQ" target="_blank" rel="noopener">Linux I/O 神器之 io_uring</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录io_uring相关笔记。
    
    </summary>
    
      <category term="I/O系统" scheme="http://liujunming.github.io/categories/I-O%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="I/O系统" scheme="http://liujunming.github.io/tags/I-O%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Notes about virtual IPI fastpath and virtual TSC-Deadline timer fastpath</title>
    <link href="http://liujunming.github.io/2022/10/30/Notes-about-virtual-IPI-fastpath/"/>
    <id>http://liujunming.github.io/2022/10/30/Notes-about-virtual-IPI-fastpath/</id>
    <published>2022-10-29T17:20:02.000Z</published>
    <updated>2022-10-30T01:39:38.435Z</updated>
    
    <content type="html"><![CDATA[<p>本文参考的内核版本为<a href="https://elixir.bootlin.com/linux/v6.0/source" target="_blank" rel="noopener">v6.0</a>。<a id="more"></a></p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><img src="/images/2022/10/18.jpg" alt></p><h3 id="virtual-IPI-fastpath"><a href="#virtual-IPI-fastpath" class="headerlink" title="virtual IPI fastpath"></a>virtual IPI fastpath</h3><p><img src="/images/2022/10/19.jpg" alt></p><p><img src="/images/2022/10/20.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vmx_vcpu_run</span><br><span class="line">└── vmx_exit_handlers_fastpath</span><br><span class="line">    └── handle_fastpath_set_msr_irqoff</span><br><span class="line">        └── handle_fastpath_set_x2apic_icr_irqoff</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The fast path for frequent and performance sensitive wrmsr emulation,</span></span><br><span class="line"><span class="comment"> * i.e. the sending of IPI, sending IPI early in the VM-Exit flow reduces</span></span><br><span class="line"><span class="comment"> * the latency of virtual IPI by avoiding the expensive bits of transitioning</span></span><br><span class="line"><span class="comment"> * from guest to host, e.g. reacquiring KVM's SRCU lock. In contrast to the</span></span><br><span class="line"><span class="comment"> * other cases which must be called after interrupts are enabled on the host.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">handle_fastpath_set_x2apic_icr_irqoff</span><span class="params">(struct kvm_vcpu *vcpu, u64 data)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!lapic_in_kernel(vcpu) || !apic_x2apic_mode(vcpu-&gt;arch.apic))</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (((data &amp; APIC_SHORT_MASK) == APIC_DEST_NOSHORT) &amp;&amp;</span><br><span class="line">    ((data &amp; APIC_DEST_MASK) == APIC_DEST_PHYSICAL) &amp;&amp;</span><br><span class="line">    ((data &amp; APIC_MODE_MASK) == APIC_DM_FIXED) &amp;&amp;</span><br><span class="line">    ((u32)(data &gt;&gt; <span class="number">32</span>) != X2APIC_BROADCAST))</span><br><span class="line"><span class="keyword">return</span> kvm_x2apic_icr_write(vcpu-&gt;arch.apic, data);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="virtual-TSC-Deadline-timer-fastpath"><a href="#virtual-TSC-Deadline-timer-fastpath" class="headerlink" title="virtual TSC-Deadline timer fastpath"></a>virtual TSC-Deadline timer fastpath</h3><p><img src="/images/2022/10/21.jpg" alt></p><p><img src="/images/2022/10/22.jpg" alt></p><p><a href="https://lore.kernel.org/kvm/1587709364-19090-5-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: X86: TSCDEADLINE MSR emulation fastpath</a><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vmx_vcpu_run</span><br><span class="line">└── vmx_exit_handlers_fastpath</span><br><span class="line">    └── handle_fastpath_set_msr_irqoff</span><br><span class="line">        └── handle_fastpath_set_tscdeadline</span><br><span class="line">            └── kvm_set_lapic_tscdeadline_msr</span><br></pre></td></tr></table></figure></p><p><img src="/images/2022/10/23.jpg" alt></p><p><a href="https://lore.kernel.org/kvm/1587709364-19090-6-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: VMX: Handle preemption timer fastpath</a><br>该patch优化的是<a href="/2022/10/22/lapic-timer-virtualization/">使用preemption timer模拟lapic timer的case</a>。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vmx_vcpu_run</span><br><span class="line">└── vmx_exit_handlers_fastpath</span><br><span class="line">    └── handle_fastpath_preemption_timer</span><br></pre></td></tr></table></figure></p><p><img src="/images/2022/10/24.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://static.sched.com/hosted_files/kvmforum2020/6e/KVM%20Latency%20and%20Scalability%20Performance%20Tuning.pdf" target="_blank" rel="noopener">KVM Latency and Scalability Performance Tuning</a></li><li><a href="https://lore.kernel.org/kvm/1574306232-872-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: VMX: FIXED+PHYSICAL mode single target IPI fastpath</a></li><li><a href="https://lore.kernel.org/kvm/1587709364-19090-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: VMX: Tscdeadline timer emulation fastpath</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文参考的内核版本为&lt;a href=&quot;https://elixir.bootlin.com/linux/v6.0/source&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;v6.0&lt;/a&gt;。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
      <category term="中断" scheme="http://liujunming.github.io/tags/%E4%B8%AD%E6%96%AD/"/>
    
  </entry>
  
  <entry>
    <title>KVM halt-polling机制分析</title>
    <link href="http://liujunming.github.io/2022/10/29/Notes-about-kvm-halt-polling/"/>
    <id>http://liujunming.github.io/2022/10/29/Notes-about-kvm-halt-polling/</id>
    <published>2022-10-29T07:35:53.000Z</published>
    <updated>2022-10-29T08:51:57.874Z</updated>
    
    <content type="html"><![CDATA[<p>   本文转载自:<a href="https://www.cnblogs.com/163yun/p/10114699.html" target="_blank" rel="noopener">KVM halt-polling机制分析</a>。<a id="more"></a> </p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>在实际业务中，guest执行HLT指令是导致虚拟化overhead的一个重要原因。如[1]。</p><p>KVM halt polling特性就是为了解决这一个问题被引入的，它在Linux 4.3-rc1被合入主干内核，其基本原理是当guest idle发生vm-exit时，host 继续polling一段时间，用于减少guest的业务时延。进一步讲，在vcpu进入idle之后，guest内核默认处理是执行HLT指令，就会发生vm-exit，host kernel并不马上让出物理核给调度器，而是poll一段时间，若guest在这段时间内被唤醒，便可以马上调度回该vcpu线程继续运行。</p><p>polling机制带来时延上的降低，至少是一个线程调度周期，通常是几微妙，但最终的性能提升是跟guest内业务模型相关的。如果在host kernel polling期间，没有唤醒事件发生或是运行队列里面其他任务变成runnable状态，那么调度器就会被唤醒去干其他任务的事。因此，halt polling机制对于那些在很短时间间隔就会被唤醒一次的业务特别有效。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ol><li>该机制有可能导致物理CPU实际空闲的情况下占用率表现为100%。因为如果guest上业务模型是隔一段时间被唤醒一次来处理很少量的流量，并且这个时间间隔比kvm halt_poll_ns短，那么host将poll整个虚拟机的block时间，cpu占用率也会冲上100%。</li><li>halt polling是电源能耗和业务时延的一个权衡。为了减少进入guest的时延，idle cpu时间转换为host kernel时间。</li><li>该机制只有在CPU上没有其他running任务的情况得以应用，不然polling动作被立马终止，唤醒调度器，调度其他进程。</li></ol><h3 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h3><p>业界针对虚拟机idle这个课题有比较多的研究，因为它带来了比较大的overhead。主要可以归结为以下几种：</p><ol><li><p>idle=poll，即把虚拟机idle时一直polling，空转，不退出。这样不利于物理CPU超线程的发挥。</p></li><li><p>阿里提出guest里面提供halt polling机制，即在VM退出前先等会儿，这样可以减少VM退出次数。 优点：性能较kvm halt polling机制好；缺点：需要修改guest内核；状态：社区未接收 <a href="https://lore.kernel.org/kvm/1510567565-5118-1-git-send-email-quan.xu0@gmail.com/" target="_blank" rel="noopener">x86/idle: add halt poll support</a> 值得注意的是， 类似idea的工作<a href="/2022/10/28/Notes-about-Guest-halt-polling/">guest halt polling</a>社区已接受</p></li><li><p>腾讯考虑guest HLT指令不退出。优点：性能较阿里好；缺点：只适用于vcpu独占物理核场景；状态：社区已接受。<a href="https://lore.kernel.org/kvm/1517813878-22248-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: X86: Add per-VM no-HLT-exiting capability</a></p></li></ol><hr><p>参考资料:</p><ol><li><a href="https://www.linux-kvm.org/images/2/27/Kvm-forum-2013-idle-latency.pdf" target="_blank" rel="noopener">KVM vs. Message Passing Throughput</a></li><li><a href="http://events17.linuxfoundation.org/sites/events/files/slides/Message%20Passing%20Workloads%20in%20KVM%20%28SLIDES%29.pdf" target="_blank" rel="noopener">Message Passing Workloads in KVM</a></li><li><a href="http://events17.linuxfoundation.org/sites/events/files/slides/KVM%20performance%20tuning%20on%20Alibaba%20Cloud.pdf" target="_blank" rel="noopener">KVM performance tuning</a></li><li><a href="https://www.kernel.org/doc/Documentation/virtual/kvm/halt-polling.txt" target="_blank" rel="noopener">The KVM halt polling system</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;   本文转载自:&lt;a href=&quot;https://www.cnblogs.com/163yun/p/10114699.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;KVM halt-polling机制分析&lt;/a&gt;。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
  </entry>
  
  <entry>
    <title>Notes about guest halt polling</title>
    <link href="http://liujunming.github.io/2022/10/28/Notes-about-Guest-halt-polling/"/>
    <id>http://liujunming.github.io/2022/10/28/Notes-about-Guest-halt-polling/</id>
    <published>2022-10-28T13:20:37.000Z</published>
    <updated>2022-10-29T08:49:07.967Z</updated>
    
    <content type="html"><![CDATA[<p>Notes about guest halt polling feature.<a id="more"></a> </p><p>前提:    需要对intel的<a href="/2020/05/01/Introduction-to-halt-pause-monitor-mwait-instruction/#hlt">hlt</a>指令有一定的了解。 </p><p>The cpuidle_haltpoll driver, with the haltpoll governor, allows the guest vcpus to poll for a specified amount of time before halting.</p><p>This provides the following benefits to host side polling:</p><ol><li>The POLL flag is set while polling is performed, which allows a remote vCPU to avoid sending an IPI (and the associated cost of handling the IPI) when performing a wakeup.</li><li>The VM-exit cost can be avoided.</li></ol><p>The downside of guest side polling is that polling is performed even with other runnable tasks in the host.</p><p>The basic logic as follows: A global value, <code>guest_halt_poll_ns</code>, is configured by the user, indicating the maximum amount of time polling is allowed. This value is fixed.</p><p>Each vcpu has an adjustable <code>guest_halt_poll_ns</code> (“per-cpu <code>guest_halt_poll_ns</code>”), which is adjusted by the algorithm in response to events.</p><p>The module parameters can be set from the debugfs files in:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sys/module/haltpoll/parameters/</span><br></pre></td></tr></table></figure></p><hr><p>参考资料:</p><ol><li><a href="https://www.kernel.org/doc/html/latest/virt/guest-halt-polling.html" target="_blank" rel="noopener">Guest halt polling</a></li><li><a href="https://lore.kernel.org/kvm/20190613224532.949768676@redhat.com/" target="_blank" rel="noopener">cpuidle haltpoll driver and governor</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Notes about guest halt polling feature.
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
  </entry>
  
</feed>
