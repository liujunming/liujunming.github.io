<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>L</title>
  
  <subtitle>make it simple, make it happen.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://liujunming.github.io/"/>
  <updated>2023-05-14T04:16:06.272Z</updated>
  <id>http://liujunming.github.io/</id>
  
  <author>
    <name>liujunming</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Notes about Crystal Beach DMA(CBDMA)</title>
    <link href="http://liujunming.github.io/2023/05/14/Notes-about-Crystal-Beach-DMA-CBDMA/"/>
    <id>http://liujunming.github.io/2023/05/14/Notes-about-Crystal-Beach-DMA-CBDMA/</id>
    <published>2023-05-14T03:23:54.000Z</published>
    <updated>2023-05-14T04:16:06.272Z</updated>
    
    <content type="html"><![CDATA[<p>Crystal Beach DMA(CBDMA)其实就是<a href="/2022/03/29/Introduction-to-Intel-I-OAT/#2-Intel®-QuickData-Technology">Intel® QuickData Technology</a>，说白了就是offload memory copy to DMA engine，<a href="/2022/10/23/Notes-about-Intel-Data-Streaming-Accelerator-DSA/">DSA</a>代替了该技术。<a id="more"></a></p><p><img src="/images/2023/05/37.jpg" alt></p><p><img src="/images/2023/05/38.jpg" alt></p><p>FAST ‘23 paper <a href="https://www.usenix.org/conference/fast23/presentation/su" target="_blank" rel="noopener">Revitalizing the Forgotten On-Chip DMA to Expedite Data Movement in NVM-based Storage Systems</a>也是使用了CBDMA来offload memory copy。</p><hr><p>参考资料:</p><ol><li><a href="https://zhuanlan.zhihu.com/p/133489817" target="_blank" rel="noopener">NFV加速利器，CPU中的CBDMA引擎</a></li><li><a href="https://www.dpdk.org/wp-content/uploads/sites/35/2018/12/JiayuHu_Accelerating_paravirtio_with_CBDMA.pdf" target="_blank" rel="noopener">Accelerating Para-Virtual I/O with CBDMA</a></li><li><a href="https://static.sched.com/hosted_files/dpdkbordeaux2019/09/Asynchronous%20CBDMA%20Enqueue%20Framework%20for%20vHost-User.pdf" target="_blank" rel="noopener">Asynchronous CBDMA Enqueue Framework for vHost-User</a></li><li><a href="https://insujang.github.io/2021-04-26/using-intel-ioat-dma/" target="_blank" rel="noopener">Using Intel IOAT DMA</a></li><li><a href="https://www.intel.com/content/www/us/en/wireless-network/accel-technology.html" target="_blank" rel="noopener">Intel® I/O Acceleration Technology</a></li><li><a href="https://www.usenix.org/conference/fast23/presentation/su" target="_blank" rel="noopener">Revitalizing the Forgotten On-Chip DMA to Expedite Data Movement in NVM-based Storage Systems</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Crystal Beach DMA(CBDMA)其实就是&lt;a href=&quot;/2022/03/29/Introduction-to-Intel-I-OAT/#2-Intel®-QuickData-Technology&quot;&gt;Intel® QuickData Technology&lt;/a&gt;，说白了就是offload memory copy to DMA engine，&lt;a href=&quot;/2022/10/23/Notes-about-Intel-Data-Streaming-Accelerator-DSA/&quot;&gt;DSA&lt;/a&gt;代替了该技术。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
  <entry>
    <title>Notes about VT-d Virtual Command Support</title>
    <link href="http://liujunming.github.io/2023/05/13/Notes-about-VT-d-Virtual-Command-Support/"/>
    <id>http://liujunming.github.io/2023/05/13/Notes-about-VT-d-Virtual-Command-Support/</id>
    <published>2023-05-12T23:41:02.000Z</published>
    <updated>2023-05-13T03:45:24.725Z</updated>
    
    <content type="html"><![CDATA[<p>Virtual Command Support (VCS) - Virtual register intended to help support virtualization of the IOMMU. Unlike an SR-IOV device where an entire device is exposed to a guest, the new model creates device instances using PASID. This requires the PASID to be a flat global space which <strong>requires the guest and host PASIDs to be the same</strong>. Only virtual IOMMUs exposed to a guest would enumerate this capability. <strong>It provides an interface to for the host to control allocation of PASIDs in a guest OS</strong>.<a id="more"></a></p><p><img src="/images/2023/05/36.jpg" alt></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Virtual command interface for enlightened pasid management. */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VCMD_CMD_ALLOC          0x1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VCMD_CMD_FREE           0x2</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VCMD_VRSP_IP            0x1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VCMD_VRSP_SC(e)         (((e) &amp; 0xff) &gt;&gt; 1)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VCMD_VRSP_SC_SUCCESS        0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VCMD_VRSP_SC_NO_PASID_AVAIL 16</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VCMD_VRSP_SC_INVALID_PASID  16</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VCMD_VRSP_RESULT_PASID(e)   (((e) &gt;&gt; 16) &amp; 0xfffff)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> VCMD_CMD_OPERAND(e)     ((e) &lt;&lt; 16)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">vcmd_alloc_pasid</span><span class="params">(struct intel_iommu *iommu, u32 *pasid)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line">    u8 status_code;</span><br><span class="line">    <span class="keyword">int</span> ret = <span class="number">0</span>;</span><br><span class="line">    u64 res;</span><br><span class="line"></span><br><span class="line">    raw_spin_lock_irqsave(&amp;iommu-&gt;register_lock, flags);</span><br><span class="line">    dmar_writeq(iommu-&gt;reg + DMAR_VCMD_REG, VCMD_CMD_ALLOC);</span><br><span class="line">    IOMMU_WAIT_OP(iommu, DMAR_VCRSP_REG, dmar_readq,</span><br><span class="line">              !(res &amp; VCMD_VRSP_IP), res);</span><br><span class="line">    raw_spin_unlock_irqrestore(&amp;iommu-&gt;register_lock, flags);</span><br><span class="line"></span><br><span class="line">    status_code = VCMD_VRSP_SC(res);</span><br><span class="line">    <span class="keyword">switch</span> (status_code) &#123;</span><br><span class="line">    <span class="keyword">case</span> VCMD_VRSP_SC_SUCCESS:</span><br><span class="line">        *pasid = VCMD_VRSP_RESULT_PASID(res);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> VCMD_VRSP_SC_NO_PASID_AVAIL:</span><br><span class="line">        pr_info(<span class="string">"IOMMU: %s: No PASID available\n"</span>, iommu-&gt;name);</span><br><span class="line">        ret = -ENOSPC;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        ret = -ENODEV;</span><br><span class="line">        pr_warn(<span class="string">"IOMMU: %s: Unexpected error code %d\n"</span>,</span><br><span class="line">            iommu-&gt;name, status_code);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">vcmd_free_pasid</span><span class="params">(struct intel_iommu *iommu, u32 pasid)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line">    u8 status_code;</span><br><span class="line">    u64 res;</span><br><span class="line"></span><br><span class="line">    raw_spin_lock_irqsave(&amp;iommu-&gt;register_lock, flags);</span><br><span class="line">    dmar_writeq(iommu-&gt;reg + DMAR_VCMD_REG,</span><br><span class="line">            VCMD_CMD_OPERAND(pasid) | VCMD_CMD_FREE);</span><br><span class="line">    IOMMU_WAIT_OP(iommu, DMAR_VCRSP_REG, dmar_readq,</span><br><span class="line">              !(res &amp; VCMD_VRSP_IP), res);</span><br><span class="line">    raw_spin_unlock_irqrestore(&amp;iommu-&gt;register_lock, flags);</span><br><span class="line"></span><br><span class="line">    status_code = VCMD_VRSP_SC(res);</span><br><span class="line">    <span class="keyword">switch</span> (status_code) &#123;</span><br><span class="line">    <span class="keyword">case</span> VCMD_VRSP_SC_SUCCESS:</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> VCMD_VRSP_SC_INVALID_PASID:</span><br><span class="line">        pr_info(<span class="string">"IOMMU: %s: Invalid PASID\n"</span>, iommu-&gt;name);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        pr_warn(<span class="string">"IOMMU: %s: Unexpected error code %d\n"</span>,</span><br><span class="line">            iommu-&gt;name, status_code);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>流程主要分为如下两个步骤:</p><ol><li><p>guest分配pasid时，写vIOMMU的vcmd寄存器，此时会trap下来，host会将分配好的host paisd传给guest，这样guest与host的pasid就一样了。</p></li><li><p>当guest配置WQ Configuration register(MMIO寄存器)的PASID field时需要trap下来，hypervisor会检查guest的pasid与host的pasid是否一致，如果一致，那么hypervisor会将这个host PASID写入物理WQ Configuration register的PASID field。</p></li></ol><hr><p>参考资料:</p><ol><li><a href="https://01.org/blogs/ashokraj/2018/recent-enhancements-intel-virtualization-technology-directed-i/o-intel-vt-d" target="_blank" rel="noopener">RECENT ENHANCEMENTS IN INTEL® VIRTUALIZATION TECHNOLOGY FOR DIRECTED I/O (INTEL® VT-D)</a></li><li><a href="https://elixir.bootlin.com/linux/v6.3/source" target="_blank" rel="noopener">Linux kernel v6.3</a></li><li>Intel VT-d spec</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Virtual Command Support (VCS) - Virtual register intended to help support virtualization of the IOMMU. Unlike an SR-IOV device where an entire device is exposed to a guest, the new model creates device instances using PASID. This requires the PASID to be a flat global space which &lt;strong&gt;requires the guest and host PASIDs to be the same&lt;/strong&gt;. Only virtual IOMMUs exposed to a guest would enumerate this capability. &lt;strong&gt;It provides an interface to for the host to control allocation of PASIDs in a guest OS&lt;/strong&gt;.
    
    </summary>
    
      <category term="VT-d" scheme="http://liujunming.github.io/categories/VT-d/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="VT-d" scheme="http://liujunming.github.io/tags/VT-d/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Shared Virtual Memory virtualization</title>
    <link href="http://liujunming.github.io/2023/05/07/Notes-about-Shared-Virtual-Memory-virtualization/"/>
    <id>http://liujunming.github.io/2023/05/07/Notes-about-Shared-Virtual-Memory-virtualization/</id>
    <published>2023-05-07T07:37:36.000Z</published>
    <updated>2023-05-07T11:32:15.311Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍下Shared Virtual Memory virtualization相关内容。<a id="more"></a></p><h2 id="1-Prerequisite"><a href="#1-Prerequisite" class="headerlink" title="1. Prerequisite"></a>1. Prerequisite</h2><ul><li><a href="/2022/03/30/Introduction-to-Shared-Virtual-Memory/">Shared Virtual Memory</a></li><li>VT-d基础知识(需要阅读VT-d spec)<ul><li>Legacy Mode Address Translation</li><li><a href="/2022/05/14/浅谈IOMMU-pageing-structures/">Scalable Mode Address Translation</a><ul><li>First-Stage Translation</li><li>Second-Stage Translation</li><li>Nested Translation</li><li>Pass-through Translation<br><img src="/images/2023/05/24.png" alt><br><img src="/images/2023/05/34.jpg" alt></li></ul></li></ul></li></ul><h2 id="2-Enable-SVM-in-VM"><a href="#2-Enable-SVM-in-VM" class="headerlink" title="2. Enable SVM in VM"></a>2. Enable SVM in VM</h2><p><img src="/images/2023/05/25.jpg" alt></p><p><img src="/images/2023/05/26.jpg" alt></p><p><img src="/images/2023/05/27.jpg" alt></p><p><img src="/images/2023/05/28.jpg" alt></p><p><img src="/images/2023/05/32.jpg" alt></p><p><img src="/images/2023/05/33.jpg" alt></p><p><img src="/images/2023/05/29.jpg" alt></p><p><img src="/images/2023/05/30.jpg" alt></p><p><img src="/images/2023/05/31.jpg" alt></p><p><img src="/images/2023/05/35.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://events19.linuxfoundation.cn/wp-content/uploads/2017/11/Shared-Virtual-Memory-in-KVM_Yi-Liu.pdf" target="_blank" rel="noopener">Shared Virtual Memory in KVM</a></li><li><a href="https://static.sched.com/hosted_files/kvmforum2018/52/kvm-forum-vSVA-yliu-jpan-jean-eric.pdf" target="_blank" rel="noopener">Shared Virtual Addressing in KVM</a></li><li><a href="https://www.youtube.com/watch?v=Kq_nfGK5MwQ" target="_blank" rel="noopener">Video for SVM in KVM forum</a></li><li><a href="http://blog.chinaunix.net/uid-28541347-id-5854016.html" target="_blank" rel="noopener">Shared Virtual Memory（SVM）介绍</a></li><li><a href="https://www.cnblogs.com/shaohef/p/12079657.html" target="_blank" rel="noopener">Shared Virtual Memory (SVM) Functions</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍下Shared Virtual Memory virtualization相关内容。
    
    </summary>
    
      <category term="VT-d" scheme="http://liujunming.github.io/categories/VT-d/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="VT-d" scheme="http://liujunming.github.io/tags/VT-d/"/>
    
  </entry>
  
  <entry>
    <title>DSA dedicated work queue virtualization</title>
    <link href="http://liujunming.github.io/2023/05/07/DSA-dedicated-work-queue-virtualization/"/>
    <id>http://liujunming.github.io/2023/05/07/DSA-dedicated-work-queue-virtualization/</id>
    <published>2023-05-07T00:13:11.000Z</published>
    <updated>2023-05-07T11:24:27.729Z</updated>
    
    <content type="html"><![CDATA[<p><a href="/2023/05/04/Scalable-Work-Submission-in-Device-Virtualization/">Scalable Work Submission in Device Virtualization</a>介绍了<a href="/2022/10/23/Notes-about-Intel-Data-Streaming-Accelerator-DSA/">DSA</a> shared work queue的virtualization，本文将介绍DSA dedicated work queue的virtualization。<a id="more"></a></p><p>本文将带着如下两个问题进行讨论：<br>Q1: 虚拟机用dedicated work queue时，要使用pasid吗？<br>Q2: 如果guest使用pasid，那pasid翻译该如何操作?</p><h3 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h3><p><img src="/images/2023/05/22.png" alt><br>从DSA的spec中可知，当使用dedicated work queue时，pasid是一个可选项。因此，当虚拟机使用dedicated work queue时，可以使用pasid，也可以不使用pasid。</p><h3 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h3><p>To submit work to a Dedicated Work Queue, software uses a 64-byte memory write transaction with write atomicity.</p><p>On Intel CPUs, work submission to a DWQ(Dedicated Work Queue) is performed using the MOVDIR64B instruction, which generates a non-torn 64-byte write. </p><p>If the PASID capability is enabled, the WQ(Work Queue) PASID Enable field of the WQ Configuration register controls whether PASID is used for each DWQ. Since the MOVDIR64B instruction does not fill in the PASID as the ENQCMD or ENQCMDS instructions do, the PASID field in the descriptor is ignored. When PASID is enabled for a DWQ, the device uses the WQ PASID field of the WQ Configuration register to do address translation. The WQ PASID field must be set by the driver before enabling a work queue in dedicated mode.</p><p><img src="/images/2023/05/23.png" alt></p><p><strong>dedicated work queue不会共享，所以MOVDIR64B就不用写入pasid了</strong>。</p><p>当guest配置WQ Configuration register(MMIO寄存器)的PASID field时需要trap下来，hypervisor分配一个host的PASID，然后将这个host PASID写入物理WQ Configuration register的PASID field。这样即可完成pasid虚拟化。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;/2023/05/04/Scalable-Work-Submission-in-Device-Virtualization/&quot;&gt;Scalable Work Submission in Device Virtualization&lt;/a&gt;介绍了&lt;a href=&quot;/2022/10/23/Notes-about-Intel-Data-Streaming-Accelerator-DSA/&quot;&gt;DSA&lt;/a&gt; shared work queue的virtualization，本文将介绍DSA dedicated work queue的virtualization。
    
    </summary>
    
      <category term="VT-d" scheme="http://liujunming.github.io/categories/VT-d/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="VT-d" scheme="http://liujunming.github.io/tags/VT-d/"/>
    
  </entry>
  
  <entry>
    <title>Scalable Work Submission in Device Virtualization</title>
    <link href="http://liujunming.github.io/2023/05/04/Scalable-Work-Submission-in-Device-Virtualization/"/>
    <id>http://liujunming.github.io/2023/05/04/Scalable-Work-Submission-in-Device-Virtualization/</id>
    <published>2023-05-04T05:47:12.000Z</published>
    <updated>2023-05-04T11:43:41.306Z</updated>
    
    <content type="html"><![CDATA[<p>本文将以<a href="/2022/10/23/Notes-about-Intel-Data-Streaming-Accelerator-DSA/">Intel Data Streaming Accelerator</a>为例，讲解DMWr (Deferrable Memory Write) TLP、ENQCMD/ENQCMDS指令、ENQCMD Virtualization、<a href="/2022/03/30/Introduction-to-Shared-Virtual-Memory/">SVA</a> Work Submission In Guest相关内容。<a id="more"></a></p><h2 id="1-DMWr-TLP"><a href="#1-DMWr-TLP" class="headerlink" title="1. DMWr TLP"></a>1. DMWr TLP</h2><h3 id="1-1-What"><a href="#1-1-What" class="headerlink" title="1.1 What"></a>1.1 What</h3><p>Deferrable Memory Write (DMWr) transactions are a new type of TLP supported by the PCI Specifications. This new feature allows the completer to return an acknowledgement to the requester of the DMWr transaction and provides the completer a mechanism to temporarily refuse the request.</p><p>The Deferrable Memory Write (DMWr) is an Optional Non-Posted Request that enables a scalable high-performance mechanism to implement shared work queues and similar capabilities. With DMWr, devices can have a single shared work queue and accept work items from multiple non-cooperating software agents in a non-blocking way.</p><p>读完上述定义后，或许对DMWr的理解不够深刻，接下来我们将以DSA的SWQ(Shared Work Queue)为例，阐述下为什么要有DMWr。</p><h3 id="1-2-Why"><a href="#1-2-Why" class="headerlink" title="1.2 Why"></a>1.2 Why</h3><p><img src="/images/2023/05/04.png" alt></p><p><img src="/images/2023/05/05.png" alt></p><p><img src="/images/2023/05/07.png" alt></p><p><img src="/images/2023/05/06.png" alt></p><blockquote><p>DMWr is a 64-byte non-posted write that waits for a response from the device before completing. The device returns Success if the descriptor is accepted into the work queue, or Retry if the descriptor is not accepted due to WQ capacity or QoS. </p></blockquote><p>正常写mmio寄存器是posted tlp，也就是说completer不会给requester返回报文。<br>DMWr是non-posted write tlp，这也为retry带来了可能！</p><h2 id="2-ENQCMD-ENQCMDS指令"><a href="#2-ENQCMD-ENQCMDS指令" class="headerlink" title="2. ENQCMD/ENQCMDS指令"></a>2. ENQCMD/ENQCMDS指令</h2><p>On Intel CPUs, DMWr is generated using the <code>ENQCMD</code> or <code>ENQCMDS</code> instructions. The <code>ENQCMD</code> and <code>ENQCMDS</code> instructions return the status of the command submission in <code>EFLAGS.ZF</code> flag; 0 indicates Success, and 1 indicates Retry.</p><p><img src="/images/2023/05/08.jpg" alt><br>SDM vol2中有这两个指令的详细描述。</p><p><img src="/images/2023/05/12.jpg" alt></p><p><img src="/images/2023/05/09.jpg" alt><br>ENQCMD 中destination offset参数的含义： enqueue registers, which are special device registers accessed using memory-mapped I/O (MMIO). 说白了，offset就是MMIO enqueue registers的location！</p><p><img src="/images/2023/05/13.jpg" alt></p><p><img src="/images/2023/05/14.jpg" alt></p><h3 id="2-1-Example-in-DSA"><a href="#2-1-Example-in-DSA" class="headerlink" title="2.1 Example in DSA"></a>2.1 Example in DSA</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span>  <span class="keyword">unsigned</span> <span class="keyword">int</span></span><br><span class="line">enqcmd(<span class="keyword">void</span> *dst, <span class="keyword">const</span> <span class="keyword">void</span> *src)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">uint8_t</span> retry;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">".byte 0xf2, 0x0f, 0x38, 0xf8, 0x02\t\n"</span></span></span></span><br><span class="line"><span class="function"><span class="params">                 <span class="string">"setz %0\t\n"</span></span></span></span><br><span class="line">                 : "=r"(retry) : "a" (dst), "d" (src));</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">unsigned</span> <span class="keyword">int</span>)retry;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">while</span> (enqcmd(wq_portal, &amp;desc) &amp;&amp; enq_retry++ &lt; ENQ_RETRY_MAX) ;</span><br><span class="line"><span class="keyword">if</span> (enq_retry == ENQ_RETRY_MAX) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"ENQCMD retry limit exceeded\n"</span>);</span><br><span class="line">    rc = EXIT_FAILURE;</span><br><span class="line">    <span class="keyword">goto</span> done;</span><br><span class="line">&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><a href="https://github.com/RaymondHuang210129/Intel-DSA-Experiments/blob/master/intel_dsa_sample.c" target="_blank" rel="noopener">https://github.com/RaymondHuang210129/Intel-DSA-Experiments/blob/master/intel_dsa_sample.c</a></p><h2 id="3-Scalability-In-Device-Virtualization"><a href="#3-Scalability-In-Device-Virtualization" class="headerlink" title="3. Scalability In Device Virtualization"></a>3. Scalability In Device Virtualization</h2><p><img src="/images/2023/05/16.jpg" alt><br><img src="/images/2023/05/17.jpg" alt><br><img src="/images/2023/05/18.jpg" alt><br><img src="/images/2023/05/19.jpg" alt></p><h2 id="4-ENQCMD-Virtualization"><a href="#4-ENQCMD-Virtualization" class="headerlink" title="4. ENQCMD Virtualization"></a>4. ENQCMD Virtualization</h2><p><img src="/images/2023/05/10.png" alt></p><p><img src="/images/2023/05/11.png" alt><br>sdm vol3  搜索ENQCMD即可！</p><p><img src="/images/2023/05/20.jpg" alt><br><img src="/images/2023/05/21.jpg" alt></p><h2 id="5-SVA-Work-Submission-In-Guest"><a href="#5-SVA-Work-Submission-In-Guest" class="headerlink" title="5. SVA Work Submission In Guest"></a>5. SVA Work Submission In Guest</h2><p><img src="/images/2023/05/15.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://static.sched.com/hosted_files/kvmforum2020/22/Scalable_Work_Submission_In_Device_Virtualization.pdf" target="_blank" rel="noopener">Scalable Work Submission in Device Virtualization</a></li><li><a href="https://blog.csdn.net/weixin_40357487/article/details/123339073" target="_blank" rel="noopener">PCIe 6.0 新特性 - DMWr (Deferrable Memory Write) 详解</a></li><li><a href="https://www.intel.com/content/www/us/en/docs/programmable/683501/22-2-6-0-0/deferrable-memory-write-dmwr.html" target="_blank" rel="noopener">Deferrable Memory Write (DMWr)</a></li><li><a href="https://www.freepatentsonline.com/y2020/0004703.html" target="_blank" rel="noopener">NON-POSTED WRITE TRANSACTIONS</a></li><li>Intel SDM</li><li>Intel Data Streaming Accelerator spec</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将以&lt;a href=&quot;/2022/10/23/Notes-about-Intel-Data-Streaming-Accelerator-DSA/&quot;&gt;Intel Data Streaming Accelerator&lt;/a&gt;为例，讲解DMWr (Deferrable Memory Write) TLP、ENQCMD/ENQCMDS指令、ENQCMD Virtualization、&lt;a href=&quot;/2022/03/30/Introduction-to-Shared-Virtual-Memory/&quot;&gt;SVA&lt;/a&gt; Work Submission In Guest相关内容。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="VT-d" scheme="http://liujunming.github.io/tags/VT-d/"/>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about NBD（Network Block Device)</title>
    <link href="http://liujunming.github.io/2023/05/04/Notes-about-NBD%EF%BC%88Network-Block-Device/"/>
    <id>http://liujunming.github.io/2023/05/04/Notes-about-NBD（Network-Block-Device/</id>
    <published>2023-05-04T05:29:23.000Z</published>
    <updated>2023-05-04T05:37:17.282Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/50460919" target="_blank" rel="noopener">NBD（Network Block Device）简介及基本使用</a></p><p>NBD指的是Network Block Device，正如其名字的意思，NBD让用户可以通过网络访问到某个块设备，或者镜像文件。<a id="more"></a></p><p><img src="/images/2023/05/03.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/50460919&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NBD（Network Block Device）简介及基本使用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;NBD指的是Network Block Device，正如其名字的意思，NBD让用户可以通过网络访问到某个块设备，或者镜像文件。
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Notes about协程</title>
    <link href="http://liujunming.github.io/2023/05/02/Notes-about%E5%8D%8F%E7%A8%8B/"/>
    <id>http://liujunming.github.io/2023/05/02/Notes-about协程/</id>
    <published>2023-05-02T06:23:49.000Z</published>
    <updated>2023-05-02T12:22:15.347Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下协程(Coroutines)相关notes。<a id="more"></a></p><h2 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h2><h3 id="1-1-Why"><a href="#1-1-Why" class="headerlink" title="1.1 Why?"></a>1.1 Why?</h3><p><a href="/pdf/什么是协程.pdf">什么是协程</a></p><p>vs多线程：<br>操作系统在线程等待IO的时候，会阻塞当前线程，切换到其它线程，这样在当前线程等待IO的过程中，其它线程可以继续执行。当系统线程较少的时候没有什么问题，但是当线程数量非常多的时候，却产生了问题。<strong>一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间</strong>。</p><p>协程刚好可以解决上述2个问题。协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。<strong>协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程</strong>，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。</p><h3 id="1-2-What"><a href="#1-2-What" class="headerlink" title="1.2 What"></a>1.2 What</h3><p><img src="/images/2023/05/02.png" alt></p><blockquote><p>协程本质上和单线程+状态机是等价的，只是用协程的话，协程负责来保存状态，开发起来方便些(不用自己写那个状态机)。</p></blockquote><h3 id="1-3-When"><a href="#1-3-When" class="headerlink" title="1.3 When"></a>1.3 When</h3><p>在有大量IO操作业务的情况下，我们采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。</p><p>在协程中尽量不要调用阻塞IO的方法，比如打印，读取文件，Socket接口等，除非改为异步调用的方式，并且协程只有在IO密集型的任务中才会发挥作用。</p><p><strong>协程只有和异步IO结合起来才能发挥出最大的威力</strong>。</p><h2 id="2-QEMU中的协程"><a href="#2-QEMU中的协程" class="headerlink" title="2. QEMU中的协程"></a>2. QEMU中的协程</h2><h3 id="2-1-为什么qemu要使用协程"><a href="#2-1-为什么qemu要使用协程" class="headerlink" title="2.1 为什么qemu要使用协程"></a>2.1 为什么qemu要使用协程</h3><p><a href="https://lore.kernel.org/qemu-devel/1311672077-4592-1-git-send-email-stefanha@linux.vnet.ibm.com/" target="_blank" rel="noopener">Coroutines for better asynchronous programming</a></p><p>仔细阅读<a href="http://blog.vmsplice.net/2014/01/coroutines-in-qemu-basics.html" target="_blank" rel="noopener">Coroutines in QEMU: The basics</a> <em>Callback hell in event-driven programs</em>即可。The coroutine version is much easier to understand because the code is sequential. Under the hood the coroutine version returns back to the event loop just like the callback version. Therefore the code still uses the event loop but it can be written like a sequential program.</p><blockquote><p>Coroutines make it possible to write sequential code that is actually executed across multiple iterations of the event loop. This is useful for code that needs to perform blocking I/O and would quickly become messy if split into a chain of callback functions. </p></blockquote><h3 id="2-2-The-QEMU-coroutine-API"><a href="#2-2-The-QEMU-coroutine-API" class="headerlink" title="2.2 The QEMU coroutine API"></a>2.2 The QEMU coroutine API</h3><p>The coroutine API is documented in <a href="https://gitlab.com/qemu-project/qemu/-/blob/stable-6.0/include/qemu/coroutine.h" target="_blank" rel="noopener">include/qemu/coroutine.h</a>. The main functions are:</p><h4 id="2-2-1-create-coroutine"><a href="#2-2-1-create-coroutine" class="headerlink" title="2.2.1 create coroutine"></a>2.2.1 create coroutine</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Coroutine entry point</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * When the coroutine is entered for the first time, opaque is passed in as an</span></span><br><span class="line"><span class="comment"> * argument.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * When this function returns, the coroutine is destroyed automatically and</span></span><br><span class="line"><span class="comment"> * execution continues in the caller who last entered the coroutine.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="keyword">void</span> coroutine_fn <span class="title">CoroutineEntry</span><span class="params">(<span class="keyword">void</span> *opaque)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Create a new coroutine</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Use qemu_coroutine_enter() to actually transfer control to the coroutine.</span></span><br><span class="line"><span class="comment"> * The opaque argument is passed as the argument to the entry point.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">Coroutine *<span class="title">qemu_coroutine_create</span><span class="params">(CoroutineEntry *entry, <span class="keyword">void</span> *opaque)</span></span>;</span><br></pre></td></tr></table></figure><p>When a new coroutine is started, it will begin executing the entry function. The caller can pass an opaque pointer to data needed by the coroutine.</p><h4 id="2-2-2-execute-coroutine"><a href="#2-2-2-execute-coroutine" class="headerlink" title="2.2.2 execute coroutine"></a>2.2.2 execute coroutine</h4><p>The new coroutine is executed by calling <code>qemu_coroutine_enter</code>:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Transfer control to a coroutine</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">qemu_coroutine_enter</span><span class="params">(Coroutine *coroutine)</span></span>;</span><br></pre></td></tr></table></figure></p><h4 id="2-2-3-yield-coroutine"><a href="#2-2-3-yield-coroutine" class="headerlink" title="2.2.3 yield coroutine"></a>2.2.3 yield coroutine</h4><p>If the coroutine needs to wait for an event such as I/O completion or user input, it calls <code>qemu_coroutine_yield</code>:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Transfer control back to a coroutine's caller</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This function does not return until the coroutine is re-entered using</span></span><br><span class="line"><span class="comment"> * qemu_coroutine_enter().</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> coroutine_fn <span class="title">qemu_coroutine_yield</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br></pre></td></tr></table></figure></p><p>The yield function transfers control back to the <code>qemu_coroutine_enter</code> caller. The coroutine can be re-entered at a later point in time by calling <code>qemu_coroutine_enter</code>, for example, when an I/O request has completed.</p><hr><p>参考资料:</p><ol><li><a href="http://blog.vmsplice.net/2014/01/coroutines-in-qemu-basics.html" target="_blank" rel="noopener">Coroutines in QEMU: The basics</a></li><li><a href="https://royhunter.github.io/2016/06/24/qemu-coroutine/" target="_blank" rel="noopener">QEMU中的协程—qemu-coroutine</a></li><li><a href="https://zhuanlan.zhihu.com/p/172471249" target="_blank" rel="noopener">什么是协程？</a></li><li><a href="https://mp.weixin.qq.com/s/SyWjLg3lYx3pIJQfEtik8Q" target="_blank" rel="noopener">​浅谈协程</a></li><li><a href="https://mp.weixin.qq.com/s/IO4ynnKEfy2Rt-Me7EIeqg" target="_blank" rel="noopener">当谈论协程时，我们在谈论什么</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下协程(Coroutines)相关notes。
    
    </summary>
    
      <category term="操作系统" scheme="http://liujunming.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="QEMU" scheme="http://liujunming.github.io/tags/QEMU/"/>
    
      <category term="操作系统" scheme="http://liujunming.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>如何mount虚拟机镜像</title>
    <link href="http://liujunming.github.io/2023/05/01/%E5%A6%82%E4%BD%95mount%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%95%9C%E5%83%8F/"/>
    <id>http://liujunming.github.io/2023/05/01/如何mount虚拟机镜像/</id>
    <published>2023-05-01T11:49:38.000Z</published>
    <updated>2023-05-01T12:36:17.731Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍下mount虚拟机镜像的方法。 <a id="more"></a></p><h3 id="losetup"><a href="#losetup" class="headerlink" title="losetup"></a>losetup</h3><p>losetup只能mount raw格式的镜像。</p><p>To check what is the first usable loop device, run<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">losetup -f</span><br></pre></td></tr></table></figure></p><p>After that, use the output of that command to link the disk image to the loop device file (using root privileges):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">losetup -P /dev/loopX example.img</span><br></pre></td></tr></table></figure></p><p>The -P flag searches through the image for partitions, which you need to mount.</p><p>After that, create the folder named example and run the command:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/loopXpY example</span><br></pre></td></tr></table></figure></p><p>The disk image should now be mounted in that directory. Depending on the Y variable, the right partition was mounted.</p><h3 id="qemu-nbd"><a href="#qemu-nbd" class="headerlink" title="qemu-nbd"></a>qemu-nbd</h3><p>Export a QEMU disk image using the NBD protocol.</p><p>qemu-nbd可以mount多种格式的虚拟机镜像，因此适用范围比losetup要广！</p><ul><li><p>Enable NBD on the host</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modprobe nbd max_part=8</span><br></pre></td></tr></table></figure></li><li><p>Connect the QCOW2 as a network block device</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-nbd -c /dev/nbd0 /var/lib/vz/images/100/vm-100-disk-1.qcow2</span><br></pre></td></tr></table></figure></li><li><p>List partitions inside the QCOW2</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fdisk /dev/nbd0 -l</span><br></pre></td></tr></table></figure></li><li><p>Mount the partition from the VM</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/nbd0p1 /mnt/somepoint/</span><br></pre></td></tr></table></figure></li><li><p>After you’re done, unmount and disconnect</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">umount /mnt/somepoint/</span><br><span class="line">qemu-nbd -d /dev/nbd0</span><br><span class="line">rmmod nbd</span><br></pre></td></tr></table></figure></li></ul><hr><p>参考资料:</p><ol><li><a href="https://iaguozhi.github.io/blogs/Change-vm-kernel-by-qemu-nbd.html" target="_blank" rel="noopener">记录一次将虚拟机kernel写坏之后的修复过程</a></li><li><a href="https://www.qemu.org/docs/master/tools/qemu-nbd.html" target="_blank" rel="noopener">QEMU Disk Network Block Device Server</a></li><li><a href="https://eloydegen.com/blog/posts/losetup/" target="_blank" rel="noopener">Mount disk images using losetup</a></li><li><a href="https://www.man7.org/linux/man-pages/man8/losetup.8.html" target="_blank" rel="noopener">man losetup</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍下mount虚拟机镜像的方法。
    
    </summary>
    
      <category term="工具" scheme="http://liujunming.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://liujunming.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Notes about GPU Direct Storage</title>
    <link href="http://liujunming.github.io/2023/05/01/Notes-about-GPU-Direct-Storage/"/>
    <id>http://liujunming.github.io/2023/05/01/Notes-about-GPU-Direct-Storage/</id>
    <published>2023-05-01T07:32:26.000Z</published>
    <updated>2023-05-01T11:29:26.325Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下GPU Direct Storage相关notes。<a id="more"></a></p><blockquote><p>从IO读取链路来看，NVMe控制器通过DMA引擎将硬盘数据直接写入GPU显存，避免了主机内存和CPU的参与，从而实现CPU和主存的IO旁路，使IO吞吐能力不在受限于系统总线的带宽压力。</p></blockquote><p>说白了，就是支持NVMe与GPU的PCIe p2p，不过只支持NVMe到GPU的方向。</p><p><img src="/images/2023/05/01.png" alt></p><p><strong>GPUDirect Storage</strong> enables a direct data path between local or remote storage, such as NVMe or NVMe over Fabric (NVMe-oF), and GPU memory. It avoids extra copies through a bounce buffer in the CPU’s memory, enabling a direct memory access (DMA) engine near the NIC or storage to move data on a direct path into or out of GPU memory — all without burdening the CPU.</p><hr><p>参考资料:</p><ol><li><a href="https://zhuanlan.zhihu.com/p/509396439" target="_blank" rel="noopener">GPU Direct Storage</a></li><li><a href="https://developer.nvidia.com/gpudirect" target="_blank" rel="noopener">NVIDIA GPUDirect</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下GPU Direct Storage相关notes。
    
    </summary>
    
      <category term="体系结构" scheme="http://liujunming.github.io/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="体系结构" scheme="http://liujunming.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
      <category term="GPU" scheme="http://liujunming.github.io/tags/GPU/"/>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about hyper_dmabuf</title>
    <link href="http://liujunming.github.io/2023/04/30/Notes-about-hyper-dmabuf/"/>
    <id>http://liujunming.github.io/2023/04/30/Notes-about-hyper-dmabuf/</id>
    <published>2023-04-30T12:26:38.000Z</published>
    <updated>2023-04-30T13:22:49.838Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下hyper_dmabuf相关notes。<a id="more"></a><br><img src="/images/2023/04/20.png" alt></p><p>Hyper_DMABUF driver is a Linux device driver running on multiple Virtual achines (VMs), which expands DMA-BUF sharing capability to the VM environment where multiple different OS instances need to share same physical data without data-copy across VMs.</p><p>To share a DMA_BUF across VMs, an instance of the Hyper_DMABUF drv on the exporting VM (so called, “exporter”) imports a local DMA_BUF from the original producer of the buffer, then re-exports it with an unique ID, hyper_dmabuf_id for the buffer to the importing VM (so called, “importer”).</p><p>Another instance of the Hyper_DMABUF driver on importer registers a hyper_dmabuf_id together with reference information for the shared physical pages associated with the DMA_BUF to its database when the export happens.</p><p>The actual mapping of the DMA_BUF on the importer’s side is done by the Hyper_DMABUF driver when user space issues the IOCTL command to access the shared DMA_BUF. The Hyper_DMABUF driver works as both an importing and exporting driver as is, that is, no special configuration is required. Consequently, only a single module per VM is needed to enable cross-VM DMA_BUF exchange.</p><hr><p>参考资料:</p><ol><li><a href="https://projectacrn.github.io/1.6.1/developer-guides/hld/hld-APL_GVT-g.html#hyper-dma-buffer-sharing" target="_blank" rel="noopener">Hyper DMA Buffer Sharing</a></li><li><a href="https://github.com/downor/linux_hyper_dmabuf/blob/hyper_dmabuf_integration_v4/Documentation/hyper-dmabuf-sharing.txt" target="_blank" rel="noopener">Linux Hyper DMABUF Driver</a></li><li><a href="https://lists.freedesktop.org/archives/dri-devel/2017-December/160709.html" target="_blank" rel="noopener">hyper_dmabuf: initial working version of hyper_dmabuf drv</a></li><li><a href="https://www.phoronix.com/news/Intel-Hyper-DMA-BUF" target="_blank" rel="noopener">Intel Introduces “Hyper DMA-BUF” To Exchange Buffers Between VMs</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下hyper_dmabuf相关notes。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Notes about dma_buf</title>
    <link href="http://liujunming.github.io/2023/04/30/Notes-about-dma-buf/"/>
    <id>http://liujunming.github.io/2023/04/30/Notes-about-dma-buf/</id>
    <published>2023-04-30T06:25:25.000Z</published>
    <updated>2023-04-30T08:16:16.512Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下dma_buf相关notes。<a id="more"></a></p><h3 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h3><p><img src="/images/2023/04/17.jpg" alt><br>以摄像头采集数据，GPU显示数据为例。摄像头设备将数据DMA到内存中后，GPU需要将这些DMA内存进行显示，也就是说摄像头DMA的输出数据是GPU的DMA输入数据。如果没有DMA buffer sharing机制，则需要将摄像头的DMA数据拷贝一份以搬到GPU的DMA数据中，因此存在内存copy的开销！<br>dma_buf则提供了一套统一框架，可以实现不同device的驱动之间DMA buffer的sharing，同时还允许userspace mmap共享的DMA buffer！</p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p><img src="/images/2023/04/19.jpg" alt></p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/images/2023/04/18.jpg" alt></p><p><img src="/images/2023/04/14.png" alt></p><h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p><img src="/images/2023/04/13.png" alt></p><p><img src="/images/2023/04/15.png" alt><br><img src="/images/2023/04/16.png" alt></p><hr><p>参考资料:</p><ol><li><a href="https://blog.csdn.net/hexiaolong2009/article/details/102596744" target="_blank" rel="noopener">dma-buf 由浅入深（一） —— 最简单的 dma-buf 驱动程序</a></li><li><a href="https://github.com/hexiaolong2008/sample-code/tree/master/dma-buf/08" target="_blank" rel="noopener">dma-buf</a></li><li><a href="https://saiyn.github.io/homepage/2018/04/18/linux-kernel-dmabuf/" target="_blank" rel="noopener">Linux内核笔记之DMA_BUF</a></li><li><a href="https://elinux.org/images/a/a8/DMA_Buffer_Sharing-_An_Introduction.pdf" target="_blank" rel="noopener">DMA Buffer Sharing Framework:An Introduction</a></li><li><a href="https://www.openfabrics.org/wp-content/uploads/2020-workshop-presentations/303.-OFI-GPU-DMA-BUF-OFA2020v2.pdf" target="_blank" rel="noopener">RDMA WITH GPU MEMORY VIA DMA-BUF</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTc0ODAzMw==&amp;mid=2247502900&amp;idx=1&amp;sn=dd73aae7e7b296317fbff613d475888e&amp;chksm=ce9ad01af9ed590c71f309a8b4ba4bad72dda1d75f9af5d153caf5dd11e229aa75c8507685c7&amp;mpshare=1&amp;scene=1&amp;srcid=0403TMj3qA6LY1DDtxctawJO&amp;sharer_sharetime=1648995232072&amp;sharer_shareid=fcd8378fa2afcbc997c8bd7f888f36e6&amp;exportkey=AZdgR1ASyNPvcNHeaNH3PpE%3D&amp;acctmode=0&amp;pass_ticket=bxkMR5mJMnjqkgrSRKMG4Na40WpTHdV%2FfvZCJEtYhn3FUItw%2FA0ZMr0FE2oTAbbL&amp;wx_header=0#rd" target="_blank" rel="noopener">dma-buf学习分享</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下dma_buf相关notes。
    
    </summary>
    
      <category term="Kernel" scheme="http://liujunming.github.io/categories/Kernel/"/>
    
    
      <category term="Kernel" scheme="http://liujunming.github.io/tags/Kernel/"/>
    
  </entry>
  
  <entry>
    <title>Notes about TSO、GSO、LRO、GRO</title>
    <link href="http://liujunming.github.io/2023/04/23/Notes-about-TSO%E3%80%81GSO%E3%80%81LRO%E3%80%81GRO/"/>
    <id>http://liujunming.github.io/2023/04/23/Notes-about-TSO、GSO、LRO、GRO/</id>
    <published>2023-04-23T09:21:32.000Z</published>
    <updated>2023-04-23T10:35:19.351Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自<a href="https://mp.weixin.qq.com/s/jtKtdtSS15dRaivtdcAbQQ" target="_blank" rel="noopener">图解网络Offload</a>，将介绍TSO、GSO、LRO、GRO相关笔记。<a id="more"></a></p><p>网络应用程序如果要发送很大的数据包，经过内核协议栈的时，大包会被分片成多个不超过MTU长度的包。这个分片比较费CPU资源。Offload技术可以把这些分片和合并的工作进行优化处理，也可以直接Offload到网卡上。</p><h3 id="MTU"><a href="#MTU" class="headerlink" title="MTU"></a>MTU</h3><p>MTU是一个二层的概念，即最大传输单元（Maximum Transmission Unit，MTU），它不包含二层以太网头尾数据。网卡发送数据包的大小都是限制在MTU内的。<br><img src="/images/2023/04/06.png" alt></p><p>Offload涉及到四个概念：TSO、GSO、LRO、GRO。（当然还有UDP的UFO，以及一些checksum的Offload，在这里不讨论。）</p><h3 id="TSO"><a href="#TSO" class="headerlink" title="TSO"></a>TSO</h3><p>TSO(TCP Segmentation Offload)是一种利用网卡对大数据包进行分片，从而减小CPU负荷的一种技术。其作用通过两个图来对比：</p><p>TSO off和GSO off 状态数据包的发送过程：<br><img src="/images/2023/04/07.png" alt></p><p>TSO on状态数据包的发送过程：<br><img src="/images/2023/04/08.png" alt><br>一个大的网络包直到进入网卡内部后才由网卡进行了分片。</p><h3 id="GSO"><a href="#GSO" class="headerlink" title="GSO"></a>GSO</h3><p>GSO（Generic Segmentation Offload）是延缓分片技术。它比TSO更通用，原因在于它不需要硬件的支持就可以进行分片。</p><p>其过程是：首先查询网卡是否支持TSO功能，如果硬件支持TSO则使用网卡的硬件分片能力执行分片；如果网卡不支持 TSO 功能，则将分片的执行，延缓到了将数据推送到网卡的前一刻执行。</p><p>网卡关闭TSO时，GSO on状态数据包的发送过程：<br><img src="/images/2023/04/09.png" alt></p><p>一个大的网络包直到进入网卡前的最后一步才进行了分片。</p><p>TSO和GSO对应数据发送过程，对应数据接收过程的是LRO和GRO。</p><h3 id="LRO"><a href="#LRO" class="headerlink" title="LRO"></a>LRO</h3><p>LRO（Large Receive Offload）是将网卡接收到的多个数据包合并成一个大的数据包，然后再传递给网络协议栈处理的技术。这样可以提高系统接收数据包的能力，减轻CPU负载。</p><p>LRO off和GRO off 状态数据包的接收过程：<br><img src="/images/2023/04/10.png" alt></p><p>LRO on状态数据包的接收过程：<br><img src="/images/2023/04/11.png" alt><br>数据一进入网卡立刻进行了合并。</p><h3 id="GRO"><a href="#GRO" class="headerlink" title="GRO"></a>GRO</h3><p>GRO（Generic Receive Offload）是LRO 的软件实现，只是GRO 的合并条件更加的严格和灵活。</p><p>GRO on状态数据包的接收过程：<br><img src="/images/2023/04/12.png" alt></p><p>以上的网络offload是网络协议栈配合网卡完成的，在现在的很多智能网卡上可以直接offload整个网络协议栈，即把网络协议的处理放到了智能网卡上。</p><hr><p>参考资料:</p><ol><li><a href="https://mp.weixin.qq.com/s/jtKtdtSS15dRaivtdcAbQQ" target="_blank" rel="noopener">图解网络Offload</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自&lt;a href=&quot;https://mp.weixin.qq.com/s/jtKtdtSS15dRaivtdcAbQQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;图解网络Offload&lt;/a&gt;，将介绍TSO、GSO、LRO、GRO相关笔记。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about 零拷贝技术splice</title>
    <link href="http://liujunming.github.io/2023/04/23/Notes-about-%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AFsplice/"/>
    <id>http://liujunming.github.io/2023/04/23/Notes-about-零拷贝技术splice/</id>
    <published>2023-04-23T06:22:39.000Z</published>
    <updated>2023-04-23T06:32:45.106Z</updated>
    
    <content type="html"><![CDATA[<p>转载自:<a href="https://mp.weixin.qq.com/s?__biz=MzA3NzYzODg1OA==&amp;mid=2648466923&amp;idx=1&amp;sn=acf2fb71a960f3831f9b98657b39d4ce&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文读懂零拷贝技术｜splice使用</a>。<a id="more"></a><br>服务端要向客户端连接发送一个文件，一般过程如下：</p><ul><li>服务端首先调用 <code>read()</code> 函数读取文件内容。</li><li>服务端通过调用 <code>write()</code>/<code>send()</code> 函数将文件内容发送给客户端连接。</li></ul><p>上面过程如下图所示：</p><p><img src="/images/2023/04/04.jpeg" alt></p><p>从上图可以看出，在发送文件的过程中，首先需要将文件页缓存（Page Cache）从内核态复制到用户态缓存中，然后再从用户态缓存复制到客户端的 Socket 缓冲区中。</p><p>其实在上面的过程中，复制文件数据到用户态缓存这个操作是多余的，我们完全可以直接把文件页缓存的数据复制到 Socket 缓冲区即可，这样就可以减少一次拷贝数据的操作。</p><p>为了实现这样的功能，内核提供了一个名为 <code>splice()</code>的系统调用，使用 <code>splice()</code>系统调用可以避免从内核态拷贝数据到用户态。</p><blockquote><p>不需要将内核态的数据拷贝到用户态缓存的技术被称为：<code>零拷贝技术</code>。</p></blockquote><p><img src="/images/2023/04/05.jpeg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://mp.weixin.qq.com/s?__biz=MzA3NzYzODg1OA==&amp;mid=2648466923&amp;idx=1&amp;sn=acf2fb71a960f3831f9b98657b39d4ce&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文读懂零拷贝技术｜splice使用</a></li><li><a href="https://mp.weixin.qq.com/s/vN1VIgX73arke4put_cyRg" target="_blank" rel="noopener">一文读懂零拷贝技术｜splice原理与实现</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转载自:&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3NzYzODg1OA==&amp;amp;mid=2648466923&amp;amp;idx=1&amp;amp;sn=acf2fb71a960f3831f9b98657b39d4ce&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;一文读懂零拷贝技术｜splice使用&lt;/a&gt;。
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux IOMMU bypass method</title>
    <link href="http://liujunming.github.io/2023/04/22/Linux-IOMMU-bypass-method/"/>
    <id>http://liujunming.github.io/2023/04/22/Linux-IOMMU-bypass-method/</id>
    <published>2023-04-22T08:45:06.000Z</published>
    <updated>2023-04-22T09:30:38.240Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/2023/04/01.jpg" alt><br><a id="more"></a><br><img src="/images/2023/04/03.jpg" alt></p><p><img src="/images/2023/04/02.jpg" alt><br>将AT字段设置为10b即可bypass IOMMU。</p><p><a href="/2019/11/24/Introduction-to-PCIe-Address-Translation-Services/">ATC</a>的深入理解：如果设备在ATC中找到对应的映射entry后，会将TLP AT字段设置为10b，并将TLP中的address字段设置为翻译后的地址。</p><hr><p>参考资料:</p><ol><li><a href="https://pdfs.semanticscholar.org/b450/50db1fb770a07bc60c66d3532ee4d1949ccb.pdf" target="_blank" rel="noopener">Thunderclap:Exploring Vulnerabilities in Operating System IOMMU Protection via DMA from Untrustworthy Peripherals</a></li><li>PCIe spec</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/2023/04/01.jpg&quot; alt&gt;&lt;br&gt;
    
    </summary>
    
      <category term="IOMMU" scheme="http://liujunming.github.io/categories/IOMMU/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
      <category term="IOMMU" scheme="http://liujunming.github.io/tags/IOMMU/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Root Complex</title>
    <link href="http://liujunming.github.io/2023/02/12/Notes-about-root-complex/"/>
    <id>http://liujunming.github.io/2023/02/12/Notes-about-root-complex/</id>
    <published>2023-02-12T09:36:29.000Z</published>
    <updated>2023-02-12T10:19:59.731Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Root Complex(RC)相关笔记。<br><img src="/images/2023/02/06.png" alt></p><a id="more"></a><p>The Root Complex is an entity that includes a Host Bridge and one or more root ports.<br><img src="/images/2023/02/07.png" alt></p><p>当CPU读写pcie设备的MMIO BAR时，RC的Host Bridge将processor transactions转换为TLP。因此当host bridge发现CPU访问的物理地址区间是MMIO时，会让目标EP(End Point)所属的root port发送memory read/write TLP，经过路由，最终TLP会下发到目标EP。</p><hr><p>参考资料:</p><ol><li><a href="http://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-1/" target="_blank" rel="noopener">Down to the TLP: How PCI express devices talk</a></li><li><a href="https://astralvx.com/introduction-to-pcie/" target="_blank" rel="noopener">Introduction to PCIe</a></li><li><a href="https://zhuanlan.zhihu.com/p/32786076" target="_blank" rel="noopener">使用Xilinx IP核进行PCIE开发学习笔记</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Root Complex(RC)相关笔记。&lt;br&gt;&lt;img src=&quot;/images/2023/02/06.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/categories/PCI-PCIe/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about vsock</title>
    <link href="http://liujunming.github.io/2023/02/11/Notes-about-vsock/"/>
    <id>http://liujunming.github.io/2023/02/11/Notes-about-vsock/</id>
    <published>2023-02-11T04:59:37.000Z</published>
    <updated>2023-02-11T06:11:05.414Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录vsock相关Notes。<a id="more"></a></p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p>VM Sockets(vsock) is a fast and efficient communication mechanism between guest virtual machines and their host. 说白了，就是允许guest与host利用socket进行通信(不依赖于虚拟机的网卡)，借助于网卡，guest与host也是可以进行socket通信的，但此时就不是vsock了。使用vsock进行socket编程时，需要使用新的socket address family AF_VSOCK。</p><h3 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h3><p><img src="/images/2023/02/01.jpg" alt><br><img src="/images/2023/02/02.jpg" alt><br><img src="/images/2023/02/03.jpg" alt></p><h3 id="How"><a href="#How" class="headerlink" title="How"></a>How</h3><p><img src="/images/2023/02/04.jpg" alt><br>There are several layers here.</p><ul><li>application, use &lt;cid,port&gt; as a socket address</li><li>socket layer, support for socket API</li><li>AF_VSOCK address family, implement the vsock core</li><li>transport, trasnport the data between guest and host.</li></ul><p>The transport layer is the mostly needed to talk as the other three just need to implement standand interfaces in kernel.</p><p>Transport as its name indicated, is used to transport the data between guest and host just like the networking card transport data between local and remote socket. There are two kinds of transports according to data’s flow direction.</p><ul><li>G2H: guest-&gt;host transport, they run in the guest and the guest vsock networking protocol uses this to communication with the host.</li><li>H2G: host-&gt;guest transport, they run in the host and the host vsock networing protocol uses this to communiction with the guest.</li></ul><p>Usually H2G transport is implemented as a device emulation, and G2H transport is implemented as the emulated device’s driver. For example, in VMware the H2G transport is a emulated vmci PCI device and the G2H is vmci device driver. In qemu the H2G transport is a emulated vhost-vsock device and the G2H transport is the vosck device’s driver.</p><p>Following picture shows the virtio(in guest) and vhost(in host) transport.<br><img src="/images/2023/02/05.jpg" alt></p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>可以参考 <a href="https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6" target="_blank" rel="noopener">https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6</a><br>在qemu-kvm + Linux guest环境中搭建vsock环境。</p><hr><p>参考资料:</p><ol><li><a href="https://vmsplice.net/~stefan/stefanha-kvm-forum-2015.pdf" target="_blank" rel="noopener">virtio-vsock Zero-configuration host/guest communication</a></li><li><a href="https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6" target="_blank" rel="noopener">https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6</a></li><li><a href="https://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/04/18/vsock-internals" target="_blank" rel="noopener">Linux vsock internals</a></li><li><a href="https://static.sched.com/hosted_files/devconfcz2020a/b1/DevConf.CZ_2020_vsock_v1.1.pdf" target="_blank" rel="noopener">VSOCK: VM ↔ host socket with minimal configuration</a></li><li><a href="https://www.man7.org/linux/man-pages/man7/vsock.7.html" target="_blank" rel="noopener">man vsock</a></li><li><a href="https://iaguozhi.github.io/blogs/vsock.html" target="_blank" rel="noopener">vsock 介绍与使用</a></li><li><a href="https://lwn.net/Articles/556550/" target="_blank" rel="noopener">Introduce VM Sockets virtio transport</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录vsock相关Notes。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Intel Hyper-Threading Technology</title>
    <link href="http://liujunming.github.io/2023/01/07/Notes-about-Intel-Hyper-Threading-Technology/"/>
    <id>http://liujunming.github.io/2023/01/07/Notes-about-Intel-Hyper-Threading-Technology/</id>
    <published>2023-01-07T05:33:43.000Z</published>
    <updated>2023-01-07T06:52:51.063Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录下作者对intel 超线程(Hyper-Threading)技术的理解。 <a id="more"></a> </p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/images/2023/01/01.jpg" alt><br><img src="/images/2023/01/02.jpg" alt><br>根据sdm的描述，同一个core上的两个超线程其实是共享execution engine的。</p><p><img src="/images/2023/01/03.jpg" alt><br>每个超线程拥有独立的通用寄存器。每个超线程的具体资源状态需要查询spec，本文不在此赘述。</p><h3 id="Execution-Engine"><a href="#Execution-Engine" class="headerlink" title="Execution Engine"></a>Execution Engine</h3><p><img src="/images/2023/01/04.jpg" alt><br>Execution Engine涉及到具体的微架构。接下来将以Ice Lake Client microarchitecture为例来介绍下Execution Engine。</p><p><img src="/images/2023/01/05.jpg" alt><br><img src="/images/2023/01/06.jpg" alt></p><p>Execution Unit是需要额外关注的。由上图可知，在一个Execution Engine内拥有4个ALU，1个Slow Int。</p><ul><li>同一个core上的两个超线程想同时执行<code>add</code>指令，这理论上是可行的，因为Execution Engine中有四个ALU Execution Unit(ALU可运行<code>add</code>指令)。</li><li>同一个core上的两个超线程想同时执行<code>mul</code>指令，这理论上是不可行的，因为Execution Engine中只有一个Slow Int Execution Unit(Slow Int可运行<code>mul</code>指令)。</li></ul><hr><p>参考资料:</p><ol><li><a href="https://cdrdv2.intel.com/v1/dl/getContent/671488" target="_blank" rel="noopener">Intel® 64 and IA-32 Architectures Optimization Reference Manual</a></li><li><a href="https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-lipp.pdf" target="_blank" rel="noopener">Meltdown: Reading Kernel Memory from User Space</a></li><li>Intel SDM Vol3</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录下作者对intel 超线程(Hyper-Threading)技术的理解。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="体系结构" scheme="http://liujunming.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
  <entry>
    <title>Notes about signal in Linux</title>
    <link href="http://liujunming.github.io/2022/12/18/Notes-about-signal-in-Linux/"/>
    <id>http://liujunming.github.io/2022/12/18/Notes-about-signal-in-Linux/</id>
    <published>2022-12-18T06:38:23.000Z</published>
    <updated>2022-12-18T08:21:07.581Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Linux的signal相关notes。<a id="more"></a><br><img src="/images/2022/12/05.jpg" alt></p><h3 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h3><p><a href="https://blog.csdn.net/w903414/article/details/109802539" target="_blank" rel="noopener">一篇文章彻底搞定信号</a></p><h4 id="信号是什么"><a href="#信号是什么" class="headerlink" title="信号是什么"></a>信号是什么</h4><p>例：</p><ol><li>输入命令，在Shell下启动一个前台进程。</li><li>用户按下Ctrl-C，键盘输入产生一个硬件中断。</li><li>如果CPU当前正在执行这个进程的代码，则该进程的用户空间代码暂停执行， CPU从用户态切换到内核态处理硬件中断。</li><li>终端驱动程序将Ctrl-C解释成一个<code>SIGINT</code>信号，记在该进程的PCB中（也可以说发送了一个<code>SIGINT</code>信号给该进程）。</li><li>当某个时刻要从内核返回到该进程的用户空间代码继续执行之前，首先处理PCB中记录的信号，发现有一个<code>SIGINT</code>信号待处理，而这个信号的默认处理动作是终止进程，所以直接终止进程而不再返回它的用户空间代码执行。</li></ol><p>在这个例子中，由Ctrl-C产生的硬件中断就是一个信号。Ctrl+C产生的信号只能发送给前台进程，命令后加&amp;就可放到后台运行。Shell可同时运行一个前台进程和任意多个后台进程，只有前台进程才能接受到像CTRL+C这种控制键产生的信号。</p><h4 id="信号的种类"><a href="#信号的种类" class="headerlink" title="信号的种类"></a>信号的种类</h4><h4 id="信号的产生"><a href="#信号的产生" class="headerlink" title="信号的产生"></a>信号的产生</h4><ul><li>硬件产生</li><li>软件产生</li></ul><h4 id="信号的注册"><a href="#信号的注册" class="headerlink" title="信号的注册"></a>信号的注册</h4><p>信号注册实际上是一个位图和一个sigqueue队列。<br><img src="/images/2022/12/06.png" alt></p><h4 id="信号的注销"><a href="#信号的注销" class="headerlink" title="信号的注销"></a>信号的注销</h4><h4 id="信号阻塞"><a href="#信号阻塞" class="headerlink" title="信号阻塞"></a>信号阻塞</h4><p><img src="/images/2022/12/07.png" alt></p><h4 id="信号未决"><a href="#信号未决" class="headerlink" title="信号未决"></a>信号未决</h4><p>实际执行信号的处理动作称为信号递达（Delivery），信号从产生到递达之间的状态，称为信号未决（Pending）。进程可以选择阻塞（Block）某个信号。被阻塞的信号产生时将保持在未决状态，直到进程解除对此信号的阻塞，才执行递达的动作。注意，阻塞和忽略是不同的，只要信号被阻塞就不会递达，而忽略是在递达之后可选的一种处理动作。</p><h4 id="信号的处理方式"><a href="#信号的处理方式" class="headerlink" title="信号的处理方式"></a>信号的处理方式</h4><p><img src="/images/2022/12/08.png" alt></p><p>每个信号都有两个标志位分别表示阻塞和未决，还有一个函数指针表示处理动作。</p><h4 id="信号的捕捉"><a href="#信号的捕捉" class="headerlink" title="信号的捕捉"></a>信号的捕捉</h4><p>条件: 如果信号的处理动作是用户自定义函数，在信号递达时就调用这个函数，这就称为信号捕捉。</p><p>流程:<br><img src="/images/2022/12/09.png" alt></p><p>内核态返回用户态会调用<code>do_signal</code>函数，两种情况：</p><ol><li>无信号：<code>sys_return</code>函数，返回用户态</li><li>有信号：先处理信号，信号返回，再调用<code>do_signal</code>函数 </li></ol><p>例：</p><ol><li>程序注册了<code>SIGQUIT</code>信号的处理函数sighandler。</li><li>当前正在执行main函数，这时发生中断或异常切换到内核态。</li><li>在中断处理完毕后要返回用户态的main函数之前检查到有信号SIGQUIT递达。</li><li>内核决定返回用户态后不是恢复main函数的上下文继续执行，而是执行sighandler函数， <strong>sighandler和main函数之间不存在调用和被调用的关系，是两个独立的控制流程。</strong></li><li>sighandler函数返回后自动执行特殊的系统调用sig_return再次进入内核态。</li><li>如果没有新的信号要递达，这次再返回用户态就是恢复main函数的上下文继续执行了。</li></ol><h4 id="常用信号集操作函数"><a href="#常用信号集操作函数" class="headerlink" title="常用信号集操作函数"></a>常用信号集操作函数</h4><h4 id="SIGCHLD信号"><a href="#SIGCHLD信号" class="headerlink" title="SIGCHLD信号"></a>SIGCHLD信号</h4><h3 id="SIGKILL-vs-SIGTERM"><a href="#SIGKILL-vs-SIGTERM" class="headerlink" title="SIGKILL vs SIGTERM"></a>SIGKILL vs SIGTERM</h3><p>Though both of these signals are used for killing a process, there are some differences between the two:</p><ul><li><code>SIGTERM</code> gracefully kills the process whereas <code>SIGKILL</code> kills the process immediately.</li><li><code>SIGTERM</code> signal can be handled, ignored, and blocked, but <code>SIGKILL</code> cannot be handled or blocked.</li><li><code>SIGTERM</code> doesn’t kill the child processes. <code>SIGKILL</code> kills the child processes as well.</li></ul><p><img src="https://linuxhandbook.com/content/images/2022/04/sigterm-vs-sigkill-tip.webp" alt></p><hr><p>参考资料:</p><ol><li><a href="https://www.man7.org/linux/man-pages/man7/signal.7.html" target="_blank" rel="noopener">man signal</a></li><li><a href="https://www-uxsup.csx.cam.ac.uk/courses/moved.Building/signals.pdf" target="_blank" rel="noopener">A list of signals and what they mean</a></li><li><a href="https://linuxhandbook.com/sigterm-vs-sigkill/#:~:text=Though%20both%20of%20these%20signals%20are%20used%20for,blocked%2C%20but%20SIGKILL%20cannot%20be%20handled%20or%20blocked." target="_blank" rel="noopener">SIGTERM vs SIGKILL: What’s the Difference?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Linux的signal相关notes。
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>深入解析virtio-blk resize原理</title>
    <link href="http://liujunming.github.io/2022/12/17/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90virtio-blk-resize%E5%8E%9F%E7%90%86/"/>
    <id>http://liujunming.github.io/2022/12/17/深入解析virtio-blk-resize原理/</id>
    <published>2022-12-17T07:05:05.000Z</published>
    <updated>2022-12-18T03:12:28.554Z</updated>
    
    <content type="html"><![CDATA[<p>本文将结合virtio spec、qemu与Linux kernel源码深入解析virtio-blk resize的原理。<a id="more"></a> </p><p>本文参考的virtio spec是<a href="https://ozlabs.org/~rusty/virtio-spec/virtio-0.9.5.pdf" target="_blank" rel="noopener">0.9.5</a>，qemu版本为<a href="https://gitlab.com/qemu-project/qemu/-/tree/v2.6.0" target="_blank" rel="noopener">v2.6.0</a>，Linux kernel版本为<a href="https://elixir.bootlin.com/linux/v4.19/source" target="_blank" rel="noopener">v4.19</a>。</p><h2 id="1-overview"><a href="#1-overview" class="headerlink" title="1. overview"></a>1. overview</h2><p>virtio-blk后端设备resize后，通过msi-x的configuration vector给guest发送中断，guest收到中断后，handler会读取virtio header中的capacity field来完成resize操作。</p><h2 id="2-基础知识"><a href="#2-基础知识" class="headerlink" title="2. 基础知识"></a>2. 基础知识</h2><p>virtio header中有configuration vector这个field。guest配置MSI-x table时，会配置好configuration vector。<br><img src="/images/2022/12/03.jpg" alt></p><p>当后端设备配置发生变化时，会触发configuration vector对应的中断。<br><img src="/images/2022/12/04.jpg" alt></p><p>对于virtio-blk设备，virtio header中的capacity存放了size信息。当resize时，capacity会发生变化。<br><img src="/images/2022/12/02.jpg" alt><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk_config</span> &#123;</span></span><br><span class="line"><span class="comment">/* The capacity (in 512-byte sectors). */</span></span><br><span class="line">__u64 capacity;</span><br><span class="line"><span class="comment">/* The maximum segment size (if VIRTIO_BLK_F_SIZE_MAX) */</span></span><br><span class="line">__u32 size_max;</span><br><span class="line"><span class="comment">/* The maximum number of segments (if VIRTIO_BLK_F_SEG_MAX) */</span></span><br><span class="line">__u32 seg_max;</span><br><span class="line"><span class="comment">/* geometry of the device (if VIRTIO_BLK_F_GEOMETRY) */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk_geometry</span> &#123;</span></span><br><span class="line">__u16 cylinders;</span><br><span class="line">__u8 heads;</span><br><span class="line">__u8 sectors;</span><br><span class="line">&#125; geometry;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* block size of device (if VIRTIO_BLK_F_BLK_SIZE) */</span></span><br><span class="line">__u32 blk_size;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* the next 4 entries are guarded by VIRTIO_BLK_F_TOPOLOGY  */</span></span><br><span class="line"><span class="comment">/* exponent for physical block per logical block. */</span></span><br><span class="line">__u8 physical_block_exp;</span><br><span class="line"><span class="comment">/* alignment offset in logical blocks. */</span></span><br><span class="line">__u8 alignment_offset;</span><br><span class="line"><span class="comment">/* minimum I/O size without performance penalty in logical blocks. */</span></span><br><span class="line">__u16 min_io_size;</span><br><span class="line"><span class="comment">/* optimal sustained I/O size in logical blocks. */</span></span><br><span class="line">__u32 opt_io_size;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* writeback mode (if VIRTIO_BLK_F_CONFIG_WCE) */</span></span><br><span class="line">__u8 wce;</span><br><span class="line">__u8 unused;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* number of vqs, only available when VIRTIO_BLK_F_MQ is set */</span></span><br><span class="line">__u16 num_queues;</span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure></p><h2 id="3-virtio-blk后端设备resize"><a href="#3-virtio-blk后端设备resize" class="headerlink" title="3. virtio-blk后端设备resize"></a>3. virtio-blk后端设备resize</h2><p>首先需要完成virtio-blk后端设备的resize，比如virtio-blk后端设备是一个文件，那么需要将这个文件resize！virtio-blk后端设备的形式较多，不在本文描述范围之内。</p><h2 id="4-QEMU发送configuration-vector中断"><a href="#4-QEMU发送configuration-vector中断" class="headerlink" title="4. QEMU发送configuration vector中断"></a>4. QEMU发送configuration vector中断</h2><h3 id="4-1-hmp-block-resize命令"><a href="#4-1-hmp-block-resize命令" class="headerlink" title="4.1 hmp block_resize命令"></a>4.1 hmp block_resize命令</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hmp_block_resize</span><br><span class="line">└── qmp_block_resize</span><br><span class="line">    └── bdrv_truncate</span><br><span class="line">        └── blk_dev_resize_cb</span><br><span class="line">            └── virtio_blk_resize[resize_cb]</span><br></pre></td></tr></table></figure><p>hmp <code>block_resize</code>命令的函数调用链如上所示，最终会调用到<code>virtio_blk_resize</code>函数。</p><h3 id="4-2-virtio-blk-resize发送configuration-vector中断"><a href="#4-2-virtio-blk-resize发送configuration-vector中断" class="headerlink" title="4.2 virtio_blk_resize发送configuration vector中断"></a>4.2 virtio_blk_resize发送configuration vector中断</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">virtio_blk_resize</span><br><span class="line">└── virtio_notify_config</span><br><span class="line">    └── virtio_notify_vector(vdev, vdev-&gt;config_vector)</span><br><span class="line">        └── virtio_pci_notify</span><br><span class="line">            └── msix_notify</span><br><span class="line">                ├── msix_get_message</span><br><span class="line">                └── msi_send_message</span><br></pre></td></tr></table></figure><p>最终qemu会调用<code>msi_send_message</code>往guest注入configuration vector中断(本质上是模拟memory write TLP)。</p><h2 id="5-guest处理configuration-vector中断"><a href="#5-guest处理configuration-vector中断" class="headerlink" title="5. guest处理configuration vector中断"></a>5. guest处理configuration vector中断</h2><h3 id="5-1-guest注册中断"><a href="#5-1-guest注册中断" class="headerlink" title="5.1 guest注册中断"></a>5.1 guest注册中断</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">vp_request_msix_vectors</span><span class="params">(struct virtio_device *vdev, <span class="keyword">int</span> nvectors,</span></span></span><br><span class="line"><span class="function"><span class="params">   <span class="keyword">bool</span> per_vq_vectors, struct irq_affinity *desc)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">err = request_irq(pci_irq_vector(vp_dev-&gt;pci_dev, v),</span><br><span class="line">vp_config_changed, <span class="number">0</span>, vp_dev-&gt;msix_names[v],</span><br><span class="line">vp_dev);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Handle a configuration change: Tell driver if it wants to know. */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> irqreturn_t <span class="title">vp_config_changed</span><span class="params">(<span class="keyword">int</span> irq, <span class="keyword">void</span> *opaque)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_pci_device</span> *<span class="title">vp_dev</span> = <span class="title">opaque</span>;</span></span><br><span class="line"></span><br><span class="line">virtio_config_changed(&amp;vp_dev-&gt;vdev);</span><br><span class="line"><span class="keyword">return</span> IRQ_HANDLED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">virtio_config_changed</span><span class="params">(struct virtio_device *dev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line"></span><br><span class="line">spin_lock_irqsave(&amp;dev-&gt;config_lock, flags);</span><br><span class="line">__virtio_config_changed(dev);</span><br><span class="line">spin_unlock_irqrestore(&amp;dev-&gt;config_lock, flags);</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL_GPL(virtio_config_changed);</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __virtio_config_changed(struct virtio_device *dev)</span><br><span class="line">&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_driver</span> *<span class="title">drv</span> = <span class="title">drv_to_virtio</span>(<span class="title">dev</span>-&gt;<span class="title">dev</span>.<span class="title">driver</span>);</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!dev-&gt;config_enabled)</span><br><span class="line">dev-&gt;config_change_pending = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (drv &amp;&amp; drv-&gt;config_changed)</span><br><span class="line">drv-&gt;config_changed(dev); <span class="comment">//for virtio-blk, it's virtblk_config_changed</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">virtio_driver</span> <span class="title">virtio_blk</span> = &#123;</span></span><br><span class="line">...</span><br><span class="line">.config_changed= virtblk_config_changed,</span><br><span class="line">...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtblk_config_changed</span><span class="params">(struct virtio_device *vdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk</span> *<span class="title">vblk</span> = <span class="title">vdev</span>-&gt;<span class="title">priv</span>;</span></span><br><span class="line"></span><br><span class="line">queue_work(virtblk_wq, &amp;vblk-&gt;config_work);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">virtblk_probe</span><span class="params">(struct virtio_device *vdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">INIT_WORK(&amp;vblk-&gt;config_work, virtblk_config_changed_work);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-2-中断handler处理resize"><a href="#5-2-中断handler处理resize" class="headerlink" title="5.2 中断handler处理resize"></a>5.2 中断handler处理resize</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">virtblk_config_changed_work</span><br><span class="line">└── virtblk_update_capacity</span><br><span class="line">    └── virtio_cread</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* The queue's logical block size must be set before calling this */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtblk_update_capacity</span><span class="params">(struct virtio_blk *vblk, <span class="keyword">bool</span> resize)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_device</span> *<span class="title">vdev</span> = <span class="title">vblk</span>-&gt;<span class="title">vdev</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">request_queue</span> *<span class="title">q</span> = <span class="title">vblk</span>-&gt;<span class="title">disk</span>-&gt;<span class="title">queue</span>;</span></span><br><span class="line"><span class="keyword">char</span> cap_str_2[<span class="number">10</span>], cap_str_10[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> nblocks;</span><br><span class="line">u64 capacity;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Host must always specify the capacity. */</span></span><br><span class="line">virtio_cread(vdev, struct virtio_blk_config, capacity, &amp;capacity);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>virtio_cread(vdev, struct virtio_blk_config, capacity, &amp;capacity)</code>其实就是读virtio header中的capacity field，此时会发生VM Exit trap到qemu中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Config space accessors. */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> virtio_cread(vdev, structname, member, ptr)\</span></span><br><span class="line"><span class="keyword">do</span> &#123;\</span><br><span class="line"><span class="comment">/* Must match the member's type, and be integer */</span>\</span><br><span class="line"><span class="keyword">if</span> (!typecheck(typeof((((structname*)<span class="number">0</span>)-&gt;member)), *(ptr))) \</span><br><span class="line">(*ptr) = <span class="number">1</span>;\</span><br><span class="line">\</span><br><span class="line"><span class="keyword">switch</span> (<span class="keyword">sizeof</span>(*ptr)) &#123;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">1</span>:\</span><br><span class="line">*(ptr) = virtio_cread8(vdev,\</span><br><span class="line">       offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">2</span>:\</span><br><span class="line">*(ptr) = virtio_cread16(vdev,\</span><br><span class="line">offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">4</span>:\</span><br><span class="line">*(ptr) = virtio_cread32(vdev,\</span><br><span class="line">offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">8</span>:\</span><br><span class="line">*(ptr) = virtio_cread64(vdev,\</span><br><span class="line">offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">default</span>:\</span><br><span class="line">BUG();\</span><br><span class="line">&#125;\</span><br><span class="line">&#125; <span class="keyword">while</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> u64 <span class="title">virtio_cread64</span><span class="params">(struct virtio_device *vdev,</span></span></span><br><span class="line"><span class="function"><span class="params"> <span class="keyword">unsigned</span> <span class="keyword">int</span> offset)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">u64 ret;</span><br><span class="line">__virtio_cread_many(vdev, offset, &amp;ret, <span class="number">1</span>, <span class="keyword">sizeof</span>(ret));</span><br><span class="line"><span class="keyword">return</span> virtio64_to_cpu(vdev, (__force __virtio64)ret);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Read @count fields, @bytes each. */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span> __virtio_cread_many(struct virtio_device *vdev,</span><br><span class="line">       <span class="keyword">unsigned</span> <span class="keyword">int</span> offset,</span><br><span class="line">       <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> count, <span class="keyword">size_t</span> bytes)</span><br><span class="line">&#123;</span><br><span class="line">u32 old, gen = vdev-&gt;config-&gt;generation ?</span><br><span class="line">vdev-&gt;config-&gt;generation(vdev) : <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"></span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">old = gen;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; count; i++)</span><br><span class="line">vdev-&gt;config-&gt;get(vdev, offset + bytes * i,</span><br><span class="line">  buf + i * bytes, bytes);</span><br><span class="line"></span><br><span class="line">gen = vdev-&gt;config-&gt;generation ?</span><br><span class="line">vdev-&gt;config-&gt;generation(vdev) : <span class="number">0</span>;</span><br><span class="line">&#125; <span class="keyword">while</span> (gen != old);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="6-qemu完成virtio-header中capacity-field的模拟"><a href="#6-qemu完成virtio-header中capacity-field的模拟" class="headerlink" title="6. qemu完成virtio header中capacity field的模拟"></a>6. qemu完成virtio header中capacity field的模拟</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">uint32_t</span> virtio_config_readb(VirtIODevice *vdev, <span class="keyword">uint32_t</span> addr)</span><br><span class="line">&#123;</span><br><span class="line">    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);</span><br><span class="line">    <span class="keyword">uint8_t</span> val;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (addr + <span class="keyword">sizeof</span>(val) &gt; vdev-&gt;config_len) &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">uint32_t</span>)<span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    k-&gt;get_config(vdev, vdev-&gt;config);<span class="comment">//对应到virtio_blk_update_config</span></span><br><span class="line"></span><br><span class="line">    val = ldub_p(vdev-&gt;config + addr);</span><br><span class="line">    <span class="keyword">return</span> val;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* coalesce internal state, copy to pci i/o region 0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtio_blk_update_config</span><span class="params">(VirtIODevice *vdev, <span class="keyword">uint8_t</span> *config)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    VirtIOBlock *s = VIRTIO_BLK(vdev);</span><br><span class="line">    BlockConf *conf = &amp;s-&gt;conf.conf;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk_config</span> <span class="title">blkcfg</span>;</span></span><br><span class="line">    <span class="keyword">uint64_t</span> capacity;</span><br><span class="line">    <span class="keyword">int</span> blk_size = conf-&gt;logical_block_size;</span><br><span class="line"></span><br><span class="line">    blk_get_geometry(s-&gt;blk, &amp;capacity);</span><br><span class="line">    <span class="built_in">memset</span>(&amp;blkcfg, <span class="number">0</span>, <span class="keyword">sizeof</span>(blkcfg));</span><br><span class="line">    virtio_stq_p(vdev, &amp;blkcfg.capacity, capacity);</span><br><span class="line">    virtio_stl_p(vdev, &amp;blkcfg.seg_max, <span class="number">128</span> - <span class="number">2</span>);</span><br><span class="line">    virtio_stw_p(vdev, &amp;blkcfg.geometry.cylinders, conf-&gt;cyls);</span><br><span class="line">    virtio_stl_p(vdev, &amp;blkcfg.blk_size, blk_size);</span><br><span class="line">    virtio_stw_p(vdev, &amp;blkcfg.min_io_size, conf-&gt;min_io_size / blk_size);</span><br><span class="line">    virtio_stw_p(vdev, &amp;blkcfg.opt_io_size, conf-&gt;opt_io_size / blk_size);</span><br><span class="line">    blkcfg.geometry.heads = conf-&gt;heads;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * We must ensure that the block device capacity is a multiple of</span></span><br><span class="line"><span class="comment">     * the logical block size. If that is not the case, let's use</span></span><br><span class="line"><span class="comment">     * sector_mask to adopt the geometry to have a correct picture.</span></span><br><span class="line"><span class="comment">     * For those devices where the capacity is ok for the given geometry</span></span><br><span class="line"><span class="comment">     * we don't touch the sector value of the geometry, since some devices</span></span><br><span class="line"><span class="comment">     * (like s390 dasd) need a specific value. Here the capacity is already</span></span><br><span class="line"><span class="comment">     * cyls*heads*secs*blk_size and the sector value is not block size</span></span><br><span class="line"><span class="comment">     * divided by 512 - instead it is the amount of blk_size blocks</span></span><br><span class="line"><span class="comment">     * per track (cylinder).</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (blk_getlength(s-&gt;blk) /  conf-&gt;heads / conf-&gt;secs % blk_size) &#123;</span><br><span class="line">        blkcfg.geometry.sectors = conf-&gt;secs &amp; ~s-&gt;sector_mask;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        blkcfg.geometry.sectors = conf-&gt;secs;</span><br><span class="line">    &#125;</span><br><span class="line">    blkcfg.size_max = <span class="number">0</span>;</span><br><span class="line">    blkcfg.physical_block_exp = get_physical_block_exp(conf);</span><br><span class="line">    blkcfg.alignment_offset = <span class="number">0</span>;</span><br><span class="line">    blkcfg.wce = blk_enable_write_cache(s-&gt;blk);</span><br><span class="line">    <span class="built_in">memcpy</span>(config, &amp;blkcfg, <span class="keyword">sizeof</span>(struct virtio_blk_config));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>参考资料:</p><ol><li><a href="http://m.blog.chinaunix.net/uid-29718549-id-4390132.html" target="_blank" rel="noopener">qemu block_resize(动态修改磁盘大小)实现简记</a></li><li><a href="https://blog.frehi.be/2022/08/01/online-resizing-block-devices-and-file-systems/" target="_blank" rel="noopener">Online resizing block devices and file systems</a></li><li><a href="https://serverfault.com/a/743106" target="_blank" rel="noopener">Is online disk resize possible with KVM?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将结合virtio spec、qemu与Linux kernel源码深入解析virtio-blk resize的原理。
    
    </summary>
    
      <category term="virtio" scheme="http://liujunming.github.io/categories/virtio/"/>
    
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Intel turbo boost</title>
    <link href="http://liujunming.github.io/2022/12/03/Notes-about-Intel-turbo-boost/"/>
    <id>http://liujunming.github.io/2022/12/03/Notes-about-Intel-turbo-boost/</id>
    <published>2022-12-03T11:08:59.000Z</published>
    <updated>2022-12-03T11:38:55.483Z</updated>
    
    <content type="html"><![CDATA[<p>Intel turbo boost的中文翻译为”睿频加速”，一般情况下turbo(睿频)指的就是Intel turbo boost。本文将记录turbo相关notes。<a id="more"></a> </p><p><img src="/images/2022/12/01.jpg" alt></p><p>CPUs don’t always need to run at their maximum frequency. Some programs are more dependent on memory to run smoothly, while others are CPU-intensive. Intel Turbo Boost Technology is an energy-efficient solution to this imbalance: it lets the CPU run at its base clock speed when handling light workloads, then jump to a higher clock speed for heavy workloads.</p><p>Running at a lower clock rate (the number of cycles executed by the processor every second) allows the processor to use less power, which can reduce heat and positively impact battery life in laptops. But when more speed is needed, Intel Turbo Boost Technology dynamically increases the clock rate to compensate.</p><p>Intel Turbo Boost Technology can potentially increase CPU speeds up to the Max Turbo Frequency while staying within safe temperature and power limits. This can increase performance in both single-threaded and multithreaded applications (programs that utilize several processor cores).</p><hr><p>参考资料:</p><ol><li><a href="https://www.intel.com/content/www/us/en/support/articles/000030893/processors.html" target="_blank" rel="noopener">What Is Intel® Turbo Boost Technology and How Does It Work?</a></li><li><a href="https://www.intel.com/content/www/us/en/gaming/resources/turbo-boost.htm" target="_blank" rel="noopener">What Is Intel® Turbo Boost Technology?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Intel turbo boost的中文翻译为”睿频加速”，一般情况下turbo(睿频)指的就是Intel turbo boost。本文将记录turbo相关notes。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
</feed>
