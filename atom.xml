<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>L</title>
  
  <subtitle>make it simple, make it happen.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://liujunming.github.io/"/>
  <updated>2022-11-13T13:19:55.638Z</updated>
  <id>http://liujunming.github.io/</id>
  
  <author>
    <name>liujunming</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Comparing VIRTIO, NVMe, and io_uring queue designs</title>
    <link href="http://liujunming.github.io/2022/11/13/Comparing-VIRTIO-NVMe-and-io-uring-queue-designs/"/>
    <id>http://liujunming.github.io/2022/11/13/Comparing-VIRTIO-NVMe-and-io-uring-queue-designs/</id>
    <published>2022-11-13T13:11:13.000Z</published>
    <updated>2022-11-13T13:19:55.638Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://blog.vmsplice.net/2022/06/comparing-virtio-nvme-and-iouring-queue.html" target="_blank" rel="noopener">http://blog.vmsplice.net/2022/06/comparing-virtio-nvme-and-iouring-queue.html</a><br>深度好文，强烈推荐！<a id="more"></a> </p><h3 id="Ring-buffer-basics"><a href="#Ring-buffer-basics" class="headerlink" title="Ring buffer basics"></a>Ring buffer basics</h3><p>A ring buffer is a circular array where new elements are produced on one side and consumed on the other side. Often terms such as head and tail are used to <strong>describe the array indices at which the next element is accessed</strong>. When the end of the array is reached, one moves back to the start of the array. The empty and full conditions are special states that must be checked to avoid underflow and overflow.</p><p>VIRTIO, NVMe, and io_uring all use single producer, single consumer shared memory ring buffers. This allows a CPU and an I/O device or two CPUs to communicate across a region of memory to which both sides have access.</p><p><a href="https://mp.weixin.qq.com/s/pjuHWagzhONS3eOmF6xkXQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/pjuHWagzhONS3eOmF6xkXQ</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://blog.vmsplice.net/2022/06/comparing-virtio-nvme-and-iouring-queue.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://blog.vmsplice.net/2022/06/comparing-virtio-nvme-and-iouring-queue.html&lt;/a&gt;&lt;br&gt;深度好文，强烈推荐！
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Notes about KVM dedicated vCPUs hint</title>
    <link href="http://liujunming.github.io/2022/11/13/Notes-about-KVM-dedicated-vCPUs-hint/"/>
    <id>http://liujunming.github.io/2022/11/13/Notes-about-KVM-dedicated-vCPUs-hint/</id>
    <published>2022-11-13T02:44:24.000Z</published>
    <updated>2022-11-13T03:08:40.720Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下KVM中的dedicated vCPUs hint KVM_HINTS_DEDICATED。<a id="more"></a> </p><p>This feature introduces dedicated vCPUs(vCPU pinning, and there is no vCPU over-commitment) hint KVM_HINTS_DEDICATED, it has two users now:</p><ol><li><p>Waiman Long mentioned that:<br> Generally speaking, unfair lock performs well for VMs with a small number of vCPUs. Native qspinlock may perform better than pvqspinlock if there is vCPU pinning and there is no vCPU over-commitment.</p></li><li><p>vCPUs are very unlikely to get preempted when they are the only task running on a CPU. PV TLB flush is slower than the native flush in that case.</p></li></ol><p><img src="/images/2022/11/05.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://static.sched.com/hosted_files/kvmforum2019/e3/Boosting%20Dedicated%20Instances%20by%20KVM%20Tax%20Cut.pdf" target="_blank" rel="noopener">Boosting Dedicated InstanceviaKVMTaxCut</a></li><li><a href="https://lore.kernel.org/kvm/1518483942-14741-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: Introduce dedicated vCPUs hint KVM_HINTS_DEDICATED</a></li><li><a href="https://lore.kernel.org/qemu-devel/1518083060-5881-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">target-i386: adds PV_DEDICATED hint CPUID feature bit</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下KVM中的dedicated vCPUs hint KVM_HINTS_DEDICATED。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
  </entry>
  
  <entry>
    <title>Notes about io_uring</title>
    <link href="http://liujunming.github.io/2022/11/12/Notes-about-io-uring/"/>
    <id>http://liujunming.github.io/2022/11/12/Notes-about-io-uring/</id>
    <published>2022-11-12T05:13:37.000Z</published>
    <updated>2022-11-13T01:24:51.868Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录io_uring相关笔记。<a id="more"></a> </p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>The native Linux AIO framework suffers from various limitations, which io_uring aims to overcome:</p><ul><li>It does not support buffered I/O, only direct I/O is supported.</li><li>It has non-deterministic behavior which may block under various circumstances.</li><li>It has a sub-optimal API, which requires at least two system calls per I/O, one to submit a request, and one to wait for its completion.<ul><li>Each submission needs to copy 64 + 8 bytes of data, and each completion needs to copy 32 bytes.</li></ul></li></ul><h3 id="Communication-channel"><a href="#Communication-channel" class="headerlink" title="Communication channel"></a>Communication channel</h3><p><img src="/images/2022/11/01.jpg" alt></p><p>An io_uring instance has two rings, a submission queue (SQ) and a completion queue (CQ), shared between the kernel and the application. The queues are single producer, single consumer, and power of two in size.</p><p>The queues provide a lock-less access interface, coordinated with memory barriers.</p><p>The application creates one or more SQ entries (SQE), and then updates the SQ tail. The kernel consumes the SQEs , and updates the SQ head.</p><p>The kernel creates CQ entries (CQE) for one or more completed requests, and updates the CQ tail. The application consumes the CQEs and updates the CQ head.</p><p>Completion events may arrive in any order but they are always associated with specific SQEs.</p><h3 id="System-call"><a href="#System-call" class="headerlink" title="System call"></a>System call</h3><p><img src="/images/2022/11/02.jpg" alt></p><h3 id="默认流程"><a href="#默认流程" class="headerlink" title="默认流程"></a>默认流程</h3><p>默认情形下，提交任务的流程，以及获取结果的方式:</p><ol><li>把sqe放入sqring</li><li>调用<code>io_uring_enter</code>通知内核</li><li><strong>可以轮询cqring等待结果</strong>或者通过带<code>IORING_ENTER_GETEVENTS</code>和<code>min_complete</code>参数的<code>io_uring_enter</code>阻塞等待指定数目的任务完成，再去cqring中检查结果</li></ol><h3 id="Submission-Queue-Polling"><a href="#Submission-Queue-Polling" class="headerlink" title="Submission Queue Polling"></a>Submission Queue Polling</h3><p>如果在调用<code>io_uring_setup</code> 时设置了 <code>IORING_SETUP_SQPOLL</code> 的 flag，内核会额外启动一个内核线程，我们称作 SQ 线程。这个内核线程可以运行在某个指定的 core 上（通过 <code>sq_thread_cpu</code> 配置）。这个内核线程会不停的 Poll SQ，除非在一段时间内没有 Poll 到任何请求（通过 <code>sq_thread_idle</code> 配置），才会被挂起。</p><p><img src="/images/2022/11/04.jpeg" alt></p><p>当程序在用户态设置完 SQE，并通过修改 SQ 的 tail 完成一次插入时，如果此时 SQ 线程处于唤醒状态，那么可以立刻捕获到这次提交，这样就避免了用户程序调用<code>io_uring_enter</code>这个系统调用。如果 SQ 线程处于休眠状态，则需要通过调用<code>io_uring_enter</code>，并使用<code>IORING_SQ_NEED_WAKEUP</code> 参数，来唤醒 SQ 线程。用户态可以通过 sqring 的 flags 变量获取 SQ 线程的状态。</p><h3 id="io-polling"><a href="#io-polling" class="headerlink" title="io polling"></a>io polling</h3><p>在默认情况下，当设备处理完IO请求后，设备会发送中断通知内核往cqring添加cqe，并更新cqring的tail指针。用户态程序会轮询cqring获取新的cqe。</p><p>但是对于IO low latency或者high IOPS的场景，使用中断并不合适，应该使用polling(refers to performing IO without relying on hardware interrupts to signal a completion event)。此时因为没有中断通知，内核就不会往 cqring中填充cqe，因此用户态程序就不能去轮询cqring了。此时，用户态程序必须调用<code>io_uring_enter</code> with <code>IORING_ENTER_GETEVENTS</code> set and <code>min_complete</code> set to 0来下发轮询任务给内核，内核会轮询检查是否有结果产生，如果有，则将结果放入cqring。 </p><p>Tips:搞清楚内核什么时候更新cqring，分为如下两种case:</p><ol><li><p>硬件中断通知内核</p></li><li><p>用户态程序调用<code>io_uring_enter</code>来下发polling任务给内核</p></li></ol><h3 id="liburing"><a href="#liburing" class="headerlink" title="liburing"></a>liburing</h3><p>为了简化使用io_uring， liburing 库应用而生。用户无需了解诸多 io_uring 细节便可以使用起来，如无需关心 memory barrier，以及 ring buffer 的管理等。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/images/2022/11/03.jpg" alt></p><p>io_uring 主要通过用户态与内核态共享内存的途径，来摒弃使用系统调用来提交 I/O 操作和获取 I/O 操作的结果，从而避免了上下文切换的情况。另外，由于用户态进程与内核态线程通过共享内存的方式通信，从而避免了内存拷贝的过程，提升了 I/O 操作的性能。</p><p>所以，io_uring 主要通过两个优化点来提升 I/O 操作的性能：</p><ul><li>摒弃使用系统调用来提交 I/O 操作和获取 I/O 操作结果</li><li>减少用户态与内核态之间的内存拷贝</li></ul><hr><p>参考资料:</p><ol><li><a href="https://blogs.oracle.com/linux/post/an-introduction-to-the-io-uring-asynchronous-io-framework" target="_blank" rel="noopener">An Introduction to the io_uring Asynchronous I/O Framework</a></li><li><a href="https://unixism.net/loti/what_is_io_uring.html" target="_blank" rel="noopener">What is io_uring?</a></li><li><a href="https://kernel.dk/io_uring.pdf" target="_blank" rel="noopener">Efficient IO with io_uring</a></li><li><a href="https://zhuanlan.zhihu.com/p/62682475" target="_blank" rel="noopener">AIO 的新归宿：io_uring</a></li><li><a href="https://kernel.dk/axboe-kr2022.pdf" target="_blank" rel="noopener">What’s new with io_uring</a></li><li><a href="https://mp.weixin.qq.com/s/4hXwPhCOJFjUjMJqzjKWgg" target="_blank" rel="noopener">io_uring 新异步 IO 机制，性能提升超 150%，堪比 SPDK</a></li><li><a href="https://zhuanlan.zhihu.com/p/361955546" target="_blank" rel="noopener">浅析开源项目之io_uring</a></li><li><a href="https://mp.weixin.qq.com/s/fzvkGpvxFXYEWMCWcfTb-w" target="_blank" rel="noopener">下一代异步 IO io_uring 技术解密</a></li><li><a href="Submission Queue Polling[¶](https://unixism.net/loti/tutorial/sq_poll.html#submission-queue-polling">Submission Queue Polling</a>)</li><li><a href="https://www.jianshu.com/p/32a3c72da1c1" target="_blank" rel="noopener">io_uring</a></li><li><a href="https://mp.weixin.qq.com/s/1wZpFhwJR-LNkQm-QzFxRQ" target="_blank" rel="noopener">Linux I/O 神器之 io_uring</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录io_uring相关笔记。
    
    </summary>
    
      <category term="I/O系统" scheme="http://liujunming.github.io/categories/I-O%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="I/O系统" scheme="http://liujunming.github.io/tags/I-O%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Notes about virtual IPI fastpath and virtual TSC-Deadline timer fastpath</title>
    <link href="http://liujunming.github.io/2022/10/30/Notes-about-virtual-IPI-fastpath/"/>
    <id>http://liujunming.github.io/2022/10/30/Notes-about-virtual-IPI-fastpath/</id>
    <published>2022-10-29T17:20:02.000Z</published>
    <updated>2022-10-30T01:39:38.435Z</updated>
    
    <content type="html"><![CDATA[<p>本文参考的内核版本为<a href="https://elixir.bootlin.com/linux/v6.0/source" target="_blank" rel="noopener">v6.0</a>。<a id="more"></a></p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><img src="/images/2022/10/18.jpg" alt></p><h3 id="virtual-IPI-fastpath"><a href="#virtual-IPI-fastpath" class="headerlink" title="virtual IPI fastpath"></a>virtual IPI fastpath</h3><p><img src="/images/2022/10/19.jpg" alt></p><p><img src="/images/2022/10/20.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vmx_vcpu_run</span><br><span class="line">└── vmx_exit_handlers_fastpath</span><br><span class="line">    └── handle_fastpath_set_msr_irqoff</span><br><span class="line">        └── handle_fastpath_set_x2apic_icr_irqoff</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The fast path for frequent and performance sensitive wrmsr emulation,</span></span><br><span class="line"><span class="comment"> * i.e. the sending of IPI, sending IPI early in the VM-Exit flow reduces</span></span><br><span class="line"><span class="comment"> * the latency of virtual IPI by avoiding the expensive bits of transitioning</span></span><br><span class="line"><span class="comment"> * from guest to host, e.g. reacquiring KVM's SRCU lock. In contrast to the</span></span><br><span class="line"><span class="comment"> * other cases which must be called after interrupts are enabled on the host.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">handle_fastpath_set_x2apic_icr_irqoff</span><span class="params">(struct kvm_vcpu *vcpu, u64 data)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!lapic_in_kernel(vcpu) || !apic_x2apic_mode(vcpu-&gt;arch.apic))</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (((data &amp; APIC_SHORT_MASK) == APIC_DEST_NOSHORT) &amp;&amp;</span><br><span class="line">    ((data &amp; APIC_DEST_MASK) == APIC_DEST_PHYSICAL) &amp;&amp;</span><br><span class="line">    ((data &amp; APIC_MODE_MASK) == APIC_DM_FIXED) &amp;&amp;</span><br><span class="line">    ((u32)(data &gt;&gt; <span class="number">32</span>) != X2APIC_BROADCAST))</span><br><span class="line"><span class="keyword">return</span> kvm_x2apic_icr_write(vcpu-&gt;arch.apic, data);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="virtual-TSC-Deadline-timer-fastpath"><a href="#virtual-TSC-Deadline-timer-fastpath" class="headerlink" title="virtual TSC-Deadline timer fastpath"></a>virtual TSC-Deadline timer fastpath</h3><p><img src="/images/2022/10/21.jpg" alt></p><p><img src="/images/2022/10/22.jpg" alt></p><p><a href="https://lore.kernel.org/kvm/1587709364-19090-5-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: X86: TSCDEADLINE MSR emulation fastpath</a><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vmx_vcpu_run</span><br><span class="line">└── vmx_exit_handlers_fastpath</span><br><span class="line">    └── handle_fastpath_set_msr_irqoff</span><br><span class="line">        └── handle_fastpath_set_tscdeadline</span><br><span class="line">            └── kvm_set_lapic_tscdeadline_msr</span><br></pre></td></tr></table></figure></p><p><img src="/images/2022/10/23.jpg" alt></p><p><a href="https://lore.kernel.org/kvm/1587709364-19090-6-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: VMX: Handle preemption timer fastpath</a><br>该patch优化的是<a href="/2022/10/22/lapic-timer-virtualization/">使用preemption timer模拟lapic timer的case</a>。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vmx_vcpu_run</span><br><span class="line">└── vmx_exit_handlers_fastpath</span><br><span class="line">    └── handle_fastpath_preemption_timer</span><br></pre></td></tr></table></figure></p><p><img src="/images/2022/10/24.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://static.sched.com/hosted_files/kvmforum2020/6e/KVM%20Latency%20and%20Scalability%20Performance%20Tuning.pdf" target="_blank" rel="noopener">KVM Latency and Scalability Performance Tuning</a></li><li><a href="https://lore.kernel.org/kvm/1574306232-872-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: VMX: FIXED+PHYSICAL mode single target IPI fastpath</a></li><li><a href="https://lore.kernel.org/kvm/1587709364-19090-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: VMX: Tscdeadline timer emulation fastpath</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文参考的内核版本为&lt;a href=&quot;https://elixir.bootlin.com/linux/v6.0/source&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;v6.0&lt;/a&gt;。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
      <category term="中断" scheme="http://liujunming.github.io/tags/%E4%B8%AD%E6%96%AD/"/>
    
  </entry>
  
  <entry>
    <title>KVM halt-polling机制分析</title>
    <link href="http://liujunming.github.io/2022/10/29/Notes-about-kvm-halt-polling/"/>
    <id>http://liujunming.github.io/2022/10/29/Notes-about-kvm-halt-polling/</id>
    <published>2022-10-29T07:35:53.000Z</published>
    <updated>2022-10-29T08:51:57.874Z</updated>
    
    <content type="html"><![CDATA[<p>   本文转载自:<a href="https://www.cnblogs.com/163yun/p/10114699.html" target="_blank" rel="noopener">KVM halt-polling机制分析</a>。<a id="more"></a> </p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>在实际业务中，guest执行HLT指令是导致虚拟化overhead的一个重要原因。如[1]。</p><p>KVM halt polling特性就是为了解决这一个问题被引入的，它在Linux 4.3-rc1被合入主干内核，其基本原理是当guest idle发生vm-exit时，host 继续polling一段时间，用于减少guest的业务时延。进一步讲，在vcpu进入idle之后，guest内核默认处理是执行HLT指令，就会发生vm-exit，host kernel并不马上让出物理核给调度器，而是poll一段时间，若guest在这段时间内被唤醒，便可以马上调度回该vcpu线程继续运行。</p><p>polling机制带来时延上的降低，至少是一个线程调度周期，通常是几微妙，但最终的性能提升是跟guest内业务模型相关的。如果在host kernel polling期间，没有唤醒事件发生或是运行队列里面其他任务变成runnable状态，那么调度器就会被唤醒去干其他任务的事。因此，halt polling机制对于那些在很短时间间隔就会被唤醒一次的业务特别有效。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ol><li>该机制有可能导致物理CPU实际空闲的情况下占用率表现为100%。因为如果guest上业务模型是隔一段时间被唤醒一次来处理很少量的流量，并且这个时间间隔比kvm halt_poll_ns短，那么host将poll整个虚拟机的block时间，cpu占用率也会冲上100%。</li><li>halt polling是电源能耗和业务时延的一个权衡。为了减少进入guest的时延，idle cpu时间转换为host kernel时间。</li><li>该机制只有在CPU上没有其他running任务的情况得以应用，不然polling动作被立马终止，唤醒调度器，调度其他进程。</li></ol><h3 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h3><p>业界针对虚拟机idle这个课题有比较多的研究，因为它带来了比较大的overhead。主要可以归结为以下几种：</p><ol><li><p>idle=poll，即把虚拟机idle时一直polling，空转，不退出。这样不利于物理CPU超线程的发挥。</p></li><li><p>阿里提出guest里面提供halt polling机制，即在VM退出前先等会儿，这样可以减少VM退出次数。 优点：性能较kvm halt polling机制好；缺点：需要修改guest内核；状态：社区未接收 <a href="https://lore.kernel.org/kvm/1510567565-5118-1-git-send-email-quan.xu0@gmail.com/" target="_blank" rel="noopener">x86/idle: add halt poll support</a> 值得注意的是， 类似idea的工作<a href="/2022/10/28/Notes-about-Guest-halt-polling/">guest halt polling</a>社区已接受</p></li><li><p>腾讯考虑guest HLT指令不退出。优点：性能较阿里好；缺点：只适用于vcpu独占物理核场景；状态：社区已接受。<a href="https://lore.kernel.org/kvm/1517813878-22248-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: X86: Add per-VM no-HLT-exiting capability</a></p></li></ol><hr><p>参考资料:</p><ol><li><a href="https://www.linux-kvm.org/images/2/27/Kvm-forum-2013-idle-latency.pdf" target="_blank" rel="noopener">KVM vs. Message Passing Throughput</a></li><li><a href="http://events17.linuxfoundation.org/sites/events/files/slides/Message%20Passing%20Workloads%20in%20KVM%20%28SLIDES%29.pdf" target="_blank" rel="noopener">Message Passing Workloads in KVM</a></li><li><a href="http://events17.linuxfoundation.org/sites/events/files/slides/KVM%20performance%20tuning%20on%20Alibaba%20Cloud.pdf" target="_blank" rel="noopener">KVM performance tuning</a></li><li><a href="https://www.kernel.org/doc/Documentation/virtual/kvm/halt-polling.txt" target="_blank" rel="noopener">The KVM halt polling system</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;   本文转载自:&lt;a href=&quot;https://www.cnblogs.com/163yun/p/10114699.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;KVM halt-polling机制分析&lt;/a&gt;。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
  </entry>
  
  <entry>
    <title>Notes about guest halt polling</title>
    <link href="http://liujunming.github.io/2022/10/28/Notes-about-Guest-halt-polling/"/>
    <id>http://liujunming.github.io/2022/10/28/Notes-about-Guest-halt-polling/</id>
    <published>2022-10-28T13:20:37.000Z</published>
    <updated>2022-10-29T08:49:07.967Z</updated>
    
    <content type="html"><![CDATA[<p>Notes about guest halt polling feature.<a id="more"></a> </p><p>前提:    需要对intel的<a href="/2020/05/01/Introduction-to-halt-pause-monitor-mwait-instruction/#hlt">hlt</a>指令有一定的了解。 </p><p>The cpuidle_haltpoll driver, with the haltpoll governor, allows the guest vcpus to poll for a specified amount of time before halting.</p><p>This provides the following benefits to host side polling:</p><ol><li>The POLL flag is set while polling is performed, which allows a remote vCPU to avoid sending an IPI (and the associated cost of handling the IPI) when performing a wakeup.</li><li>The VM-exit cost can be avoided.</li></ol><p>The downside of guest side polling is that polling is performed even with other runnable tasks in the host.</p><p>The basic logic as follows: A global value, <code>guest_halt_poll_ns</code>, is configured by the user, indicating the maximum amount of time polling is allowed. This value is fixed.</p><p>Each vcpu has an adjustable <code>guest_halt_poll_ns</code> (“per-cpu <code>guest_halt_poll_ns</code>”), which is adjusted by the algorithm in response to events.</p><p>The module parameters can be set from the debugfs files in:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sys/module/haltpoll/parameters/</span><br></pre></td></tr></table></figure></p><hr><p>参考资料:</p><ol><li><a href="https://www.kernel.org/doc/html/latest/virt/guest-halt-polling.html" target="_blank" rel="noopener">Guest halt polling</a></li><li><a href="https://lore.kernel.org/kvm/20190613224532.949768676@redhat.com/" target="_blank" rel="noopener">cpuidle haltpoll driver and governor</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Notes about guest halt polling feature.
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Intel Data Streaming Accelerator(DSA)</title>
    <link href="http://liujunming.github.io/2022/10/23/Notes-about-Intel-Data-Streaming-Accelerator-DSA/"/>
    <id>http://liujunming.github.io/2022/10/23/Notes-about-Intel-Data-Streaming-Accelerator-DSA/</id>
    <published>2022-10-23T12:34:39.000Z</published>
    <updated>2022-11-13T13:11:38.803Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Intel Data Streaming Accelerator(DSA)相关notes。想要了解细节的话，还是需要去查询spec。<a id="more"></a> </p><p>Intel DSA is a high-performance data copy and transformation accelerator that will be integrated in future Intel® processors, targeted for optimizing streaming data movement and transformation operations common with applications for high-performance storage, networking, persistent memory, and various data processing applications.</p><p>The goal is to provide higher overall system performance for data mover and transformation operations, while freeing up CPU cycles for higher level functions. Intel DSA enables high performance data mover capability to/from volatile memory, persistent memory, memory-mapped I/O, and through a Non-Transparent Bridge (NTB) device to/from remote volatile and persistent memory on another node in a cluster. Enumeration and configuration is done with a PCI Express compatible programming interface to the Operating System (OS) and can be controlled through a device driver.</p><p>Besides the basic data mover operations, Intel DSA supports a set of transformation operations on memory. For example:</p><ul><li>Generate and test CRC checksum, or Data Integrity Field (DIF) to support storage and networking applications.</li><li>Memory Compare and delta generate/merge to support VM migration, VM Fast check-pointing and software managed memory deduplication usages.</li></ul><p>比如用DSA做memcpy的话，与CPU相比，优势在哪里呢？</p><ol><li>可以释放CPU资源，将memcpy的功能offload到DSA上</li><li>DSA支持并行批量化处理，当memcpy大量数据的话，DSA可以并行处理，因此可以提高效。如果是少量的memcpy的话，用DSA的效率就不如CPU的了。</li></ol><p><img src="/images/2022/10/17.jpg" alt></p><p>Figure 3-1 illustrates the high-level blocks within the device at a conceptual level. The I/O fabric interface is used for receiving downstream work requests from clients and for upstream read, write, and address translation operations.</p><p>Each device contains the following basic components:</p><ul><li>Work Queues (WQ) - On device storage to queue descriptors to the device. Requests are added to a WQ by using new instructions to write to the memory mapped “portal” associated with each WQ.</li><li>Groups - Abstract container that can include one or more engines and work queues.</li><li>Engines - Pulls work submitted to the WQs and process them.</li></ul><p>Two types of WQs are supported:</p><ul><li>Dedicated WQ (DWQ) - A single client owns this exclusively and can submit work to it.</li><li>Shared WQ (SWQ) - Multiple clients can submit work to the SWQ.</li></ul><p>A client using DWQ submits work descriptors using the <em>MOVDIR64B</em> instruction. This is a posted write, so the client must track the number of descriptors submitted to ensure that it does not exceed the configured work queue length as any additional descriptors would be dropped.</p><p>Clients using shared work queues submit work descriptors using either <em>ENQCMDS</em> (from supervisor mode) or <em>ENQCMD</em> (from user mode). These instructions indicate via the <strong>EFLAGS.ZF</strong> bit whether the request was accepted.</p><hr><p>参考资料:</p><ol><li><a href="https://01.org/blogs/2019/introducing-intel-data-streaming-accelerator" target="_blank" rel="noopener">INTRODUCING THE INTEL® DATA STREAMING ACCELERATOR </a></li><li><a href="https://software.intel.com/en-us/download/intel-data-streaming-accelerator-preliminary-architecture-specification" target="_blank" rel="noopener">DSA spec</a></li><li><a href="https://www.cnblogs.com/shaohef/p/12820952.html" target="_blank" rel="noopener">intel DSA spec 解读</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Intel Data Streaming Accelerator(DSA)相关notes。想要了解细节的话，还是需要去查询spec。
    
    </summary>
    
      <category term="SDM" scheme="http://liujunming.github.io/categories/SDM/"/>
    
    
      <category term="SDM" scheme="http://liujunming.github.io/tags/SDM/"/>
    
  </entry>
  
  <entry>
    <title>Notes about vt-x &quot;acknowledge interrupt on exit&quot; feature</title>
    <link href="http://liujunming.github.io/2022/10/23/Notes-about-vtx-acknowledge-interrupt-on-exit-feature/"/>
    <id>http://liujunming.github.io/2022/10/23/Notes-about-vtx-acknowledge-interrupt-on-exit-feature/</id>
    <published>2022-10-23T01:28:25.000Z</published>
    <updated>2022-10-23T12:59:47.683Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍VT-x中的”acknowledge interrupt on exit” feature。 <a id="more"></a> </p><h3 id="definition"><a href="#definition" class="headerlink" title="definition"></a>definition</h3><p>sdm中的相关描述:</p><p><img src="/images/2022/10/14.jpg" alt></p><p><img src="/images/2022/10/15.jpg" alt></p><h3 id="description"><a href="#description" class="headerlink" title="description"></a>description</h3><blockquote><p>The “acknowledge interrupt on exit” VM-exit control in the controlling VMCS controls processor behavior for external interrupt acknowledgement. If the control is 1, the processor acknowledges the interrupt controller to acquire the interrupt vector upon VM exit, and stores the vector in the VM-exit interruption-information field. If the control is 0, the external interrupt is not acknowledged during VM exit. Since RFLAGS.IF is automatically cleared on VM exits due to external interrupts, VMM re-enabling of interrupts(setting RFLAGS.IF = 1) initiates the external interrupt acknowledgement and vectoring of the external interrupt through the monitor/host IDT.</p></blockquote><p><img src="/images/2022/10/16.jpg" alt></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>当“acknowledge interrupt on exit” VM-exit control位为0：</li></ul><p>当vCPU在non-root mode时，external interrupt会导致VM Exit，此时VM Exit interruption information field is marked as invalid。在root mode下，lapic的IRR对应的bit位会被置上。在root mode下，硬件会完成interrupt evaluation和interrupt recognition，当hypervisor设置RFLAGS.IF后，就会发生interrupt delivery，处理器就调用IDT对应的中断处理函数。</p><ul><li>当“acknowledge interrupt on exit” VM-exit control位为1：</li></ul><p>当vCPU在non-root mode时，external interrupt会导致VM Exit，此时VM Exit interruption information field is marked as valid，并且会记录external interrupt的vector号，此时lapic的IRR对应的bit位并没有被置上，但lapic ISR对应的bit位会被置上(logical processor acknowledges the interrupt controller)。在root mode下，由于lapic的IRR对应的bit位并没有被置上，此时就不会走interrupt evaluation和interrupt recognition这条路径了，也就不会发生interrupt delivery了，处理器不会通过IDT调用中断处理函数。此时需要hypervisor手动调用IDT的中断处理函数。</p><h3 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h3><p>本文参考的内核版本为<a href="https://elixir.bootlin.com/linux/v5.0/source/" target="_blank" rel="noopener">v5.0</a>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="title">int</span> <span class="params">(*kvm_vmx_exit_handlers[])</span><span class="params">(struct kvm_vcpu *vcpu)</span> </span>= &#123;</span><br><span class="line">...</span><br><span class="line">[EXIT_REASON_EXTERNAL_INTERRUPT]      = handle_external_interrupt,</span><br><span class="line">...</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> __<span class="function">always_inline <span class="keyword">int</span> <span class="title">handle_external_interrupt</span><span class="params">(struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">++vcpu-&gt;stat.irq_exits;</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由代码可知，external interrupt的handler只是增加统计信息而已，并没有处理外部中断。</p><p>最终是vmx_handle_external_intr进行了外部中断的真正处理。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vcpu_run</span><br><span class="line">└── vcpu_enter_guest</span><br><span class="line">    └── vmx_handle_external_intr[kvm_x86_ops-&gt;handle_external_intr]</span><br></pre></td></tr></table></figure></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">vmx_handle_external_intr</span><span class="params">(struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">u32 exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 如果中断的类型是外部中断 */</span></span><br><span class="line"><span class="keyword">if</span> ((exit_intr_info &amp; (INTR_INFO_VALID_MASK | INTR_INFO_INTR_TYPE_MASK))</span><br><span class="line">== (INTR_INFO_VALID_MASK | INTR_TYPE_EXT_INTR)) &#123;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> <span class="built_in">vector</span>;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> entry;</span><br><span class="line">gate_desc *desc;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">vcpu_vmx</span> *<span class="title">vmx</span> = <span class="title">to_vmx</span>(<span class="title">vcpu</span>);</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_X86_64</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> tmp;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 取得外部中断的vector值，</span></span><br><span class="line"><span class="comment"> * (这是因为处理器的"acknowledge interrupt on exit"特性会自动ACK，就自动拿到了vector，</span></span><br><span class="line"><span class="comment"> *  但是这个特性使能之后，处理器不会再通过IDT调用中断处理函数，而是使用vmx handler </span></span><br><span class="line"><span class="comment"> *  vmx handler在这里构造中断栈帧，然后根据vector的值到IDT中找到真正的处理函数完成中断的处理</span></span><br><span class="line"><span class="comment"> *  注意，这里会将中断栈帧中的IF置位，这样中断处理完成的时候，就会自动的开启中断了)   </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="built_in">vector</span> =  exit_intr_info &amp; INTR_INFO_VECTOR_MASK;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 找到中断描述符，并得到门入口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">desc = (gate_desc *)vmx-&gt;host_idt_base + <span class="built_in">vector</span>;</span><br><span class="line">entry = gate_offset(desc);</span><br><span class="line"><span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">#ifdef CONFIG_X86_64</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">"mov %%"</span> _ASM_SP <span class="string">", %[sp]\n\t"</span></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">"and $0xfffffffffffffff0, %%"</span> _ASM_SP <span class="string">"\n\t"</span></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">"push $%c[ss]\n\t"</span></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">"push %[sp]\n\t"</span></span></span></span><br><span class="line"><span class="function"><span class="params">#endif</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">"pushf\n\t"</span></span></span></span><br><span class="line">__ASM_SIZE(push) " $%c[cs]\n\t"</span><br><span class="line">CALL_NOSPEC <span class="comment">/*调用真正的中断处理函数*/</span></span><br><span class="line">:</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_X86_64</span></span><br><span class="line">[sp]<span class="string">"=&amp;r"</span>(tmp),</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">ASM_CALL_CONSTRAINT</span><br><span class="line">:</span><br><span class="line">THUNK_TARGET(entry),</span><br><span class="line">[ss]<span class="string">"i"</span>(__KERNEL_DS),</span><br><span class="line">[cs]<span class="string">"i"</span>(__KERNEL_CS)</span><br><span class="line">);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>参考资料:</p><ol><li><a href="https://lore.kernel.org/kvm/1359549372-4764-1-git-send-email-yang.z.zhang@intel.com/" target="_blank" rel="noopener">KVM: VMX: enable acknowledge interupt on vmexit</a></li><li><a href="https://blog.csdn.net/leoufung/article/details/52502192" target="_blank" rel="noopener">关于KVM中处理外部中断的处理代码</a></li><li><a href="https://blog.csdn.net/jemmy858585/article/details/5854437" target="_blank" rel="noopener">kvm对外部中断的处理</a></li><li><a href="/pdf/Interrupt_and_interrupt_virtualization.pdf">Interrupt and Interrupt Virtualization</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍VT-x中的”acknowledge interrupt on exit” feature。
    
    </summary>
    
      <category term="VT-x" scheme="http://liujunming.github.io/categories/VT-x/"/>
    
    
      <category term="VT-x" scheme="http://liujunming.github.io/tags/VT-x/"/>
    
      <category term="中断" scheme="http://liujunming.github.io/tags/%E4%B8%AD%E6%96%AD/"/>
    
      <category term="虚拟化 " scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>lapic timer virtualization</title>
    <link href="http://liujunming.github.io/2022/10/22/lapic-timer-virtualization/"/>
    <id>http://liujunming.github.io/2022/10/22/lapic-timer-virtualization/</id>
    <published>2022-10-22T08:55:24.000Z</published>
    <updated>2022-10-22T11:03:18.142Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍kvm中lapic timer的虚拟化。为了方便，只介绍<a href="/2022/09/05/The-relationship-between-LAPIC-timer-and-TSC/">TSC-deadline模式的lapic timer</a>。<a id="more"></a><br>本文参考的内核版本为<a href="https://elixir.bootlin.com/linux/v5.18/source" target="_blank" rel="noopener">v5.18</a>。</p><blockquote><p>host有自己的lapic timer，硬件实现，guest也有自己的lapic timer，kvm模拟。一个pcup上要运行很多个vcpu，每个vcpu都有自己的lapic timer，kvm要模拟很多个lapic timer，kvm用软件定时器hrtimer来模拟lapic timer，guest写tscdeadline msr，kvm把这个tsc值转换成一个软件定时器的值，启动软件定时器，硬件定时器<strong>驱动</strong>软件定时器，软件定时器超时后，假如硬件timer中断正好把vcpu exiting出来，那么设置timer interrupt pending，重新enter时把timer中断注入，如果vcpu运行在其它pcpu上，需要把vcpu kick出来，所以最好保持timer绑定的物理cpu和vcpu所运行的物理cpu始终一致，如果vcpu运行的物理cpu变化了，migrate timer到新的物理cpu，这样中断来了vcpu自动exit，不再需要kick一次。</p></blockquote><p>hrtimer由physical lapic timer来驱动。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kvm_set_lapic_tscdeadline_msr</span><br><span class="line">└── start_apic_timer</span><br><span class="line">    └── __start_apic_timer</span><br><span class="line">        └── restart_apic_timer</span><br><span class="line">            └── <span class="keyword">if</span> (!start_hv_timer(apic)) start_sw_timer(apic);</span><br></pre></td></tr></table></figure><p>这里的hv_timer就是<a href="/2022/04/01/Introduction-to-VT-x-Preemption-Timer/">preemption timer</a>，sw_timer是软件hrtimer。有preemption timer就用hv_timer，没有就用sw_timer。hv_timer的问题就是可能时间没到，vcpu由于其它原因exit出来，那么就需要kvm_lapic_switch_to_sw_timer，再次enter时kvm_lapic_switch_to_hv_timer。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">start_hv_timer</span><br><span class="line">├── vmx_set_hv_timer[kvm_x86_set_hv_timer]</span><br><span class="line">├── ktimer-&gt;hv_timer_in_use = <span class="literal">true</span>;</span><br><span class="line">└── hrtimer_cancel(&amp;ktimer-&gt;timer);</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start_sw_timer</span><br><span class="line">└── start_sw_tscdeadline</span><br><span class="line">    └── hrtimer_start</span><br></pre></td></tr></table></figure><hr><p>参考资料:</p><ol><li><a href="https://zhuanlan.zhihu.com/p/390345238" target="_blank" rel="noopener">kvm timer虚拟化</a></li><li><a href="https://www.codeleading.com/article/91825014645/" target="_blank" rel="noopener">APIC Timer模拟</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍kvm中lapic timer的虚拟化。为了方便，只介绍&lt;a href=&quot;/2022/09/05/The-relationship-between-LAPIC-timer-and-TSC/&quot;&gt;TSC-deadline模式的lapic timer&lt;/a&gt;。
    
    </summary>
    
      <category term="Time" scheme="http://liujunming.github.io/categories/Time/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="Time" scheme="http://liujunming.github.io/tags/Time/"/>
    
      <category term="中断" scheme="http://liujunming.github.io/tags/%E4%B8%AD%E6%96%AD/"/>
    
  </entry>
  
  <entry>
    <title>每周分享第33期</title>
    <link href="http://liujunming.github.io/2022/10/22/%E6%AF%8F%E5%91%A8%E5%88%86%E4%BA%AB%E7%AC%AC33%E6%9C%9F/"/>
    <id>http://liujunming.github.io/2022/10/22/每周分享第33期/</id>
    <published>2022-10-22T08:01:51.000Z</published>
    <updated>2022-10-22T09:58:14.333Z</updated>
    
    <content type="html"><![CDATA[<h3 id="ASCII-Tree-树形目录图表生成器"><a href="#ASCII-Tree-树形目录图表生成器" class="headerlink" title="ASCII Tree 树形目录图表生成器"></a>ASCII Tree 树形目录图表生成器</h3><p>链接: <a href="https://tree.nathanfriend.io/" target="_blank" rel="noopener">https://tree.nathanfriend.io/</a><br>源码: <a href="https://github.com/nfriend/tree-online" target="_blank" rel="noopener">https://github.com/nfriend/tree-online</a></p><p><img src="/images/2022/10/13.jpg" alt></p><p>以tree的形式输出函数调用图。<br><a id="more"></a> </p><h3 id="intel、amd、arm和power-spec"><a href="#intel、amd、arm和power-spec" class="headerlink" title="intel、amd、arm和power spec"></a>intel、amd、arm和power spec</h3><p><a href="https://kib.kiev.ua/x86docs/" target="_blank" rel="noopener">https://kib.kiev.ua/x86docs/</a></p><h3 id="Linus-Torvalds：Rust-将被合并到-Linux-6-1-主线"><a href="#Linus-Torvalds：Rust-将被合并到-Linux-6-1-主线" class="headerlink" title="Linus Torvalds：Rust 将被合并到 Linux 6.1 主线"></a>Linus Torvalds：Rust 将被合并到 Linux 6.1 主线</h3><p><a href="https://mp.weixin.qq.com/s/yv2qceJZsZyiTXdnnMMAPA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/yv2qceJZsZyiTXdnnMMAPA</a></p><h3 id="soft-lockup和hard-lockup的检测原理"><a href="#soft-lockup和hard-lockup的检测原理" class="headerlink" title="soft lockup和hard lockup的检测原理"></a>soft lockup和hard lockup的检测原理</h3><p><a href="https://mp.weixin.qq.com/s/OwdLj3EdpWCW-lUYnexl1A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/OwdLj3EdpWCW-lUYnexl1A</a></p><p><a href="/pdf/soft lockup和hard lockup的检测原理.pdf">archive pdf</a></p><h3 id="王选院士：我一生中的八个重要抉择"><a href="#王选院士：我一生中的八个重要抉择" class="headerlink" title="王选院士：我一生中的八个重要抉择"></a>王选院士：我一生中的八个重要抉择</h3><p><a href="https://mp.weixin.qq.com/s/mzGku8RZ8yc4z3SecflZXw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/mzGku8RZ8yc4z3SecflZXw</a></p><h3 id="“GPU池化”术语发布"><a href="#“GPU池化”术语发布" class="headerlink" title="“GPU池化”术语发布"></a>“GPU池化”术语发布</h3><p><a href="https://mp.weixin.qq.com/s/6RRhhosfMYk2k72kXnxfNA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/6RRhhosfMYk2k72kXnxfNA</a></p><h3 id="Infrastructure-Programmer-Development-Kit-IPDK"><a href="#Infrastructure-Programmer-Development-Kit-IPDK" class="headerlink" title="Infrastructure Programmer Development Kit (IPDK)"></a>Infrastructure Programmer Development Kit (IPDK)</h3><p><a href="https://ipdk.io/" target="_blank" rel="noopener">https://ipdk.io/</a><br>Infrastructure Programmer Development Kit (IPDK) is an open source, vendor agnostic framework of drivers and APIs for infrastructure offload and management that runs on a CPU, IPU, DPU or switch.</p><h3 id="p50-p90-p99-pct-50-pct-90-pct-99-指什么？"><a href="#p50-p90-p99-pct-50-pct-90-pct-99-指什么？" class="headerlink" title="p50, p90, p99 (pct 50, pct 90, pct 99)指什么？"></a>p50, p90, p99 (pct 50, pct 90, pct 99)指什么？</h3><p><a href="https://blog.csdn.net/Solo95/article/details/119110134" target="_blank" rel="noopener">https://blog.csdn.net/Solo95/article/details/119110134</a></p><h3 id="CPU-IPU：揭秘英特尔数据中心芯片布局"><a href="#CPU-IPU：揭秘英特尔数据中心芯片布局" class="headerlink" title="CPU+IPU：揭秘英特尔数据中心芯片布局"></a>CPU+IPU：揭秘英特尔数据中心芯片布局</h3><p><a href="https://mp.weixin.qq.com/s/a1eU0LWjyjTM-UvMjHF22Q" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/a1eU0LWjyjTM-UvMjHF22Q</a></p><h3 id="使用DSA加速NVMe-TCP-PDU-Digest的CRC32C计算"><a href="#使用DSA加速NVMe-TCP-PDU-Digest的CRC32C计算" class="headerlink" title="使用DSA加速NVMe/TCP PDU Digest的CRC32C计算"></a>使用DSA加速NVMe/TCP PDU Digest的CRC32C计算</h3><p><a href="https://mp.weixin.qq.com/s/2nYlD7MuxVbVNdDTrgSOCw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/2nYlD7MuxVbVNdDTrgSOCw</a><br>Idea:使用DSA卸载SPDK NVMf over TCP的CRC32C计算</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;ASCII-Tree-树形目录图表生成器&quot;&gt;&lt;a href=&quot;#ASCII-Tree-树形目录图表生成器&quot; class=&quot;headerlink&quot; title=&quot;ASCII Tree 树形目录图表生成器&quot;&gt;&lt;/a&gt;ASCII Tree 树形目录图表生成器&lt;/h3&gt;&lt;p&gt;链接: &lt;a href=&quot;https://tree.nathanfriend.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://tree.nathanfriend.io/&lt;/a&gt;&lt;br&gt;源码: &lt;a href=&quot;https://github.com/nfriend/tree-online&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/nfriend/tree-online&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/2022/10/13.jpg&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;以tree的形式输出函数调用图。&lt;br&gt;
    
    </summary>
    
      <category term="经验" scheme="http://liujunming.github.io/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="经验" scheme="http://liujunming.github.io/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>posted interrupt的一些思考</title>
    <link href="http://liujunming.github.io/2022/10/16/posted-interrupt%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"/>
    <id>http://liujunming.github.io/2022/10/16/posted-interrupt的一些思考/</id>
    <published>2022-10-16T10:36:36.000Z</published>
    <updated>2022-10-22T11:21:47.886Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录一些对posted interrupt的思考。<a id="more"></a> </p><p>本文参考的内核版为<a href="https://elixir.bootlin.com/linux/v5.18/source" target="_blank" rel="noopener">v5.18</a></p><h3 id="1-irqfd亦可使用posted-interrupt"><a href="#1-irqfd亦可使用posted-interrupt" class="headerlink" title="1. irqfd亦可使用posted interrupt"></a>1. irqfd亦可使用posted interrupt</h3><p><a href="/2021/10/27/Dive-into-irqfd-KVM-side-mechanism/">irqfd</a>其实也可以使用VT-x posted interrupt来避免interrupt acceptance的一次VM Exit。</p><h4 id="1-1-kvm-arch-set-irq-inatomic"><a href="#1-1-kvm-arch-set-irq-inatomic" class="headerlink" title="1.1 kvm_arch_set_irq_inatomic"></a>1.1 kvm_arch_set_irq_inatomic</h4><blockquote><p>QEMU写了<code>irqfd</code>后，KVM内核模块中的irqfd poll就收到一个<code>POLL_IN</code>事件，然后将MSIx中断自动投递给对应的LAPIC。 大致流程是：<code>POLL_IN</code> -&gt; <code>kvm_arch_set_irq_inatomic</code> -&gt; <code>kvm_set_msi_irq</code>, <code>kvm_irq_delivery_to_apic_fast</code></p></blockquote><p><a href="https://elixir.bootlin.com/linux/v5.18/source/arch/x86/kvm/irq_comm.c#L157" target="_blank" rel="noopener">kvm_arch_set_irq_inatomic</a>最终会调用<a href="https://elixir.bootlin.com/linux/v5.18/source/arch/x86/kvm/lapic.c#L1015" target="_blank" rel="noopener">kvm_irq_delivery_to_apic_fast</a>来给guest注入interrupt。</p><h4 id="1-2-kvm-irq-delivery-to-apic-fast"><a href="#1-2-kvm-irq-delivery-to-apic-fast" class="headerlink" title="1.2 kvm_irq_delivery_to_apic_fast"></a>1.2 kvm_irq_delivery_to_apic_fast</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kvm_irq_delivery_to_apic_fast</span><br><span class="line">└── kvm_apic_set_irq</span><br><span class="line">    └── __apic_accept_irq</span><br><span class="line">        └── vmx_deliver_interrupt</span><br><span class="line">            └── vmx_deliver_posted_interrupt</span><br><span class="line">                └── kvm_vcpu_trigger_posted_interrupt</span><br></pre></td></tr></table></figure><h3 id="2-apic-accept-irq"><a href="#2-apic-accept-irq" class="headerlink" title="2. __apic_accept_irq"></a>2. __apic_accept_irq</h3><p><a href="https://elixir.bootlin.com/linux/v5.18/source/arch/x86/kvm/lapic.c#L1098" target="_blank" rel="noopener">__apic_accept_irq</a>其实就会使用VT-x的posted interrupt完成中断的注入。</p><p><code>KVM_SIGNAL_MSI</code>、<code>KVM_IRQ_LINE</code>等ioctl其实会在KVM中调用<code>__apic_accept_irq</code>函数，因此，最终会使用到posted interrupt来完成虚拟中断的注入。</p><p>根据我的理解(待实验验证)，在VNC中的鼠标键盘操作，其实本质上是给虚拟机注入中断，对于这种中断，也是可以使用posted interrupt的。</p><h3 id="3-在虚拟化下，lapic-timer可以用VT-x-posted-interrupt呢？"><a href="#3-在虚拟化下，lapic-timer可以用VT-x-posted-interrupt呢？" class="headerlink" title="3. 在虚拟化下，lapic timer可以用VT-x posted interrupt呢？"></a>3. 在虚拟化下，lapic timer可以用VT-x posted interrupt呢？</h3><p>在虚拟化场景下，假设vCPU与pCPU一一绑定，那么，lapic timer可以使用VT-x posted interrupt吗？<br>在KVM架构下，答案是否定的，分析如下:<br><img src="/images/2022/10/12.jpg" alt><br>当前是设置了External-interrupt exiting这个位的。当vCPU在non-root mode，此时物理的lapic timer的中断来了，那么就会导致VM Exit，此时使用VT-x posted interrupt已经没有意义了。</p><p><a href="/2022/09/11/LAPIC-Implement-Exitless-Timer/">Injection Exitless LAPIC Timer</a>的Idea是offload lapic timer to housekeeping cpus，然后由housekeeping cpu利用VT-x posted interrupt为vCPU注入中断！</p><p>ps:如果<a href="/2022/10/22/lapic-timer-virtualization/">vCPU的lapic timer</a>由preemption timer进行模拟的话，定时器到期后vCPU会陷出，此时也没有必要用posted interrupt了。</p><h3 id="4-WNV的发送in-VT-d"><a href="#4-WNV的发送in-VT-d" class="headerlink" title="4. WNV的发送in VT-d"></a>4. WNV的发送in VT-d</h3><p><a href="https://elixir.bootlin.com/linux/v5.18/source/arch/x86/kvm/vmx/posted_intr.c#L163" target="_blank" rel="noopener">new.nv = POSTED_INTR_WAKEUP_VECTOR</a></p><p>当vCPU处于ready-to-run或者halted状态时，物理中断来了，此时IOMMU会发送WNV来<a href="https://elixir.bootlin.com/linux/v5.18/source/arch/x86/kvm/vmx/posted_intr.c#L212" target="_blank" rel="noopener">唤醒vCPU</a>。<br>值得注意的是: WNV是IOMMU发送的，而非软件。</p><hr><p>参考资料:</p><ol><li><a href="https://kernelgo.org/virtio-overview.html" target="_blank" rel="noopener">Virtio Spec Overview</a></li><li><a href="https://biscuitos.github.io/blog/Broiler-vInterrupt/" target="_blank" rel="noopener">Broiler Interrupt Virtualization Technology</a></li><li><a href="https://martins3.github.io/qemu/interrupt.html" target="_blank" rel="noopener">QEMU 如何模拟中断</a></li><li><a href="https://www.binss.me/blog/qemu-note-of-interrupt/" target="_blank" rel="noopener">QEMU学习笔记——中断</a></li><li><a href="https://blog.csdn.net/weixin_43780260/article/details/110224589" target="_blank" rel="noopener">QEMU 如何处理PCI设备的中断（二）</a></li><li><a href="https://blog.csdn.net/qihoo_tech/article/details/117137150" target="_blank" rel="noopener">kvm post interrupt</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录一些对posted interrupt的思考。
    
    </summary>
    
      <category term="中断" scheme="http://liujunming.github.io/categories/%E4%B8%AD%E6%96%AD/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="中断" scheme="http://liujunming.github.io/tags/%E4%B8%AD%E6%96%AD/"/>
    
  </entry>
  
  <entry>
    <title>bytedance trace-irqoff tool</title>
    <link href="http://liujunming.github.io/2022/10/15/bytedance-trace-irqoff-tool/"/>
    <id>http://liujunming.github.io/2022/10/15/bytedance-trace-irqoff-tool/</id>
    <published>2022-10-15T11:44:40.000Z</published>
    <updated>2022-10-16T10:56:59.862Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/ByteDanceTech/article/details/105632131" target="_blank" rel="noopener">Trace-irqoff</a><br><a href="https://github.com/bytedance/trace-irqoff/tree/master" target="_blank" rel="noopener">Open Source Repo</a><br><a id="more"></a> </p><p><img src="/images/2022/10/10.jpg" alt></p><p><img src="/images/2022/10/11.jpg" alt></p><p>个人总结: </p><ul><li>对于hardirq的关闭检测，是通过定期的hrtimer来判断的，hrtimer执行的上下文就是hardirq，利用相邻两次hrtimer的时间间隔来评估hardirq的关闭时间</li><li>对于softirq，是利用普通的定时器timer(执行的上下文就是softirq)两次执行的时间间隔来采样两次相邻softirq之间的时间间隔，因此检测的不仅仅是softirq的关闭时间。当第二次的timer执行在ksoftirqd进程时，打印出的堆栈就没有意义了，此时，利用hrtimer(在hardirq上下文中)来记录softirq多长时间没有得到执行</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/ByteDanceTech/article/details/105632131&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Trace-irqoff&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/bytedance/trace-irqoff/tree/master&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Open Source Repo&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="debug" scheme="http://liujunming.github.io/categories/debug/"/>
    
    
      <category term="debug" scheme="http://liujunming.github.io/tags/debug/"/>
    
  </entry>
  
  <entry>
    <title>Notes about linux swapper task</title>
    <link href="http://liujunming.github.io/2022/10/09/Notes-about-linux-swapper-task/"/>
    <id>http://liujunming.github.io/2022/10/09/Notes-about-linux-swapper-task/</id>
    <published>2022-10-09T10:13:02.000Z</published>
    <updated>2022-10-11T13:44:01.051Z</updated>
    
    <content type="html"><![CDATA[<p>Notes about linux swapper task.<a id="more"></a> </p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p>The swapper task is the task running, if no other task is runnable. It has the lowest possible priority, so that’s why it’s running if no other task is runnable.</p><h3 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h3><h4 id="Programmatic-reason"><a href="#Programmatic-reason" class="headerlink" title="Programmatic reason"></a>Programmatic reason</h4><p>This simplifies process scheduling a lot, because you don’t have to care about the special case: “What happens if no task is runnable?”, because there always is at least one task runnable, the idle task. Also you can count the amount of cpu time used per task. Without the idle task, which task gets the cpu-time accounted no one needs?</p><h4 id="Historical-reason"><a href="#Historical-reason" class="headerlink" title="Historical reason"></a>Historical reason</h4><p>Before we had cpus which are able to step-down or go into power saving modes, it had to run on full speed at any time. It ran a series of NOP-instructions, if no tasks were runnable. Today the scheduling of the idle task usually steps down the cpu by using HLT-instructions (halt), so power is saved. So there is a functionality somehow in the idle task in our days.</p><h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><p>How can you believe that swapper (PID 0) even exists? if you can’t see it using <code>ps</code>. I am going to use <code>bpftrace</code> for demonstrating that. In the demo I am going to trace the kernel function <code>hrtimer_wakeup</code> which is responsible for waking up a process and move it to the set of runnable processes. During the trace I am going to print the pid of the calling process and the executable name (the comm field of the task_struct [/include/linux/sched.h]). Here is the command:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo bpftrace -e ‘kfunc:hrtimer_wakeup &#123; printf(“%s:%d\n”,curtask-&gt;comm,curtask-&gt;pid); &#125;’</span><br></pre></td></tr></table></figure><p>From the output we can see we have 3 instances of swapper: swapper/0, swapper/1 and swapper/2 all of them with PID 0. The reason we have three is because my VM has 3 virtual CPUs and there is a swapper process for each one of them — see the output of the command in the image below.</p><p><img src="/images/2022/10/09.jpeg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://stackoverflow.com/questions/464483/why-do-we-need-a-swapper-task-in-linux" target="_blank" rel="noopener">Why do we need a swapper task in linux?</a></li><li><a href="https://programming.vip/docs/deep-understanding-of-swapper-processes-in-perf-reports.html" target="_blank" rel="noopener">Deep understanding of swapper processes in perf reports</a></li><li><a href="https://medium.com/@boutnaru/the-linux-process-journey-pid-0-swapper-7868d1131316" target="_blank" rel="noopener">The Linux Process Journey — PID 0 (swapper)</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Notes about linux swapper task.
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux kernel dump_pagetable function</title>
    <link href="http://liujunming.github.io/2022/10/06/Linux-kernel-dump-pagetable-function/"/>
    <id>http://liujunming.github.io/2022/10/06/Linux-kernel-dump-pagetable-function/</id>
    <published>2022-10-06T12:26:48.000Z</published>
    <updated>2022-10-06T12:58:10.525Z</updated>
    
    <content type="html"><![CDATA[<p>在Linux内核中，可以使用<code>dump_pagetable</code>函数来dump虚拟地址对应的页表信息。</p><p><a href="https://elixir.bootlin.com/linux/v5.19/source/arch/x86/mm/fault.c#L348" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/v5.19/source/arch/x86/mm/fault.c#L348</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在Linux内核中，可以使用&lt;code&gt;dump_pagetable&lt;/code&gt;函数来dump虚拟地址对应的页表信息。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://elixir.bootlin.com/linux/v5.19/source/arch/x86/mm/fa
      
    
    </summary>
    
      <category term="Kernel" scheme="http://liujunming.github.io/categories/Kernel/"/>
    
    
      <category term="Kernel" scheme="http://liujunming.github.io/tags/Kernel/"/>
    
  </entry>
  
  <entry>
    <title>如何获得内核函数地址</title>
    <link href="http://liujunming.github.io/2022/10/06/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%BE%97%E5%86%85%E6%A0%B8%E5%87%BD%E6%95%B0%E5%9C%B0%E5%9D%80/"/>
    <id>http://liujunming.github.io/2022/10/06/如何获得内核函数地址/</id>
    <published>2022-10-06T11:38:23.000Z</published>
    <updated>2022-10-11T13:44:01.052Z</updated>
    
    <content type="html"><![CDATA[<p>本文内容主要转载自<a href="https://blog.csdn.net/gatieme/article/details/78310036" target="_blank" rel="noopener">获得内核函数地址的四种方法</a>。<a id="more"></a> </p><p>本文以获取内核函数<code>vfs_read()</code>的地址为例。</p><h2 id="1-从-System-map-文件中直接得到地址"><a href="#1-从-System-map-文件中直接得到地址" class="headerlink" title="1. 从 System.map 文件中直接得到地址"></a>1. 从 System.map 文件中直接得到地址</h2><p>内核镜像的<code>System.map</code>文件存储了内核符号表的信息, 可以通过此文件获取到具体的信息。</p><p>查看内核函数的地址:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo grep vfs_read /boot/System.map-`uname -r`</span><br></pre></td></tr></table></figure></p><h2 id="2-从-proc-kallsyms-文件获得地址"><a href="#2-从-proc-kallsyms-文件获得地址" class="headerlink" title="2. 从 /proc/kallsyms 文件获得地址"></a>2. 从 /proc/kallsyms 文件获得地址</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/kallsyms | grep vfs_read</span><br></pre></td></tr></table></figure><p><img src="/images/2022/10/08.jpg" alt></p><h2 id="3-使用内核函数接口"><a href="#3-使用内核函数接口" class="headerlink" title="3. 使用内核函数接口"></a>3. 使用内核函数接口</h2><h3 id="3-1-已知内核符号，获取内核符号地址"><a href="#3-1-已知内核符号，获取内核符号地址" class="headerlink" title="3.1 已知内核符号，获取内核符号地址"></a>3.1 已知内核符号，获取内核符号地址</h3><p>使用 <code>kallsyms_lookup_name()</code>。</p><p>该函数在 <code>kernel/kallsyms.c</code> 文件中定义的, 要使用它必须启用 <code>CONFIG_KALLSYMS</code> 编译内核.</p><p><code>kallsyms_lookup_name()</code> 接受一个字符串格式内核函数名, 返回那个内核函数的地址.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kallsyms_lookup_name(<span class="string">"函数名"</span>);</span><br></pre></td></tr></table></figure></p><h3 id="3-2-已知内核符号地址-获取内核符号名"><a href="#3-2-已知内核符号地址-获取内核符号名" class="headerlink" title="3.2 已知内核符号地址, 获取内核符号名"></a>3.2 已知内核符号地址, 获取内核符号名</h3><p>使用 <code>sprint_symbol</code> 内核函数。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/kallsyms.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sprint_symbol</span><span class="params">(<span class="keyword">char</span> *buffer, <span class="keyword">unsigned</span> <span class="keyword">long</span> address)</span></span></span><br></pre></td></tr></table></figure></p><p>该函数根据一个内存中的地址 <code>address</code> 查找一个内核符号, 并将该符号的基本信息, 如符号名 <code>name</code>, 它在内核符号表中的偏移 <code>offset</code> 和大小 <code>size</code>, 所属的模块名(如果有的话)等信息连接成字符串赋值给文本缓冲区 <code>buffer</code>. 其中所查找的内核符号可以是原本就存在于内核中的符号, 也可以是位于动态插入的模块中的符号.</p><hr><p>参考资料:</p><ol><li><a href="https://blog.csdn.net/gatieme/article/details/78310036" target="_blank" rel="noopener">获得内核函数地址的四种方法</a></li><li><a href="https://blog.csdn.net/qq_34258344/article/details/103547971" target="_blank" rel="noopener">如何使用Linux内核中没有被导出的变量或函数</a></li><li><a href="http://kerneltravel.net/blog/2020/syscall_ljr_1/" target="_blank" rel="noopener">LINUX使用内核模块添加系统调用的方法（无需编译内核）</a></li><li><a href="https://developer.aliyun.com/article/53679" target="_blank" rel="noopener">linux内核符号表kallsyms简介</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文内容主要转载自&lt;a href=&quot;https://blog.csdn.net/gatieme/article/details/78310036&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;获得内核函数地址的四种方法&lt;/a&gt;。
    
    </summary>
    
      <category term="Kernel" scheme="http://liujunming.github.io/categories/Kernel/"/>
    
    
      <category term="Kernel" scheme="http://liujunming.github.io/tags/Kernel/"/>
    
  </entry>
  
  <entry>
    <title>Linux watch命令</title>
    <link href="http://liujunming.github.io/2022/10/05/Linux-watch-command/"/>
    <id>http://liujunming.github.io/2022/10/05/Linux-watch-command/</id>
    <published>2022-10-05T13:10:29.000Z</published>
    <updated>2022-10-05T13:59:49.981Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark watch命令相关notes。<a id="more"></a> </p><p>watch命令以周期性的方式执行给定的指令，指令输出以全屏方式显示。watch是一个非常实用的命令，基本所有的Linux发行版都带有这个小工具，如同名字一样，watch可以帮你监测一个命令的运行结果，省得你一遍遍的手动运行。</p><p>下面将介绍下watch命令的一个用例。</p><p>在虚拟化环境下，如何确认TLB shootdown是引起性能下降的因素之一？<br>在 Guest 中执行：<br><code>watch -d -n 1 &quot;cat /proc/interrupts | grep TLB&quot;</code></p><p>如果看到数据上涨比较厉害，那么基本就可以看到问题了。</p><hr><p>参考资料:</p><ol><li><a href="https://man7.org/linux/man-pages/man1/watch.1.html" target="_blank" rel="noopener">man</a></li><li><a href="https://wangchujiang.com/linux-command/c/watch.html" target="_blank" rel="noopener">watch</a></li><li><a href="https://blog.csdn.net/ByteDanceTech/article/details/104765810" target="_blank" rel="noopener">深入理解 Linux 内核–jemalloc 引起的 TLB shootdown 及优化</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark watch命令相关notes。
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux 中 2＞&amp;1 详解</title>
    <link href="http://liujunming.github.io/2022/10/05/Linux-%E4%B8%AD-2%EF%BC%9E-1-%E8%AF%A6%E8%A7%A3/"/>
    <id>http://liujunming.github.io/2022/10/05/Linux-中-2＞-1-详解/</id>
    <published>2022-10-05T08:20:30.000Z</published>
    <updated>2022-10-05T08:37:46.919Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自: <a href="https://blog.csdn.net/icanlove/article/details/38018169" target="_blank" rel="noopener">Linux 中 2＞&amp;1 详解</a><a id="more"></a> </p><h3 id="1和2在Linux中的含义"><a href="#1和2在Linux中的含义" class="headerlink" title="1和2在Linux中的含义"></a>1和2在Linux中的含义</h3><p>在Linux系统中0 1 2是一个文件描述符：<br>标准的输入，输出和错误输出分别表示为STDIN,STDOUT,STDERR，也可以用0，1，2来表示。<br>整理成表格如下：<br><img src="/images/2022/10/06.jpg" alt></p><p>其中0表示键盘输入 1表示屏幕输出 2表示错误输出。</p><h3 id="2-gt-amp-1的含义"><a href="#2-gt-amp-1的含义" class="headerlink" title="2&gt;&amp;1的含义"></a>2&gt;&amp;1的含义</h3><p>2&gt;&amp;1的含义：将标准错误输出重定向到标准输出。<br>注意：符号&gt;&amp;是一个整体，不可分开，分开后就不是上述含义了。</p><p><code>strace -f -p 1510 2&gt;&amp;1 | grep madvise</code></p><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p><img src="/images/2022/10/07.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自: &lt;a href=&quot;https://blog.csdn.net/icanlove/article/details/38018169&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Linux 中 2＞&amp;amp;1 详解&lt;/a&gt;
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Notes about strace</title>
    <link href="http://liujunming.github.io/2022/10/05/Notes-about-strace/"/>
    <id>http://liujunming.github.io/2022/10/05/Notes-about-strace/</id>
    <published>2022-10-05T02:20:51.000Z</published>
    <updated>2022-10-05T08:13:42.572Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录strace相关笔记。<a id="more"></a> </p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>strace is a diagnostic, debugging and instructional userspace utility for Linux. It is used to monitor and tamper with interactions between processes and the Linux kernel, which include system calls, signal deliveries, and changes of process state.</p><p>System administrators, diagnosticians and trouble-shooters will find it invaluable for solving problems with programs for which the source is not readily available since they do not need to be recompiled in order to trace them.</p><p>The operation of strace is made possible by the kernel feature known as <code>ptrace</code>.</p><p><img src="/images/2022/10/05.jpg" alt></p><blockquote><p>strace解决的问题都是关于寻找程序依赖的文件、找出程序卡住或慢的原因、或者找出程序失败的原因。</p></blockquote><h3 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h3><p><a href="https://man7.org/linux/man-pages/man1/strace.1.html" target="_blank" rel="noopener">man strace</a><br><a href="https://nanxiao.github.io/strace-little-book/" target="_blank" rel="noopener">Strace little book</a></p><p><img src="/images/2022/10/04.jpg" alt></p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><ul><li><p>Print stack trace of every system call<br><code>-k</code> option is used to print stack trace of every system call.<br><a href="https://nanxiao.github.io/strace-little-book/posts/print-stack-trace-of-every-system-call.html" target="_blank" rel="noopener">Print stack trace of every system call</a></p></li><li><p><code>-f</code>跟踪目标进程，以及目标进程创建的所有子进程</p></li><li><p><code>-t</code> 在输出中的每一行前加上时间信息(<code>-tt</code> 表示微秒级)</p></li><li><p><code>-T</code> 显示每个系统调用所耗的时间</p></li><li><p><code>-o</code> filename: Write the trace output to the file filename rather than to stderr.</p></li><li><p><code>-c</code> Count time, calls, and errors for each system call and report a summary on program exit, suppressing the regular output. </p></li></ul><h3 id="Case"><a href="#Case" class="headerlink" title="Case"></a>Case</h3><ul><li><a href="https://blog.csdn.net/joeyon1985/article/details/72986412" target="_blank" rel="noopener">手把手教你用Strace诊断问题</a></li><li><a href="https://zhuanlan.zhihu.com/p/180053751" target="_blank" rel="noopener">Linux神器strace的使用方法及实践</a></li><li><a href="https://zhuanlan.zhihu.com/p/362348075" target="_blank" rel="noopener">strace 可以解决什么问题?</a><ul><li>配置文件在哪里？</li><li>这个程序还依赖什么文件？</li><li>为什么这个程序会挂掉？</li><li>这个程序卡住了吗？</li><li>为什么这个程序很慢？</li><li>隐藏的权限错误</li><li>正在使用什么命令行参数？</li><li>为什么这个网络连接失败？</li><li>为什么这个程序以一种方式运行时成功，以另一种方式运行时失败？</li></ul></li></ul><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><ul><li><a href="https://blog.packagecloud.io/how-does-strace-work/" target="_blank" rel="noopener">How does strace work?</a></li></ul><hr><p>参考资料:</p><ol><li><a href="https://www.cnblogs.com/chenxinshuo/p/11986858.html" target="_blank" rel="noopener">Debug 利器：pstack &amp; strace</a></li><li><a href="https://blog.csdn.net/joeyon1985/article/details/72986412" target="_blank" rel="noopener">Linux strace、pstack 命令 使用详解</a></li><li><a href="https://blog.csdn.net/ByteDanceTech/article/details/104765810" target="_blank" rel="noopener">深入理解 Linux 内核–jemalloc 引起的 TLB shootdown 及优化</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录strace相关笔记。
    
    </summary>
    
      <category term="工具" scheme="http://liujunming.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://liujunming.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>每周分享第32期</title>
    <link href="http://liujunming.github.io/2022/10/04/%E6%AF%8F%E5%91%A8%E5%88%86%E4%BA%AB%E7%AC%AC32%E6%9C%9F/"/>
    <id>http://liujunming.github.io/2022/10/04/每周分享第32期/</id>
    <published>2022-10-04T08:25:23.000Z</published>
    <updated>2022-10-04T09:35:39.036Z</updated>
    
    <content type="html"><![CDATA[<h3 id="七千字详解阿里云新一代云计算体系架构-CIPU"><a href="#七千字详解阿里云新一代云计算体系架构-CIPU" class="headerlink" title="七千字详解阿里云新一代云计算体系架构 CIPU"></a>七千字详解阿里云新一代云计算体系架构 CIPU</h3><p><a href="https://mp.weixin.qq.com/s/OX4Iyu_rOekNiP9hUMzGew" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/OX4Iyu_rOekNiP9hUMzGew</a><a id="more"></a> </p><h3 id="Linux-如何测量函数的执行时间"><a href="#Linux-如何测量函数的执行时间" class="headerlink" title="Linux - 如何测量函数的执行时间"></a>Linux - 如何测量函数的执行时间</h3><p><a href="https://zhuanlan.zhihu.com/p/476264071" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/476264071</a></p><ul><li>bpftrace</li><li>bcc-tools</li><li>systemtap</li></ul><h3 id="In-which-conditions-the-ioctl-KVM-RUN-returns"><a href="#In-which-conditions-the-ioctl-KVM-RUN-returns" class="headerlink" title="In which conditions the ioctl KVM_RUN returns?"></a>In which conditions the ioctl KVM_RUN returns?</h3><p><a href="https://stackoverflow.com/questions/65194712/in-which-conditions-the-ioctl-kvm-run-returns" target="_blank" rel="noopener">https://stackoverflow.com/questions/65194712/in-which-conditions-the-ioctl-kvm-run-returns</a><br><img src="/images/2022/10/03.jpg" alt></p><h3 id="陈海波：面向-2030-的操作系统架构与演进思考"><a href="#陈海波：面向-2030-的操作系统架构与演进思考" class="headerlink" title="陈海波：面向 2030 的操作系统架构与演进思考"></a>陈海波：面向 2030 的操作系统架构与演进思考</h3><p><a href="https://mp.weixin.qq.com/s/3k8ro-QahNHsQQXa183VOw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/3k8ro-QahNHsQQXa183VOw</a></p><h3 id="英伟达高管交流纪要"><a href="#英伟达高管交流纪要" class="headerlink" title="英伟达高管交流纪要"></a>英伟达高管交流纪要</h3><p><a href="https://xueqiu.com/6846564531/223664454?sharetime=2" target="_blank" rel="noopener">https://xueqiu.com/6846564531/223664454?sharetime=2</a></p><h3 id="他是世界上最杰出的程序员，一个月写了个操作系统，退休后去做飞行员！"><a href="#他是世界上最杰出的程序员，一个月写了个操作系统，退休后去做飞行员！" class="headerlink" title="他是世界上最杰出的程序员，一个月写了个操作系统，退休后去做飞行员！"></a>他是世界上最杰出的程序员，一个月写了个操作系统，退休后去做飞行员！</h3><p><a href="https://mp.weixin.qq.com/s/fUKv2Nfznf5-uExSh3XTfw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/fUKv2Nfznf5-uExSh3XTfw</a></p><h3 id="80岁还在写代码！Hello-World发明人、UNIX命名者项目登上GitHub热榜"><a href="#80岁还在写代码！Hello-World发明人、UNIX命名者项目登上GitHub热榜" class="headerlink" title="80岁还在写代码！Hello World发明人、UNIX命名者项目登上GitHub热榜"></a>80岁还在写代码！Hello World发明人、UNIX命名者项目登上GitHub热榜</h3><p><a href="https://mp.weixin.qq.com/s/9HA8a7dQ_xhT0cx4rB5FXg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/9HA8a7dQ_xhT0cx4rB5FXg</a></p><h3 id="github-copilot"><a href="#github-copilot" class="headerlink" title="github copilot"></a>github copilot</h3><p>GitHub Copilot（以下简称Copilot）是近期发布的代码智能生成插件，目前支持VSCode、JetBrains等IDE平台，不同于其他代码补全工具只提供最多一行的补全结果，Copilot能通过代码上下文以及语言描述，生成整个代码片段，无疑是开发者的编码利器。<br><a href="https://www.pc-daily.com/jichu/105890.html" target="_blank" rel="noopener">https://www.pc-daily.com/jichu/105890.html</a></p><h3 id="阿里云张伟丰：基于小芯片的计算架构正在演进成为一个大趋势"><a href="#阿里云张伟丰：基于小芯片的计算架构正在演进成为一个大趋势" class="headerlink" title="阿里云张伟丰：基于小芯片的计算架构正在演进成为一个大趋势"></a>阿里云张伟丰：基于小芯片的计算架构正在演进成为一个大趋势</h3><p><a href="https://mp.weixin.qq.com/s/PwZ4c4ezZXxMIpamuBnM0A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/PwZ4c4ezZXxMIpamuBnM0A</a></p><h3 id="deepl"><a href="#deepl" class="headerlink" title="deepl"></a>deepl</h3><p><a href="https://www.deepl.com/translator" target="_blank" rel="noopener">https://www.deepl.com/translator</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;七千字详解阿里云新一代云计算体系架构-CIPU&quot;&gt;&lt;a href=&quot;#七千字详解阿里云新一代云计算体系架构-CIPU&quot; class=&quot;headerlink&quot; title=&quot;七千字详解阿里云新一代云计算体系架构 CIPU&quot;&gt;&lt;/a&gt;七千字详解阿里云新一代云计算体系架构 CIPU&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/OX4Iyu_rOekNiP9hUMzGew&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/OX4Iyu_rOekNiP9hUMzGew&lt;/a&gt;
    
    </summary>
    
      <category term="经验" scheme="http://liujunming.github.io/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="经验" scheme="http://liujunming.github.io/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>perf-tools funcgraph</title>
    <link href="http://liujunming.github.io/2022/10/04/perf-tools-funcgraph/"/>
    <id>http://liujunming.github.io/2022/10/04/perf-tools-funcgraph/</id>
    <published>2022-10-04T05:18:31.000Z</published>
    <updated>2022-10-04T08:17:08.727Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍如何利用perf-tools的funcgraph traces a graph of kernel function calls, showing children and times。既有助于学习内核源码，也有助于debug。<a id="more"></a> </p><h3 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h3><p><a href="https://github.com/brendangregg/perf-tools#prerequisites" target="_blank" rel="noopener">https://github.com/brendangregg/perf-tools#prerequisites</a></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><a href="https://github.com/brendangregg/perf-tools#install" target="_blank" rel="noopener">https://github.com/brendangregg/perf-tools#install</a></p><h3 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h3><p>官方文档:<a href="https://github.com/brendangregg/perf-tools/blob/master/examples/funcgraph_example.txt" target="_blank" rel="noopener">funcgraph_example.txt</a></p><p>文档值得好好研究!</p><p><img src="/images/2022/10/02.jpg" alt></p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><ul><li><a href="https://github.com/brendangregg/perf-tools/blob/master/kernel/funcgraph" target="_blank" rel="noopener">script</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ ./funcgraph </span><br><span class="line">USAGE: funcgraph [-aCDhHPtT] [-m maxdepth] [-p PID] [-L TID] [-d secs] funcstring</span><br><span class="line">                 -a              # all info (same as -HPt)</span><br><span class="line">                 -C              # measure on-CPU time only</span><br><span class="line">                 -d seconds      # trace duration, and use buffers</span><br><span class="line">                 -D              # do not show function duration</span><br><span class="line">                 -h              # this usage message</span><br><span class="line">                 -H              # include column headers</span><br><span class="line">                 -m maxdepth     # max stack depth to show</span><br><span class="line">                 -p PID          # trace when this pid is on-CPU</span><br><span class="line">                 -L TID          # trace when this thread is on-CPU</span><br><span class="line">                 -P              # show process names &amp; PIDs</span><br><span class="line">                 -t              # show timestamps</span><br><span class="line">                 -T              # comment function tails</span><br><span class="line">  eg,</span><br><span class="line">       funcgraph do_nanosleep    # trace do_nanosleep() and children</span><br><span class="line">       funcgraph -m 3 do_sys_open # trace do_sys_open() to 3 levels only</span><br><span class="line">       funcgraph -a do_sys_open    # include timestamps and process name</span><br><span class="line">       funcgraph -p 198 do_sys_open # trace vfs_read() for PID 198 only</span><br><span class="line">       funcgraph -d 1 do_sys_open &gt;out # trace 1 sec, then write to file</span><br><span class="line"></span><br><span class="line">See the man page and example file for more info.</span><br></pre></td></tr></table></figure><hr><p>参考资料:</p><ol><li><a href="https://www.ebpf.top/post/no_space_left_on_devices/" target="_blank" rel="noopener">eBPF+Ftrace 合璧剑指：no space left on device?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍如何利用perf-tools的funcgraph traces a graph of kernel function calls, showing children and times。既有助于学习内核源码，也有助于debug。
    
    </summary>
    
      <category term="工具" scheme="http://liujunming.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://liujunming.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
</feed>
