<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>L</title>
  
  <subtitle>make it simple, make it happen.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://liujunming.github.io/"/>
  <updated>2024-01-27T11:59:26.788Z</updated>
  <id>http://liujunming.github.io/</id>
  
  <author>
    <name>liujunming</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深入理解VMDq(Virtual Machine Device Queue)</title>
    <link href="http://liujunming.github.io/2024/01/27/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3VMDq-Virtual-Machine-Device-Queue/"/>
    <id>http://liujunming.github.io/2024/01/27/深入理解VMDq-Virtual-Machine-Device-Queue/</id>
    <published>2024-01-27T12:31:01.000Z</published>
    <updated>2024-01-27T11:59:26.788Z</updated>
    
    <content type="html"><![CDATA[<p>本文将探究VMDq(Virtual Machine Device Queue)相关内容。<a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将探究VMDq(Virtual Machine Device Queue)相关内容。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Live Migration with SR-IOV Pass-through on KVM Forum 2015</title>
    <link href="http://liujunming.github.io/2024/01/27/Live-Migration-with-SR-IOV-Pass-through-on-KVM-Forum-2015/"/>
    <id>http://liujunming.github.io/2024/01/27/Live-Migration-with-SR-IOV-Pass-through-on-KVM-Forum-2015/</id>
    <published>2024-01-27T12:00:36.000Z</published>
    <updated>2024-01-27T12:22:05.235Z</updated>
    
    <content type="html"><![CDATA[<p>Notes about Live migration with SR-IOV pass-through by Weidong Han on KVM Forum 2015.<a id="more"></a></p><ul><li><a href="https://www.linux-kvm.org/images/9/9a/03x07-Juniper-Weidong_Han-LiveMigrationWithSR-IOVPass-through.pdf" target="_blank" rel="noopener">slides</a></li><li><a href="https://www.youtube.com/watch?v=vnwEnzVp9Zo" target="_blank" rel="noopener">video</a></li></ul><p><img src="/images/2024/01/005.jpg" alt></p><p>iproute2 is a collection of userspace utilities for controlling and monitoring various aspects of networking in the Linux kernel, including routing, network interfaces, tunnels, traffic control, and network-related device drivers.</p><p><img src="/images/2024/01/008.jpg" alt></p><p><img src="/images/2024/01/006.jpg" alt></p><p><img src="/images/2024/01/007.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://www.wikiwand.com/en/Iproute2" target="_blank" rel="noopener">https://www.wikiwand.com/en/Iproute2</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Notes about Live migration with SR-IOV pass-through by Weidong Han on KVM Forum 2015.
    
    </summary>
    
      <category term="live migration" scheme="http://liujunming.github.io/categories/live-migration/"/>
    
    
      <category term="live migration" scheme="http://liujunming.github.io/tags/live-migration/"/>
    
  </entry>
  
  <entry>
    <title>notes:Live migration with pass-through device for Linux VM</title>
    <link href="http://liujunming.github.io/2024/01/21/notes-Live-migration-with-pass-through-device-for-Linux-VM/"/>
    <id>http://liujunming.github.io/2024/01/21/notes-Live-migration-with-pass-through-device-for-Linux-VM/</id>
    <published>2024-01-21T04:29:09.000Z</published>
    <updated>2024-01-21T04:40:21.839Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/liujunming/paper_reading_notes/issues/54" target="_blank" rel="noopener">Live migration with pass-through device for Linux VM</a><a id="more"></a></p><p><img src="/images/2024/01/004.jpg" alt></p><p>通过Linux bounding机制实现，将直通网络设备和PV设备通过bounding机制绑定为一张网卡，做热迁移时切换到PV设备。</p><p><strong>Bonded Interface</strong>用于将多个网络接口聚合成一个逻辑上的”bonded”接口。可用于故障备份或负载均衡等场景。</p><p><img src="/images/2024/01/003.png" alt></p><hr><p>参考资料:</p><ol><li><a href="https://calinyara.github.io/technology/2019/08/22/vnet_interface.html" target="_blank" rel="noopener">虚拟网络设备简介</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/liujunming/paper_reading_notes/issues/54&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Live migration with pass-through device for Linux VM&lt;/a&gt;
    
    </summary>
    
      <category term="live migration" scheme="http://liujunming.github.io/categories/live-migration/"/>
    
    
      <category term="live migration" scheme="http://liujunming.github.io/tags/live-migration/"/>
    
  </entry>
  
  <entry>
    <title>TC Filter Actions</title>
    <link href="http://liujunming.github.io/2024/01/06/TC-Filter-Actions/"/>
    <id>http://liujunming.github.io/2024/01/06/TC-Filter-Actions/</id>
    <published>2024-01-06T13:37:56.000Z</published>
    <updated>2024-01-06T14:37:12.286Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下TC Filter Actions机制的相关notes。<a id="more"></a></p><p>TC框架实现中加入了Filter Actions机制。filter实际作用就是classifier，当数据包匹配到特定的filter之后，可以执行该filter所挂载的actions对数据包进行处理。</p><p>如图:<br><img src="/images/2024/01/002.png" alt></p><p>The tc filter framework provides the infrastructure to another extensible set of tools as well, namely tc actions. As the name suggests, they allow to do things with packets (or associated data). (The list of) Actions are part of a given filter. If it matches, each action it contains is executed in order before returning the classification result.</p><p>在lwn中看到了<a href="https://lwn.net/Articles/879034/" target="_blank" rel="noopener">offload tc action to net device</a>的工作，有机会再细看。</p><hr><p>参考资料:</p><ol><li><a href="https://just4coding.com/2022/08/05/tc/" target="_blank" rel="noopener">Linux流量控制(Traffic Control)介绍</a></li><li><a href="http://linux-ip.net/gl/tc-filters/tc-filters-node2.html" target="_blank" rel="noopener">Filter Actions</a></li><li><a href="https://people.netfilter.org/pablo/netdev0.1/papers/Linux-Traffic-Control-Classifier-Action-Subsystem-Architecture.pdf" target="_blank" rel="noopener">Linux Traffic Control Classifier-Action Subsystem Architecture</a></li><li><a href="https://lwn.net/Articles/879034/" target="_blank" rel="noopener">allow user to offload tc action to net device</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下TC Filter Actions机制的相关notes。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about ifb(Intermediate Functional Block) in TC</title>
    <link href="http://liujunming.github.io/2024/01/06/Notes-about-ifb-Intermediate-Functional-Block-in-TC/"/>
    <id>http://liujunming.github.io/2024/01/06/Notes-about-ifb-Intermediate-Functional-Block-in-TC/</id>
    <published>2024-01-06T07:23:49.000Z</published>
    <updated>2024-01-06T13:33:25.783Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Linux TC的ifb(Intermediate Functional Block)相关notes。<br><a id="more"></a></p><h3 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* drivers/net/ifb.c:</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    The purpose of this driver is to provide a device that allows</span></span><br><span class="line"><span class="comment">    for sharing of resources:</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    1) qdiscs/policies that are per device as opposed to system wide.</span></span><br><span class="line"><span class="comment">    ifb allows for a device which can be redirected to thus providing</span></span><br><span class="line"><span class="comment">    an impression of sharing.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    2) Allows for queueing incoming traffic for shaping instead of</span></span><br><span class="line"><span class="comment">    dropping.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    The original concept is based on what is known as the IMQ</span></span><br><span class="line"><span class="comment">    driver initially written by Martin Devera, later rewritten</span></span><br><span class="line"><span class="comment">    by Patrick McHardy and then maintained by Andre Correa.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    You need the tc action  mirror or redirect to feed this device</span></span><br><span class="line"><span class="comment">    packets.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    Authors:    Jamal Hadi Salim (2005)</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><p>从内核的注释中可知，ifb的motivation是为了解决如下两个问题：</p><ol><li>Qdisc的多网卡共享</li><li>对输入方向的流量做队列调度</li></ol><h3 id="Qdisc的多网卡共享"><a href="#Qdisc的多网卡共享" class="headerlink" title="Qdisc的多网卡共享"></a>Qdisc的多网卡共享</h3><p>在多个网卡之间共享一个根Qdisc是ifb实现的一个初衷。如果你有10块网卡，想在这10块网卡上实现相同的流控策略，你需要配置10遍吗？将相同的东西抽出来，实现一个ifb虚拟网卡，然后将这10块网卡的流量全部重定向到这个ifb虚拟网卡上，此时只需要在这个虚拟网卡上配置一个Qdisc就可以了。</p><h3 id="对输入方向的流量做队列调度"><a href="#对输入方向的流量做队列调度" class="headerlink" title="对输入方向的流量做队列调度"></a>对输入方向的流量做队列调度</h3><p>Linux中的QoS分为入口(Ingress)部分和出口(Egress)部分，入口部分主要用于进行入口流量限速(policing)，出口部分主要用于队列调度(queuing scheduling)。</p><p>大多数排队规则(qdisc)都是用于输出方向的，输入方向只有一个排队规则，即ingress qdisc。ingress qdisc本身的功能很有限，但可用于重定向incoming packets。通过Ingress qdisc把输入方向的数据包重定向到虚拟设备ifb，而ifb的输出方向可以配置多种qdisc，就可以达到对输入方向的流量做队列调度的目的。</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>IFB is an alternative to tc filters for handling ingress traffic, by redirecting it to a virtual interface and treat is as egress traffic there.You need one ifb interface per physical interface, to redirect ingress traffic from eth0 to ifb0, eth1 to ifb1 and so on.</p><p>When inserting the ifb module, tell it the number of virtual interfaces you need. The default is 2:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modprobe ifb numifbs=1</span><br></pre></td></tr></table></figure></p><p>Now, enable all ifb interfaces:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip link set dev ifb0 up # repeat for ifb1, ifb2, ...</span><br></pre></td></tr></table></figure></p><p>And redirect ingress traffic from the physical interfaces to corresponding ifb interface. For eth0 -&gt; ifb0:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tc qdisc add dev eth0 handle ffff: ingress</span><br><span class="line">tc filter add dev eth0 parent ffff: protocol ip u32 match u32 0 0 action mirred egress redirect dev ifb0</span><br></pre></td></tr></table></figure></p><p>Again, repeat for eth1 -&gt; ifb1, eth2 -&gt; ifb2 and so on, until all the interfaces you want to shape are covered.</p><p>Now, you can apply all the rules you want. Egress rules for eth0 go as usual in eth0. Let’s limit bandwidth, for example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tc qdisc add dev eth0 root handle 1: htb default 10</span><br><span class="line">tc class add dev eth0 parent 1: classid 1:1 htb rate 1mbit</span><br><span class="line">tc class add dev eth0 parent 1:1 classid 1:10 htb rate 1mbit</span><br></pre></td></tr></table></figure></p><p>Needless to say, repeat for eth1, eth2, …</p><p>Ingress rules for eth0, now go as egress rules on ifb0 (whatever goes into ifb0 must come out, and only eth0 ingress traffic goes into ifb0). Again, a bandwidth limit example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tc qdisc add dev ifb0 root handle 1: htb default 10</span><br><span class="line">tc class add dev ifb0 parent 1: classid 1:1 htb rate 1mbit</span><br><span class="line">tc class add dev ifb0 parent 1:1 classid 1:10 htb rate 1mbit</span><br></pre></td></tr></table></figure></p><p>The advantage of this approach is that egress rules are much more flexible than ingress filters. Ingress filters only allow you to drop packets, not introduce wait times, for example. By handling ingress traffic as egress you can setup queue disciplines, with traffic classes and, if need be, filters. You get access to the whole tc tree, not only simple filters.</p><hr><p>参考资料:</p><ol><li><a href="https://man7.org/linux/man-pages/man8/tc-mirred.8.html" target="_blank" rel="noopener">man tc-mirred</a></li><li><a href="https://blog.csdn.net/dog250/article/details/40680765" target="_blank" rel="noopener">Linux TC的ifb原理以及ingress流控</a></li><li><a href="http://linux-ip.net/gl/tc-filters/tc-filters-node3.html" target="_blank" rel="noopener">Intermediate Functional Block</a></li><li><a href="https://blog.csdn.net/eydwyz/article/details/53392227" target="_blank" rel="noopener">输入方向的流量控制 –ifb</a></li><li><a href="https://serverfault.com/questions/350023/tc-ingress-policing-and-ifb-mirroring" target="_blank" rel="noopener">Tc: ingress policing and ifb mirroring</a></li><li><a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#ifb" target="_blank" rel="noopener">Introduction to Linux interfaces for virtual networking</a></li><li><a href="https://wiki.linuxfoundation.org/networking/ifb" target="_blank" rel="noopener">Linux Foundation wiki on IFB</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Linux TC的ifb(Intermediate Functional Block)相关notes。&lt;br&gt;
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Basic knowledge of linux Traffic Control(TC)</title>
    <link href="http://liujunming.github.io/2024/01/06/Basic-knowledge-of-linux-Traffic-Control-TC/"/>
    <id>http://liujunming.github.io/2024/01/06/Basic-knowledge-of-linux-Traffic-Control-TC/</id>
    <published>2024-01-06T02:37:26.000Z</published>
    <updated>2024-01-06T07:15:09.115Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Linux Traffic Control(TC)机制的相关notes。<a id="more"></a></p><h2 id="What"><a href="#What" class="headerlink" title="What"></a>What</h2><p>流量控制Traffic Control简称TC，表示网络设备接收和发送数据包的排队机制。比如，数据包的接收速率、发送速率、多个数据包的发送顺序等。</p><p>Linux实现了流量控制子系统，它包括两部分：</p><ul><li>内核部分的traffic control框架</li><li>用户态的规则配置工具：iproute2软件包中的tc程序</li></ul><p>它们有些类似于内核态的netfilter框架和用户态的iptables程序。</p><p>Traffic Control的作用包括以下几种:</p><ul><li>调整(Shaping): 通过推迟数据包发送来控制发送速率，只用于网络出方向(egress)</li><li>时序(Scheduling)：调度不同类型数据包发送顺序，比如在交互流量和批量下载类型数据包之间进行发送顺序的调整。只用于网络出方向(egress)</li><li>监督(Policing): 根据到达速率决策接收还是丢弃数据包，用于网络入方向(ingress)</li><li>丢弃(Dropping): 根据带宽丢弃数据包，可以用于出入两个方向</li></ul><h2 id="Components"><a href="#Components" class="headerlink" title="Components"></a>Components</h2><h3 id="qdisc"><a href="#qdisc" class="headerlink" title="qdisc"></a>qdisc</h3><p>Simply put, a qdisc is a scheduler. Every output interface needs a scheduler of some kind, and the default scheduler is a FIFO. Other qdiscs available under Linux will rearrange the packets entering the scheduler’s queue in accordance with that scheduler’s rules.</p><p>The qdisc is the major building block on which all of Linux traffic control is built, and is also called a <strong>queuing discipline</strong>.</p><p>The classful qdiscs can contain classes, and provide a handle to which to attach filters.</p><p>The classless qdiscs can contain no classes, nor is it possible to attach filter to a classless qdisc.</p><p>要实现对数据包接收和发送的这些控制行为，需要使用队列结构来临时保存数据包。在Linux实现中，把这种包括数据结构和算法实现的控制机制抽象为结构队列规程:Queuing discipline，简称为qdisc。qdisc对外暴露两个回调接口enqueue和dequeue分别用于数据包入队和数据包出队，而具体的排队算法实现则在qdisc内部隐藏。</p><p>A qdisc has two operations:</p><ul><li>enqueue requests so that a packet can be queued up for later transmission</li><li>dequeue requests so that one of the queued-up packets can be chosen for immediate transmission</li></ul><h3 id="class"><a href="#class" class="headerlink" title="class"></a>class</h3><p>Classes only exist inside a classful qdisc (e.g., HTB and CBQ). Classes are immensely flexible and can always contain either multiple children classes or a single child qdisc. </p><p>Any class can also have an arbitrary number of filters attached to it, which allows the selection of a child class or the use of a filter to reclassify or drop traffic entering a particular class.</p><p>A leaf class is a terminal class in a qdisc. It contains a qdisc (default FIFO) and will never contain a child class. Any class which contains a child class is an inner class (or root class) and not a leaf class.</p><h3 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h3><p>A filter is used by a classful qdisc to determine in which class a packet will be enqueued.</p><h2 id="Full-picture"><a href="#Full-picture" class="headerlink" title="Full picture"></a>Full picture</h2><p>基于qdisc, class和filter三种元素可以构建出非常复杂的树形qdisc结构，极大扩展流量控制的能力。</p><p>对于树形结构的qdisc, 当数据包流至最顶层qdisc时，会层层向下递归进行调用。如，父对象(qdisc/class)的enqueue回调接口被调用时，其上所挂载的所有filter依次被调用，直到一个filter匹配成功。然后将数据包入队到filter所指向的class，具体实现则是调用class所配置的Qdisc的enqueue函数。没有成功匹配filter的数据包分类到默认的class中。</p><p>如图:<br><img src="/images/2024/01/001.png" alt></p><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><h3 id="handle"><a href="#handle" class="headerlink" title="handle"></a>handle</h3><p>Every class and classful qdisc requires a unique identifier within the traffic control structure. This unique identifier is known as a handle and has two constituent members, a major number and a minor number. These numbers can be assigned arbitrarily by the user in accordance with the following rules.</p><p><strong>The numbering of handles for classes and qdiscs</strong></p><ul><li><p>major<br>This parameter is completely free of meaning to the kernel. The user may use an arbitrary numbering scheme, however all objects in the traffic control structure with the same parent must share a major handle number. Conventional numbering schemes start at 1 for objects attached directly to the root qdisc.</p></li><li><p>minor<br>This parameter unambiguously identifies the object as a qdisc if minor is 0. Any other value identifies the object as a class. All classes sharing a parent must have unique minor numbers.</p></li></ul><p>The special handle ffff:0 is reserved for the ingress qdisc.</p><p>The handle is used as the target in <strong>classid</strong> and <strong>flowid</strong> phrases of tc filter statements. These handles are external identifiers for the objects, usable by userland applications. The kernel maintains internal identifiers for each object.</p><h3 id="man"><a href="#man" class="headerlink" title="man"></a>man</h3><p>可以查询<a href="https://man7.org/linux/man-pages/man8/tc.8.html" target="_blank" rel="noopener">man tc</a>、<a href="https://man7.org/linux/man-pages/man8/tc-u32.8.html" target="_blank" rel="noopener">man tc-u32</a>、<a href="https://man7.org/linux/man-pages/man8/tc-htb.8.html" target="_blank" rel="noopener">man tc-htb</a>等man手册。</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>As a simple example, in order to limit bandwidth of individual IP addresses stored in <code>CLIENT_IP</code> shell variable, with limitations like the following:</p><ul><li>device name = eth0</li><li>total bandwidth available/allowed for the device = 1000kbps up to 1500kbps</li><li>default bandwidth (for clients that do not fall into our filters) = 1kbps up to 2kbps</li><li>bandwidth of <code>CLIENT_IP</code> = 100kbps</li><li>Maximum bandwidth of <code>CLIENT_IP</code> (if there is more bandwidth available) = 200kbps</li></ul><p>Commands below would suffice:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tc qdisc add dev eth0 root handle 1: htb default 10</span><br><span class="line">tc class add dev eth0 parent 1: classid 1:1 htb rate 1000kbps ceil 1500kbps </span><br><span class="line">tc class add dev eth0 parent 1:1 classid 1:10 htb rate 1kbps ceil 2kbps</span><br><span class="line">tc class add dev eth0 parent 1:1 classid 1:11 htb rate 100kbps ceil 200kbps</span><br><span class="line">tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32 match ip src $&#123;CLIENT_IP&#125; flowid 1:11</span><br></pre></td></tr></table></figure></p><hr><p>参考资料:</p><ol><li><a href="https://man7.org/linux/man-pages/man8/tc.8.html" target="_blank" rel="noopener">man tc</a></li><li><a href="https://serverfault.com/questions/174010/limit-network-bandwith-for-an-ip" target="_blank" rel="noopener">limit network bandwith for an ip</a></li><li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/linux-traffic-control_configuring-and-managing-networking" target="_blank" rel="noopener">Linux traffic control</a></li><li><a href="https://just4coding.com/2022/08/05/tc/" target="_blank" rel="noopener">Linux流量控制(Traffic Control)介绍</a></li><li><a href="https://zhuanlan.zhihu.com/p/627042688" target="_blank" rel="noopener">利用 Linux tc (traffic control) 进行egress, ingress的网络流量管控</a></li><li><a href="https://tldp.org/HOWTO/Traffic-Control-HOWTO/" target="_blank" rel="noopener">Traffic Control HOWTO</a></li><li><a href="https://github.com/tonydeng/sdn-handbook/blob/master/linux/tc.md" target="_blank" rel="noopener">Linux的流量控制文档</a></li><li><a href="http://linux-ip.net/gl/tc-filters/tc-filters.html" target="_blank" rel="noopener">QoS in Linux with TC and Filters</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Linux Traffic Control(TC)机制的相关notes。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about ingress and egress  in network</title>
    <link href="http://liujunming.github.io/2023/12/30/Notes-about-ingress-and-egress-in-network/"/>
    <id>http://liujunming.github.io/2023/12/30/Notes-about-ingress-and-egress-in-network/</id>
    <published>2023-12-30T10:07:02.000Z</published>
    <updated>2023-12-30T10:09:07.056Z</updated>
    
    <content type="html"><![CDATA[<p>The answer from quora:</p><p>Network ingress and egress are terms used in networking to describe the direction of network traffic. In general, ingress refers to network traffic that enters a network or a device, while egress refers to network traffic that exits a network or a device. <a id="more"></a></p><p>For example, when you browse a website, the data packets that are sent from the website’s server to your browser are considered ingress traffic for your device and egress traffic for the server. Conversely, the data packets that are sent from your browser to the website’s server are considered egress traffic for your device and ingress traffic for the server.</p><p><a href="https://www.quora.com/What-are-network-ingress-and-egress" target="_blank" rel="noopener">https://www.quora.com/What-are-network-ingress-and-egress</a></p><p>The answer from chatgpt:</p><p><strong>Network ingress and egress refer to the movement of data into and out of a network</strong>. Ingress: This refers to the <strong>incoming</strong> data traffic that enters a network from an external source, such as the internet or another network. Egress: This refers to the outgoing data traffic that leaves a network to an external destination, such as the internet or another network. In networking, understanding and managing network ingress and egress is important for maintaining the security, performance, and efficiency of a network.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The answer from quora:&lt;/p&gt;
&lt;p&gt;Network ingress and egress are terms used in networking to describe the direction of network traffic. In general, ingress refers to network traffic that enters a network or a device, while egress refers to network traffic that exits a network or a device.
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Standardizing Live Migration with NVM Express</title>
    <link href="http://liujunming.github.io/2023/12/03/Notes-about-Standardizing-Live-Migration-with-NVM-Express/"/>
    <id>http://liujunming.github.io/2023/12/03/Notes-about-Standardizing-Live-Migration-with-NVM-Express/</id>
    <published>2023-12-03T12:06:55.000Z</published>
    <updated>2023-12-03T14:03:01.465Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要是mark下<a href="https://drive.google.com/file/d/1obwZNWd89MPfrZWSsj24ub0N7JHJZ6FU/view?usp=drive_link" target="_blank" rel="noopener">Standardizing Live Migration with NVM Express®</a>相关notes，相关细节可以参考原文。<a id="more"></a></p><p><img src="/images/2023/12/005.jpg" alt></p><p>slides中有如下描述：</p><blockquote><p>Host may use a new mechanism to throttle commands processing by migrating controller to slow down changes</p></blockquote><p>其对应的是:</p><blockquote><p>Support limit the BW and IOPS of a controller to allow slowing down of command processing on a migrating controller</p></blockquote><p>这是QoS的相关实现，考虑写磁盘多的workload，不限速的话，最后一轮的脏LBAs可能会很多，downtime就会有些大了。</p><p>原文考虑了本地盘与非本地盘的NVMe Live Migration。</p><p>对于本地盘的情况，需要记录脏的LBAs，在热迁移每轮迭代中，会传输脏的LBAs(类似于热迁移的脏页传输)。</p><p>对于非本地盘的情况，其实就无效考虑脏的LBAs了。</p><p>对于IPU/DPU的NVMe Live Migration，详情可以参考<a href="https://mp.weixin.qq.com/s/GnN06H864XuXU41-jFH4jA" target="_blank" rel="noopener">NVMe VFIO Live Migration for IPU/DPU Devices</a>。</p><p><img src="/images/2023/12/003.jpg" alt></p><p><img src="/images/2023/12/004.jpg" alt><br>值得注意的是，如果host上的IOMMU支持DMA脏页记录的话，就无需NVMe Device自己去记录DMA脏页了。</p><hr><p>参考资料:</p><ol><li><a href="https://nvmexpress.org/wp-content/uploads/FMS-2023-Host-Controlled-Live-Migration.pdf" target="_blank" rel="noopener">FMS 2023 Host Controlled Live Migration</a></li><li><a href="https://www.bilibili.com/video/BV19N4y1S74F/" target="_blank" rel="noopener">Standardizing Live Migration with NVM Express®</a></li><li><a href="https://www.opencompute.org/events/past-events/2023-ocp-global-summit" target="_blank" rel="noopener">2023 OCP Global Summit</a></li><li><a href="https://mp.weixin.qq.com/s/GnN06H864XuXU41-jFH4jA" target="_blank" rel="noopener">NVMe VFIO Live Migration for IPU/DPU Devices</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要是mark下&lt;a href=&quot;https://drive.google.com/file/d/1obwZNWd89MPfrZWSsj24ub0N7JHJZ6FU/view?usp=drive_link&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Standardizing Live Migration with NVM Express®&lt;/a&gt;相关notes，相关细节可以参考原文。
    
    </summary>
    
      <category term="NVMe" scheme="http://liujunming.github.io/categories/NVMe/"/>
    
    
      <category term="live migration" scheme="http://liujunming.github.io/tags/live-migration/"/>
    
      <category term="存储" scheme="http://liujunming.github.io/tags/%E5%AD%98%E5%82%A8/"/>
    
      <category term="NVMe" scheme="http://liujunming.github.io/tags/NVMe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about NVMe Namespaces</title>
    <link href="http://liujunming.github.io/2023/12/02/Notes-about-NVMe-Namespaces/"/>
    <id>http://liujunming.github.io/2023/12/02/Notes-about-NVMe-Namespaces/</id>
    <published>2023-12-02T12:20:04.000Z</published>
    <updated>2024-01-06T07:24:22.343Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下NVMe Namespaces相关notes。<a id="more"></a></p><ul><li>What is the meaning of nvme0n1 nvme0n2 nvme1n1 nvme1n2 in Linux?<ul><li>nvmeXnY: X means controller, Y means namespace</li></ul></li><li>NVMe controller<ul><li>A PCI Express function that implements the NVM Express interface</li></ul></li><li>NVMe namespace<ul><li>A namespace is a collection of logical block addresses (LBA) accessible to host software. A namespace ID (NSID) is an identifier used by a controller to provide access to a namespace. A namespace is not the physical isolation of blocks, rather the isolation of logical blocks addressable by the host software</li></ul></li><li>A NVM Express controller may support multiple namespaces that are referenced using a namespace ID</li></ul><p><img src="/images/2023/12/001.jpg" alt></p><p>无需理解LUNs。</p><p><img src="/images/2023/12/002.jpg" alt><br>无需理解vSAN。</p><hr><p>参考资料:</p><ol><li><a href="https://www.snia.org/sites/default/files/SDCEMEA/2020/4%20-%20Or%20Lapid%20Micron%20-%20Understanding%20NVMe%20namespaces%20-%20Final.pdf" target="_blank" rel="noopener">NVMe™ Namespaces:Micron Storage Solutions Engineering</a></li><li><a href="https://nvmexpress.org/resource/nvme-namespaces/" target="_blank" rel="noopener">NVMe Namespaces</a></li><li><a href="https://narasimhan-v.github.io/2020/06/12/Managing-NVMe-Namespaces.html" target="_blank" rel="noopener">Managing Nvme Namespaces</a></li><li><a href="https://unix.stackexchange.com/questions/520231/what-are-nvme-namespaces-how-do-they-work" target="_blank" rel="noopener">What are nvme namespaces? How do they work?</a></li><li><a href="https://www.flashmemorysummit.com/English/Collaterals/Proceedings/2013/20130812_PreConfD_Marks.pdf" target="_blank" rel="noopener">An NVM Express Tutorial</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下NVMe Namespaces相关notes。
    
    </summary>
    
      <category term="NVMe" scheme="http://liujunming.github.io/categories/NVMe/"/>
    
    
      <category term="存储" scheme="http://liujunming.github.io/tags/%E5%AD%98%E5%82%A8/"/>
    
      <category term="NVMe" scheme="http://liujunming.github.io/tags/NVMe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about virtio-net configuration changes</title>
    <link href="http://liujunming.github.io/2023/10/28/Notes-about-virtio-net-configuration-changes/"/>
    <id>http://liujunming.github.io/2023/10/28/Notes-about-virtio-net-configuration-changes/</id>
    <published>2023-10-28T07:15:59.000Z</published>
    <updated>2023-10-28T08:26:01.702Z</updated>
    
    <content type="html"><![CDATA[<p>参考<a href="https://docs.oasis-open.org/virtio/virtio/v1.2/csd01/virtio-v1.2-csd01.html#x1-2230004" target="_blank" rel="noopener">virtio 1.2 spec</a>，Linux kernel version <a href="https://elixir.bootlin.com/linux/v6.0/source" target="_blank" rel="noopener">v6.0</a>。<a id="more"></a></p><ul><li><em>speed</em> contains the device speed, in units of 1 MBit per second, 0 to 0x7fffffff, or 0xffffffff for unknown speed.</li><li><em>duplex</em> has the values of 0x01 for full duplex, 0x00 for half duplex and 0xff for unknown duplex state.</li></ul><p>Both <em>speed</em> and <em>duplex</em> can change, thus the driver is expected to re-read these values after receiving a configuration change notification.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_net_config</span> &#123;</span> </span><br><span class="line">        u8 mac[<span class="number">6</span>]; </span><br><span class="line">        le16 status; </span><br><span class="line">        le16 max_virtqueue_pairs; </span><br><span class="line">        le16 mtu; </span><br><span class="line">        le32 speed; </span><br><span class="line">        u8 duplex; </span><br><span class="line">        u8 rss_max_key_size; </span><br><span class="line">        le16 rss_max_indirection_table_length; </span><br><span class="line">        le32 supported_hash_types; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>Linux kernel source code:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtnet_config_changed_work</span><span class="params">(struct work_struct *work)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">virtnet_info</span> *<span class="title">vi</span> =</span></span><br><span class="line"><span class="class">        <span class="title">container_of</span>(<span class="title">work</span>, <span class="title">struct</span> <span class="title">virtnet_info</span>, <span class="title">config_work</span>);</span></span><br><span class="line">    u16 v;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (virtio_cread_feature(vi-&gt;vdev, VIRTIO_NET_F_STATUS,</span><br><span class="line">                 struct virtio_net_config, status, &amp;v) &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (v &amp; VIRTIO_NET_S_ANNOUNCE) &#123;</span><br><span class="line">        netdev_notify_peers(vi-&gt;dev);</span><br><span class="line">        virtnet_ack_link_announce(vi);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Ignore unknown (future) status bits */</span></span><br><span class="line">    v &amp;= VIRTIO_NET_S_LINK_UP;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (vi-&gt;status == v)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    vi-&gt;status = v;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (vi-&gt;status &amp; VIRTIO_NET_S_LINK_UP) &#123;</span><br><span class="line">        virtnet_update_settings(vi);</span><br><span class="line">        netif_carrier_on(vi-&gt;dev);</span><br><span class="line">        netif_tx_wake_all_queues(vi-&gt;dev);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        netif_carrier_off(vi-&gt;dev);</span><br><span class="line">        netif_tx_stop_all_queues(vi-&gt;dev);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtnet_update_settings</span><span class="params">(struct virtnet_info *vi)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    u32 speed;</span><br><span class="line">    u8 duplex;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!virtio_has_feature(vi-&gt;vdev, VIRTIO_NET_F_SPEED_DUPLEX))</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    virtio_cread_le(vi-&gt;vdev, struct virtio_net_config, speed, &amp;speed);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ethtool_validate_speed(speed))</span><br><span class="line">        vi-&gt;speed = speed;</span><br><span class="line"></span><br><span class="line">    virtio_cread_le(vi-&gt;vdev, struct virtio_net_config, duplex, &amp;duplex);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ethtool_validate_duplex(duplex))</span><br><span class="line">        vi-&gt;duplex = duplex;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考&lt;a href=&quot;https://docs.oasis-open.org/virtio/virtio/v1.2/csd01/virtio-v1.2-csd01.html#x1-2230004&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;virtio 1.2 spec&lt;/a&gt;，Linux kernel version &lt;a href=&quot;https://elixir.bootlin.com/linux/v6.0/source&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;v6.0&lt;/a&gt;。
    
    </summary>
    
      <category term="virtio" scheme="http://liujunming.github.io/categories/virtio/"/>
    
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about XDP</title>
    <link href="http://liujunming.github.io/2023/10/22/Notes-about-XDP/"/>
    <id>http://liujunming.github.io/2023/10/22/Notes-about-XDP/</id>
    <published>2023-10-22T06:14:58.000Z</published>
    <updated>2023-10-22T11:12:06.844Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下eXpress Data Path (XDP)相关notes。<a id="more"></a></p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p>XDP其实是位于网卡驱动程序里的一个快速处理数据包的HOOK点，为什么快？因为数据包处理位置非常底层，避开了很多内核skb处理开销。</p><p>XDP暴露了一个可以加载BPF程序的网络钩子。在这个钩子中，程序能够对传入的数据包进行任意修改和快速决策，避免了内核内部处理带来的额外开销。这使得XDP在性能速度方面成为最佳钩子，例如缓解DDoS攻击等。 </p><h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p><img src="/images/2023/11/016.jpg" alt></p><p><img src="/images/2023/11/015.jpg" alt></p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><img src="/images/2023/11/014.jpg" alt></p><p><img src="/images/2023/11/017.jpg" alt></p><h3 id="Introduction-to-eBPF-and-XDP"><a href="#Introduction-to-eBPF-and-XDP" class="headerlink" title="Introduction to eBPF and XDP"></a>Introduction to eBPF and XDP</h3><ul><li><a href="https://www.bilibili.com/video/BV1qq4y1r7uB/" target="_blank" rel="noopener">B站视频</a></li><li><a href="https://www.slideshare.net/lcplcp1/introduction-to-ebpf-and-xdp" target="_blank" rel="noopener">slides</a></li></ul><p>建议阅读上述资料，会对XDP有不错的认识。</p><p><img src="/images/2023/11/005.jpg" alt></p><p>以DDoS为例:</p><p><img src="/images/2023/11/006.jpg" alt></p><p><img src="/images/2023/11/007.jpg" alt></p><p><img src="/images/2023/11/008.jpg" alt></p><p><img src="/images/2023/11/009.jpg" alt></p><p>The XDP program is executed at the earliest possible moment after a packet is received from the hardware, before the kernel allocates its per-packet <code>sk_buff</code> data structure.</p><p><img src="/images/2023/11/010.jpg" alt></p><p><img src="/images/2023/11/011.jpg" alt></p><p>代码层的理解:<br><img src="/images/2023/11/001.jpg" alt></p><p><img src="/images/2023/11/002.jpg" alt></p><p><img src="/images/2023/11/003.jpg" alt></p><p><img src="/images/2023/11/004.jpg" alt></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/images/2023/11/012.jpg" alt></p><h3 id="Execution-flow-of-a-typical-XDP-program"><a href="#Execution-flow-of-a-typical-XDP-program" class="headerlink" title="Execution flow of a typical XDP program"></a>Execution flow of a typical XDP program</h3><p><img src="/images/2023/11/013.jpg" alt></p><p>详情参考<a href="https://github.com/tohojo/xdp-paper/blob/master/xdp-the-express-data-path.pdf" target="_blank" rel="noopener">xdp paper</a>3.1 The XDP Driver Hook。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>建议阅读<a href="http://arthurchiao.art/blog/xdp-paper-acm-2018-zh/" target="_blank" rel="noopener">[译] [论文] XDP (eXpress Data Path)：在操作系统内核中实现快速、可编程包处理（ACM，2018）</a>。</p><p>某种意义上来说，XDP 可以认为是一种 offload 方式：</p><ol><li>性能敏感的处理逻辑下放到网卡驱动中，以提升性能；</li><li>其他的处理逻辑仍然走内核网络栈；</li><li>如果没有用到内核 helper 函数，那整个 XDP 程序都可以 offload 到网卡（目前 Netronome smart-NICs已经支持）。</li></ol><hr><p>参考资料:</p><ol><li><a href="https://github.com/tohojo/xdp-paper/blob/master/xdp-the-express-data-path.pdf" target="_blank" rel="noopener">xdp paper</a></li><li><a href="https://github.com/tohojo/xdp-paper/blob/master/xdp-presentation.pdf" target="_blank" rel="noopener">xdp slides</a></li><li><a href="http://arthurchiao.art/blog/xdp-paper-acm-2018-zh/" target="_blank" rel="noopener">[译] [论文] XDP (eXpress Data Path)：在操作系统内核中实现快速、可编程包处理（ACM，2018）</a></li><li><a href="https://mp.weixin.qq.com/s/BqXhOlRisvNXETRj-TehUQ" target="_blank" rel="noopener">初识XDP</a></li><li><a href="https://mp.weixin.qq.com/s/qlgdIAGGv7yQXFGlGA5I8Q" target="_blank" rel="noopener">实现一个基于XDP_eBPF的学习型网桥</a></li><li><a href="https://www.youtube.com/watch?v=arq5XzodNmY" target="_blank" rel="noopener">Introduction to eBPF and XDP</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下eXpress Data Path (XDP)相关notes。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>PCI Express Max Read Request, Max Payload Size and why you care</title>
    <link href="http://liujunming.github.io/2023/10/06/PCI-Express-Max-Read-Request-Max-Payload-Size-and-why-you-care/"/>
    <id>http://liujunming.github.io/2023/10/06/PCI-Express-Max-Read-Request-Max-Payload-Size-and-why-you-care/</id>
    <published>2023-10-05T22:16:38.000Z</published>
    <updated>2023-10-06T08:26:40.127Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自:<a href="https://codywu2010.wordpress.com/2015/11/26/pci-express-max-read-request-max-payload-size-and-why-you-care/" target="_blank" rel="noopener">PCI Express Max Read Request, Max Payload Size and why you care</a><a id="more"></a></p><p>Modern high performance server is nearly all based on PCIE architecture and technologies derived from it such as Direct Media Interface (DMI) or Quick Path Interconnect (QPI).</p><p>For example below is a sample block diagram for a dual processor system:</p><p><img src="/images/2023/10/020.png" alt></p><p>A PCI Express system consists of many components, most important of which to us are:</p><ul><li>CPU</li><li>Root Complex (Root Port)</li><li>PCIE Switch</li><li>End Point</li></ul><p>Root Complex acts as the agent which helps with:</p><ul><li>Receive CPU request to initiate Memory/IO read/write towards end point</li><li>Receive End Point read/write request and either pass it to another end point or access system memory on their behalf</li></ul><p>The End point is usually of most interest to us because that’s where we put our high performance device.</p><p>It is GPU in the sample block diagram while in real time it can be a high speed Ethernet card or data collecting/processing card, or an infiniband card talking to some storage device in a large data center.</p><p>Below is a refined block diagram that amplify the interconnection of those components:</p><p><img src="/images/2023/10/021.png" alt></p><p>Based on this topology let’s talk about a typical scenario where Remote Direct Memory Access (RDMA) is used to allow a end point PCIE device to write directly to a pre-allocated system memory whenever data arrives, which offload to the maximum any involvements of CPU.</p><p>So the device will initiate a write request with data and send it along hoping root complex will help it get the data into system memory.</p><p>PCIE, different from traditional PCI or PCI-X, bases its communication traffic on the concepts of packets flying over point-to-point serial link, which is sometimes why people mention PCIE as a sort of tiny network topology.</p><p>So the RDMA device, acting as requester, sends its request package bearing the data along the link towards root complex.</p><p>The packet will arrive at intermediary PCIE switch and forward to root complex and root complex will diligently move data in the payload to system memory through its private memory controller.</p><p>Of course we would expect some overhead besides pure data payload and here goes the packet structure of PICE gen3:</p><p><img src="/images/2023/10/022.png" alt></p><p>So obviously given those additional “tax” you have to pay you would hope that you can put as large a payload as you can which would hopefully increase the effective utilization ratio.</p><p>However it does not always work and here comes to our discussion about <strong>“max payload size”</strong>.</p><p>Each device has a <strong>“max payload size supported”</strong> in its dev cap config register part indicating its capability and a “max payload size” in its dev control register part which will be programmed with actual <strong>“max playload set”</strong> it can use.</p><p>Below shows the related registers extracted from pcie base spec:</p><p><img src="/images/2023/10/018.jpg" alt></p><p><img src="/images/2023/10/019.jpg" alt></p><p>So how do we decide on what value to set within the range not above max payload supported?</p><p>The idea is it has to be equal to the minimum max payload supported along the route.</p><p>So for our data write request it would have to consider end point’s max payload supported as well as pcie switch (which is abstracted as pcie device while we do enumeration) and root complex’s root port (which is also abstracted as a device).</p><p>PCIE base spec actually described it this way without giving detailed implementation:</p><p><img src="/images/2023/10/023.png" alt></p><p>Now let’s take a look at how linux does it.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">pcie_write_mps</span><span class="params">(struct pci_dev *dev, <span class="keyword">int</span> mps)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rc;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (pcie_bus_config == PCIE_BUS_PERFORMANCE) &#123;</span><br><span class="line">        mps = <span class="number">128</span> &lt;&lt; dev-&gt;pcie_mpss;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (pci_pcie_type(dev) != PCI_EXP_TYPE_ROOT_PORT &amp;&amp;</span><br><span class="line">            dev-&gt;bus-&gt;self)</span><br><span class="line"></span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * For "Performance", the assumption is made that</span></span><br><span class="line"><span class="comment">             * downstream communication will never be larger than</span></span><br><span class="line"><span class="comment">             * the MRRS.  So, the MPS only needs to be configured</span></span><br><span class="line"><span class="comment">             * for the upstream communication.  This being the case,</span></span><br><span class="line"><span class="comment">             * walk from the top down and set the MPS of the child</span></span><br><span class="line"><span class="comment">             * to that of the parent bus.</span></span><br><span class="line"><span class="comment">             *</span></span><br><span class="line"><span class="comment">             * Configure the device MPS with the smaller of the</span></span><br><span class="line"><span class="comment">             * device MPSS or the bridge MPS (which is assumed to be</span></span><br><span class="line"><span class="comment">             * properly configured at this point to the largest</span></span><br><span class="line"><span class="comment">             * allowable MPS based on its parent bus).</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            mps = min(mps, pcie_get_mps(dev-&gt;bus-&gt;self));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    rc = pcie_set_mps(dev, mps);</span><br><span class="line">    <span class="keyword">if</span> (rc)</span><br><span class="line">        pci_err(dev, <span class="string">"Failed attempting to set the MPS\n"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>So linux follows the same idea and take the minimum of upstream device capability and downstream pci device.</p><p>The only exception is for root port which is supposed to be the top of PCI hierarchy so we can simply set by its max supported.</p><p><code>pcie_set_mps</code> does real setting of the config register and it can be seen that it is taking the min.</p><p>Now we have finished talking about <strong>max payload size</strong>, let’s turn our attention to <strong>max read request size</strong>.</p><p>It does not apply to memory write request but it applies to memory read request by that you cannot request more than that size in a single memory request.</p><p>We can imagine a slightly different use case where some application prepares a block of data to be processed by the end point device and then we notifying the device of the memory address of size and ask the device to take over.</p><p>The device will have to initiate a series of memory read request to fetch the data and process in place on the card and put the result int some preset location.</p><p>So even though packet payload can go at max to 4096 bytes the device will have to work in trickle like way if we program its max read request to be a very small value.</p><p>Here is the explanation from PCIE base spec on max read request:</p><p><img src="/images/2023/10/024.png" alt></p><p><img src="/images/2023/10/025.png" alt></p><p>So again let’s say how linux programs <strong>max read request size</strong>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">pcie_write_mrrs</span><span class="params">(struct pci_dev *dev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rc, mrrs;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * In the "safe" case, do not configure the MRRS.  There appear to be</span></span><br><span class="line"><span class="comment">     * issues with setting MRRS to 0 on a number of devices.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (pcie_bus_config != PCIE_BUS_PERFORMANCE)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * For max performance, the MRRS must be set to the largest supported</span></span><br><span class="line"><span class="comment">     * value.  However, it cannot be configured larger than the MPS the</span></span><br><span class="line"><span class="comment">     * device or the bus can support.  This should already be properly</span></span><br><span class="line"><span class="comment">     * configured by a prior call to pcie_write_mps().</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    mrrs = pcie_get_mps(dev);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * MRRS is a R/W register.  Invalid values can be written, but a</span></span><br><span class="line"><span class="comment">     * subsequent read will verify if the value is acceptable or not.</span></span><br><span class="line"><span class="comment">     * If the MRRS value provided is not acceptable (e.g., too large),</span></span><br><span class="line"><span class="comment">     * shrink the value until it is acceptable to the HW.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">while</span> (mrrs != pcie_get_readrq(dev) &amp;&amp; mrrs &gt;= <span class="number">128</span>) &#123;</span><br><span class="line">        rc = pcie_set_readrq(dev, mrrs);</span><br><span class="line">        <span class="keyword">if</span> (!rc)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">        pci_warn(dev, <span class="string">"Failed attempting to set the MRRS\n"</span>);</span><br><span class="line">        mrrs /= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (mrrs &lt; <span class="number">128</span>)</span><br><span class="line">        pci_err(dev, <span class="string">"MRRS was unable to be configured with a safe value.  If problems are experienced, try running with pci=pcie_bus_safe\n"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>pcie_set_readrq</code> does the real setting and surprisingly it uses <strong>max payload size</strong> as the ceiling even though it has not relationship with that.</p><p>We can well send a large read request but when data is returned from root complex it will be split into many small packets each with payload size less or equal to max payload size.</p><p>So above code is mainly executed in PCI bus enumeration phase.</p><p>And if we grep with this function name <code>pcie_set_readrq</code> we can see other device drivers provide overrides probably to increase the read request efficiency.</p><p>So how big an impact the two settings has on your specific device?</p><p>It’s hard to tell though you can easily find on the internet discussions talking about it.</p><p>Here is a good one <a href="http://www.xilinx.com/support/documentation/white_papers/wp350.pdf" target="_blank" rel="noopener">Understanding Performance of PCI Express Systems</a>.</p><p>And here is another good one <a href="https://billauer.co.il/blog/2011/05/pcie-pci-express-linux-max-payload-size-configuration-capabilities-tlp-lspci/" target="_blank" rel="noopener">PCI Express Max Payload size and its impact on Bandwidth</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自:&lt;a href=&quot;https://codywu2010.wordpress.com/2015/11/26/pci-express-max-read-request-max-payload-size-and-why-you-care/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PCI Express Max Read Request, Max Payload Size and why you care&lt;/a&gt;
    
    </summary>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/categories/PCI-PCIe/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about virtio-net failover</title>
    <link href="http://liujunming.github.io/2023/10/05/Notes-about-virtio-net-failover/"/>
    <id>http://liujunming.github.io/2023/10/05/Notes-about-virtio-net-failover/</id>
    <published>2023-10-05T07:03:24.000Z</published>
    <updated>2023-10-07T13:29:26.784Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要是mark下<a href="https://www.redhat.com/en/blog/virtio-net-failover-introduction" target="_blank" rel="noopener">Virtio-net failover: An introduction</a>相关notes。<a id="more"></a></p><p>Virtio-net failover is a virtualization technology that allows a virtual machine (VM) to switch from a Virtual Function I/O (VFIO) device to a virtio-net device when the VM needs to be migrated from a host to another.</p><p>On one hand, the Single Root I/O Virtualization (SR-IOV) technology allows a device like a networking card to be split into several devices (the Virtual Functions) and with the help of the VFIO technology, the kernel of the VM can directly drive these devices. This is interesting in terms of performance, because it can reach the same level as a bare metal system. In this case, the cost of the performance is that a VFIO device cannot be migrated.</p><p>On the other hand, virtio-net is a paravirtualized networking device that has good performance and can be migrated. The trade off is that performance is not as good as with VFIO devices.</p><p>Virtio-net failover tries to bring the best of both worlds: performance of a VFIO device with the migration capability of a virtio-net device.</p><h3 id="Principles"><a href="#Principles" class="headerlink" title="Principles"></a>Principles</h3><p>Virtio-net failover relies on a several blocks of technology to migrate a VM using a VFIO device:</p><ul><li>Live migration, to move the VM from one host to another</li><li>Virtio-net, to keep network connection while the migration is in progress</li><li>VFIO, to use a host hardware device</li><li>Failover, to switch from a networking device to another in a transparent way</li></ul><h3 id="Failover"><a href="#Failover" class="headerlink" title="Failover"></a>Failover</h3><p>Failover is a term that comes from the high availability (HA) domain in an attempt to provide reliability, availability and serviceability (RAS) to a system.</p><p>The principle of failover is to bind two devices together, so called the primary and the standby, in a redundant way. The system only uses the primary device, but if the primary device becomes unavailable, unusable or disconnected, the failover manager can detect the problem and disable the primary device to switch to the standby device. </p><p>The standby is used to maintain service availability. While the standby is in use, an operator can remove the dysfunctional device and replace it with a healthy one. Once the problem is corrected, the new device can be used as the new standby device while the old standby device becomes the new primary device. Alternately, the newly replaced device could be restored as the primary device and the other switched back to standby.</p><h3 id="Virtio-net-failover-operation"><a href="#Virtio-net-failover-operation" class="headerlink" title="Virtio-net failover operation"></a>Virtio-net failover operation</h3><p>Virtio-net failover plays with the failover principle to bind two devices together, but in this case, the VFIO device is chosen with caution to be the primary device and used during the regular state of operation of the system. When a migration occurs, the hypervisor triggers a primary device fault (by unplugging it), that will force the failover manager (in our case the guest kernel failover_net driver) to disable the primary device and use the standby device, the virtio-net device, that is able to survive to a VM live migration. </p><p>The hypervisor also takes the role of the operator by restoring the disabled device on the migration destination side by hotplugging a new VFIO device. In this case, failover_net driver is configured to restore the VFIO device as the primary and to keep the virtio-net as the standby as the devices are not identical.</p><p><img src="/images/2023/10/016.png" alt></p><p>To implement virtio-net failover, we need support at guest kernel level and at hypervisor level:</p><ul><li>The hypervisor detects when a migration is started and unplugs the VFIO device as it cannot be migrated, at the same time it will block the migration while the VFIO card is being unplugged.</li><li>Guest kernel needs the ability to switch transparently between  the VFIO device and the virtio-net device.</li><li>On normal operation, VFIO is used for its performance, but when the hypervisor asks to unplug the card, the kernel unplugs it and switches the networking traffic from the VFIO device to the virtio-net device.</li><li>While the migration is processed, the VM is not stopped and all the networking traffic that usually crosses the VFIO device is redirected to the virtio-net device. There is no service interruption,</li><li>At the end of the migration, on the destination side, the hypervisor plugs in a VFIO device, and the traffic switches back from the virtio-net device to the VFIO device.</li></ul><p><img src="/images/2023/10/017.png" alt></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Virtio-net failover allows a VM hypervisor to migrate a VM with a VFIO device without interrupting the network connection. To reach this goal we need collaboration between the hypervisor and the guest kernel — the hypervisor unplugs the card and the guest kernel switches the network connection to the virtio-net device, and then they restore the original state on the destination host.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要是mark下&lt;a href=&quot;https://www.redhat.com/en/blog/virtio-net-failover-introduction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Virtio-net failover: An introduction&lt;/a&gt;相关notes。
    
    </summary>
    
      <category term="live migration" scheme="http://liujunming.github.io/categories/live-migration/"/>
    
    
      <category term="live migration" scheme="http://liujunming.github.io/tags/live-migration/"/>
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
      <category term="VFIO" scheme="http://liujunming.github.io/tags/VFIO/"/>
    
  </entry>
  
  <entry>
    <title>基于E810网卡的VF热迁移</title>
    <link href="http://liujunming.github.io/2023/10/05/%E5%9F%BA%E4%BA%8EE810%E7%BD%91%E5%8D%A1%E7%9A%84VF%E7%83%AD%E8%BF%81%E7%A7%BB/"/>
    <id>http://liujunming.github.io/2023/10/05/基于E810网卡的VF热迁移/</id>
    <published>2023-10-05T06:34:15.000Z</published>
    <updated>2023-10-05T06:51:02.097Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自: <a href="https://mp.weixin.qq.com/s/GRxfeN7Vlr_NM2_kRw_5uQ" target="_blank" rel="noopener">基于E810网卡的VF热迁移–依托第四代Xeon可扩展处理器的加速案例</a><a id="more"></a></p><p>Intel E810网卡对VF透传设备的热迁移支持，使高性能数据面和灵活的运维得以兼顾，并且热迁移依托第四代志强可扩展处理器可以得到显著加速。</p><p><img src="/images/2023/10/001.png" alt></p><p><img src="/images/2023/10/002.png" alt></p><p><img src="/images/2023/10/003.png" alt></p><p><img src="/images/2023/10/004.png" alt></p><p><img src="/images/2023/10/005.png" alt></p><p><img src="/images/2023/10/006.png" alt></p><p><img src="/images/2023/10/007.png" alt></p><p><img src="/images/2023/10/008.png" alt></p><p>从slides里可以看出，对于Device State，改动的是e810 driver中增加的live migration支持(e810网卡协议本身支持live migration)，然后VFIO framework去调用e810 driver提供的接口，即可获取到Device State。</p><p><img src="/images/2023/10/009.png" alt></p><p><img src="/images/2023/10/010.png" alt></p><p><img src="/images/2023/10/011.png" alt></p><p><img src="/images/2023/10/012.png" alt></p><p><img src="/images/2023/10/013.png" alt></p><p><img src="/images/2023/10/014.png" alt></p><p><img src="/images/2023/10/015.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自: &lt;a href=&quot;https://mp.weixin.qq.com/s/GRxfeN7Vlr_NM2_kRw_5uQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;基于E810网卡的VF热迁移–依托第四代Xeon可扩展处理器的加速案例&lt;/a&gt;
    
    </summary>
    
      <category term="live migration" scheme="http://liujunming.github.io/categories/live-migration/"/>
    
    
      <category term="live migration" scheme="http://liujunming.github.io/tags/live-migration/"/>
    
      <category term="VFIO" scheme="http://liujunming.github.io/tags/VFIO/"/>
    
  </entry>
  
  <entry>
    <title>AMD虚拟化支持TLBi</title>
    <link href="http://liujunming.github.io/2023/09/24/AMD%E8%99%9A%E6%8B%9F%E5%8C%96%E6%94%AF%E6%8C%81TLBi/"/>
    <id>http://liujunming.github.io/2023/09/24/AMD虚拟化支持TLBi/</id>
    <published>2023-09-24T05:40:24.000Z</published>
    <updated>2023-09-24T06:48:01.927Z</updated>
    
    <content type="html"><![CDATA[<p>本文转自<a href="https://github.com/ChinaLinuxKernel/CLK/blob/master/CLK2021/3-1%20AMD%E6%9E%B6%E6%9E%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5.pdf" target="_blank" rel="noopener">CLK2021 AMD架构虚拟机性能探索与实践</a>。<a id="more"></a></p><p><img src="/images/2023/09/001.jpg" alt></p><p><img src="/images/2023/09/002.jpg" alt></p><p><img src="/images/2023/09/003.jpg" alt></p><p><img src="/images/2023/09/004.jpg" alt></p><p><img src="/images/2023/09/005.jpg" alt></p><p><img src="/images/2023/09/006.jpg" alt></p><p><img src="/images/2023/09/007.jpg" alt></p><p><img src="/images/2023/09/008.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转自&lt;a href=&quot;https://github.com/ChinaLinuxKernel/CLK/blob/master/CLK2021/3-1%20AMD%E6%9E%B6%E6%9E%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CLK2021 AMD架构虚拟机性能探索与实践&lt;/a&gt;。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="AMD" scheme="http://liujunming.github.io/tags/AMD/"/>
    
  </entry>
  
  <entry>
    <title>Intel FRED feature</title>
    <link href="http://liujunming.github.io/2023/09/10/Intel-FRED-feature/"/>
    <id>http://liujunming.github.io/2023/09/10/Intel-FRED-feature/</id>
    <published>2023-09-10T08:40:11.000Z</published>
    <updated>2023-09-10T09:13:22.119Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Intel的FRED(Flexible Return and Event Delivery) feature。<a id="more"></a></p><p>FRED has the capability of helping system performance and response time.</p><p>Intel engineers summed up FRED as:</p><blockquote><p>The Intel flexible return and event delivery (FRED) architecture defines simple new transitions that change privilege level (ring transitions).  The FRED architecture was designed with the following goals:<br>1) Improve overall performance and response time by replacing event delivery through the interrupt descriptor table (IDT event delivery) and event return by<br>the IRET instruction with lower latency transitions.<br>2) Improve software robustness by ensuring that event delivery establishes the full supervisor context and that event return establishes the full user context.</p></blockquote><blockquote><p>The new transitions defined by the FRED architecture are FRED event delivery and, for returning from events, two FRED return instructions. FRED event delivery can effect a transition from ring 3 to ring 0, but it is used also to deliver events incident to ring 0(ring0 -&gt; ring0之间也可以用FRED). One FRED instruction (ERETU) effects a return from ring 0 to ring 3, while the other (ERETS) returns while remaining in ring 0.</p></blockquote><blockquote><p>In addition to these transitions, the FRED architecture defines a new instruction (LKGS) for managing the state of the GS segment register. The LKGS instruction can be used by 64-bit operating systems that do not use the new FRED transitions.</p></blockquote><p>Simply put, FRED is basically about lower-latency transitions between CPU privilege levels.</p><p>点到为止，按需再细看吧。</p><hr><p>参考资料:</p><ol><li><a href="https://www.phoronix.com/news/Intel-FRED-Linux-Patches" target="_blank" rel="noopener">Intel Sends Out Initial Linux Kernel Patches For FRED</a></li><li><a href="https://cdrdv2.intel.com/v1/dl/getContent/678938" target="_blank" rel="noopener">FRED spec</a></li><li><a href="https://lore.kernel.org/lkml/20221220063658.19271-1-xin3.li@intel.com/" target="_blank" rel="noopener">RFC patch</a></li><li><a href="https://www.eejournal.com/article/we-interrupt-this-program/" target="_blank" rel="noopener">Intel and AMD Contemplate Different Replacements for x86 Interrupt Handling</a></li><li><a href="https://www.zdnet.com/article/linus-torvalds-on-how-amd-and-intel-are-changing-how-processor-interrupts-are-handled/" target="_blank" rel="noopener">Linus Torvalds on how AMD and Intel are changing how processor interrupts are handled</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Intel的FRED(Flexible Return and Event Delivery) feature。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
  <entry>
    <title>Understand Weak Symbols by Examples</title>
    <link href="http://liujunming.github.io/2023/09/03/Understand-Weak-Symbols-by-Examples/"/>
    <id>http://liujunming.github.io/2023/09/03/Understand-Weak-Symbols-by-Examples/</id>
    <published>2023-09-03T09:12:53.000Z</published>
    <updated>2023-09-03T09:21:03.797Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自<a href="http://winfred-lu.blogspot.com/2009/11/understand-weak-symbols-by-examples.html" target="_blank" rel="noopener">Understand Weak Symbols by Examples</a>。</p><p>Wikipedia defines the weak symbols: </p><blockquote><p>In computing, a weak symbol is a symbol definition in an object file or dynamic library that may be overridden by other symbol definitions, its value will be zero if no definition found by loader.</p></blockquote><p>In other words, we can define a symbol that doesn’t need to be resolved at link time. It is a very well-known feature and used a lot in Linux Kernel, Glibc, and so on.</p><a id="more"></a><p>Take a look at the example, we are not able to compile it due to the ‘undefined reference’ error.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cat err.c</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        f();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ gcc err.c</span><br><span class="line">/tmp/ccYx7WNg.o: In function `main':</span><br><span class="line">err.c:(.text+<span class="number">0x12</span>): undefined reference to `f'</span><br><span class="line">collect2: ld returned <span class="number">1</span> <span class="built_in">exit</span> status</span><br></pre></td></tr></table></figure></p><p>Try to declare ‘f’ as an weak symbol, and we can compile it without error.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat weak.c</span><br><span class="line"><span class="keyword">void</span> __attribute__((weak)) f();</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (f)</span><br><span class="line">            f();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">$ gcc weak.c</span><br></pre></td></tr></table></figure></p><p>Note that the function ‘f’ is called inside an if statement. If not calling ‘f’ this way, we will get a ‘Segmentation fault’ error. In the weak.c example, ‘f’ is actually not invoked. It is because ‘f’ is an un-defined weak symbol and therefore will be zero when the loader cannot find it.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ ./a.out</span><br><span class="line">$ nm a.out</span><br><span class="line">...</span><br><span class="line">w f</span><br><span class="line"><span class="number">08048324</span> T main</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>Let’s define the function ‘f’ in another file, and link the objects together. This time, ‘f’ will be correctly called. (Note that puts is the optimization of printf by gcc)</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ cat f.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"hello from f\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ gcc -c weak.c f.c</span><br><span class="line">$ gcc -o weak weak.o f.o</span><br><span class="line">$ ./weak</span><br><span class="line">hello from f</span><br><span class="line"></span><br><span class="line">$ nm weak.o</span><br><span class="line">w f</span><br><span class="line"><span class="number">00000000</span> T main</span><br><span class="line">$ nm f.o</span><br><span class="line"><span class="number">00000000</span> T f</span><br><span class="line">U <span class="built_in">puts</span></span><br><span class="line">$ nm weak</span><br><span class="line">...</span><br><span class="line"><span class="number">08048384</span> T f</span><br><span class="line"><span class="number">08048354</span> T main</span><br><span class="line">U <span class="built_in">puts</span>@@GLIBC_2<span class="number">.0</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>We may even override the original weak symbol (type ‘W’) with a strong symbol (type ‘T’).<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">$ cat orig.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">void</span> __attribute__((weak)) f()</span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"original f..\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        f();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">$ gcc orig.c</span><br><span class="line">$ ./a.out</span><br><span class="line">original f..</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ cat ovrd.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"overridden f!\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line">$ gcc -c orig.c ovrd.c</span><br><span class="line">$ gcc -o ovrd orig.o ovrd.o</span><br><span class="line">$ ./ovrd</span><br><span class="line">overridden f!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ nm orig.o</span><br><span class="line"><span class="number">00000000</span> W f</span><br><span class="line"><span class="number">00000014</span> T main</span><br><span class="line">U <span class="built_in">puts</span></span><br><span class="line">$ nm ovrd.o</span><br><span class="line"><span class="number">00000000</span> T f</span><br><span class="line">U <span class="built_in">puts</span></span><br><span class="line">$ nm ovrd</span><br><span class="line">...</span><br><span class="line"><span class="number">0804838</span>c T f</span><br><span class="line"><span class="number">08048368</span> T main</span><br><span class="line">U <span class="built_in">puts</span>@@GLIBC_2<span class="number">.0</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>And of course, we can also override a weak object (type ‘V’) with a strong object (type ‘D’).<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">$ cat orig-obj.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">int</span> __attribute__((weak)) x = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> __attribute__((weak)) y = <span class="number">1</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"x = %d, y = %d\n"</span>, x, y);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">$ gcc orig-obj.c</span><br><span class="line">$ ./a.out</span><br><span class="line">x = <span class="number">1</span>, y = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ cat ovrd-obj.c</span><br><span class="line"><span class="keyword">int</span> x = <span class="number">2</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">&#125;</span><br><span class="line">$ gcc -c orig-obj.c ovrd-obj.c</span><br><span class="line">$ gcc -o ovrd-obj orig-obj.o ovrd-obj.o</span><br><span class="line">$ ./ovrd-obj</span><br><span class="line">x = <span class="number">2</span>, y = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ nm orig-obj.o</span><br><span class="line"><span class="number">00000000</span> T main</span><br><span class="line">U <span class="built_in">printf</span></span><br><span class="line"><span class="number">00000000</span> V x</span><br><span class="line"><span class="number">00000004</span> V y</span><br><span class="line">$ nm ovrd-obj.o</span><br><span class="line"><span class="number">00000000</span> T f</span><br><span class="line"><span class="number">00000000</span> D x</span><br><span class="line">$ nm ovrd-obj</span><br><span class="line">...</span><br><span class="line"><span class="number">08048394</span> T f</span><br><span class="line"><span class="number">08048354</span> T main</span><br><span class="line">U <span class="built_in">printf</span>@@GLIBC_2<span class="number">.0</span></span><br><span class="line"><span class="number">080495</span>c8 D x</span><br><span class="line"><span class="number">080495</span>c4 V y</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>What if there are multiple symbols? Linker’s symbol rules tell us that:</p><ol><li>Multiple strong symbols are not allowed</li><li>Given a strong symbol and multiple weak symbols –&gt; choose the strong symbol</li><li>Given multiple weak symbols –&gt; choose any of those weak symbols</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">$ cat mul.c</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        f();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">$ cat s1.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"1st strong f from %s\n"</span>, __FILE__);</span><br><span class="line">&#125;</span><br><span class="line">$ cat s2.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"2nd strong f from %s\n"</span>, __FILE__);</span><br><span class="line">&#125;</span><br><span class="line">$ cat w1.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">void</span> __attribute__((weak)) f(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"1st weak f from %s\n"</span>, __FILE__);</span><br><span class="line">&#125;</span><br><span class="line">$ cat w2.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">void</span> __attribute__((weak)) f(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"2nd weak f from %s\n"</span>, __FILE__);</span><br><span class="line">&#125;</span><br><span class="line">$ gcc -c mul.c s1.c s2.c w1.c w2.c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ gcc -o test1 mul.o s1.o s2.o</span><br><span class="line">s2.o: In function `f':</span><br><span class="line">s2.c:(.text+<span class="number">0x0</span>): multiple definition of `f'</span><br><span class="line">s1.o:s1.c:(.text+<span class="number">0x0</span>): first defined here</span><br><span class="line">collect2: ld returned <span class="number">1</span> <span class="built_in">exit</span> status</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ gcc -o test2 mul.o s1.o w1.o w2.o</span><br><span class="line">$ ./test2</span><br><span class="line"><span class="number">1</span>st strong f from s1.c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ gcc -o test3<span class="number">-1</span> mul.o w1.o w2.o</span><br><span class="line">$ ./test3<span class="number">-1</span></span><br><span class="line"><span class="number">1</span>st weak f from w1.c</span><br><span class="line">$ gcc -o test3<span class="number">-2</span> mul.o w2.o w1.o</span><br><span class="line">$ ./test3<span class="number">-2</span></span><br><span class="line"><span class="number">2</span>nd weak f from w2.c</span><br></pre></td></tr></table></figure><p>Hope these examples help!</p><p>References:</p><ol><li><a href="http://en.wikipedia.org/wiki/Weak_symbol" target="_blank" rel="noopener">Wikipedia, “Weak Symbol”</a></li><li><a href="http://gcc.gnu.org/onlinedocs/gcc-3.2/gcc/Function-Attributes.html" target="_blank" rel="noopener">gcc manual, “Declaring Attributes of Functions”</a></li><li><a href="http://sourceware.org/binutils/docs/binutils/nm.html" target="_blank" rel="noopener">binutil Document, “nm”</a></li><li><a href="http://www.slideshare.net/satpalparmar/linkers-and-loaders-presentation" target="_blank" rel="noopener">Sandeep Grover, “Linkers &amp; Loaders - A Programmers Perspective”</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自&lt;a href=&quot;http://winfred-lu.blogspot.com/2009/11/understand-weak-symbols-by-examples.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Understand Weak Symbols by Examples&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Wikipedia defines the weak symbols: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In computing, a weak symbol is a symbol definition in an object file or dynamic library that may be overridden by other symbol definitions, its value will be zero if no definition found by loader.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, we can define a symbol that doesn’t need to be resolved at link time. It is a very well-known feature and used a lot in Linux Kernel, Glibc, and so on.&lt;/p&gt;
    
    </summary>
    
      <category term="C语言" scheme="http://liujunming.github.io/categories/C%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="C语言" scheme="http://liujunming.github.io/tags/C%E8%AF%AD%E8%A8%80/"/>
    
  </entry>
  
  <entry>
    <title>每周分享第36期</title>
    <link href="http://liujunming.github.io/2023/09/03/%E6%AF%8F%E5%91%A8%E5%88%86%E4%BA%AB%E7%AC%AC36%E6%9C%9F/"/>
    <id>http://liujunming.github.io/2023/09/03/每周分享第36期/</id>
    <published>2023-09-03T04:39:26.000Z</published>
    <updated>2023-09-03T05:13:08.469Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Live-migration-of-virtual-machines-over-CXL"><a href="#Live-migration-of-virtual-machines-over-CXL" class="headerlink" title="Live migration of virtual machines over CXL"></a>Live migration of virtual machines over CXL</h3><p><a href="https://lwn.net/Articles/931528/" target="_blank" rel="noopener">https://lwn.net/Articles/931528/</a><br><a id="more"></a></p><h3 id="spot-instance"><a href="#spot-instance" class="headerlink" title="spot instance"></a>spot instance</h3><p>竞价实例（Spot Instance）：节省80-90％的云计算成本</p><p>竞价实例是云中的闲置计算能力，它是云供应商出售其计算能力的一种方式之一—另外两种是按需实例和预留实例（包年包月实例）。就服务器本身而言，这三者之间没有区别，不同之处在于商业模式。按需实例是根据使用时长来收费的，用户只需要在使用的时候才付费。预留实例允许用户以“月”或者“年”为单位来购买。竞价实例允许用户通过使用使用云中当前闲置的服务器资源来节省高达90％的云计算成本，云供应商希望通过以极低的价格出售这些位于云中闲置的服务器，将这些空闲资源利用起来以带来收益。</p><p>关于竞价实例（Spot Instance），您应该知道什么：</p><p>1.竞价实例很便宜</p><p>和按需实例对比，竞价实例通常仅是其价格的10-20％。和预留实例对比，竞价实例通常仅是其价格的30-60％。竞价实例提供了大量节省云资源费用的可能性。</p><p>2.竞价实例可能随时会被终止</p><p>使用竞价实例的风险是，云供应商可以在几乎没有警告（通常会提前几分钟通知）的情况下终止这些实例。如果您的应用需要保证可用性，一致性或数据一致中的任何一个，那么当您使用竞价实例时，您需要专门的管理配置工具去保证这些。云供应商不会为竞价实例提供SLA，您的应用需要去处理这些随时可能发生的中断。</p><p><a href="https://cloud.tencent.com/developer/article/1544459" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1544459</a></p><h3 id="利用-chrt-命令查询与修改进程调度器"><a href="#利用-chrt-命令查询与修改进程调度器" class="headerlink" title="利用 chrt 命令查询与修改进程调度器"></a>利用 chrt 命令查询与修改进程调度器</h3><p>chrt 命令是 linux 提供的一个底层应用指令，它可以在运行时设置进程的某些属性，还可以更改调度策略和调度优先级。</p><p><a href="https://cloud.tencent.com/developer/article/2118807" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/2118807</a></p><h3 id="万字干货分享-阿里云-CIPU-技术解析"><a href="#万字干货分享-阿里云-CIPU-技术解析" class="headerlink" title="万字干货分享 | 阿里云 CIPU 技术解析"></a>万字干货分享 | 阿里云 CIPU 技术解析</h3><p><a href="https://mp.weixin.qq.com/s/wtLX0q9BnQDghmBvCL5uGQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/wtLX0q9BnQDghmBvCL5uGQ</a></p><h3 id="揭秘！CIPU-最新秘密武器——弹性-RDMA-的技术解析与实践"><a href="#揭秘！CIPU-最新秘密武器——弹性-RDMA-的技术解析与实践" class="headerlink" title="揭秘！CIPU 最新秘密武器——弹性 RDMA 的技术解析与实践"></a>揭秘！CIPU 最新秘密武器——弹性 RDMA 的技术解析与实践</h3><p><a href="https://mp.weixin.qq.com/s/yWVOA60Kp6MROOFxK4kSdw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/yWVOA60Kp6MROOFxK4kSdw</a></p><h3 id="Future-Generation-Xeon"><a href="#Future-Generation-Xeon" class="headerlink" title="Future-Generation Xeon"></a>Future-Generation Xeon</h3><p><a href="https://mp.weixin.qq.com/s/ZdcR3Q2fiX2UjxrW4ez6_g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ZdcR3Q2fiX2UjxrW4ez6_g</a></p><h3 id="仅-8670-行代码，Linux-内核第一版-v0-01-开源代码解读"><a href="#仅-8670-行代码，Linux-内核第一版-v0-01-开源代码解读" class="headerlink" title="仅 8670 行代码，Linux 内核第一版 (v0.01) 开源代码解读"></a>仅 8670 行代码，Linux 内核第一版 (v0.01) 开源代码解读</h3><p><a href="https://mp.weixin.qq.com/s/TX_DTkiLsUOADoVyX8x_TQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/TX_DTkiLsUOADoVyX8x_TQ</a><br><a href="https://seiya.me/blog/reading-linux-v0.01" target="_blank" rel="noopener">https://seiya.me/blog/reading-linux-v0.01</a></p><h3 id="sycl"><a href="#sycl" class="headerlink" title="sycl"></a>sycl</h3><p><a href="https://oneapi-src.github.io/SYCLomatic/dev_guide/compare-prog-models.html" target="_blank" rel="noopener">CUDA and SYCL Programming Model Comparison</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Live-migration-of-virtual-machines-over-CXL&quot;&gt;&lt;a href=&quot;#Live-migration-of-virtual-machines-over-CXL&quot; class=&quot;headerlink&quot; title=&quot;Live migration of virtual machines over CXL&quot;&gt;&lt;/a&gt;Live migration of virtual machines over CXL&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://lwn.net/Articles/931528/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://lwn.net/Articles/931528/&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="经验" scheme="http://liujunming.github.io/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="经验" scheme="http://liujunming.github.io/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Paravirtualized ticket spinlocks</title>
    <link href="http://liujunming.github.io/2023/08/27/Notes-about-Paravirtualized-ticket-spinlocks/"/>
    <id>http://liujunming.github.io/2023/08/27/Notes-about-Paravirtualized-ticket-spinlocks/</id>
    <published>2023-08-27T06:01:48.000Z</published>
    <updated>2023-08-27T09:20:28.580Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下kvm中的Paravirtualized ticket spinlocks相关notes。<br>参考内核版本为v5.0，主要内容转载自<a href="http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/10/01/kvm-performance-2" target="_blank" rel="noopener">kvm performance optimization technologies, part two</a>。<a id="more"></a></p><p>在kvm中，也会将Paravirtualized ticket spinlocks称为PV unhalt。</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Now, suppose that vCPU A grabs a spinlock, and before it finishes, is preempted by the scheduler. And then suppose vCPU B tries to grab the spinlock. Now B, instead of spinning for the short period of time that A needed the spinlock for, will be spinning until vCPU is scheduled again — which may be anywhere from several milliseconds to hundreds of milliseconds, depending on how busy the system is. B is now using the cpu but accomplishing nothing. It’s burning up its VM’s share of CPU time, and keeping other VMs with useful work to do from running. Worse yet, it may even be that the reason A is not running is that the hypervisor’s scheduler is trying to give priority to B — so B is actively keeping A from finishing the work that it needed to do with the spinlock.</p><p>The situation gets even worse with a more advanced form of spinlock called a ticketlock. Ticketlocks have a lot of advantages for large systems, including reduced cacheline bouncing and more predictable wait time. (See this <a href="https://lwn.net/Articles/267968/" target="_blank" rel="noopener">LWN article</a> for a complete description.) The key attribute for this discussion is that ticketlocks essentially make a first-come first-served queue: if A has the lock, then B tries to grab it, and then C, B is guaranteed to get the lock before C. So now, if C is spinning waiting for the lock, it must wait for both A and B to finish before it can get the lock.</p><p>The result is that on a moderately loaded system, the vast majority of the cpu cycles are actually spent waiting for ticketlocks rather than doing any useful work. This is called a “ticketlock storm”. </p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>The PV unhalt feature is used to set the <code>pv_lock_ops</code> to rewrite the native spinlock’s function so it can be more optimizated.</p><p>Though the total implementation of pv spinlock is related with the spinlock implementation such as ticketlock and queued spinlock, the basic idea behind the pv spinlock is the same. That is <strong>instead of spining while the vCPU can’t get the spinlock, it will execute halt instruction and let the other vCPU got scheduled. When the vCPU can get the spinlock, allows a vCPU to kick the target vCPU out of halt state.</strong></p><p>When the time spent waiting for a lock reaches a given threshold, kvm is notified via a hypercall that a vCPU is currently blocked by a held lock. KVM then halts the waiting vCPU until the lock is detected to be available.</p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><h3 id="kvm-side"><a href="#kvm-side" class="headerlink" title="kvm side"></a>kvm side</h3><p>kvm should expose the <code>KVM_FEATURE_PV_UNHALT</code> to the guest.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> __do_cpuid_ent(struct kvm_cpuid_entry2 *entry, u32 function,</span><br><span class="line">                 u32 index, <span class="keyword">int</span> *nent, <span class="keyword">int</span> maxnent)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> KVM_CPUID_FEATURES:</span><br><span class="line">        entry-&gt;eax = (<span class="number">1</span> &lt;&lt; KVM_FEATURE_CLOCKSOURCE) |</span><br><span class="line">                 ...</span><br><span class="line">                 (<span class="number">1</span> &lt;&lt; KVM_FEATURE_PV_UNHALT) |</span><br><span class="line">                 ...</span><br></pre></td></tr></table></figure></p><h3 id="guest-side"><a href="#guest-side" class="headerlink" title="guest side"></a>guest side</h3><p>When the guest startup, <code>kvm_spinlock_init</code> is used to initialize the pv spinlock.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> __<span class="function">init <span class="title">kvm_spinlock_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!kvm_para_available())</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="comment">/* Does host kernel support KVM_FEATURE_PV_UNHALT? */</span></span><br><span class="line">    <span class="keyword">if</span> (!kvm_para_has_feature(KVM_FEATURE_PV_UNHALT))</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (kvm_para_has_hint(KVM_HINTS_REALTIME))</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Don't use the pvqspinlock code if there is only 1 vCPU. */</span></span><br><span class="line">    <span class="keyword">if</span> (num_possible_cpus() == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    __pv_init_lock_hash();</span><br><span class="line">    pv_ops.lock.queued_spin_lock_slowpath = __pv_queued_spin_lock_slowpath;</span><br><span class="line">    pv_ops.lock.queued_spin_unlock =</span><br><span class="line">        PV_CALLEE_SAVE(__pv_queued_spin_unlock);</span><br><span class="line">    pv_ops.lock.wait = kvm_wait;</span><br><span class="line">    pv_ops.lock.kick = kvm_kick_cpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (kvm_para_has_feature(KVM_FEATURE_STEAL_TIME)) &#123;</span><br><span class="line">        pv_ops.lock.vcpu_is_preempted =</span><br><span class="line">            PV_CALLEE_SAVE(__kvm_vcpu_is_preempted);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>最值得关注的函数是<code>kvm_wait</code>和<code>kvm_kick_cpu</code>，会在下面进行详细的介绍。</p><h2 id="halt-when-vCPU-is-blocked-by-a-held-lock"><a href="#halt-when-vCPU-is-blocked-by-a-held-lock" class="headerlink" title="halt when vCPU is blocked by a held lock"></a>halt when vCPU is blocked by a held lock</h2><h3 id="guest-side-1"><a href="#guest-side-1" class="headerlink" title="guest side"></a>guest side</h3><p>When the vCPU can’t get the spinlock, it will call wait callback.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> __<span class="function">always_inline <span class="keyword">void</span> <span class="title">pv_wait</span><span class="params">(u8 *ptr, u8 val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PVOP_VCALL2(lock.wait, ptr, val);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Then it will execute the halt instruction in <code>kvm_wait</code>.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_wait</span><span class="params">(u8 *ptr, u8 val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (in_nmi())</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    local_irq_save(flags);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (READ_ONCE(*ptr) != val)</span><br><span class="line">        <span class="keyword">goto</span> out;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * halt until it's our turn and kicked. Note that we do safe halt</span></span><br><span class="line"><span class="comment">     * for irq enabled case to avoid hang when lock info is overwritten</span></span><br><span class="line"><span class="comment">     * in irq spinlock slowpath and no spurious interrupt occur to save us.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (arch_irqs_disabled_flags(flags))</span><br><span class="line">        halt();</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        safe_halt();</span><br><span class="line"></span><br><span class="line">out:</span><br><span class="line">    local_irq_restore(flags);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="kvm-side-1"><a href="#kvm-side-1" class="headerlink" title="kvm side"></a>kvm side</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">handle_halt</span><br><span class="line">└── kvm_emulate_halt</span><br><span class="line">    └── kvm_vcpu_halt</span><br></pre></td></tr></table></figure><p>When the guest execute halt instruction, the <code>kvm_emulate_halt</code>-&gt;<code>kvm_vcpu_halt</code> will be called. This will set the <code>vcpu-&gt;arch.mp_state</code> to <code>KVM_MP_STATE_HALTED</code>. Then <code>vcpu_block</code> will be called to block this vCPU.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">vcpu_run</span><span class="params">(struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> r;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kvm</span> *<span class="title">kvm</span> = <span class="title">vcpu</span>-&gt;<span class="title">kvm</span>;</span></span><br><span class="line"></span><br><span class="line">    vcpu-&gt;srcu_idx = srcu_read_lock(&amp;kvm-&gt;srcu);</span><br><span class="line">    vcpu-&gt;arch.l1tf_flush_l1d = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">if</span> (kvm_vcpu_running(vcpu)) &#123;</span><br><span class="line">            r = vcpu_enter_guest(vcpu);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            r = vcpu_block(kvm, vcpu);</span><br><span class="line">        &#125;</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">vcpu_block</span><span class="params">(struct kvm *kvm, struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!kvm_arch_vcpu_runnable(vcpu) &amp;&amp;</span><br><span class="line">        (!kvm_x86_ops-&gt;pre_block || kvm_x86_ops-&gt;pre_block(vcpu) == <span class="number">0</span>)) &#123;</span><br><span class="line">        srcu_read_unlock(&amp;kvm-&gt;srcu, vcpu-&gt;srcu_idx);</span><br><span class="line">        kvm_vcpu_block(vcpu);</span><br><span class="line">        vcpu-&gt;srcu_idx = srcu_read_lock(&amp;kvm-&gt;srcu);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (kvm_x86_ops-&gt;post_block)</span><br><span class="line">            kvm_x86_ops-&gt;post_block(vcpu);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!kvm_check_request(KVM_REQ_UNHALT, vcpu))</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    kvm_apic_accept_events(vcpu);</span><br><span class="line">    <span class="keyword">switch</span>(vcpu-&gt;arch.mp_state) &#123;</span><br><span class="line">    <span class="keyword">case</span> KVM_MP_STATE_HALTED:</span><br><span class="line">        vcpu-&gt;arch.pv.pv_unhalted = <span class="literal">false</span>;</span><br><span class="line">        vcpu-&gt;arch.mp_state =</span><br><span class="line">            KVM_MP_STATE_RUNNABLE;</span><br><span class="line">        <span class="comment">/* fall through */</span></span><br><span class="line">    <span class="keyword">case</span> KVM_MP_STATE_RUNNABLE:</span><br><span class="line">        vcpu-&gt;arch.apf.halted = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> KVM_MP_STATE_INIT_RECEIVED:</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">return</span> -EINTR;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="kick-the-halted-vCPU-until-the-lock-is-detected-to-be-available"><a href="#kick-the-halted-vCPU-until-the-lock-is-detected-to-be-available" class="headerlink" title="kick the halted vCPU until the lock is detected to be available"></a>kick the halted vCPU until the lock is detected to be available</h2><h3 id="guest-side-2"><a href="#guest-side-2" class="headerlink" title="guest side"></a>guest side</h3><p>When the halted vCPU can get the spinlock, the <code>kick</code> callback will be called by <code>pv_kick</code> by a running vCPU. The <code>kvm_kick_cpu</code> will be called and this trigger a <code>KVM_HC_KICK_CPU</code> hypercall.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> __<span class="function">always_inline <span class="keyword">void</span> <span class="title">pv_kick</span><span class="params">(<span class="keyword">int</span> cpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PVOP_VCALL1(lock.kick, cpu);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Kick a cpu by its apicid. Used to wake up a halted vcpu */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_kick_cpu</span><span class="params">(<span class="keyword">int</span> cpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> apicid;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    apicid = per_cpu(x86_cpu_to_apicid, cpu);</span><br><span class="line">    kvm_hypercall2(KVM_HC_KICK_CPU, flags, apicid);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="kvm-side-2"><a href="#kvm-side-2" class="headerlink" title="kvm side"></a>kvm side</h3><p>When the guest trigger <code>KVM_HC_KICK_CPU</code> hypercall, <code>kvm_pv_kick_cpu_op</code> will be called.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kvm_emulate_hypercall</span><span class="params">(struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> KVM_HC_KICK_CPU:</span><br><span class="line">        kvm_pv_kick_cpu_op(vcpu-&gt;kvm, a0, a1);</span><br><span class="line">        ret = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>The <code>kvm_pv_kick_cpu_op</code> will send an interrupt to the lapic.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * kvm_pv_kick_cpu_op:  Kick a vcpu.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @apicid - apicid of vcpu to be kicked.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_pv_kick_cpu_op</span><span class="params">(struct kvm *kvm, <span class="keyword">unsigned</span> <span class="keyword">long</span> flags, <span class="keyword">int</span> apicid)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kvm_lapic_irq</span> <span class="title">lapic_irq</span>;</span></span><br><span class="line"></span><br><span class="line">    lapic_irq.shorthand = <span class="number">0</span>;</span><br><span class="line">    lapic_irq.dest_mode = <span class="number">0</span>;</span><br><span class="line">    lapic_irq.level = <span class="number">0</span>;</span><br><span class="line">    lapic_irq.dest_id = apicid;</span><br><span class="line">    lapic_irq.msi_redir_hint = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    lapic_irq.delivery_mode = APIC_DM_REMRD;</span><br><span class="line">    kvm_irq_delivery_to_apic(kvm, <span class="literal">NULL</span>, &amp;lapic_irq, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kvm_irq_delivery_to_apic</span><br><span class="line">└── kvm_apic_set_irq</span><br><span class="line">    └── __apic_accept_irq</span><br></pre></td></tr></table></figure><p>Then in <code>__apic_accept_irq</code> it will kick the blocked vCPU.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Add a pending IRQ into lapic.</span></span><br><span class="line"><span class="comment"> * Return 1 if successfully added and 0 if discarded.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> __apic_accept_irq(struct kvm_lapic *apic, <span class="keyword">int</span> delivery_mode,</span><br><span class="line">                 <span class="keyword">int</span> <span class="built_in">vector</span>, <span class="keyword">int</span> level, <span class="keyword">int</span> trig_mode,</span><br><span class="line">                 struct dest_map *dest_map)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> APIC_DM_REMRD:</span><br><span class="line">        result = <span class="number">1</span>;</span><br><span class="line">        vcpu-&gt;arch.pv.pv_unhalted = <span class="number">1</span>;</span><br><span class="line">        kvm_make_request(KVM_REQ_EVENT, vcpu);</span><br><span class="line">        kvm_vcpu_kick(vcpu);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>For the halted vCPU, then <code>kvm_vcpu_block</code> returns, it will set <code>vcpu-&gt;arch.mp_state</code> to <code>KVM_MP_STATE_RUNNABLE</code> and let the halted vCPU enter Non-root mode to get the spinlock.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">vcpu_block</span><span class="params">(struct kvm *kvm, struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!kvm_arch_vcpu_runnable(vcpu) &amp;&amp;</span><br><span class="line">        (!kvm_x86_ops-&gt;pre_block || kvm_x86_ops-&gt;pre_block(vcpu) == <span class="number">0</span>)) &#123;</span><br><span class="line">        srcu_read_unlock(&amp;kvm-&gt;srcu, vcpu-&gt;srcu_idx);</span><br><span class="line">        kvm_vcpu_block(vcpu);</span><br><span class="line">        vcpu-&gt;srcu_idx = srcu_read_lock(&amp;kvm-&gt;srcu);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (kvm_x86_ops-&gt;post_block)</span><br><span class="line">            kvm_x86_ops-&gt;post_block(vcpu);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 此时kvm_check_request(KVM_REQ_UNHALT, vcpu)为true</span></span><br><span class="line">        <span class="comment">// 因为__apic_accept_irq调用了kvm_make_request(KVM_REQ_EVENT, vcpu)</span></span><br><span class="line">        <span class="keyword">if</span> (!kvm_check_request(KVM_REQ_UNHALT, vcpu))</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    kvm_apic_accept_events(vcpu);</span><br><span class="line">    <span class="keyword">switch</span>(vcpu-&gt;arch.mp_state) &#123;</span><br><span class="line">    <span class="keyword">case</span> KVM_MP_STATE_HALTED:</span><br><span class="line">        vcpu-&gt;arch.pv.pv_unhalted = <span class="literal">false</span>;</span><br><span class="line">        vcpu-&gt;arch.mp_state =</span><br><span class="line">            KVM_MP_STATE_RUNNABLE;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><hr><p>参考资料:</p><ol><li><a href="http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/10/01/kvm-performance-2" target="_blank" rel="noopener">kvm performance optimization technologies, part two</a></li><li><a href="https://lore.kernel.org/kvm/20120323080503.14568.43092.sendpatchset@codeblue/" target="_blank" rel="noopener">kvm : Paravirt-spinlock support for KVM guests</a></li><li><a href="https://people.cs.pitt.edu/~ouyang/files/paper/vee13-pmtlock-paper.pdf" target="_blank" rel="noopener">Preemptable Ticket Spinlocks: Improving Consolidated Performance in the Cloud</a></li><li><a href="https://wiki.xenproject.org/wiki/Benchmarking_the_new_PV_ticketlock_implementation" target="_blank" rel="noopener">Benchmarking the new PV ticketlock implementation</a></li><li><a href="https://www.researchgate.net/publication/200014431_Lock-holder_preemption_on_Xen" target="_blank" rel="noopener">How to deal with lock-holder preemption</a></li><li>Towards scalable multiprocessor virtual machines. In Proceedings of the 3rd conference on Virtual Machine Research And Technology Symposium - Volume 3</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下kvm中的Paravirtualized ticket spinlocks相关notes。&lt;br&gt;参考内核版本为v5.0，主要内容转载自&lt;a href=&quot;http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/10/01/kvm-performance-2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kvm performance optimization technologies, part two&lt;/a&gt;。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
      <category term="Concurrency" scheme="http://liujunming.github.io/tags/Concurrency/"/>
    
  </entry>
  
  <entry>
    <title>Notes about PV sched yield</title>
    <link href="http://liujunming.github.io/2023/08/26/Notes-about-PV-sched-yield/"/>
    <id>http://liujunming.github.io/2023/08/26/Notes-about-PV-sched-yield/</id>
    <published>2023-08-26T10:08:30.000Z</published>
    <updated>2023-08-27T11:42:54.428Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下kvm中的PV sched yield相关notes，参考内核版本是v6.0。<a id="more"></a></p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Idea:<br>When sending a call-function IPI-many to vCPUs, yield(by hypercall) if any of the IPI target vCPU was preempted, yield to(让步于) the first preempted target vCPU which we found.</p><p>如果IPI的source vCPU不yield to the preempted target vCPU的话，source vCPU在Non-root mode下依然会busy waiting(参考<code>smp_call_function_many_cond</code>函数)，直到preempted target vCPU被调度到Non-root mode后才结束；还不如直接yiled source vCPU，yield to the preempted target vCPU。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">smp_call_function_many_cond</span><span class="params">(<span class="keyword">const</span> struct cpumask *mask,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">smp_call_func_t</span> func, <span class="keyword">void</span> *info,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">unsigned</span> <span class="keyword">int</span> scf_flags,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">smp_cond_func_t</span> cond_func)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (run_remote &amp;&amp; wait) &#123;</span><br><span class="line">        <span class="comment">// 按顺序等各个cpu修改csd的flag，不然就死等</span></span><br><span class="line">        for_each_cpu(cpu, cfd-&gt;cpumask) &#123;</span><br><span class="line">            <span class="keyword">call_single_data_t</span> *csd;</span><br><span class="line"></span><br><span class="line">            csd = &amp;per_cpu_ptr(cfd-&gt;pcpu, cpu)-&gt;csd;</span><br><span class="line">            csd_lock_wait(csd);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>下图阐述了IPI target vCPUs are good yield candidates的原因。<br><img src="/images/2023/08/014.jpg" alt><br>详情建议阅读<a href="https://lore.kernel.org/kvm/1563457031-21189-2-git-send-email-pbonzini@redhat.com/" target="_blank" rel="noopener">KVM: Boost vCPUs that are delivering interrupts</a>。</p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><h3 id="kvm-side"><a href="#kvm-side" class="headerlink" title="kvm side"></a>kvm side</h3><p>export this feature to the guest<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> __do_cpuid_func(struct kvm_cpuid_array *<span class="built_in">array</span>, u32 function)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> KVM_CPUID_FEATURES:</span><br><span class="line">        entry-&gt;eax = (<span class="number">1</span> &lt;&lt; KVM_FEATURE_CLOCKSOURCE) |</span><br><span class="line">                  ...</span><br><span class="line">                 (<span class="number">1</span> &lt;&lt; KVM_FEATURE_PV_SCHED_YIELD) |</span><br></pre></td></tr></table></figure></p><h3 id="guest-side"><a href="#guest-side" class="headerlink" title="guest side"></a>guest side</h3><p>When the guest startup it will replace the <code>smp_ops.send_call_func_ipi</code> with <code>kvm_smp_send_call_func_ipi</code> if the PV sched yield feature supported.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">init <span class="title">kvm_guest_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (pv_sched_yield_supported()) &#123;</span><br><span class="line">        smp_ops.send_call_func_ipi = kvm_smp_send_call_func_ipi;</span><br><span class="line">        pr_info(<span class="string">"setup PV sched yield\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">bool</span> <span class="title">pv_sched_yield_supported</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (kvm_para_has_feature(KVM_FEATURE_PV_SCHED_YIELD) &amp;&amp;</span><br><span class="line">        !kvm_para_has_hint(KVM_HINTS_REALTIME) &amp;&amp;</span><br><span class="line">        kvm_para_has_feature(KVM_FEATURE_STEAL_TIME) &amp;&amp;</span><br><span class="line">        !boot_cpu_has(X86_FEATURE_MWAIT) &amp;&amp;</span><br><span class="line">        (num_possible_cpus() != <span class="number">1</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="yield-to-the-preempted-target-vCPU"><a href="#yield-to-the-preempted-target-vCPU" class="headerlink" title="yield to the preempted target vCPU"></a>yield to the preempted target vCPU</h2><h3 id="guest-side-1"><a href="#guest-side-1" class="headerlink" title="guest side"></a>guest side</h3><p>When the guest send call func IPI, the current vcpu will call <code>native_send_call_func_ipi</code> to send IPI to the target vcpu. If the target vCPU is preempted, it will issue a hypercall <code>KVM_HC_SCHED_YIELD</code>. </p><p>We just select the first preempted target vCPU which we found since the state of target vCPUs can change underneath and to avoid race conditions.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_smp_send_call_func_ipi</span><span class="params">(<span class="keyword">const</span> struct cpumask *mask)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> cpu;</span><br><span class="line"></span><br><span class="line">    native_send_call_func_ipi(mask);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Make sure other vCPUs get a chance to run if they need to. */</span></span><br><span class="line">    for_each_cpu(cpu, mask) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!idle_cpu(cpu) &amp;&amp; vcpu_is_preempted(cpu)) &#123;</span><br><span class="line">            kvm_hypercall1(KVM_HC_SCHED_YIELD, per_cpu(x86_cpu_to_apicid, cpu));</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="kvm-side-1"><a href="#kvm-side-1" class="headerlink" title="kvm side"></a>kvm side</h3><p>kvm needs to implement the hypercall handler to process the yield hypercall.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kvm_emulate_hypercall</span><span class="params">(struct kvm_vcpu *vcpu)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">case</span> KVM_HC_SCHED_YIELD:</span><br><span class="line">        <span class="keyword">if</span> (!guest_pv_has(vcpu, KVM_FEATURE_PV_SCHED_YIELD))</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">        kvm_sched_yield(vcpu, a0);</span><br><span class="line">        ret = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Find the target vcpu and yield to it.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kvm_sched_yield</span><span class="params">(struct kvm_vcpu *vcpu, <span class="keyword">unsigned</span> <span class="keyword">long</span> dest_id)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kvm_vcpu</span> *<span class="title">target</span> = <span class="title">NULL</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kvm_apic_map</span> *<span class="title">map</span>;</span></span><br><span class="line"></span><br><span class="line">    vcpu-&gt;stat.directed_yield_attempted++;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (single_task_running())</span><br><span class="line">        <span class="keyword">goto</span> no_yield;</span><br><span class="line"></span><br><span class="line">    rcu_read_lock();</span><br><span class="line">    <span class="built_in">map</span> = rcu_dereference(vcpu-&gt;kvm-&gt;arch.apic_map);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (likely(<span class="built_in">map</span>) &amp;&amp; dest_id &lt;= <span class="built_in">map</span>-&gt;max_apic_id &amp;&amp; <span class="built_in">map</span>-&gt;phys_map[dest_id])</span><br><span class="line">        target = <span class="built_in">map</span>-&gt;phys_map[dest_id]-&gt;vcpu;</span><br><span class="line"></span><br><span class="line">    rcu_read_unlock();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!target || !READ_ONCE(target-&gt;ready))</span><br><span class="line">        <span class="keyword">goto</span> no_yield;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Ignore requests to yield to self */</span></span><br><span class="line">    <span class="keyword">if</span> (vcpu == target)</span><br><span class="line">        <span class="keyword">goto</span> no_yield;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (kvm_vcpu_yield_to(target) &lt;= <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">goto</span> no_yield;</span><br><span class="line"></span><br><span class="line">    vcpu-&gt;stat.directed_yield_successful++;</span><br><span class="line"></span><br><span class="line">no_yield:</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>上述代码的第26行<code>kvm_vcpu_yield_to(target)</code>，<code>target</code>就是目标vCPU，当前代码的执行上下文是IPI的source vCPU thread，执行完<code>kvm_vcpu_yield_to</code>后，即可yield to 目标vCPU。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kvm_vcpu_yield_to</span><span class="params">(struct kvm_vcpu *target)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">pid</span> *<span class="title">pid</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">task</span> = <span class="title">NULL</span>;</span></span><br><span class="line">    <span class="keyword">int</span> ret = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    rcu_read_lock();</span><br><span class="line">    pid = rcu_dereference(target-&gt;pid);</span><br><span class="line">    <span class="keyword">if</span> (pid)</span><br><span class="line">        task = get_pid_task(pid, PIDTYPE_PID);</span><br><span class="line">    rcu_read_unlock();</span><br><span class="line">    <span class="keyword">if</span> (!task)</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    ret = yield_to(task, <span class="number">1</span>);</span><br><span class="line">    put_task_struct(task);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再看下<code>yield_to</code>函数:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return:</span></span><br><span class="line"><span class="comment"> *  true (&gt;0) if we indeed boosted the target task.</span></span><br><span class="line"><span class="comment"> *  false (0) if we failed to boost the target.</span></span><br><span class="line"><span class="comment"> *  -ESRCH if there's no task to yield to.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> __<span class="function">sched <span class="title">yield_to</span><span class="params">(struct task_struct *p, <span class="keyword">bool</span> preempt)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// yield_to_task主动放弃CPU并执行指定的task_struct</span></span><br><span class="line">    yielded = curr-&gt;sched_class-&gt;yield_to_task(rq, p, preempt);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><hr><p>参考资料:</p><ol><li><a href="http://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/09/10/kvm-performance-1" target="_blank" rel="noopener">kvm performance optimization technologies, part one</a></li><li><a href="https://lore.kernel.org/kvm/1560255830-8656-1-git-send-email-wanpengli@tencent.com/" target="_blank" rel="noopener">KVM: Yield to IPI target if necessary</a></li><li><a href="https://static.sched.com/hosted_files/kvmforum2020/6e/KVM%20Latency%20and%20Scalability%20Performance%20Tuning.pdf" target="_blank" rel="noopener">KVM Latency and Scalability Performance Tuning</a></li><li><a href="https://zhuanlan.zhihu.com/p/442921692" target="_blank" rel="noopener">进程管理：一文读懂Linux内核中的任务间调度策略</a></li><li><a href="https://cloud.tencent.com/developer/article/1648811" target="_blank" rel="noopener">从一个softlock问题来谈谈Kernel IPI的实现</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下kvm中的PV sched yield相关notes，参考内核版本是v6.0。
    
    </summary>
    
      <category term="KVM" scheme="http://liujunming.github.io/categories/KVM/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="KVM" scheme="http://liujunming.github.io/tags/KVM/"/>
    
      <category term="调度" scheme="http://liujunming.github.io/tags/%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
</feed>
