<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>L</title>
  
  <subtitle>make it simple, make it happen.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://liujunming.github.io/"/>
  <updated>2023-05-04T05:37:17.282Z</updated>
  <id>http://liujunming.github.io/</id>
  
  <author>
    <name>liujunming</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Notes about NBD（Network Block Device)</title>
    <link href="http://liujunming.github.io/2023/05/04/Notes-about-NBD%EF%BC%88Network-Block-Device/"/>
    <id>http://liujunming.github.io/2023/05/04/Notes-about-NBD（Network-Block-Device/</id>
    <published>2023-05-04T05:29:23.000Z</published>
    <updated>2023-05-04T05:37:17.282Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/50460919" target="_blank" rel="noopener">NBD（Network Block Device）简介及基本使用</a></p><p>NBD指的是Network Block Device，正如其名字的意思，NBD让用户可以通过网络访问到某个块设备，或者镜像文件。<a id="more"></a></p><p><img src="/images/2023/05/03.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/50460919&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NBD（Network Block Device）简介及基本使用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;NBD指的是Network Block Device，正如其名字的意思，NBD让用户可以通过网络访问到某个块设备，或者镜像文件。
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Notes about协程</title>
    <link href="http://liujunming.github.io/2023/05/02/Notes-about%E5%8D%8F%E7%A8%8B/"/>
    <id>http://liujunming.github.io/2023/05/02/Notes-about协程/</id>
    <published>2023-05-02T06:23:49.000Z</published>
    <updated>2023-05-02T12:22:15.347Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下协程(Coroutines)相关notes。<a id="more"></a></p><h2 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h2><h3 id="1-1-Why"><a href="#1-1-Why" class="headerlink" title="1.1 Why?"></a>1.1 Why?</h3><p><a href="/pdf/什么是协程.pdf">什么是协程</a></p><p>vs多线程：<br>操作系统在线程等待IO的时候，会阻塞当前线程，切换到其它线程，这样在当前线程等待IO的过程中，其它线程可以继续执行。当系统线程较少的时候没有什么问题，但是当线程数量非常多的时候，却产生了问题。<strong>一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间</strong>。</p><p>协程刚好可以解决上述2个问题。协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。<strong>协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程</strong>，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。</p><h3 id="1-2-What"><a href="#1-2-What" class="headerlink" title="1.2 What"></a>1.2 What</h3><p><img src="/images/2023/05/02.png" alt></p><blockquote><p>协程本质上和单线程+状态机是等价的，只是用协程的话，协程负责来保存状态，开发起来方便些(不用自己写那个状态机)。</p></blockquote><h3 id="1-3-When"><a href="#1-3-When" class="headerlink" title="1.3 When"></a>1.3 When</h3><p>在有大量IO操作业务的情况下，我们采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。</p><p>在协程中尽量不要调用阻塞IO的方法，比如打印，读取文件，Socket接口等，除非改为异步调用的方式，并且协程只有在IO密集型的任务中才会发挥作用。</p><p><strong>协程只有和异步IO结合起来才能发挥出最大的威力</strong>。</p><h2 id="2-QEMU中的协程"><a href="#2-QEMU中的协程" class="headerlink" title="2. QEMU中的协程"></a>2. QEMU中的协程</h2><h3 id="2-1-为什么qemu要使用协程"><a href="#2-1-为什么qemu要使用协程" class="headerlink" title="2.1 为什么qemu要使用协程"></a>2.1 为什么qemu要使用协程</h3><p><a href="https://lore.kernel.org/qemu-devel/1311672077-4592-1-git-send-email-stefanha@linux.vnet.ibm.com/" target="_blank" rel="noopener">Coroutines for better asynchronous programming</a></p><p>仔细阅读<a href="http://blog.vmsplice.net/2014/01/coroutines-in-qemu-basics.html" target="_blank" rel="noopener">Coroutines in QEMU: The basics</a> <em>Callback hell in event-driven programs</em>即可。The coroutine version is much easier to understand because the code is sequential. Under the hood the coroutine version returns back to the event loop just like the callback version. Therefore the code still uses the event loop but it can be written like a sequential program.</p><blockquote><p>Coroutines make it possible to write sequential code that is actually executed across multiple iterations of the event loop. This is useful for code that needs to perform blocking I/O and would quickly become messy if split into a chain of callback functions. </p></blockquote><h3 id="2-2-The-QEMU-coroutine-API"><a href="#2-2-The-QEMU-coroutine-API" class="headerlink" title="2.2 The QEMU coroutine API"></a>2.2 The QEMU coroutine API</h3><p>The coroutine API is documented in <a href="https://gitlab.com/qemu-project/qemu/-/blob/stable-6.0/include/qemu/coroutine.h" target="_blank" rel="noopener">include/qemu/coroutine.h</a>. The main functions are:</p><h4 id="2-2-1-create-coroutine"><a href="#2-2-1-create-coroutine" class="headerlink" title="2.2.1 create coroutine"></a>2.2.1 create coroutine</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Coroutine entry point</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * When the coroutine is entered for the first time, opaque is passed in as an</span></span><br><span class="line"><span class="comment"> * argument.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * When this function returns, the coroutine is destroyed automatically and</span></span><br><span class="line"><span class="comment"> * execution continues in the caller who last entered the coroutine.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="keyword">void</span> coroutine_fn <span class="title">CoroutineEntry</span><span class="params">(<span class="keyword">void</span> *opaque)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Create a new coroutine</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Use qemu_coroutine_enter() to actually transfer control to the coroutine.</span></span><br><span class="line"><span class="comment"> * The opaque argument is passed as the argument to the entry point.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">Coroutine *<span class="title">qemu_coroutine_create</span><span class="params">(CoroutineEntry *entry, <span class="keyword">void</span> *opaque)</span></span>;</span><br></pre></td></tr></table></figure><p>When a new coroutine is started, it will begin executing the entry function. The caller can pass an opaque pointer to data needed by the coroutine.</p><h4 id="2-2-2-execute-coroutine"><a href="#2-2-2-execute-coroutine" class="headerlink" title="2.2.2 execute coroutine"></a>2.2.2 execute coroutine</h4><p>The new coroutine is executed by calling <code>qemu_coroutine_enter</code>:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Transfer control to a coroutine</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">qemu_coroutine_enter</span><span class="params">(Coroutine *coroutine)</span></span>;</span><br></pre></td></tr></table></figure></p><h4 id="2-2-3-yield-coroutine"><a href="#2-2-3-yield-coroutine" class="headerlink" title="2.2.3 yield coroutine"></a>2.2.3 yield coroutine</h4><p>If the coroutine needs to wait for an event such as I/O completion or user input, it calls <code>qemu_coroutine_yield</code>:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Transfer control back to a coroutine's caller</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This function does not return until the coroutine is re-entered using</span></span><br><span class="line"><span class="comment"> * qemu_coroutine_enter().</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> coroutine_fn <span class="title">qemu_coroutine_yield</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br></pre></td></tr></table></figure></p><p>The yield function transfers control back to the <code>qemu_coroutine_enter</code> caller. The coroutine can be re-entered at a later point in time by calling <code>qemu_coroutine_enter</code>, for example, when an I/O request has completed.</p><hr><p>参考资料:</p><ol><li><a href="http://blog.vmsplice.net/2014/01/coroutines-in-qemu-basics.html" target="_blank" rel="noopener">Coroutines in QEMU: The basics</a></li><li><a href="https://royhunter.github.io/2016/06/24/qemu-coroutine/" target="_blank" rel="noopener">QEMU中的协程—qemu-coroutine</a></li><li><a href="https://zhuanlan.zhihu.com/p/172471249" target="_blank" rel="noopener">什么是协程？</a></li><li><a href="https://mp.weixin.qq.com/s/SyWjLg3lYx3pIJQfEtik8Q" target="_blank" rel="noopener">​浅谈协程</a></li><li><a href="https://mp.weixin.qq.com/s/IO4ynnKEfy2Rt-Me7EIeqg" target="_blank" rel="noopener">当谈论协程时，我们在谈论什么</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下协程(Coroutines)相关notes。
    
    </summary>
    
      <category term="操作系统" scheme="http://liujunming.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="QEMU" scheme="http://liujunming.github.io/tags/QEMU/"/>
    
      <category term="操作系统" scheme="http://liujunming.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>如何mount虚拟机镜像</title>
    <link href="http://liujunming.github.io/2023/05/01/%E5%A6%82%E4%BD%95mount%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%95%9C%E5%83%8F/"/>
    <id>http://liujunming.github.io/2023/05/01/如何mount虚拟机镜像/</id>
    <published>2023-05-01T11:49:38.000Z</published>
    <updated>2023-05-01T12:36:17.731Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍下mount虚拟机镜像的方法。 <a id="more"></a></p><h3 id="losetup"><a href="#losetup" class="headerlink" title="losetup"></a>losetup</h3><p>losetup只能mount raw格式的镜像。</p><p>To check what is the first usable loop device, run<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">losetup -f</span><br></pre></td></tr></table></figure></p><p>After that, use the output of that command to link the disk image to the loop device file (using root privileges):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">losetup -P /dev/loopX example.img</span><br></pre></td></tr></table></figure></p><p>The -P flag searches through the image for partitions, which you need to mount.</p><p>After that, create the folder named example and run the command:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/loopXpY example</span><br></pre></td></tr></table></figure></p><p>The disk image should now be mounted in that directory. Depending on the Y variable, the right partition was mounted.</p><h3 id="qemu-nbd"><a href="#qemu-nbd" class="headerlink" title="qemu-nbd"></a>qemu-nbd</h3><p>Export a QEMU disk image using the NBD protocol.</p><p>qemu-nbd可以mount多种格式的虚拟机镜像，因此适用范围比losetup要广！</p><ul><li><p>Enable NBD on the host</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modprobe nbd max_part=8</span><br></pre></td></tr></table></figure></li><li><p>Connect the QCOW2 as a network block device</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-nbd -c /dev/nbd0 /var/lib/vz/images/100/vm-100-disk-1.qcow2</span><br></pre></td></tr></table></figure></li><li><p>List partitions inside the QCOW2</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fdisk /dev/nbd0 -l</span><br></pre></td></tr></table></figure></li><li><p>Mount the partition from the VM</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/nbd0p1 /mnt/somepoint/</span><br></pre></td></tr></table></figure></li><li><p>After you’re done, unmount and disconnect</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">umount /mnt/somepoint/</span><br><span class="line">qemu-nbd -d /dev/nbd0</span><br><span class="line">rmmod nbd</span><br></pre></td></tr></table></figure></li></ul><hr><p>参考资料:</p><ol><li><a href="https://iaguozhi.github.io/blogs/Change-vm-kernel-by-qemu-nbd.html" target="_blank" rel="noopener">记录一次将虚拟机kernel写坏之后的修复过程</a></li><li><a href="https://www.qemu.org/docs/master/tools/qemu-nbd.html" target="_blank" rel="noopener">QEMU Disk Network Block Device Server</a></li><li><a href="https://eloydegen.com/blog/posts/losetup/" target="_blank" rel="noopener">Mount disk images using losetup</a></li><li><a href="https://www.man7.org/linux/man-pages/man8/losetup.8.html" target="_blank" rel="noopener">man losetup</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍下mount虚拟机镜像的方法。
    
    </summary>
    
      <category term="工具" scheme="http://liujunming.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://liujunming.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Notes about GPU Direct Storage</title>
    <link href="http://liujunming.github.io/2023/05/01/Notes-about-GPU-Direct-Storage/"/>
    <id>http://liujunming.github.io/2023/05/01/Notes-about-GPU-Direct-Storage/</id>
    <published>2023-05-01T07:32:26.000Z</published>
    <updated>2023-05-01T11:29:26.325Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下GPU Direct Storage相关notes。<a id="more"></a></p><blockquote><p>从IO读取链路来看，NVMe控制器通过DMA引擎将硬盘数据直接写入GPU显存，避免了主机内存和CPU的参与，从而实现CPU和主存的IO旁路，使IO吞吐能力不在受限于系统总线的带宽压力。</p></blockquote><p>说白了，就是支持NVMe与GPU的PCIe p2p，不过只支持NVMe到GPU的方向。</p><p><img src="/images/2023/05/01.png" alt></p><p><strong>GPUDirect Storage</strong> enables a direct data path between local or remote storage, such as NVMe or NVMe over Fabric (NVMe-oF), and GPU memory. It avoids extra copies through a bounce buffer in the CPU’s memory, enabling a direct memory access (DMA) engine near the NIC or storage to move data on a direct path into or out of GPU memory — all without burdening the CPU.</p><hr><p>参考资料:</p><ol><li><a href="https://zhuanlan.zhihu.com/p/509396439" target="_blank" rel="noopener">GPU Direct Storage</a></li><li><a href="https://developer.nvidia.com/gpudirect" target="_blank" rel="noopener">NVIDIA GPUDirect</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下GPU Direct Storage相关notes。
    
    </summary>
    
      <category term="体系结构" scheme="http://liujunming.github.io/categories/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="体系结构" scheme="http://liujunming.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
      <category term="GPU" scheme="http://liujunming.github.io/tags/GPU/"/>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about hyper_dmabuf</title>
    <link href="http://liujunming.github.io/2023/04/30/Notes-about-hyper-dmabuf/"/>
    <id>http://liujunming.github.io/2023/04/30/Notes-about-hyper-dmabuf/</id>
    <published>2023-04-30T12:26:38.000Z</published>
    <updated>2023-04-30T13:22:49.838Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下hyper_dmabuf相关notes。<a id="more"></a><br><img src="/images/2023/04/20.png" alt></p><p>Hyper_DMABUF driver is a Linux device driver running on multiple Virtual achines (VMs), which expands DMA-BUF sharing capability to the VM environment where multiple different OS instances need to share same physical data without data-copy across VMs.</p><p>To share a DMA_BUF across VMs, an instance of the Hyper_DMABUF drv on the exporting VM (so called, “exporter”) imports a local DMA_BUF from the original producer of the buffer, then re-exports it with an unique ID, hyper_dmabuf_id for the buffer to the importing VM (so called, “importer”).</p><p>Another instance of the Hyper_DMABUF driver on importer registers a hyper_dmabuf_id together with reference information for the shared physical pages associated with the DMA_BUF to its database when the export happens.</p><p>The actual mapping of the DMA_BUF on the importer’s side is done by the Hyper_DMABUF driver when user space issues the IOCTL command to access the shared DMA_BUF. The Hyper_DMABUF driver works as both an importing and exporting driver as is, that is, no special configuration is required. Consequently, only a single module per VM is needed to enable cross-VM DMA_BUF exchange.</p><hr><p>参考资料:</p><ol><li><a href="https://projectacrn.github.io/1.6.1/developer-guides/hld/hld-APL_GVT-g.html#hyper-dma-buffer-sharing" target="_blank" rel="noopener">Hyper DMA Buffer Sharing</a></li><li><a href="https://github.com/downor/linux_hyper_dmabuf/blob/hyper_dmabuf_integration_v4/Documentation/hyper-dmabuf-sharing.txt" target="_blank" rel="noopener">Linux Hyper DMABUF Driver</a></li><li><a href="https://lists.freedesktop.org/archives/dri-devel/2017-December/160709.html" target="_blank" rel="noopener">hyper_dmabuf: initial working version of hyper_dmabuf drv</a></li><li><a href="https://www.phoronix.com/news/Intel-Hyper-DMA-BUF" target="_blank" rel="noopener">Intel Introduces “Hyper DMA-BUF” To Exchange Buffers Between VMs</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下hyper_dmabuf相关notes。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Notes about dma_buf</title>
    <link href="http://liujunming.github.io/2023/04/30/Notes-about-dma-buf/"/>
    <id>http://liujunming.github.io/2023/04/30/Notes-about-dma-buf/</id>
    <published>2023-04-30T06:25:25.000Z</published>
    <updated>2023-04-30T08:16:16.512Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下dma_buf相关notes。<a id="more"></a></p><h3 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h3><p><img src="/images/2023/04/17.jpg" alt><br>以摄像头采集数据，GPU显示数据为例。摄像头设备将数据DMA到内存中后，GPU需要将这些DMA内存进行显示，也就是说摄像头DMA的输出数据是GPU的DMA输入数据。如果没有DMA buffer sharing机制，则需要将摄像头的DMA数据拷贝一份以搬到GPU的DMA数据中，因此存在内存copy的开销！<br>dma_buf则提供了一套统一框架，可以实现不同device的驱动之间DMA buffer的sharing，同时还允许userspace mmap共享的DMA buffer！</p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p><img src="/images/2023/04/19.jpg" alt></p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/images/2023/04/18.jpg" alt></p><p><img src="/images/2023/04/14.png" alt></p><h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p><img src="/images/2023/04/13.png" alt></p><p><img src="/images/2023/04/15.png" alt><br><img src="/images/2023/04/16.png" alt></p><hr><p>参考资料:</p><ol><li><a href="https://blog.csdn.net/hexiaolong2009/article/details/102596744" target="_blank" rel="noopener">dma-buf 由浅入深（一） —— 最简单的 dma-buf 驱动程序</a></li><li><a href="https://github.com/hexiaolong2008/sample-code/tree/master/dma-buf/08" target="_blank" rel="noopener">dma-buf</a></li><li><a href="https://saiyn.github.io/homepage/2018/04/18/linux-kernel-dmabuf/" target="_blank" rel="noopener">Linux内核笔记之DMA_BUF</a></li><li><a href="https://elinux.org/images/a/a8/DMA_Buffer_Sharing-_An_Introduction.pdf" target="_blank" rel="noopener">DMA Buffer Sharing Framework:An Introduction</a></li><li><a href="https://www.openfabrics.org/wp-content/uploads/2020-workshop-presentations/303.-OFI-GPU-DMA-BUF-OFA2020v2.pdf" target="_blank" rel="noopener">RDMA WITH GPU MEMORY VIA DMA-BUF</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTc0ODAzMw==&amp;mid=2247502900&amp;idx=1&amp;sn=dd73aae7e7b296317fbff613d475888e&amp;chksm=ce9ad01af9ed590c71f309a8b4ba4bad72dda1d75f9af5d153caf5dd11e229aa75c8507685c7&amp;mpshare=1&amp;scene=1&amp;srcid=0403TMj3qA6LY1DDtxctawJO&amp;sharer_sharetime=1648995232072&amp;sharer_shareid=fcd8378fa2afcbc997c8bd7f888f36e6&amp;exportkey=AZdgR1ASyNPvcNHeaNH3PpE%3D&amp;acctmode=0&amp;pass_ticket=bxkMR5mJMnjqkgrSRKMG4Na40WpTHdV%2FfvZCJEtYhn3FUItw%2FA0ZMr0FE2oTAbbL&amp;wx_header=0#rd" target="_blank" rel="noopener">dma-buf学习分享</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下dma_buf相关notes。
    
    </summary>
    
      <category term="Kernel" scheme="http://liujunming.github.io/categories/Kernel/"/>
    
    
      <category term="Kernel" scheme="http://liujunming.github.io/tags/Kernel/"/>
    
  </entry>
  
  <entry>
    <title>Notes about TSO、GSO、LRO、GRO</title>
    <link href="http://liujunming.github.io/2023/04/23/Notes-about-TSO%E3%80%81GSO%E3%80%81LRO%E3%80%81GRO/"/>
    <id>http://liujunming.github.io/2023/04/23/Notes-about-TSO、GSO、LRO、GRO/</id>
    <published>2023-04-23T09:21:32.000Z</published>
    <updated>2023-04-23T10:35:19.351Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自<a href="https://mp.weixin.qq.com/s/jtKtdtSS15dRaivtdcAbQQ" target="_blank" rel="noopener">图解网络Offload</a>，将介绍TSO、GSO、LRO、GRO相关笔记。<a id="more"></a></p><p>网络应用程序如果要发送很大的数据包，经过内核协议栈的时，大包会被分片成多个不超过MTU长度的包。这个分片比较费CPU资源。Offload技术可以把这些分片和合并的工作进行优化处理，也可以直接Offload到网卡上。</p><h3 id="MTU"><a href="#MTU" class="headerlink" title="MTU"></a>MTU</h3><p>MTU是一个二层的概念，即最大传输单元（Maximum Transmission Unit，MTU），它不包含二层以太网头尾数据。网卡发送数据包的大小都是限制在MTU内的。<br><img src="/images/2023/04/06.png" alt></p><p>Offload涉及到四个概念：TSO、GSO、LRO、GRO。（当然还有UDP的UFO，以及一些checksum的Offload，在这里不讨论。）</p><h3 id="TSO"><a href="#TSO" class="headerlink" title="TSO"></a>TSO</h3><p>TSO(TCP Segmentation Offload)是一种利用网卡对大数据包进行分片，从而减小CPU负荷的一种技术。其作用通过两个图来对比：</p><p>TSO off和GSO off 状态数据包的发送过程：<br><img src="/images/2023/04/07.png" alt></p><p>TSO on状态数据包的发送过程：<br><img src="/images/2023/04/08.png" alt><br>一个大的网络包直到进入网卡内部后才由网卡进行了分片。</p><h3 id="GSO"><a href="#GSO" class="headerlink" title="GSO"></a>GSO</h3><p>GSO（Generic Segmentation Offload）是延缓分片技术。它比TSO更通用，原因在于它不需要硬件的支持就可以进行分片。</p><p>其过程是：首先查询网卡是否支持TSO功能，如果硬件支持TSO则使用网卡的硬件分片能力执行分片；如果网卡不支持 TSO 功能，则将分片的执行，延缓到了将数据推送到网卡的前一刻执行。</p><p>网卡关闭TSO时，GSO on状态数据包的发送过程：<br><img src="/images/2023/04/09.png" alt></p><p>一个大的网络包直到进入网卡前的最后一步才进行了分片。</p><p>TSO和GSO对应数据发送过程，对应数据接收过程的是LRO和GRO。</p><h3 id="LRO"><a href="#LRO" class="headerlink" title="LRO"></a>LRO</h3><p>LRO（Large Receive Offload）是将网卡接收到的多个数据包合并成一个大的数据包，然后再传递给网络协议栈处理的技术。这样可以提高系统接收数据包的能力，减轻CPU负载。</p><p>LRO off和GRO off 状态数据包的接收过程：<br><img src="/images/2023/04/10.png" alt></p><p>LRO on状态数据包的接收过程：<br><img src="/images/2023/04/11.png" alt><br>数据一进入网卡立刻进行了合并。</p><h3 id="GRO"><a href="#GRO" class="headerlink" title="GRO"></a>GRO</h3><p>GRO（Generic Receive Offload）是LRO 的软件实现，只是GRO 的合并条件更加的严格和灵活。</p><p>GRO on状态数据包的接收过程：<br><img src="/images/2023/04/12.png" alt></p><p>以上的网络offload是网络协议栈配合网卡完成的，在现在的很多智能网卡上可以直接offload整个网络协议栈，即把网络协议的处理放到了智能网卡上。</p><hr><p>参考资料:</p><ol><li><a href="https://mp.weixin.qq.com/s/jtKtdtSS15dRaivtdcAbQQ" target="_blank" rel="noopener">图解网络Offload</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自&lt;a href=&quot;https://mp.weixin.qq.com/s/jtKtdtSS15dRaivtdcAbQQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;图解网络Offload&lt;/a&gt;，将介绍TSO、GSO、LRO、GRO相关笔记。
    
    </summary>
    
      <category term="计算机网络" scheme="http://liujunming.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://liujunming.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Notes about 零拷贝技术splice</title>
    <link href="http://liujunming.github.io/2023/04/23/Notes-about-%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AFsplice/"/>
    <id>http://liujunming.github.io/2023/04/23/Notes-about-零拷贝技术splice/</id>
    <published>2023-04-23T06:22:39.000Z</published>
    <updated>2023-04-23T06:32:45.106Z</updated>
    
    <content type="html"><![CDATA[<p>转载自:<a href="https://mp.weixin.qq.com/s?__biz=MzA3NzYzODg1OA==&amp;mid=2648466923&amp;idx=1&amp;sn=acf2fb71a960f3831f9b98657b39d4ce&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文读懂零拷贝技术｜splice使用</a>。<a id="more"></a><br>服务端要向客户端连接发送一个文件，一般过程如下：</p><ul><li>服务端首先调用 <code>read()</code> 函数读取文件内容。</li><li>服务端通过调用 <code>write()</code>/<code>send()</code> 函数将文件内容发送给客户端连接。</li></ul><p>上面过程如下图所示：</p><p><img src="/images/2023/04/04.jpeg" alt></p><p>从上图可以看出，在发送文件的过程中，首先需要将文件页缓存（Page Cache）从内核态复制到用户态缓存中，然后再从用户态缓存复制到客户端的 Socket 缓冲区中。</p><p>其实在上面的过程中，复制文件数据到用户态缓存这个操作是多余的，我们完全可以直接把文件页缓存的数据复制到 Socket 缓冲区即可，这样就可以减少一次拷贝数据的操作。</p><p>为了实现这样的功能，内核提供了一个名为 <code>splice()</code>的系统调用，使用 <code>splice()</code>系统调用可以避免从内核态拷贝数据到用户态。</p><blockquote><p>不需要将内核态的数据拷贝到用户态缓存的技术被称为：<code>零拷贝技术</code>。</p></blockquote><p><img src="/images/2023/04/05.jpeg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://mp.weixin.qq.com/s?__biz=MzA3NzYzODg1OA==&amp;mid=2648466923&amp;idx=1&amp;sn=acf2fb71a960f3831f9b98657b39d4ce&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文读懂零拷贝技术｜splice使用</a></li><li><a href="https://mp.weixin.qq.com/s/vN1VIgX73arke4put_cyRg" target="_blank" rel="noopener">一文读懂零拷贝技术｜splice原理与实现</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转载自:&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3NzYzODg1OA==&amp;amp;mid=2648466923&amp;amp;idx=1&amp;amp;sn=acf2fb71a960f3831f9b98657b39d4ce&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;一文读懂零拷贝技术｜splice使用&lt;/a&gt;。
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux IOMMU bypass method</title>
    <link href="http://liujunming.github.io/2023/04/22/Linux-IOMMU-bypass-method/"/>
    <id>http://liujunming.github.io/2023/04/22/Linux-IOMMU-bypass-method/</id>
    <published>2023-04-22T08:45:06.000Z</published>
    <updated>2023-04-22T09:30:38.240Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/2023/04/01.jpg" alt><br><a id="more"></a><br><img src="/images/2023/04/03.jpg" alt></p><p><img src="/images/2023/04/02.jpg" alt><br>将AT字段设置为10b即可bypass IOMMU。</p><p><a href="/2019/11/24/Introduction-to-PCIe-Address-Translation-Services/">ATC</a>的深入理解：如果设备在ATC中找到对应的映射entry后，会将TLP AT字段设置为10b，并将TLP中的address字段设置为翻译后的地址。</p><hr><p>参考资料:</p><ol><li><a href="https://pdfs.semanticscholar.org/b450/50db1fb770a07bc60c66d3532ee4d1949ccb.pdf" target="_blank" rel="noopener">Thunderclap:Exploring Vulnerabilities in Operating System IOMMU Protection via DMA from Untrustworthy Peripherals</a></li><li>PCIe spec</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/2023/04/01.jpg&quot; alt&gt;&lt;br&gt;
    
    </summary>
    
      <category term="IOMMU" scheme="http://liujunming.github.io/categories/IOMMU/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
      <category term="IOMMU" scheme="http://liujunming.github.io/tags/IOMMU/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Root Complex</title>
    <link href="http://liujunming.github.io/2023/02/12/Notes-about-root-complex/"/>
    <id>http://liujunming.github.io/2023/02/12/Notes-about-root-complex/</id>
    <published>2023-02-12T09:36:29.000Z</published>
    <updated>2023-02-12T10:19:59.731Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Root Complex(RC)相关笔记。<br><img src="/images/2023/02/06.png" alt></p><a id="more"></a><p>The Root Complex is an entity that includes a Host Bridge and one or more root ports.<br><img src="/images/2023/02/07.png" alt></p><p>当CPU读写pcie设备的MMIO BAR时，RC的Host Bridge将processor transactions转换为TLP。因此当host bridge发现CPU访问的物理地址区间是MMIO时，会让目标EP(End Point)所属的root port发送memory read/write TLP，经过路由，最终TLP会下发到目标EP。</p><hr><p>参考资料:</p><ol><li><a href="http://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-1/" target="_blank" rel="noopener">Down to the TLP: How PCI express devices talk</a></li><li><a href="https://astralvx.com/introduction-to-pcie/" target="_blank" rel="noopener">Introduction to PCIe</a></li><li><a href="https://zhuanlan.zhihu.com/p/32786076" target="_blank" rel="noopener">使用Xilinx IP核进行PCIE开发学习笔记</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Root Complex(RC)相关笔记。&lt;br&gt;&lt;img src=&quot;/images/2023/02/06.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/categories/PCI-PCIe/"/>
    
    
      <category term="PCI&amp;PCIe" scheme="http://liujunming.github.io/tags/PCI-PCIe/"/>
    
  </entry>
  
  <entry>
    <title>Notes about vsock</title>
    <link href="http://liujunming.github.io/2023/02/11/Notes-about-vsock/"/>
    <id>http://liujunming.github.io/2023/02/11/Notes-about-vsock/</id>
    <published>2023-02-11T04:59:37.000Z</published>
    <updated>2023-02-11T06:11:05.414Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录vsock相关Notes。<a id="more"></a></p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p>VM Sockets(vsock) is a fast and efficient communication mechanism between guest virtual machines and their host. 说白了，就是允许guest与host利用socket进行通信(不依赖于虚拟机的网卡)，借助于网卡，guest与host也是可以进行socket通信的，但此时就不是vsock了。使用vsock进行socket编程时，需要使用新的socket address family AF_VSOCK。</p><h3 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h3><p><img src="/images/2023/02/01.jpg" alt><br><img src="/images/2023/02/02.jpg" alt><br><img src="/images/2023/02/03.jpg" alt></p><h3 id="How"><a href="#How" class="headerlink" title="How"></a>How</h3><p><img src="/images/2023/02/04.jpg" alt><br>There are several layers here.</p><ul><li>application, use &lt;cid,port&gt; as a socket address</li><li>socket layer, support for socket API</li><li>AF_VSOCK address family, implement the vsock core</li><li>transport, trasnport the data between guest and host.</li></ul><p>The transport layer is the mostly needed to talk as the other three just need to implement standand interfaces in kernel.</p><p>Transport as its name indicated, is used to transport the data between guest and host just like the networking card transport data between local and remote socket. There are two kinds of transports according to data’s flow direction.</p><ul><li>G2H: guest-&gt;host transport, they run in the guest and the guest vsock networking protocol uses this to communication with the host.</li><li>H2G: host-&gt;guest transport, they run in the host and the host vsock networing protocol uses this to communiction with the guest.</li></ul><p>Usually H2G transport is implemented as a device emulation, and G2H transport is implemented as the emulated device’s driver. For example, in VMware the H2G transport is a emulated vmci PCI device and the G2H is vmci device driver. In qemu the H2G transport is a emulated vhost-vsock device and the G2H transport is the vosck device’s driver.</p><p>Following picture shows the virtio(in guest) and vhost(in host) transport.<br><img src="/images/2023/02/05.jpg" alt></p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>可以参考 <a href="https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6" target="_blank" rel="noopener">https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6</a><br>在qemu-kvm + Linux guest环境中搭建vsock环境。</p><hr><p>参考资料:</p><ol><li><a href="https://vmsplice.net/~stefan/stefanha-kvm-forum-2015.pdf" target="_blank" rel="noopener">virtio-vsock Zero-configuration host/guest communication</a></li><li><a href="https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6" target="_blank" rel="noopener">https://gist.github.com/nrdmn/7971be650919b112343b1cb2757a3fe6</a></li><li><a href="https://terenceli.github.io/%E6%8A%80%E6%9C%AF/2020/04/18/vsock-internals" target="_blank" rel="noopener">Linux vsock internals</a></li><li><a href="https://static.sched.com/hosted_files/devconfcz2020a/b1/DevConf.CZ_2020_vsock_v1.1.pdf" target="_blank" rel="noopener">VSOCK: VM ↔ host socket with minimal configuration</a></li><li><a href="https://www.man7.org/linux/man-pages/man7/vsock.7.html" target="_blank" rel="noopener">man vsock</a></li><li><a href="https://iaguozhi.github.io/blogs/vsock.html" target="_blank" rel="noopener">vsock 介绍与使用</a></li><li><a href="https://lwn.net/Articles/556550/" target="_blank" rel="noopener">Introduce VM Sockets virtio transport</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录vsock相关Notes。
    
    </summary>
    
      <category term="虚拟化" scheme="http://liujunming.github.io/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
    
      <category term="虚拟化" scheme="http://liujunming.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Intel Hyper-Threading Technology</title>
    <link href="http://liujunming.github.io/2023/01/07/Notes-about-Intel-Hyper-Threading-Technology/"/>
    <id>http://liujunming.github.io/2023/01/07/Notes-about-Intel-Hyper-Threading-Technology/</id>
    <published>2023-01-07T05:33:43.000Z</published>
    <updated>2023-01-07T06:52:51.063Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录下作者对intel 超线程(Hyper-Threading)技术的理解。 <a id="more"></a> </p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/images/2023/01/01.jpg" alt><br><img src="/images/2023/01/02.jpg" alt><br>根据sdm的描述，同一个core上的两个超线程其实是共享execution engine的。</p><p><img src="/images/2023/01/03.jpg" alt><br>每个超线程拥有独立的通用寄存器。每个超线程的具体资源状态需要查询spec，本文不在此赘述。</p><h3 id="Execution-Engine"><a href="#Execution-Engine" class="headerlink" title="Execution Engine"></a>Execution Engine</h3><p><img src="/images/2023/01/04.jpg" alt><br>Execution Engine涉及到具体的微架构。接下来将以Ice Lake Client microarchitecture为例来介绍下Execution Engine。</p><p><img src="/images/2023/01/05.jpg" alt><br><img src="/images/2023/01/06.jpg" alt></p><p>Execution Unit是需要额外关注的。由上图可知，在一个Execution Engine内拥有4个ALU，1个Slow Int。</p><ul><li>同一个core上的两个超线程想同时执行<code>add</code>指令，这理论上是可行的，因为Execution Engine中有四个ALU Execution Unit(ALU可运行<code>add</code>指令)。</li><li>同一个core上的两个超线程想同时执行<code>mul</code>指令，这理论上是不可行的，因为Execution Engine中只有一个Slow Int Execution Unit(Slow Int可运行<code>mul</code>指令)。</li></ul><hr><p>参考资料:</p><ol><li><a href="https://cdrdv2.intel.com/v1/dl/getContent/671488" target="_blank" rel="noopener">Intel® 64 and IA-32 Architectures Optimization Reference Manual</a></li><li><a href="https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-lipp.pdf" target="_blank" rel="noopener">Meltdown: Reading Kernel Memory from User Space</a></li><li>Intel SDM Vol3</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录下作者对intel 超线程(Hyper-Threading)技术的理解。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="体系结构" scheme="http://liujunming.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
  <entry>
    <title>Notes about signal in Linux</title>
    <link href="http://liujunming.github.io/2022/12/18/Notes-about-signal-in-Linux/"/>
    <id>http://liujunming.github.io/2022/12/18/Notes-about-signal-in-Linux/</id>
    <published>2022-12-18T06:38:23.000Z</published>
    <updated>2022-12-18T08:21:07.581Z</updated>
    
    <content type="html"><![CDATA[<p>本文将mark下Linux的signal相关notes。<a id="more"></a><br><img src="/images/2022/12/05.jpg" alt></p><h3 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h3><p><a href="https://blog.csdn.net/w903414/article/details/109802539" target="_blank" rel="noopener">一篇文章彻底搞定信号</a></p><h4 id="信号是什么"><a href="#信号是什么" class="headerlink" title="信号是什么"></a>信号是什么</h4><p>例：</p><ol><li>输入命令，在Shell下启动一个前台进程。</li><li>用户按下Ctrl-C，键盘输入产生一个硬件中断。</li><li>如果CPU当前正在执行这个进程的代码，则该进程的用户空间代码暂停执行， CPU从用户态切换到内核态处理硬件中断。</li><li>终端驱动程序将Ctrl-C解释成一个<code>SIGINT</code>信号，记在该进程的PCB中（也可以说发送了一个<code>SIGINT</code>信号给该进程）。</li><li>当某个时刻要从内核返回到该进程的用户空间代码继续执行之前，首先处理PCB中记录的信号，发现有一个<code>SIGINT</code>信号待处理，而这个信号的默认处理动作是终止进程，所以直接终止进程而不再返回它的用户空间代码执行。</li></ol><p>在这个例子中，由Ctrl-C产生的硬件中断就是一个信号。Ctrl+C产生的信号只能发送给前台进程，命令后加&amp;就可放到后台运行。Shell可同时运行一个前台进程和任意多个后台进程，只有前台进程才能接受到像CTRL+C这种控制键产生的信号。</p><h4 id="信号的种类"><a href="#信号的种类" class="headerlink" title="信号的种类"></a>信号的种类</h4><h4 id="信号的产生"><a href="#信号的产生" class="headerlink" title="信号的产生"></a>信号的产生</h4><ul><li>硬件产生</li><li>软件产生</li></ul><h4 id="信号的注册"><a href="#信号的注册" class="headerlink" title="信号的注册"></a>信号的注册</h4><p>信号注册实际上是一个位图和一个sigqueue队列。<br><img src="/images/2022/12/06.png" alt></p><h4 id="信号的注销"><a href="#信号的注销" class="headerlink" title="信号的注销"></a>信号的注销</h4><h4 id="信号阻塞"><a href="#信号阻塞" class="headerlink" title="信号阻塞"></a>信号阻塞</h4><p><img src="/images/2022/12/07.png" alt></p><h4 id="信号未决"><a href="#信号未决" class="headerlink" title="信号未决"></a>信号未决</h4><p>实际执行信号的处理动作称为信号递达（Delivery），信号从产生到递达之间的状态，称为信号未决（Pending）。进程可以选择阻塞（Block）某个信号。被阻塞的信号产生时将保持在未决状态，直到进程解除对此信号的阻塞，才执行递达的动作。注意，阻塞和忽略是不同的，只要信号被阻塞就不会递达，而忽略是在递达之后可选的一种处理动作。</p><h4 id="信号的处理方式"><a href="#信号的处理方式" class="headerlink" title="信号的处理方式"></a>信号的处理方式</h4><p><img src="/images/2022/12/08.png" alt></p><p>每个信号都有两个标志位分别表示阻塞和未决，还有一个函数指针表示处理动作。</p><h4 id="信号的捕捉"><a href="#信号的捕捉" class="headerlink" title="信号的捕捉"></a>信号的捕捉</h4><p>条件: 如果信号的处理动作是用户自定义函数，在信号递达时就调用这个函数，这就称为信号捕捉。</p><p>流程:<br><img src="/images/2022/12/09.png" alt></p><p>内核态返回用户态会调用<code>do_signal</code>函数，两种情况：</p><ol><li>无信号：<code>sys_return</code>函数，返回用户态</li><li>有信号：先处理信号，信号返回，再调用<code>do_signal</code>函数 </li></ol><p>例：</p><ol><li>程序注册了<code>SIGQUIT</code>信号的处理函数sighandler。</li><li>当前正在执行main函数，这时发生中断或异常切换到内核态。</li><li>在中断处理完毕后要返回用户态的main函数之前检查到有信号SIGQUIT递达。</li><li>内核决定返回用户态后不是恢复main函数的上下文继续执行，而是执行sighandler函数， <strong>sighandler和main函数之间不存在调用和被调用的关系，是两个独立的控制流程。</strong></li><li>sighandler函数返回后自动执行特殊的系统调用sig_return再次进入内核态。</li><li>如果没有新的信号要递达，这次再返回用户态就是恢复main函数的上下文继续执行了。</li></ol><h4 id="常用信号集操作函数"><a href="#常用信号集操作函数" class="headerlink" title="常用信号集操作函数"></a>常用信号集操作函数</h4><h4 id="SIGCHLD信号"><a href="#SIGCHLD信号" class="headerlink" title="SIGCHLD信号"></a>SIGCHLD信号</h4><h3 id="SIGKILL-vs-SIGTERM"><a href="#SIGKILL-vs-SIGTERM" class="headerlink" title="SIGKILL vs SIGTERM"></a>SIGKILL vs SIGTERM</h3><p>Though both of these signals are used for killing a process, there are some differences between the two:</p><ul><li><code>SIGTERM</code> gracefully kills the process whereas <code>SIGKILL</code> kills the process immediately.</li><li><code>SIGTERM</code> signal can be handled, ignored, and blocked, but <code>SIGKILL</code> cannot be handled or blocked.</li><li><code>SIGTERM</code> doesn’t kill the child processes. <code>SIGKILL</code> kills the child processes as well.</li></ul><p><img src="https://linuxhandbook.com/content/images/2022/04/sigterm-vs-sigkill-tip.webp" alt></p><hr><p>参考资料:</p><ol><li><a href="https://www.man7.org/linux/man-pages/man7/signal.7.html" target="_blank" rel="noopener">man signal</a></li><li><a href="https://www-uxsup.csx.cam.ac.uk/courses/moved.Building/signals.pdf" target="_blank" rel="noopener">A list of signals and what they mean</a></li><li><a href="https://linuxhandbook.com/sigterm-vs-sigkill/#:~:text=Though%20both%20of%20these%20signals%20are%20used%20for,blocked%2C%20but%20SIGKILL%20cannot%20be%20handled%20or%20blocked." target="_blank" rel="noopener">SIGTERM vs SIGKILL: What’s the Difference?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将mark下Linux的signal相关notes。
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>深入解析virtio-blk resize原理</title>
    <link href="http://liujunming.github.io/2022/12/17/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90virtio-blk-resize%E5%8E%9F%E7%90%86/"/>
    <id>http://liujunming.github.io/2022/12/17/深入解析virtio-blk-resize原理/</id>
    <published>2022-12-17T07:05:05.000Z</published>
    <updated>2022-12-18T03:12:28.554Z</updated>
    
    <content type="html"><![CDATA[<p>本文将结合virtio spec、qemu与Linux kernel源码深入解析virtio-blk resize的原理。<a id="more"></a> </p><p>本文参考的virtio spec是<a href="https://ozlabs.org/~rusty/virtio-spec/virtio-0.9.5.pdf" target="_blank" rel="noopener">0.9.5</a>，qemu版本为<a href="https://gitlab.com/qemu-project/qemu/-/tree/v2.6.0" target="_blank" rel="noopener">v2.6.0</a>，Linux kernel版本为<a href="https://elixir.bootlin.com/linux/v4.19/source" target="_blank" rel="noopener">v4.19</a>。</p><h2 id="1-overview"><a href="#1-overview" class="headerlink" title="1. overview"></a>1. overview</h2><p>virtio-blk后端设备resize后，通过msi-x的configuration vector给guest发送中断，guest收到中断后，handler会读取virtio header中的capacity field来完成resize操作。</p><h2 id="2-基础知识"><a href="#2-基础知识" class="headerlink" title="2. 基础知识"></a>2. 基础知识</h2><p>virtio header中有configuration vector这个field。guest配置MSI-x table时，会配置好configuration vector。<br><img src="/images/2022/12/03.jpg" alt></p><p>当后端设备配置发生变化时，会触发configuration vector对应的中断。<br><img src="/images/2022/12/04.jpg" alt></p><p>对于virtio-blk设备，virtio header中的capacity存放了size信息。当resize时，capacity会发生变化。<br><img src="/images/2022/12/02.jpg" alt><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk_config</span> &#123;</span></span><br><span class="line"><span class="comment">/* The capacity (in 512-byte sectors). */</span></span><br><span class="line">__u64 capacity;</span><br><span class="line"><span class="comment">/* The maximum segment size (if VIRTIO_BLK_F_SIZE_MAX) */</span></span><br><span class="line">__u32 size_max;</span><br><span class="line"><span class="comment">/* The maximum number of segments (if VIRTIO_BLK_F_SEG_MAX) */</span></span><br><span class="line">__u32 seg_max;</span><br><span class="line"><span class="comment">/* geometry of the device (if VIRTIO_BLK_F_GEOMETRY) */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk_geometry</span> &#123;</span></span><br><span class="line">__u16 cylinders;</span><br><span class="line">__u8 heads;</span><br><span class="line">__u8 sectors;</span><br><span class="line">&#125; geometry;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* block size of device (if VIRTIO_BLK_F_BLK_SIZE) */</span></span><br><span class="line">__u32 blk_size;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* the next 4 entries are guarded by VIRTIO_BLK_F_TOPOLOGY  */</span></span><br><span class="line"><span class="comment">/* exponent for physical block per logical block. */</span></span><br><span class="line">__u8 physical_block_exp;</span><br><span class="line"><span class="comment">/* alignment offset in logical blocks. */</span></span><br><span class="line">__u8 alignment_offset;</span><br><span class="line"><span class="comment">/* minimum I/O size without performance penalty in logical blocks. */</span></span><br><span class="line">__u16 min_io_size;</span><br><span class="line"><span class="comment">/* optimal sustained I/O size in logical blocks. */</span></span><br><span class="line">__u32 opt_io_size;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* writeback mode (if VIRTIO_BLK_F_CONFIG_WCE) */</span></span><br><span class="line">__u8 wce;</span><br><span class="line">__u8 unused;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* number of vqs, only available when VIRTIO_BLK_F_MQ is set */</span></span><br><span class="line">__u16 num_queues;</span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure></p><h2 id="3-virtio-blk后端设备resize"><a href="#3-virtio-blk后端设备resize" class="headerlink" title="3. virtio-blk后端设备resize"></a>3. virtio-blk后端设备resize</h2><p>首先需要完成virtio-blk后端设备的resize，比如virtio-blk后端设备是一个文件，那么需要将这个文件resize！virtio-blk后端设备的形式较多，不在本文描述范围之内。</p><h2 id="4-QEMU发送configuration-vector中断"><a href="#4-QEMU发送configuration-vector中断" class="headerlink" title="4. QEMU发送configuration vector中断"></a>4. QEMU发送configuration vector中断</h2><h3 id="4-1-hmp-block-resize命令"><a href="#4-1-hmp-block-resize命令" class="headerlink" title="4.1 hmp block_resize命令"></a>4.1 hmp block_resize命令</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hmp_block_resize</span><br><span class="line">└── qmp_block_resize</span><br><span class="line">    └── bdrv_truncate</span><br><span class="line">        └── blk_dev_resize_cb</span><br><span class="line">            └── virtio_blk_resize[resize_cb]</span><br></pre></td></tr></table></figure><p>hmp <code>block_resize</code>命令的函数调用链如上所示，最终会调用到<code>virtio_blk_resize</code>函数。</p><h3 id="4-2-virtio-blk-resize发送configuration-vector中断"><a href="#4-2-virtio-blk-resize发送configuration-vector中断" class="headerlink" title="4.2 virtio_blk_resize发送configuration vector中断"></a>4.2 virtio_blk_resize发送configuration vector中断</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">virtio_blk_resize</span><br><span class="line">└── virtio_notify_config</span><br><span class="line">    └── virtio_notify_vector(vdev, vdev-&gt;config_vector)</span><br><span class="line">        └── virtio_pci_notify</span><br><span class="line">            └── msix_notify</span><br><span class="line">                ├── msix_get_message</span><br><span class="line">                └── msi_send_message</span><br></pre></td></tr></table></figure><p>最终qemu会调用<code>msi_send_message</code>往guest注入configuration vector中断(本质上是模拟memory write TLP)。</p><h2 id="5-guest处理configuration-vector中断"><a href="#5-guest处理configuration-vector中断" class="headerlink" title="5. guest处理configuration vector中断"></a>5. guest处理configuration vector中断</h2><h3 id="5-1-guest注册中断"><a href="#5-1-guest注册中断" class="headerlink" title="5.1 guest注册中断"></a>5.1 guest注册中断</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">vp_request_msix_vectors</span><span class="params">(struct virtio_device *vdev, <span class="keyword">int</span> nvectors,</span></span></span><br><span class="line"><span class="function"><span class="params">   <span class="keyword">bool</span> per_vq_vectors, struct irq_affinity *desc)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">err = request_irq(pci_irq_vector(vp_dev-&gt;pci_dev, v),</span><br><span class="line">vp_config_changed, <span class="number">0</span>, vp_dev-&gt;msix_names[v],</span><br><span class="line">vp_dev);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Handle a configuration change: Tell driver if it wants to know. */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> irqreturn_t <span class="title">vp_config_changed</span><span class="params">(<span class="keyword">int</span> irq, <span class="keyword">void</span> *opaque)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_pci_device</span> *<span class="title">vp_dev</span> = <span class="title">opaque</span>;</span></span><br><span class="line"></span><br><span class="line">virtio_config_changed(&amp;vp_dev-&gt;vdev);</span><br><span class="line"><span class="keyword">return</span> IRQ_HANDLED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">virtio_config_changed</span><span class="params">(struct virtio_device *dev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line"></span><br><span class="line">spin_lock_irqsave(&amp;dev-&gt;config_lock, flags);</span><br><span class="line">__virtio_config_changed(dev);</span><br><span class="line">spin_unlock_irqrestore(&amp;dev-&gt;config_lock, flags);</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL_GPL(virtio_config_changed);</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __virtio_config_changed(struct virtio_device *dev)</span><br><span class="line">&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_driver</span> *<span class="title">drv</span> = <span class="title">drv_to_virtio</span>(<span class="title">dev</span>-&gt;<span class="title">dev</span>.<span class="title">driver</span>);</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!dev-&gt;config_enabled)</span><br><span class="line">dev-&gt;config_change_pending = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (drv &amp;&amp; drv-&gt;config_changed)</span><br><span class="line">drv-&gt;config_changed(dev); <span class="comment">//for virtio-blk, it's virtblk_config_changed</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">virtio_driver</span> <span class="title">virtio_blk</span> = &#123;</span></span><br><span class="line">...</span><br><span class="line">.config_changed= virtblk_config_changed,</span><br><span class="line">...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtblk_config_changed</span><span class="params">(struct virtio_device *vdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk</span> *<span class="title">vblk</span> = <span class="title">vdev</span>-&gt;<span class="title">priv</span>;</span></span><br><span class="line"></span><br><span class="line">queue_work(virtblk_wq, &amp;vblk-&gt;config_work);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">virtblk_probe</span><span class="params">(struct virtio_device *vdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">INIT_WORK(&amp;vblk-&gt;config_work, virtblk_config_changed_work);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-2-中断handler处理resize"><a href="#5-2-中断handler处理resize" class="headerlink" title="5.2 中断handler处理resize"></a>5.2 中断handler处理resize</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">virtblk_config_changed_work</span><br><span class="line">└── virtblk_update_capacity</span><br><span class="line">    └── virtio_cread</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* The queue's logical block size must be set before calling this */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtblk_update_capacity</span><span class="params">(struct virtio_blk *vblk, <span class="keyword">bool</span> resize)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_device</span> *<span class="title">vdev</span> = <span class="title">vblk</span>-&gt;<span class="title">vdev</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">request_queue</span> *<span class="title">q</span> = <span class="title">vblk</span>-&gt;<span class="title">disk</span>-&gt;<span class="title">queue</span>;</span></span><br><span class="line"><span class="keyword">char</span> cap_str_2[<span class="number">10</span>], cap_str_10[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> nblocks;</span><br><span class="line">u64 capacity;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Host must always specify the capacity. */</span></span><br><span class="line">virtio_cread(vdev, struct virtio_blk_config, capacity, &amp;capacity);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>virtio_cread(vdev, struct virtio_blk_config, capacity, &amp;capacity)</code>其实就是读virtio header中的capacity field，此时会发生VM Exit trap到qemu中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Config space accessors. */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> virtio_cread(vdev, structname, member, ptr)\</span></span><br><span class="line"><span class="keyword">do</span> &#123;\</span><br><span class="line"><span class="comment">/* Must match the member's type, and be integer */</span>\</span><br><span class="line"><span class="keyword">if</span> (!typecheck(typeof((((structname*)<span class="number">0</span>)-&gt;member)), *(ptr))) \</span><br><span class="line">(*ptr) = <span class="number">1</span>;\</span><br><span class="line">\</span><br><span class="line"><span class="keyword">switch</span> (<span class="keyword">sizeof</span>(*ptr)) &#123;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">1</span>:\</span><br><span class="line">*(ptr) = virtio_cread8(vdev,\</span><br><span class="line">       offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">2</span>:\</span><br><span class="line">*(ptr) = virtio_cread16(vdev,\</span><br><span class="line">offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">4</span>:\</span><br><span class="line">*(ptr) = virtio_cread32(vdev,\</span><br><span class="line">offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">case</span> <span class="number">8</span>:\</span><br><span class="line">*(ptr) = virtio_cread64(vdev,\</span><br><span class="line">offsetof(structname, member)); \</span><br><span class="line"><span class="keyword">break</span>;\</span><br><span class="line"><span class="keyword">default</span>:\</span><br><span class="line">BUG();\</span><br><span class="line">&#125;\</span><br><span class="line">&#125; <span class="keyword">while</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> u64 <span class="title">virtio_cread64</span><span class="params">(struct virtio_device *vdev,</span></span></span><br><span class="line"><span class="function"><span class="params"> <span class="keyword">unsigned</span> <span class="keyword">int</span> offset)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">u64 ret;</span><br><span class="line">__virtio_cread_many(vdev, offset, &amp;ret, <span class="number">1</span>, <span class="keyword">sizeof</span>(ret));</span><br><span class="line"><span class="keyword">return</span> virtio64_to_cpu(vdev, (__force __virtio64)ret);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Read @count fields, @bytes each. */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span> __virtio_cread_many(struct virtio_device *vdev,</span><br><span class="line">       <span class="keyword">unsigned</span> <span class="keyword">int</span> offset,</span><br><span class="line">       <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> count, <span class="keyword">size_t</span> bytes)</span><br><span class="line">&#123;</span><br><span class="line">u32 old, gen = vdev-&gt;config-&gt;generation ?</span><br><span class="line">vdev-&gt;config-&gt;generation(vdev) : <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"></span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">old = gen;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; count; i++)</span><br><span class="line">vdev-&gt;config-&gt;get(vdev, offset + bytes * i,</span><br><span class="line">  buf + i * bytes, bytes);</span><br><span class="line"></span><br><span class="line">gen = vdev-&gt;config-&gt;generation ?</span><br><span class="line">vdev-&gt;config-&gt;generation(vdev) : <span class="number">0</span>;</span><br><span class="line">&#125; <span class="keyword">while</span> (gen != old);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="6-qemu完成virtio-header中capacity-field的模拟"><a href="#6-qemu完成virtio-header中capacity-field的模拟" class="headerlink" title="6. qemu完成virtio header中capacity field的模拟"></a>6. qemu完成virtio header中capacity field的模拟</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">uint32_t</span> virtio_config_readb(VirtIODevice *vdev, <span class="keyword">uint32_t</span> addr)</span><br><span class="line">&#123;</span><br><span class="line">    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);</span><br><span class="line">    <span class="keyword">uint8_t</span> val;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (addr + <span class="keyword">sizeof</span>(val) &gt; vdev-&gt;config_len) &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">uint32_t</span>)<span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    k-&gt;get_config(vdev, vdev-&gt;config);<span class="comment">//对应到virtio_blk_update_config</span></span><br><span class="line"></span><br><span class="line">    val = ldub_p(vdev-&gt;config + addr);</span><br><span class="line">    <span class="keyword">return</span> val;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* coalesce internal state, copy to pci i/o region 0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">virtio_blk_update_config</span><span class="params">(VirtIODevice *vdev, <span class="keyword">uint8_t</span> *config)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    VirtIOBlock *s = VIRTIO_BLK(vdev);</span><br><span class="line">    BlockConf *conf = &amp;s-&gt;conf.conf;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">virtio_blk_config</span> <span class="title">blkcfg</span>;</span></span><br><span class="line">    <span class="keyword">uint64_t</span> capacity;</span><br><span class="line">    <span class="keyword">int</span> blk_size = conf-&gt;logical_block_size;</span><br><span class="line"></span><br><span class="line">    blk_get_geometry(s-&gt;blk, &amp;capacity);</span><br><span class="line">    <span class="built_in">memset</span>(&amp;blkcfg, <span class="number">0</span>, <span class="keyword">sizeof</span>(blkcfg));</span><br><span class="line">    virtio_stq_p(vdev, &amp;blkcfg.capacity, capacity);</span><br><span class="line">    virtio_stl_p(vdev, &amp;blkcfg.seg_max, <span class="number">128</span> - <span class="number">2</span>);</span><br><span class="line">    virtio_stw_p(vdev, &amp;blkcfg.geometry.cylinders, conf-&gt;cyls);</span><br><span class="line">    virtio_stl_p(vdev, &amp;blkcfg.blk_size, blk_size);</span><br><span class="line">    virtio_stw_p(vdev, &amp;blkcfg.min_io_size, conf-&gt;min_io_size / blk_size);</span><br><span class="line">    virtio_stw_p(vdev, &amp;blkcfg.opt_io_size, conf-&gt;opt_io_size / blk_size);</span><br><span class="line">    blkcfg.geometry.heads = conf-&gt;heads;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * We must ensure that the block device capacity is a multiple of</span></span><br><span class="line"><span class="comment">     * the logical block size. If that is not the case, let's use</span></span><br><span class="line"><span class="comment">     * sector_mask to adopt the geometry to have a correct picture.</span></span><br><span class="line"><span class="comment">     * For those devices where the capacity is ok for the given geometry</span></span><br><span class="line"><span class="comment">     * we don't touch the sector value of the geometry, since some devices</span></span><br><span class="line"><span class="comment">     * (like s390 dasd) need a specific value. Here the capacity is already</span></span><br><span class="line"><span class="comment">     * cyls*heads*secs*blk_size and the sector value is not block size</span></span><br><span class="line"><span class="comment">     * divided by 512 - instead it is the amount of blk_size blocks</span></span><br><span class="line"><span class="comment">     * per track (cylinder).</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (blk_getlength(s-&gt;blk) /  conf-&gt;heads / conf-&gt;secs % blk_size) &#123;</span><br><span class="line">        blkcfg.geometry.sectors = conf-&gt;secs &amp; ~s-&gt;sector_mask;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        blkcfg.geometry.sectors = conf-&gt;secs;</span><br><span class="line">    &#125;</span><br><span class="line">    blkcfg.size_max = <span class="number">0</span>;</span><br><span class="line">    blkcfg.physical_block_exp = get_physical_block_exp(conf);</span><br><span class="line">    blkcfg.alignment_offset = <span class="number">0</span>;</span><br><span class="line">    blkcfg.wce = blk_enable_write_cache(s-&gt;blk);</span><br><span class="line">    <span class="built_in">memcpy</span>(config, &amp;blkcfg, <span class="keyword">sizeof</span>(struct virtio_blk_config));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>参考资料:</p><ol><li><a href="http://m.blog.chinaunix.net/uid-29718549-id-4390132.html" target="_blank" rel="noopener">qemu block_resize(动态修改磁盘大小)实现简记</a></li><li><a href="https://blog.frehi.be/2022/08/01/online-resizing-block-devices-and-file-systems/" target="_blank" rel="noopener">Online resizing block devices and file systems</a></li><li><a href="https://serverfault.com/a/743106" target="_blank" rel="noopener">Is online disk resize possible with KVM?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将结合virtio spec、qemu与Linux kernel源码深入解析virtio-blk resize的原理。
    
    </summary>
    
      <category term="virtio" scheme="http://liujunming.github.io/categories/virtio/"/>
    
    
      <category term="virtio" scheme="http://liujunming.github.io/tags/virtio/"/>
    
  </entry>
  
  <entry>
    <title>Notes about Intel turbo boost</title>
    <link href="http://liujunming.github.io/2022/12/03/Notes-about-Intel-turbo-boost/"/>
    <id>http://liujunming.github.io/2022/12/03/Notes-about-Intel-turbo-boost/</id>
    <published>2022-12-03T11:08:59.000Z</published>
    <updated>2022-12-03T11:38:55.483Z</updated>
    
    <content type="html"><![CDATA[<p>Intel turbo boost的中文翻译为”睿频加速”，一般情况下turbo(睿频)指的就是Intel turbo boost。本文将记录turbo相关notes。<a id="more"></a> </p><p><img src="/images/2022/12/01.jpg" alt></p><p>CPUs don’t always need to run at their maximum frequency. Some programs are more dependent on memory to run smoothly, while others are CPU-intensive. Intel Turbo Boost Technology is an energy-efficient solution to this imbalance: it lets the CPU run at its base clock speed when handling light workloads, then jump to a higher clock speed for heavy workloads.</p><p>Running at a lower clock rate (the number of cycles executed by the processor every second) allows the processor to use less power, which can reduce heat and positively impact battery life in laptops. But when more speed is needed, Intel Turbo Boost Technology dynamically increases the clock rate to compensate.</p><p>Intel Turbo Boost Technology can potentially increase CPU speeds up to the Max Turbo Frequency while staying within safe temperature and power limits. This can increase performance in both single-threaded and multithreaded applications (programs that utilize several processor cores).</p><hr><p>参考资料:</p><ol><li><a href="https://www.intel.com/content/www/us/en/support/articles/000030893/processors.html" target="_blank" rel="noopener">What Is Intel® Turbo Boost Technology and How Does It Work?</a></li><li><a href="https://www.intel.com/content/www/us/en/gaming/resources/turbo-boost.htm" target="_blank" rel="noopener">What Is Intel® Turbo Boost Technology?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Intel turbo boost的中文翻译为”睿频加速”，一般情况下turbo(睿频)指的就是Intel turbo boost。本文将记录turbo相关notes。
    
    </summary>
    
      <category term="Intel" scheme="http://liujunming.github.io/categories/Intel/"/>
    
    
      <category term="Intel" scheme="http://liujunming.github.io/tags/Intel/"/>
    
  </entry>
  
  <entry>
    <title>How to use IO poll in Linux NVMe driver</title>
    <link href="http://liujunming.github.io/2022/11/29/How-to-use-IO-poll-in-Linux-NVMe-driver/"/>
    <id>http://liujunming.github.io/2022/11/29/How-to-use-IO-poll-in-Linux-NVMe-driver/</id>
    <published>2022-11-29T15:09:37.000Z</published>
    <updated>2022-11-29T15:35:56.810Z</updated>
    
    <content type="html"><![CDATA[<p>使用NVMe driver的<code>poll_queues</code>参数即可开启IO queue的poll。<a id="more"></a> </p><h3 id="内核源码"><a href="#内核源码" class="headerlink" title="内核源码"></a>内核源码</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//https://elixir.bootlin.com/linux/v6.0/source/drivers/nvme/host/pci.c</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> poll_queues;</span><br><span class="line">module_param_cb(poll_queues, &amp;io_queue_count_ops, &amp;poll_queues, <span class="number">0644</span>);</span><br><span class="line">MODULE_PARM_DESC(poll_queues, <span class="string">"Number of queues to use for polled IO."</span>);</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nvme_setup_io_queues</span><span class="params">(struct nvme_dev *dev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">dev-&gt;nr_poll_queues = poll_queues;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>当只有一个IO queue时，设置<code>poll_queues</code>为1后，发现依然有中断。其实这是符合预取的。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nvme_setup_irqs</span><span class="params">(struct nvme_dev *dev, <span class="keyword">unsigned</span> <span class="keyword">int</span> nr_io_queues)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pci_dev</span> *<span class="title">pdev</span> = <span class="title">to_pci_dev</span>(<span class="title">dev</span>-&gt;<span class="title">dev</span>);</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">irq_affinity</span> <span class="title">affd</span> = &#123;</span></span><br><span class="line">.pre_vectors= <span class="number">1</span>,</span><br><span class="line">.calc_sets= nvme_calc_irq_sets,</span><br><span class="line">.priv= dev,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> irq_queues, poll_queues;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Poll queues don't need interrupts, but we need at least one I/O queue</span></span><br><span class="line"><span class="comment"> * left over for non-polled I/O.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">poll_queues = min(dev-&gt;nr_poll_queues, nr_io_queues - <span class="number">1</span>);</span><br><span class="line">dev-&gt;io_queues[HCTX_TYPE_POLL] = poll_queues;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Initialize for the single interrupt case, will be updated in</span></span><br><span class="line"><span class="comment"> * nvme_calc_irq_sets().</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">dev-&gt;io_queues[HCTX_TYPE_DEFAULT] = <span class="number">1</span>;</span><br><span class="line">dev-&gt;io_queues[HCTX_TYPE_READ] = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * We need interrupts for the admin queue and each non-polled I/O queue,</span></span><br><span class="line"><span class="comment"> * but some Apple controllers require all queues to use the first</span></span><br><span class="line"><span class="comment"> * vector.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">irq_queues = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span> (!(dev-&gt;ctrl.quirks &amp; NVME_QUIRK_SINGLE_VECTOR))</span><br><span class="line">irq_queues += (nr_io_queues - poll_queues);</span><br><span class="line"><span class="keyword">return</span> pci_alloc_irq_vectors_affinity(pdev, <span class="number">1</span>, irq_queues,</span><br><span class="line">      PCI_IRQ_ALL_TYPES | PCI_IRQ_AFFINITY, &amp;affd);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>由上述代码可知，driver至少留一个IO queue使用interrupt而非poll。</p><p>因此，当只有一个IO queue时，即使driver参数设置了<code>poll_queues</code>为1，其实是不生效的(<code>nvme_setup_irqs</code>中的<code>poll_queues</code>变量为0)，这个唯一的IO queue使用的依然是interrupt而非poll。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用NVMe driver的&lt;code&gt;poll_queues&lt;/code&gt;参数即可开启IO queue的poll。
    
    </summary>
    
      <category term="存储" scheme="http://liujunming.github.io/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="http://liujunming.github.io/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Notes about sysctl</title>
    <link href="http://liujunming.github.io/2022/11/27/Notes-about-sysctl/"/>
    <id>http://liujunming.github.io/2022/11/27/Notes-about-sysctl/</id>
    <published>2022-11-27T07:28:45.000Z</published>
    <updated>2022-11-27T11:15:38.702Z</updated>
    
    <content type="html"><![CDATA[<p><code>sysctl</code>的用法可参考<code>man sysctl</code>。<a id="more"></a><br>本文主要转载自<a href="https://cloud.tencent.com/developer/article/1657639" target="_blank" rel="noopener">Linux 下的 Sysctl 命令</a>。</p><p>作为一个 Linux 系统管理员，有时候你需要修改默认的内核行为。例如，你可能想要启用 SysRq 或者增加 Kernel 能够接受的连接数量。 内核参数可以在构建内核的时候，在系统启动时，或者在运行时进行设置。</p><p>本文讲解如何使用<code>sysct</code>l命令在运行时进行查看并且修改内核参数。</p><h3 id="1-使用sysctl查看-Kernel-参数"><a href="#1-使用sysctl查看-Kernel-参数" class="headerlink" title="1. 使用sysctl查看 Kernel 参数"></a>1. 使用sysctl查看 Kernel 参数</h3><p>想要查看所有的当前内核参数，运行<code>sysctl</code> 命令加上<code>-a</code>选项：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -a</span><br></pre></td></tr></table></figure></p><p>这将会输出一个很大的列表，看起来像下面这样，每行包含一个参数和对应的值：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">abi.vsyscall32 = 1</span><br><span class="line">debug.exception-trace = 1</span><br><span class="line">debug.kprobes-optimization = 1</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>所有用户可以查看当前的内核参数；仅仅 root 用户可以修改它们的值。</p><p>通过将参数名传递给<code>sysctl</code>,你可以检查单个参数的取值。例如，想要检查当前的 swappiness 取值，你可以输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl vm.swappiness</span><br></pre></td></tr></table></figure></p><p>输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vm.swappiness = 60</span><br></pre></td></tr></table></figure></p><p>Swappiness 是一个内核属性，它定义了系统多长时间会使用swap space。</p><p>这个<code>sysctl</code>命令将会从<code>/proc/sys</code>目录下读取信息。 <code>/proc/sys</code>是一个虚拟目录，它包含文件对象，可以被用来查看或者设置当前的内核参数。</p><p>你也可以通过显示合适的文件，来查看参数值。唯一的不同就是文件如何被展示。例如，<code>sysctl vm.swappiness</code>和<code>cat /proc/sys/vm/swappiness</code>都将给出同样的输出。当使用<code>sysctl</code>时，目录中的斜杠将会被点所替代，并且<code>proc.sys</code>部分被去掉了。</p><h3 id="2-使用sysctl来修改内核参数"><a href="#2-使用sysctl来修改内核参数" class="headerlink" title="2. 使用sysctl来修改内核参数"></a>2. 使用sysctl来修改内核参数</h3><p>想要在系统运行时设置一个内核参数，按照下面的格式运行<code>sysctl</code>命令加上参数名和取值：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w parameter=value</span><br></pre></td></tr></table></figure><p>如果这个取值包含空格或者特殊符号，使用双引号包裹取值。你还可以在同一个命令中传递多个<code>parameter=value</code> 键值对。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在生产系统中修改内核设置必须非常小心，这可能会使得内核不稳当，并且你需要重启系统。</span><br></pre></td></tr></table></figure><p>例如，想要允许 IPV4 包转发，你需要运行：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv4.ip_forward=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>这个修改立即生效，但是它不是持久化的。在系统重启后，默认值会被重新加载。</p><p>想要永久修改一个参数，你需要修改设置到文件<code>/etc/sysctl.conf</code> ：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv4.ip_forward=<span class="number">1</span> &gt;&gt; <span class="regexp">/etc/</span>sysctl.conf</span><br></pre></td></tr></table></figure><p>另外修改参数的方式就是使用<code>echo</code>命令将设置写入到<code>/proc/sys</code>目录下的文件中。例如，不使用上面的命令，你还可以用：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo <span class="number">1</span> &gt; <span class="regexp">/proc/</span>sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><p>这个<code>-p</code>选项允许你从一个配置文件中加载设置：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -p /etc/sysctl.d/file_name.conf</span><br></pre></td></tr></table></figure><p>如果没有给出文件，那么 <code>sysctl</code> 从 <code>/etc/sysctl.conf</code>文件中读取。</p><h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h3><p><code>sysctl</code> 命令允许你查看并且修改 Linux 内核参数。</p><hr><p>参考资料:</p><ol><li><a href="https://linux.die.net/man/8/sysctl" target="_blank" rel="noopener">man sysctl</a></li><li><a href="https://cloud.tencent.com/developer/article/1657639" target="_blank" rel="noopener">Linux 下的 Sysctl 命令</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;sysctl&lt;/code&gt;的用法可参考&lt;code&gt;man sysctl&lt;/code&gt;。
    
    </summary>
    
      <category term="工具" scheme="http://liujunming.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://liujunming.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Linux Hungtask机制</title>
    <link href="http://liujunming.github.io/2022/11/27/Linux-Hungtask%E6%9C%BA%E5%88%B6/"/>
    <id>http://liujunming.github.io/2022/11/27/Linux-Hungtask机制/</id>
    <published>2022-11-27T03:36:29.000Z</published>
    <updated>2022-11-27T06:33:40.495Z</updated>
    
    <content type="html"><![CDATA[<p>本文将总结Linux的Hungtask机制。<a id="more"></a><br>本文参考的内核源码版本为<a href="https://elixir.bootlin.com/linux/v4.0/source" target="_blank" rel="noopener">v4.0</a>。</p><h3 id="1-现象"><a href="#1-现象" class="headerlink" title="1. 现象"></a>1. 现象</h3><p>内核日志会看到如下信息:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INFO: task filebench:7143 blocked for more than 120 seconds.</span><br><span class="line">21794 Oct 24 13:21:33 localhost kernel: &quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.</span><br></pre></td></tr></table></figure></p><h3 id="2-背景知识"><a href="#2-背景知识" class="headerlink" title="2. 背景知识"></a>2. 背景知识</h3><p>长期以来，处于D状态(<code>TASK_UNINTERRUPTIBLE</code>状态)的进程都是让人比较烦恼的问题，处于D状态的进程不能接收信号，kill不掉。在一些场景下，常见的进程长期处于D状态，用户对此无能为力，也不知道原因，只能重启恢复。<br>其实进程长期处于D状态肯定是不正常的，内核中设计D状态的目的是为了让进程等待IO完成，正常情况下IO应该会顺利完成，然后唤醒相应的D状态进程，即使在异常情况下(比如磁盘离或损坏、磁阵链路断开等)，IO处理也是有超时机制的，原理上不会存在永久处于D状态的进程。但是因为内核代码流程中可能存在一些bug，或者用户内核模块中的相关机制不合理，可能导致进程长期处于D状态，无法唤醒，类似于死锁状态。<br>针对这种情况，内核中提供了hung task机制用于检测系统中是否存在处于D状态超过120s(时长可以设置)的进程，如果存在，则打印相关警告和进程堆栈。如果配置了<code>hung_task_panic</code>，则直接发起panic，结合kdump可以搜集到vmcore。从内核的角度看，如果有进程处于D状态的时间超过了120s，那肯定已经出现异常了，以此机制来收集相关的异常信息，用于分析定位问题。</p><h3 id="3-基本原理"><a href="#3-基本原理" class="headerlink" title="3. 基本原理"></a>3. 基本原理</h3><p>创建一个内核线程(khungtaskd)，定期(120s)唤醒后，遍历系统中的所有进程，检查是否存在处于D状态超过120s(时长可以设置)的进程，如果存在，则打印相关警告和进程堆栈。如果配置了hung_task_panic（proc或内核启动参数），则直接发起panic。</p><h3 id="4-源码解析"><a href="#4-源码解析" class="headerlink" title="4. 源码解析"></a>4. 源码解析</h3><p><a href="https://elixir.bootlin.com/linux/v4.0/source/kernel/hung_task.c" target="_blank" rel="noopener">kernel/hung_task.c</a><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hung_task_init</span><br><span class="line">└── watchdog</span><br><span class="line">    └── check_hung_uninterruptible_tasks</span><br><span class="line">        └── check_hung_task</span><br></pre></td></tr></table></figure></p><h4 id="4-1-初始化"><a href="#4-1-初始化" class="headerlink" title="4.1 初始化"></a>4.1 初始化</h4><p>初始化一个内核线程来检测系统中是否存在D状态超过120s的进程。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> __<span class="function">init <span class="title">hung_task_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">/*注册panic通知链，在panic时执行相关操作。*/</span></span><br><span class="line">atomic_notifier_chain_register(&amp;panic_notifier_list, &amp;panic_block);</span><br><span class="line"><span class="comment">/*创建内核线程khungtaskd，执行函数为watchdog*/</span></span><br><span class="line">watchdog_task = kthread_run(watchdog, <span class="literal">NULL</span>, <span class="string">"khungtaskd"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-2-watchdog"><a href="#4-2-watchdog" class="headerlink" title="4.2 watchdog"></a>4.2 watchdog</h4><p>khungtaskd内核线程的处理函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * kthread which checks for tasks stuck in D state</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">watchdog</span><span class="params">(<span class="keyword">void</span> *dummy)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">/*设置当前khungtaskd内核线程的nice为0，即普通优先级，为了不影响业务运行*/</span></span><br><span class="line">set_user_nice(current, <span class="number">0</span>);</span><br><span class="line"><span class="comment">/*死循环进行检测*/</span></span><br><span class="line"><span class="keyword">for</span> ( ; ; ) &#123;</span><br><span class="line"><span class="comment">/*进程处于D状态的时间上限可通过sysctl/proc控制，默认为120s*/</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> timeout = sysctl_hung_task_timeout_secs;</span><br><span class="line"><span class="comment">/*检测线程(khungtaskd)sleep 120s(默认)后，再次唤醒。*/</span></span><br><span class="line"><span class="keyword">while</span> (schedule_timeout_interruptible(timeout_jiffies(timeout)))</span><br><span class="line">timeout = sysctl_hung_task_timeout_secs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (atomic_xchg(&amp;reset_hung_task, <span class="number">0</span>))</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line"><span class="comment">/*醒来后执行实际的检测操作*/</span></span><br><span class="line">check_hung_uninterruptible_tasks(timeout);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-3-check-hung-uninterruptible-tasks"><a href="#4-3-check-hung-uninterruptible-tasks" class="headerlink" title="4.3 check_hung_uninterruptible_tasks"></a>4.3 check_hung_uninterruptible_tasks</h4><p>遍历系统中的所有进程，检测是否有处于D状态超过120s的进程，如果有则打印警告或panic。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Check whether a TASK_UNINTERRUPTIBLE does not get woken up for</span></span><br><span class="line"><span class="comment"> * a really long time (120 seconds). If that happens, print out</span></span><br><span class="line"><span class="comment"> * a warning.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">check_hung_uninterruptible_tasks</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">long</span> timeout)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">/*hung task检测是检查的最大进程数，默认为最大的进程号*/</span></span><br><span class="line"><span class="keyword">int</span> max_count = sysctl_hung_task_check_count;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 每次遍历进程数的上限，默认为1024，这样做的目的是为了:</span></span><br><span class="line"><span class="comment"> * 1、防止rcu_read_lock的占用时间太长。</span></span><br><span class="line"><span class="comment"> * 2、hung task的watchdog占用CPU时间太长。如果没开内核抢占，则如果内核线程不主动调度的话，是不能发生进程切换的</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 如果系统中的进程数比较多，那么就可能检测不到部分D状态进程了?不会，因为这里只是会调度一次，调度回来后，会继续遍历后面的进程</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> batch_count = HUNG_TASK_BATCHING;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">g</span>, *<span class="title">t</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * If the system crashed already then all bets are off,</span></span><br><span class="line"><span class="comment"> * do not report extra hung tasks:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">/*如果系统已经处于crash状态了，就不再报hung task了。*/</span></span><br><span class="line"><span class="keyword">if</span> (test_taint(TAINT_DIE) || did_panic)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">rcu_read_lock();</span><br><span class="line"><span class="comment">/*遍历系统中的所有进程*/</span></span><br><span class="line">do_each_thread(g, t) &#123;</span><br><span class="line"><span class="keyword">if</span> (!max_count--)</span><br><span class="line"><span class="keyword">goto</span> unlock;</span><br><span class="line"><span class="comment">/*如果每次检测的进程数量超过1024了，则需要发起调度，结束rcu优雅周期*/</span></span><br><span class="line"><span class="keyword">if</span> (!--batch_count) &#123;</span><br><span class="line">batch_count = HUNG_TASK_BATCHING;</span><br><span class="line"><span class="comment">/*释放rcu，并主动调度，调度回来后检查相应进程是否还在，如果不在了，则退出遍历，否则继续*/</span></span><br><span class="line"><span class="keyword">if</span> (!rcu_lock_break(g, t))</span><br><span class="line"><span class="keyword">goto</span> unlock;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* use "==" to skip the TASK_KILLABLE tasks waiting on NFS */</span></span><br><span class="line"><span class="comment">/*检测进程状态是否为D*/</span></span><br><span class="line"><span class="keyword">if</span> (t-&gt;state == TASK_UNINTERRUPTIBLE)</span><br><span class="line"><span class="comment">/*检测进程处于D状态的时间是否超过120s。*/</span></span><br><span class="line">check_hung_task(t, timeout);</span><br><span class="line">&#125; while_each_thread(g, t);</span><br><span class="line"> unlock:</span><br><span class="line">rcu_read_unlock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-4-check-hung-task"><a href="#4-4-check-hung-task" class="headerlink" title="4.4 check_hung_task"></a>4.4 check_hung_task</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">check_hung_task</span><span class="params">(struct task_struct *t, <span class="keyword">unsigned</span> <span class="keyword">long</span> timeout)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">/*进程上下文切换计数，以此来判断该进程是否发生过调度*/</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> switch_count = t-&gt;nvcsw + t-&gt;nivcsw;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Ensure the task is not frozen.</span></span><br><span class="line"><span class="comment"> * Also, skip vfork and any other user process that freezer should skip.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (unlikely(t-&gt;flags &amp; (PF_FROZEN | PF_FREEZER_SKIP)))</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * When a freshly created task is scheduled once, changes its state to</span></span><br><span class="line"><span class="comment"> * TASK_UNINTERRUPTIBLE without having ever been switched out once, it</span></span><br><span class="line"><span class="comment"> * musn't be checked.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (unlikely(!switch_count))</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 如果当前switch_count等于last_switch_count，则说明在khungtaskd进程被唤醒期间，该进程没有发生过调度。</span></span><br><span class="line"><span class="comment"> * 也就是说，该进程一直处于D状态，因为last_switch_count只在这里更新，其它地方不会。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (switch_count != t-&gt;last_switch_count) </span><br><span class="line"><span class="comment">/* 更新last_switch_count计数，只在这里更新，该计数专用于hung task的检测。*/</span></span><br><span class="line">t-&gt;last_switch_count = switch_count;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">trace_sched_process_hang(t);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * hung task错误打印次数限制，防止dos攻击。默认为10次，由于是全局变量，</span></span><br><span class="line"><span class="comment"> * 表示系统运行期间最多打印10次，超过后就不打印了。该参数应该可以</span></span><br><span class="line"><span class="comment"> * 通过sysctl修改</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (!sysctl_hung_task_warnings)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (sysctl_hung_task_warnings &gt; <span class="number">0</span>)</span><br><span class="line">sysctl_hung_task_warnings--;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Ok, the task did not get scheduled for more than 2 minutes,</span></span><br><span class="line"><span class="comment"> * complain:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">/*如下就是我们平常常见的hung task打印了*/</span></span><br><span class="line">pr_err(<span class="string">"INFO: task %s:%d blocked for more than %ld seconds.\n"</span>,</span><br><span class="line">t-&gt;comm, t-&gt;pid, timeout);</span><br><span class="line">pr_err(<span class="string">"      %s %s %.*s\n"</span>,</span><br><span class="line">print_tainted(), init_utsname()-&gt;release,</span><br><span class="line">(<span class="keyword">int</span>)<span class="built_in">strcspn</span>(init_utsname()-&gt;version, <span class="string">" "</span>),</span><br><span class="line">init_utsname()-&gt;version);</span><br><span class="line">pr_err(<span class="string">"\"echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs\""</span></span><br><span class="line"><span class="string">" disables this message.\n"</span>);</span><br><span class="line"><span class="comment">/*打印堆栈*/</span></span><br><span class="line">sched_show_task(t);</span><br><span class="line"><span class="comment">/*如果开启了debug_lock，则打印锁的占用情况*/</span></span><br><span class="line">debug_show_held_locks(t);</span><br><span class="line"></span><br><span class="line">touch_nmi_watchdog();</span><br><span class="line"><span class="comment">/*检测是否配置了/proc/sys/kernel/hung_task_panic，如果配置则直接触发panic*/</span></span><br><span class="line"><span class="keyword">if</span> (sysctl_hung_task_panic) &#123;</span><br><span class="line"><span class="comment">/*打印所有CPU的堆栈*/</span></span><br><span class="line">trigger_all_cpu_backtrace();</span><br><span class="line"><span class="comment">/*触发panic，如果配置了kdump就有用了*/</span></span><br><span class="line">panic(<span class="string">"hung_task: blocked tasks"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-Hungtask定位思路"><a href="#5-Hungtask定位思路" class="headerlink" title="5. Hungtask定位思路"></a>5. Hungtask定位思路</h3><p><img src="/images/2022/11/14.jpg" alt></p><hr><p>参考资料:</p><ol><li><a href="https://mp.weixin.qq.com/s/Jpex9c0_GBZsxB4J21ojxA" target="_blank" rel="noopener">Hungtask原理及分析</a></li><li><a href="https://zhuanlan.zhihu.com/p/463433198" target="_blank" rel="noopener">内核Hungtask原理和定位思路总结</a></li><li><a href="https://blog.csdn.net/weixin_33921089/article/details/86390346" target="_blank" rel="noopener">hung task机制</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将总结Linux的Hungtask机制。
    
    </summary>
    
      <category term="Kernel" scheme="http://liujunming.github.io/categories/Kernel/"/>
    
    
      <category term="Kernel" scheme="http://liujunming.github.io/tags/Kernel/"/>
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Notes about linux进程D状态</title>
    <link href="http://liujunming.github.io/2022/11/26/Notes-about-%E8%BF%9B%E7%A8%8BD%E7%8A%B6%E6%80%81/"/>
    <id>http://liujunming.github.io/2022/11/26/Notes-about-进程D状态/</id>
    <published>2022-11-26T08:50:19.000Z</published>
    <updated>2022-11-27T03:37:43.130Z</updated>
    
    <content type="html"><![CDATA[<p>本文将记录进程D状态相关笔记。</p><a id="more"></a> <h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>man ps中的描述:<br><img src="/images/2022/11/11.jpg" alt></p><p>Linux kernel中的宏定义: <a href="https://elixir.bootlin.com/linux/v6.0/source/include/linux/sched.h#L86" target="_blank" rel="noopener">TASK_UNINTERRUPTIBLE</a></p><h3 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h3><p><img src="/images/2022/11/12.jpg" alt><br><img src="/images/2022/11/13.jpg" alt></p><h3 id="资料推荐"><a href="#资料推荐" class="headerlink" title="资料推荐"></a>资料推荐</h3><p>强烈推荐<a href="/pdf/炫技！bug 排查大曝光，涉及Linux 内核的那种.pdf">炫技！bug 排查大曝光，涉及Linux 内核的那种</a>一文，会收获颇丰!</p><hr><p>参考资料:</p><ol><li><a href="https://www.man7.org/linux/man-pages/man1/ps.1.html" target="_blank" rel="noopener">man ps</a></li><li><a href="https://www.cnblogs.com/embedded-linux/p/7043569.html" target="_blank" rel="noopener">linux进程D状态</a></li><li><a href="https://mp.weixin.qq.com/s/5OOqJRhBRhdih7Pb0f5e5A" target="_blank" rel="noopener">炫技！bug 排查大曝光，涉及Linux 内核的那种</a></li><li><a href="https://www.zouhl.com/posts/linux%E4%B8%8B%E5%B8%B8%E8%A7%81%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90-d%E7%8A%B6%E6%80%81%E5%92%8Cz%E7%8A%B6%E6%80%81/" target="_blank" rel="noopener">Linux下常见的系统问题分析 D状态和Z状态</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将记录进程D状态相关笔记。&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="http://liujunming.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="http://liujunming.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>利用bpftrace打印内核函数调用栈</title>
    <link href="http://liujunming.github.io/2022/11/20/%E5%88%A9%E7%94%A8bpftrace%E6%89%93%E5%8D%B0%E5%86%85%E6%A0%B8%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%A0%88/"/>
    <id>http://liujunming.github.io/2022/11/20/利用bpftrace打印内核函数调用栈/</id>
    <published>2022-11-20T08:30:23.000Z</published>
    <updated>2022-11-20T08:39:58.395Z</updated>
    
    <content type="html"><![CDATA[<p>本文将以<code>vp_notify</code>函数为例，介绍下如何利用bpftrace打印内核函数调用栈。<a id="more"></a> </p><ul><li><p>确定目标内核函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bpftrace -l &apos;kprobe:*&apos; | grep vp_notify</span><br><span class="line">kprobe:vp_notify</span><br></pre></td></tr></table></figure></li><li><p><code>kstack</code>: Stack Traces, Kernel</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ bpftrace -e &apos;kprobe:vp_notify &#123; @[kstack] = count(); &#125;&apos;</span><br><span class="line">Attaching 1 probe...</span><br><span class="line">^C</span><br></pre></td></tr></table></figure></li></ul><p><a href="https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md#7-kstack-stack-traces-kernel" target="_blank" rel="noopener">https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md#7-kstack-stack-traces-kernel</a></p><p><a href="https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md#2-count-count" target="_blank" rel="noopener">count()</a>的含义</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将以&lt;code&gt;vp_notify&lt;/code&gt;函数为例，介绍下如何利用bpftrace打印内核函数调用栈。
    
    </summary>
    
      <category term="工具" scheme="http://liujunming.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://liujunming.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="debug" scheme="http://liujunming.github.io/tags/debug/"/>
    
  </entry>
  
</feed>
