<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Understanding the Linux Kernel 读书笔记 -Kernel Synchronization"/>




  <meta name="keywords" content="Kernel, 读书笔记, Concurrency, L" />










  <link rel="alternate" href="/atom.xml" title="L">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1" />



<link rel="canonical" href="http://liujunming.github.io/2018/12/14/Understanding-the-Linux-Kernel-读书笔记-Kernel-Synchronization/"/>



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css" />



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1" />



  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>









<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true};
</script>

    <title> Understanding the Linux Kernel 读书笔记 -Kernel Synchronization - L </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">L</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/links">
        <li class="mobile-menu-item">
          
          
            Links
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">L</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/links">
            
            
              Links
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Understanding the Linux Kernel 读书笔记 -Kernel Synchronization
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-12-14
        </span>
        
          <span class="post-category">
            
              <a href="/categories/Kernel/">Kernel</a>
            
          </span>
        
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-How-the-Kernel-Services-Requests"><span class="toc-text">1 How the Kernel Services Requests</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Kernel-Preemption"><span class="toc-text">1.1 Kernel Preemption</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Synchronization-Primitives"><span class="toc-text">2 Synchronization Primitives</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Per-CPU-Variables"><span class="toc-text">2.1 Per-CPU Variables</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Atomic-Operations"><span class="toc-text">2.2 Atomic Operations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Optimization-and-Memory-Barriers"><span class="toc-text">2.3 Optimization and Memory Barriers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-Spin-Locks"><span class="toc-text">2.4 Spin Locks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-Read-Write-Spin-Locks"><span class="toc-text">2.5 Read/Write Spin Locks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-Seqlocks"><span class="toc-text">2.6 Seqlocks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-7-Read-Copy-Update-RCU"><span class="toc-text">2.7 Read-Copy Update (RCU)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-8-Semaphores"><span class="toc-text">2.8 Semaphores</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-9-Read-Write-Semaphores"><span class="toc-text">2.9 Read/Write Semaphores</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-10-Completions"><span class="toc-text">2.10 Completions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-11-Local-Interrupt-Disabling"><span class="toc-text">2.11 Local Interrupt Disabling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-Disabling-and-Enabling-Deferrable-Functions"><span class="toc-text">2.12 Disabling and Enabling Deferrable Functions</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Synchronizing-Accesses-to-Kernel-Data-Structures"><span class="toc-text">3 Synchronizing Accesses to Kernel Data Structures</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Choosing-Among-Spin-Locks-Semaphores-and-Interrupt-Disabling"><span class="toc-text">3.1 Choosing Among Spin Locks, Semaphores, and Interrupt Disabling</span></a></li></ol></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <p>You could think of the kernel as a server that answers requests; these requests can come either from a process running on a CPU or an external device issuing an interrupt request. We make this analogy to underscore that parts of the kernel are not run serially, but in an interleaved way. Thus, they can give rise to race conditions, which must be controlled through proper synchronization techniques.<a id="more"></a> </p>
<h2 id="1-How-the-Kernel-Services-Requests"><a href="#1-How-the-Kernel-Services-Requests" class="headerlink" title="1 How the Kernel Services Requests"></a>1 How the Kernel Services Requests</h2><p>In the rest of this chapter, we will generally denote as “exceptions” both the system calls and the usual exceptions.</p>
<h3 id="1-1-Kernel-Preemption"><a href="#1-1-Kernel-Preemption" class="headerlink" title="1.1 Kernel Preemption"></a>1.1 Kernel Preemption</h3><p>内核抢占<br>In nonpreemptive kernels, the current process cannot be replaced unless it is about to switch to User Mode. Therefore, the main characteristic of a preemptive kernel is that a process running in Kernel Mode can be replaced by another process while in the middle of a kernel function.</p>
<p>The main motivation for making a kernel preemptive is to reduce the dispatch latency of the User Mode processes, that is, the delay between the time they become runnable and the time they actually begin running. </p>
<p>The kernel can be preempted only when it is executing an exception handler (in particular a system call) and the kernel preemption has not been explicitly disabled. The local CPU must have local interrupts enabled, otherwise kernel preemption is not performed.</p>
<p>Kernel preemption may happen either when a kernel control path (usually, an interrupt handler) is terminated, or when an exception handler reenables kernel preemption by means of <code>preempt_enable()</code>.</p>
<h2 id="2-Synchronization-Primitives"><a href="#2-Synchronization-Primitives" class="headerlink" title="2 Synchronization Primitives"></a>2 Synchronization Primitives</h2><center><img src="/images/2018/12/21.png" alt=""></center>

<h3 id="2-1-Per-CPU-Variables"><a href="#2-1-Per-CPU-Variables" class="headerlink" title="2.1 Per-CPU Variables"></a>2.1 Per-CPU Variables</h3><p>The simplest and most efficient synchronization technique consists of declaring kernel variables as <em>per-CPU variables</em>. Basically, a per-CPU variable is an array of data structures, one element per each CPU in the system. However, that the per-CPU variables can be used only in particular cases—basically, when it makes sense to logically split the data across the CPUs of the system.</p>
<p>Furthermore, per-CPU variables are prone to race conditions caused by kernel preemption, both in uniprocessor and multiprocessor systems. As a general rule, a kernel control path should access a per-CPU variable with kernel preemption disabled.</p>
<h3 id="2-2-Atomic-Operations"><a href="#2-2-Atomic-Operations" class="headerlink" title="2.2 Atomic Operations"></a>2.2 Atomic Operations</h3><p>Several assembly language instructions are of type “read-modify-write”—that is, they access a memory location twice, the first time to read the old value and the second time to write a new value.</p>
<p>The easiest way to prevent race conditions due to “read-modify-write” instructions is by ensuring that such operations are atomic at the chip level. Every such operation must be executed in a single instruction without being interrupted in the middle and avoiding accesses to the same memory location by other CPUs.</p>
<h3 id="2-3-Optimization-and-Memory-Barriers"><a href="#2-3-Optimization-and-Memory-Barriers" class="headerlink" title="2.3 Optimization and Memory Barriers"></a>2.3 Optimization and Memory Barriers</h3><p>When using optimizing compilers, you should never take for granted that instructions will be performed in the exact order in which they appear in the source code. For example, a compiler might reorder the assembly language instructions in such a way to optimize how registers are used. Moreover, modern CPUs usually execute several instructions in parallel and might reorder memory accesses. These kinds of reordering can greatly speed up the program.</p>
<p>When dealing with synchronization, however, reordering instructions must be avoided. Things would quickly become hairy if an instruction placed after a synchronization primitive is executed before the synchronization primitive itself. Therefore, all synchronization primitives act as optimization and memory barriers.</p>
<p>An <em>optimization barrier</em> primitive ensures that the assembly language instructions corresponding to C statements placed before the primitive are not mixed by the compiler with assembly language instructions corresponding to C statements placed after the primitive. In Linux the <code>barrier()</code> macro acts as an optimization barrier.</p>
<p>A <em>memory barrier</em> primitive ensures that the operations placed before the primitive are finished before starting the operations placed after the primitive. </p>
<p><img src="/images/2018/12/22.png" alt=""></p>
<p>Notice that in multiprocessor systems, all atomic operations described in the earlier section “Atomic Operations” act as memory barriers.</p>
<h3 id="2-4-Spin-Locks"><a href="#2-4-Spin-Locks" class="headerlink" title="2.4 Spin Locks"></a>2.4 Spin Locks</h3><p><em>Spin locks</em> are a special kind of lock designed to work in a multiprocessor environment. If the kernel control path finds the spin lock “open,” it acquires the lock and continues its execution. Conversely, if the kernel control path finds the lock “closed” by a kernel control path running on another CPU, it “spins” around, repeatedly executing a tight instruction loop, until the lock is released.</p>
<p>The instruction loop of spin locks represents a “busy wait.” The waiting kernel control path keeps running on the CPU, even if it has nothing to do besides waste time. Nevertheless, spin locks are usually convenient, because many kernel resources are locked for a fraction of a millisecond only; therefore, it would be far more time-consuming to release the CPU and reacquire it later.</p>
<p>As a general rule, <strong>kernel preemption is disabled in every critical region protected by spin locks</strong>. In the case of a uniprocessor system, the locks themselves are useless, and the spin lock primitives just disable or enable the kernel preemption. Please notice that kernel preemption is still enabled during the busy wait phase, thus a process waiting for a spin lock to be released could be replaced by a higher priority process.<br><img src="/images/2018/12/23.png" alt=""></p>
<h3 id="2-5-Read-Write-Spin-Locks"><a href="#2-5-Read-Write-Spin-Locks" class="headerlink" title="2.5 Read/Write Spin Locks"></a>2.5 Read/Write Spin Locks</h3><p><em>Read/write spin locks</em> have been introduced to increase the amount of concurrency inside the kernel. They allow several kernel control paths to simultaneously read the same data structure, as long as no kernel control path modifies it. If a kernel control path wishes to write to the structure, it must acquire the write version of the read/write lock, which grants exclusive access to the resource. Of course, allowing concurrent reads on data structures improves system performance.</p>
<p><strong>Getting and releasing a lock for reading</strong></p>
<ul>
<li><code>read_lock</code></li>
<li><code>read_unlock</code></li>
</ul>
<p><strong>Getting and releasing a lock for writing</strong></p>
<ul>
<li><code>write_lock</code></li>
<li><code>write_unlock</code></li>
</ul>
<h3 id="2-6-Seqlocks"><a href="#2-6-Seqlocks" class="headerlink" title="2.6 Seqlocks"></a>2.6 Seqlocks</h3><p>When using read/write spin locks, requests issued by kernel control paths to perform a <code>read_lock</code> or a <code>write_lock</code> operation have the same priority: readers must wait until the writer has finished and, similarly, a writer must wait until all readers have finished.</p>
<p><em>Seqlocks</em> are similar to read/write spin locks, except that they give a much higher priority to writers: in fact a writer is allowed to proceed even when readers are active. The good part of this strategy is that a writer never waits (unless another writer is active); the bad part is that a reader may sometimes be forced to read the same data several times until it gets a valid copy.</p>
<p>The critical regions of the readers should be short and writers should seldom acquire the seqlock</p>
<h3 id="2-7-Read-Copy-Update-RCU"><a href="#2-7-Read-Copy-Update-RCU" class="headerlink" title="2.7 Read-Copy Update (RCU)"></a>2.7 Read-Copy Update (RCU)</h3><p><a href="http://liujunming.top/2018/12/13/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-Linux-%E7%9A%84-RCU-%E6%9C%BA%E5%88%B6/" target="_blank" rel="noopener">深入理解 Linux 的 RCU 机制</a><br><em>Read-copy update (RCU)</em> is yet another synchronization technique designed to protect data structures that are mostly accessed for reading by several CPUs. RCU is lock-free, that is, it uses no lock or counter shared by all CPUs; this is a great advantage over read/write spin locks and seqlocks, which have a high overhead due to cache line-snooping and invalidation.</p>
<p>How does RCU obtain the surprising result of synchronizing several CPUs without shared data structures? The key idea consists of limiting the scope of RCU as follows:</p>
<ol>
<li>Only data structures that are dynamically allocated and referenced by means of pointers can be protected by RCU.</li>
<li>No kernel control path can sleep inside a critical region protected by RCU.</li>
</ol>
<h3 id="2-8-Semaphores"><a href="#2-8-Semaphores" class="headerlink" title="2.8 Semaphores"></a>2.8 Semaphores</h3><p>Essentially, Semaphores implement a locking primitive that allows waiters to sleep until the desired resource becomes free.</p>
<p>Actually, Linux offers two kinds of semaphores:</p>
<ul>
<li>Kernel semaphores, which are used by kernel control paths</li>
<li>System V IPC semaphores, which are used by User Mode processes</li>
</ul>
<p>In this section, we focus on kernel semaphores.</p>
<p>A kernel semaphore is similar to a spin lock, in that it doesn’t allow a kernel control path to proceed unless the lock is open. However, whenever a kernel control path tries to acquire a busy resource protected by a kernel semaphore, the corresponding process is suspended. It becomes runnable again when the resource is released. Therefore, kernel semaphores can be acquired only by functions that are allowed to sleep; interrupt handlers and deferrable functions cannot use them.</p>
<p>The <code>init_MUTEX()</code> and <code>init_MUTEX_LOCKED()</code> functions may be used to initialize a semaphore for exclusive access.</p>
<p><strong>Getting and releasing semaphores</strong></p>
<ul>
<li><code>up()</code></li>
<li><code>down()</code></li>
</ul>
<h3 id="2-9-Read-Write-Semaphores"><a href="#2-9-Read-Write-Semaphores" class="headerlink" title="2.9 Read/Write Semaphores"></a>2.9 Read/Write Semaphores</h3><p>Read/write semaphores are similar to the read/write spin locks described earlier in the section “Read/Write Spin Locks,” except that waiting processes are suspended instead of spinning until the semaphore becomes open again.</p>
<p>Many kernel control paths may concurrently acquire a read/write semaphore for reading; however, every writer kernel control path must have exclusive access to the protected resource. Therefore, the semaphore can be acquired for writing only if no other kernel control path is holding it for either read or write access. Read/write semaphores improve the amount of concurrency inside the kernel and improve overall system performance.</p>
<p>The <code>down_read()</code> and <code>down_write()</code> functions acquire the read/write semaphore for reading and writing, respectively. Similarly, the <code>up_read()</code> and <code>up_write()</code> functions release a read/write semaphore previously acquired for reading and for writing.</p>
<h3 id="2-10-Completions"><a href="#2-10-Completions" class="headerlink" title="2.10 Completions"></a>2.10 Completions</h3><p>Linux 2.6 also makes use of another synchronization primitive similar to semaphores: <em>completions</em>. They have been introduced to solve a subtle race condition that occurs in multiprocessor systems when process A allocates a temporary semaphore variable, initializes it as closed MUTEX, passes its address to process B, and then invokes <code>down()</code> on it. Process A plans to destroy the semaphore as soon as it awakens. Later on, process B running on a different CPU invokes <code>up()</code> on the semaphore. However, in the current implementation <code>up()</code> and <code>down()</code> can execute concurrently on the same semaphore. Thus, process A can be woken up and destroy the temporary semaphore while process B is still executing the <code>up()</code> function. As a result, <code>up()</code>might attempt to access a data structure that no longer exists.</p>
<h3 id="2-11-Local-Interrupt-Disabling"><a href="#2-11-Local-Interrupt-Disabling" class="headerlink" title="2.11 Local Interrupt Disabling"></a>2.11 Local Interrupt Disabling</h3><p>Interrupt disabling is one of the key mechanisms used to ensure that a sequence of kernel statements is treated as a critical section. It allows a kernel control path to continue executing even when hardware devices issue IRQ signals, thus providing an effective way to protect data structures that are also accessed by interrupt handlers. By itself, however, local interrupt disabling does not protect against concurrent accesses to data structures by interrupt handlers running on other CPUs, so in multi-processor systems, local interrupt disabling is often coupled with spin locks.</p>
<p>The <code>local_irq_disable()</code> macro disables interrupts on the local CPU. The <code>local_irq_enable()</code> macro enables them.</p>
<h3 id="2-12-Disabling-and-Enabling-Deferrable-Functions"><a href="#2-12-Disabling-and-Enabling-Deferrable-Functions" class="headerlink" title="2.12 Disabling and Enabling Deferrable Functions"></a>2.12 Disabling and Enabling Deferrable Functions</h3><p>Deferrable functions can be executed at unpredictable times (essentially, on termination of hardware interrupt handlers). Therefore, data structures accessed by deferrable functions must be protected against race conditions.<br>The kernel sometimes needs to disable deferrable functions without disabling interrupts. Local deferrable functions can be enabled or disabled on the local CPU by acting on the softirq counter stored in the <code>preempt_count</code> field of the current’s <code>thread_info</code> descriptor.</p>
<h2 id="3-Synchronizing-Accesses-to-Kernel-Data-Structures"><a href="#3-Synchronizing-Accesses-to-Kernel-Data-Structures" class="headerlink" title="3 Synchronizing Accesses to Kernel Data Structures"></a>3 Synchronizing Accesses to Kernel Data Structures</h2><p>Usually, the following rule of thumb is adopted by kernel developers: <em>always keep the concurrency level as high as possible in the system</em>.</p>
<p>In turn, the concurrency level in the system depends on two main factors:</p>
<ul>
<li>The number of I/O devices that operate concurrently</li>
<li>The number of CPUs that do productive work</li>
</ul>
<p>To maximize I/O throughput, interrupts should be disabled for very short periods of time. To use CPUs efficiently, synchronization primitives based on spin locks should be avoided whenever possible.</p>
<h3 id="3-1-Choosing-Among-Spin-Locks-Semaphores-and-Interrupt-Disabling"><a href="#3-1-Choosing-Among-Spin-Locks-Semaphores-and-Interrupt-Disabling" class="headerlink" title="3.1 Choosing Among Spin Locks, Semaphores, and Interrupt Disabling"></a>3.1 Choosing Among Spin Locks, Semaphores, and Interrupt Disabling</h3><p>Generally speaking, choosing the synchronization primitives depends on what kinds of kernel control paths access the data structure, as shown in Table 5-8. Remember that whenever a kernel control path acquires a spin lock (as well as a read/write lock, a seqlock, or a RCU “read lock”), disables the local interrupts, or disables the local softirqs, kernel preemption is automatically disabled.</p>
<p><img src="/images/2018/12/24.png" alt=""></p>

      
    </div>

    
      
      



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/Kernel/">Kernel</a>
            
              <a href="/tags/读书笔记/">读书笔记</a>
            
              <a href="/tags/Concurrency/">Concurrency</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
    
      <a class="next" href="/2018/12/13/深入理解-Linux-的-RCU-机制/">
        <span class="next-text nav-default">深入理解 Linux 的 RCU 机制</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:liujunming1163@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/liujunming" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2016 - 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">liujunming</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  <script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://liujunming.github.io/2018/12/14/Understanding-the-Linux-Kernel-读书笔记-Kernel-Synchronization/';
        this.page.identifier = '2018/12/14/Understanding-the-Linux-Kernel-读书笔记-Kernel-Synchronization/';
        this.page.title = 'Understanding the Linux Kernel 读书笔记 -Kernel Synchronization';
    };
    (function() {
    var d = document, s = d.createElement('script');

    s.src = '//http-liujunming-top-2.disqus.com/embed.js';

    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();  
  </script>

  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script>

  </body>
</html>
