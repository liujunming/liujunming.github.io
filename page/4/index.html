<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="liujunming's personal blog."/>













  <link rel="alternate" href="/atom.xml" title="L">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1" />



<link rel="canonical" href="http://liujunming.github.io/page/4/"/>



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css" />



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1" />



  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>









<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true};
</script>

    <title> L </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">L</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">L</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <section id="posts" class="posts">
    
      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/12/24/Device-mapper-direct-lvm-配置/">Device mapper direct-lvm 配置</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-12-24
        </span>
        
          <span class="post-category">
            
              <a href="/categories/容器/">容器</a>
            
          </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <p>本文只介绍Device mapper direct-lvm模式的配置，关于容器的其他知识在后续博客中会有介绍。</p>
<p>以下过程将创建配置为thin pool的logical volume，以用作存储池的备份。 现在假定在<code>/dev/sda3</code>上有一个备用块设备，并具有足够的可用空间来完成任务。该过程还假定Docker守护进程处于stopped状态。</p>
<h3 id="1-确定要使用的块设备"><a href="#1-确定要使用的块设备" class="headerlink" title="1. 确定要使用的块设备"></a>1. 确定要使用的块设备</h3><p>确保<code>/dev/sda3</code>有足够的空闲空间，同时确认<code>/dev/sda3</code>是空闲分区。</p>
<h3 id="2-Stop-Docker"><a href="#2-Stop-Docker" class="headerlink" title="2. Stop Docker"></a>2. Stop Docker</h3><p><code>systemctl stop docker</code></p>
<p>且需要删除所有镜像和容器，有重要资料，请做好备份：<br><code>rm -rf /var/lib/docker/*</code></p>
<h3 id="3-创建-physical-volume"><a href="#3-创建-physical-volume" class="headerlink" title="3. 创建 physical volume"></a>3. 创建 physical volume</h3><p> <code>pvcreate /dev/sda3</code></p>
<h3 id="4-创建docker-volume-group"><a href="#4-创建docker-volume-group" class="headerlink" title="4. 创建docker volume group"></a>4. 创建docker volume group</h3><p><code>vgcreate docker /dev/sda3</code></p>
<h3 id="5-创建能够组成thin-pool的两个logical-volume"><a href="#5-创建能够组成thin-pool的两个logical-volume" class="headerlink" title="5. 创建能够组成thin-pool的两个logical volume"></a>5. 创建能够组成thin-pool的两个logical volume</h3><p><code>lvcreate --wipesignatures y -n thinpool docker -l 95%VG</code></p>
<p><code>lvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VG</code></p>
<h3 id="6-创建thin-pool"><a href="#6-创建thin-pool" class="headerlink" title="6. 创建thin-pool"></a>6. 创建thin-pool</h3><p><code>lvconvert -y --zero n -c 64K --thinpool docker/thinpool --poolmetadata docker/thinpoolmeta</code></p>
<h3 id="7-配置thin-pool的自动扩展"><a href="#7-配置thin-pool的自动扩展" class="headerlink" title="7. 配置thin-pool的自动扩展"></a>7. 配置thin-pool的自动扩展</h3><p>修改lvm配置文件<br><code>vim /etc/lvm/profile/docker-thinpool.profile</code><br>内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">activation&#123;</span><br><span class="line">   thin_pool_autoextend_threshold=80</span><br><span class="line">   thin_pool_autoextend_percent=20</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="8-激活配置文件"><a href="#8-激活配置文件" class="headerlink" title="8. 激活配置文件"></a>8. 激活配置文件</h3><p><code>lvchange --metadataprofiledocker-thinpool docker/thinpool</code></p>
<h3 id="9-启用对主机上-logical-volume的监视"><a href="#9-启用对主机上-logical-volume的监视" class="headerlink" title="9. 启用对主机上 logical volume的监视"></a>9. 启用对主机上 logical volume的监视</h3><p><code>lvs -o+seg_monitor</code></p>
<h3 id="10-使用脚本配置devicemapper-storage-driver"><a href="#10-使用脚本配置devicemapper-storage-driver" class="headerlink" title="10. 使用脚本配置devicemapper storage driver"></a>10. 使用脚本配置devicemapper storage driver</h3><p><code>vim /etc/docker/daemon.json</code></p>
<p>内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;storage-driver&quot;: &quot;devicemapper&quot;,</span><br><span class="line">    &quot;storage-opts&quot;: [</span><br><span class="line">    &quot;dm.thinpooldev=/dev/mapper/docker-thinpool&quot;,</span><br><span class="line">    &quot;dm.use_deferred_removal=true&quot;,</span><br><span class="line">    &quot;dm.use_deferred_deletion=true&quot;,</span><br><span class="line">    &quot;dm.fs=ext4&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="11-开启Docker"><a href="#11-开启Docker" class="headerlink" title="11. 开启Docker"></a>11. 开启Docker</h3><p><code>service docker start</code></p>
<h4 id="12-验证Docker是否正在使用新的配置"><a href="#12-验证Docker是否正在使用新的配置" class="headerlink" title="12. 验证Docker是否正在使用新的配置"></a>12. 验证Docker是否正在使用新的配置</h4><p><code>docker info</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Containers: 0</span><br><span class="line"> Running: 0</span><br><span class="line"> Paused: 0</span><br><span class="line"> Stopped: 0</span><br><span class="line">Images: 0</span><br><span class="line">Server Version: 17.03.1-ce</span><br><span class="line">Storage Driver: devicemapper</span><br><span class="line"> Pool Name: docker-thinpool</span><br><span class="line"> Pool Blocksize: 524.3 kB</span><br><span class="line"> Base Device Size: 10.74 GB</span><br><span class="line"> Backing Filesystem: ext4</span><br><span class="line"> Data file:</span><br><span class="line"> Metadata file:</span><br><span class="line"> Data Space Used: 19.92 MB</span><br><span class="line"> Data Space Total: 102 GB</span><br><span class="line"> Data Space Available: 102 GB</span><br><span class="line"> Metadata Space Used: 147.5 kB</span><br><span class="line"> Metadata Space Total: 1.07 GB</span><br><span class="line"> Metadata Space Available: 1.069 GB</span><br><span class="line"> Thin Pool Minimum Free Space: 10.2 GB</span><br><span class="line"> Udev Sync Supported: true</span><br><span class="line"> Deferred Removal Enabled: true</span><br><span class="line"> Deferred Deletion Enabled: true</span><br><span class="line"> Deferred Deleted Device Count: 0</span><br><span class="line"> Library Version: 1.02.135-RHEL7 (2016-11-16)</span><br></pre></td></tr></table></figure></p>
<p>如果Docker配置正确，Data file和Metadata file将是空白的，pool name将是docker-thinpool。<br>如果显示不对，重启主机后再测试。</p>
<hr>
<p>参考资料:</p>
<ol>
<li><a href="https://docs.docker.com/engine/userguide/storagedriver/device-mapper-driver/#configure-direct-lvm-mode-for-production" target="_blank" rel="noopener">Use the Device mapper storage driver</a></li>
<li><a href="http://blog.csdn.net/a85880819/article/details/52457702" target="_blank" rel="noopener">Devicemapper的direct-lvm模式</a></li>
</ol>

        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/11/27/Sysbench环境搭建/">Sysbench环境搭建</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-11-27
        </span>
        
          <span class="post-category">
            
              <a href="/categories/benchmark/">benchmark</a>
            
          </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <h2 id="sysbench"><a href="#sysbench" class="headerlink" title="sysbench"></a>sysbench</h2><p>本文只介绍sysbench的使用教程，详细介绍见参考资料。</p>
<h3 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h3><ul>
<li><code>sudo apt-get install mysql-server</code></li>
</ul>
<p>安装过程中需要设置密码，我们设置为123。</p>
<ul>
<li>更改mysql配置文件</li>
</ul>
<p><code>vim /etc/mysql/mysql.conf.d/mysqld.cnf</code>或者<code>vim /etc/mysql/my.cnf</code><br>这一步依照自己的需求而定。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">innodb_buffer_pool_size = 4G</span><br><span class="line">query_cache_type        = 0</span><br></pre></td></tr></table></figure></p>
<p>更改完配置文件之后，需要重启mysql:<code>sudo service  mysql restart</code></p>
<h3 id="安装sysbench"><a href="#安装sysbench" class="headerlink" title="安装sysbench"></a>安装sysbench</h3><ul>
<li><code>sudo apt-get install sysbench</code></li>
</ul>
<h3 id="测试运行"><a href="#测试运行" class="headerlink" title="测试运行"></a>测试运行</h3><ul>
<li>进入mysql</li>
</ul>
<p><code>mysql -u root -p</code></p>
<ul>
<li>创建数据库 </li>
</ul>
<p><code>create database sbtest;</code></p>
<ul>
<li><p>创建测试数据 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysbench --test=oltp --oltp-test-mode=nontrx --mysql-table-engine=innodb --mysql-user=root --db-driver=mysql --num-threads=8 --max-requests=5000000  --oltp-nontrx-mode=select --mysql-db=sbtest  --oltp-table-size=7000000 --oltp-table-name=sbtest  --mysql-host=127.0.0.1 --mysql-socket=/var/run/mysqld/mysqld.sock --mysql-password=123 prepare</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time sysbench --test=oltp --oltp-test-mode=nontrx --mysql-table-engine=innodb --mysql-user=root --db-driver=mysql --num-threads=8 --max-requests=5000000  --oltp-nontrx-mode=select --mysql-db=sbtest  --oltp-table-size=7000000 --oltp-table-name=sbtest  --mysql-host=127.0.0.1 --mysql-socket=/var/run/mysqld/mysqld.sock --mysql-password=123 run</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>性能指标为每秒处理的事务数：<br><img src="/images/2017/11/1.png" alt=""></p>
<ul>
<li>注意事项：</li>
</ul>
<p>如果需要提前将测试数据读入内存，可使用如下指令：<br><code>use sbtest;</code><br><code>select count(id) from (select * from sbtest)aa;</code></p>
<p>如果需要重新创建测试数据，则需要删除原先的数据：<br><code>drop table sbtest;</code></p>
<p>查看cache hit情况可使用如下指令：<br><code>show global status like &#39;innodb%read%&#39;;</code></p>
<hr>
<p>参考资料:</p>
<ol>
<li><a href="http://www.cnblogs.com/zhoujinyi/archive/2013/04/19/3029134.html" target="_blank" rel="noopener">sysbench 安装、使用和测试</a></li>
<li><a href="http://imysql.cn/node/312" target="_blank" rel="noopener">sysbench的安装和做性能测试</a></li>
<li><a href="http://blog.csdn.net/cy309173854/article/details/53112904" target="_blank" rel="noopener">sysbench压力测试工具使用方法</a></li>
<li><a href="http://blog.csdn.net/lijingkuan/article/details/72801097" target="_blank" rel="noopener">sysbench简单使用介绍</a></li>
<li><a href="http://keithlan.github.io/2016/12/16/sysbench_mysql/" target="_blank" rel="noopener">使用sysbench对mysql进行测试</a></li>
<li><a href="http://imysql.com/2015/03/27/mysql-faq-why-should-we-disable-query-cache.shtml" target="_blank" rel="noopener">为什么要关闭query cache，如何关闭</a></li>
</ol>

        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/11/14/mmap函数内核实现/">mmap函数内核实现</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-11-14
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          
        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/10/31/SPECjbb环境搭建/">SPECjbb环境搭建</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-10-31
        </span>
        
          <span class="post-category">
            
              <a href="/categories/benchmark/">benchmark</a>
            
          </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <h2 id="SPECjbb2005"><a href="#SPECjbb2005" class="headerlink" title="SPECjbb2005"></a>SPECjbb2005</h2><h3 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h3><p>下载<a href="https://github.com/liujunming/SPECjbb2005/" target="_blank" rel="noopener">SPECjbb2005</a>源码。</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>SPECjbb2005(Java Business Benchmark)基准测试模拟一个三层架构环境来进行JAVA 应用服务器测试， 目的是衡量应用服务器端JAVA 应用之性能。正规SPECjbb2005 测试结果发布必须提供bops 值, 即每秒钟完成多少笔JAVA 业务操作(Business Operation Per Second), 同时要求提供完整的测试环境资料。</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>每个”warehouse”会产生一个独立的线程，从而决定测试线程的并发数。</p>
<p>具体在使用过程中需要修改配置文件SPECjbb.props，根据所测试服务器核数多少来设置warehouse，一般warehouse为核数的两倍。</p>
<p>下面为配置文件主要参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">input.starting_number_warehouses=0</span><br><span class="line">input.increment_number_warehouses=1</span><br><span class="line">input.ending_number_warehouses=8</span><br><span class="line">input.sequence_of_number_of_warehouses=1 2 3 4 5 6 7 8</span><br><span class="line">//warehouse设置为8，每次增量为1，初始化时为0，打印的序列号为1-8。即测试服务器核数为4。</span><br><span class="line">input.ramp_up_seconds=30</span><br><span class="line">//warehouse未到达核数时，每个warehouse测试时间为30秒。</span><br><span class="line">input.measurement_seconds=240</span><br><span class="line">//warehouse超过核数时，每个warehouse测试时间为240秒。</span><br></pre></td></tr></table></figure></p>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>主要配置文件参数设置结束后，然后可以直接开始测试，因为测试的命令比较繁琐，因此写成一个脚本操作。</p>
<ul>
<li><code>chmod +x ./run.sh</code></li>
<li><code>./run.sh</code></li>
</ul>
<p>run.sh内容如下：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo $CLASSPATH</span><br><span class="line">CLASSPATH=./jbb.jar:./check.jar:$CLASSPATH</span><br><span class="line">echo $CLASSPATH</span><br><span class="line">export CLASSPATH</span><br><span class="line">export LD_LIBRARY_PATH=$THORDIR/lib</span><br><span class="line">JAVA=/usr/bin/java</span><br><span class="line"><span class="meta">$</span>JAVA -fullversion</span><br><span class="line"><span class="meta">$</span>JAVA -Xms2048m -Xmx2048m spec.jbb.JBBmain -propfile SPECjbb.props</span><br></pre></td></tr></table></figure></p>
<p>这里关于-Xms2048m -Xmx2048m需要注意，-Xmx2048m:设置JVM最大可用内存为2048M.-Xms2048m:设置JVM促使内存为2048m.此值可以设置与-Xmx相同,以避免每次垃圾回收完成后JVM重新分配内存.且这里设置内存大小标准为，不要超过服务器内存的80%。超过后性能会降低，如果分配内存过少，性能也会较低。</p>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>SPECjbb2005比较好用的一点是，输出结果时会同时生成走势图。走势图和warehouse结果都在results/SPECjbbSingleJVM里。<br>bops显示在运行结果的最后：</p>
<p><img src="/images/2017/10/9.png" alt=""></p>
<hr>
<p>参考资料:</p>
<ol>
<li><a href="http://blog.csdn.net/guofu8241260/article/details/9232747" target="_blank" rel="noopener">服务器JAVA性能测试——SPECjbb2005</a></li>
<li><a href="https://sp.ts.fujitsu.com/dmsp/Publications/public/Benchmark_Overview_SPECjbb2005.pdf" target="_blank" rel="noopener">Benchmark overview SPECjbb2005</a></li>
</ol>

        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/10/10/Linux内核高端内存/">Linux内核高端内存</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-10-10
        </span>
        
          <span class="post-category">
            
              <a href="/categories/内存管理/">内存管理</a>
            
          </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <h2 id="Linux内核高端内存"><a href="#Linux内核高端内存" class="headerlink" title="Linux内核高端内存"></a>Linux内核高端内存</h2><p>本文内容主要来自<a href="http://ilinuxkernel.com/?p=1013" target="_blank" rel="noopener">ilinuxkernel.com</a>，并对该部分内容进行了扩充。</p>
<p>下图展示的部分内容包含了本文的知识点，值得细细分析。<br><img src="/images/2017/10/8.gif" alt=""></p>
<h3 id="Linux内核地址空间划分"><a href="#Linux内核地址空间划分" class="headerlink" title="Linux内核地址空间划分"></a>Linux内核地址空间划分</h3><p>通常<strong>32位Linux进程地址空间</strong>划分0~3G为用户空间，3~4G为空间。注意这里是32位进程地址空间划分，64位进程地址空间划分是不同的。<br><img src="/images/2017/10/4.png" alt=""></p>
<h3 id="Linux内核高端内存的由来"><a href="#Linux内核高端内存的由来" class="headerlink" title="Linux内核高端内存的由来"></a>Linux内核高端内存的由来</h3><p>当内核模块代码或线程访问内存时，代码中的内存地址都为逻辑地址，而对应到真正的物理内存地址，需要地址<strong>一对一</strong>的映射，如逻辑地址0xc0000003对应的物理地址为0x3，0xc0000004对应的物理地址为0x4，… …，逻辑地址与物理地址对应的关系为:<br><code>物理地址 = 逻辑地址 – 0xC0000000</code></p>
<p>假设按照上述简单的地址映射关系，那么内核逻辑地址空间访问为0xc0000000 ~ 0xffffffff，那么对应的物理内存范围就为0x0 ~ 0x40000000，即只能访问1G物理内存。若机器中安装8G物理内存，那么内核就只能访问前1G物理内存，后面7G物理内存将会无法访问，因为内核的地址空间已经全部映射到物理内存地址范围0x0 ~ 0x40000000。即使安装了8G物理内存，那么物理地址为0x40000001的内存，内核该怎么去访问呢？代码中必须要有内存逻辑地址的，0xc0000000 ~ 0xffffffff的地址空间已经被用完了，所以无法访问物理地址0x40000000以后的内存。</p>
<p>显然不能将内核地址空间0xc0000000 ~ 0xfffffff全部用来简单的地址映射。x86架构中将物理地址空间划分三部分：ZONE_DMA、ZONE_NORMAL和ZONE_HIGHMEM。ZONE_HIGHMEM即为高端内存，这就是高端内存概念的由来。</p>
<p>在x86结构中，三种类型的区域如下：</p>
<ul>
<li><strong> ZONE_DMA</strong>        物理内存开始的16MB</li>
<li><strong>ZONE_NORMAL</strong>       物理内存的16MB~896MB</li>
<li><strong>ZONE_HIGHMEM</strong>       物理内存的896MB ~ 结束<br><img src="/images/2017/10/5.png" alt=""></li>
</ul>
<h3 id="Linux内核高端内存的理解"><a href="#Linux内核高端内存的理解" class="headerlink" title="Linux内核高端内存的理解"></a>Linux内核高端内存的理解</h3><p>前面我们解释了高端内存的由来。 Linux将物理地址空间划分为三部分ZONE_DMA、ZONE_NORMAL和ZONE_HIGHMEM，高端内存HIGH_MEM地址空间映射的内核线性地址范围为0xF8000000 ~ 0xFFFFFFFF（896MB～1024MB）。</p>
<p>当内核想访问高于896MB物理地址内存时，从0xF8000000 ~ 0xFFFFFFFF地址空间范围内找一段相应大小空闲的逻辑地址空间，借用一会。借用这段逻辑地址空间，建立映射到想访问的那段物理内存（即填充内核页表），<strong>临时用一会，用完后归还</strong>。这样别人也可以借用这段地址空间访问其他物理内存，实现了使用有限的地址空间，访问所有所有物理内存。如下图:<br><img src="/images/2017/10/6.png" alt=""></p>
<p>例如内核想访问2G开始的一段大小为1MB的物理内存，即物理地址范围为0x80000000 ~ 0x800FFFFF。访问之前先找到一段1MB大小的空闲地址空间，假设找到的空闲地址空间为0xF8700000 ~ 0xF87FFFFF，用这1MB的逻辑地址空间映射到物理地址空间0x80000000 ~ 0x800FFFFF的内存。</p>
<p>当内核访问完0x80000000 ~ 0x800FFFFF物理内存后，就将0xF8700000 ~ 0xF87FFFFF内核线性空间释放。这样其他进程或代码也可以使用0xF8700000 ~ 0xF87FFFFF这段地址访问其他物理内存。</p>
<p>从上面的描述，我们可以知道<strong>高端内存的最基本思想</strong>：借一段地址空间，建立临时地址映射，用完后释放，达到这段地址空间可以循环使用，访问所有物理内存。</p>
<h3 id="高端内存的映射"><a href="#高端内存的映射" class="headerlink" title="高端内存的映射"></a>高端内存的映射</h3><p>0xF8000000 ~ 0xFFFFFFFF（896MB～1024MB)的128MB内核线性地址空间被划分为3部分：VMALLOC_START~VMALLOC_END、KMAP_BASE~FIXADDR_START和FIXADDR_START~4G。</p>
<p><img src="/images/2017/10/7.png" alt=""></p>
<p>对于高端内存，可以通过 alloc_page() 或者其它函数获得对应的 page，但是要想访问实际物理内存，还得把 page 转为线性地址才行，也就是说，我们需要为高端内存对应的 page 找一个线性空间，这个过程称为高端内存映射。</p>
<p>对应128MB内核线性地址空间的3部分，高端内存映射有三种方式：</p>
<ul>
<li><strong>映射到”内核动态映射空间”（noncontiguous memory allocation）</strong></li>
</ul>
<p>这种方式很简单，因为通过 vmalloc() ，在”内核动态映射空间”申请内存的时候，就从高端内存获得页面，因此说高端内存有可能映射到”内核动态映射空间”中。</p>
<ul>
<li><strong>持久内核映射（permanent kernel mapping）</strong></li>
</ul>
<p>内核专门留出一块线性空间，从 PKMAP_BASE 到 FIXADDR_START ，用于映射高端内存。在 2.6内核上，这个地址范围是 4G-8M 到 4G-4M 之间。这个空间叫”持久内核映射空间”。通过<code>kmap()</code>，可以把一个 page 映射到这个空间来。因为允许永久映射的数量有限，当不再需要高端内存时，应该解除映射，这可以通过<code>kunmap()</code>函数来完成。</p>
<ul>
<li><strong>临时映射（temporary kernel mapping）</strong></li>
</ul>
<p>内核在 FIXADDR_START 到 FIXADDR_TOP(4GB)之间保留了一些线性空间用于特殊需求。这个空间称为”固定映射空间”，在这个空间中，有一部分用于高端内存的临时映射。<br>这个空间具有如下特点：</p>
<ol>
<li>每个 CPU 占用一块空间</li>
<li>在每个 CPU 占用的那块空间中，又分为多个小空间，每个小空间大小是 1 个 page，每个小空间用于一个目的，这些目的定义在 kmap_types.h 中的 km_type 中。</li>
</ol>
<p>当要进行一次临时映射的时候，需要指定映射的目的，根据映射目的，可以找到对应的小空间，然后把这个空间的地址作为映射地址。这意味着一次临时映射会导致以前的映射被覆盖。通过<code>kmap_atomic()</code>可实现临时映射。</p>
<h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><p>1. 用户空间是否有高端内存概念？</p>
<p>用户空间没有高端内存概念，只有内核空间才存在高端内存。</p>
<p>2. 64位内核中有高端内存吗？</p>
<p>目前现实中，64位Linux内核不存在高端内存，因为64位内核可以支持超过512GB内存。若机器安装的物理内存超过内核地址空间范围，就会存在高端内存。</p>
<p>3. 高端内存和物理地址、线性地址的关系？</p>
<p>高端内存只和物理地址有关系，和线性地址没有直接关系。</p>
<hr>
<p>参考资料：</p>
<ol>
<li><a href="http://ilinuxkernel.com/?p=1013" target="_blank" rel="noopener">ilinuxkernel Linux内核高端内存</a></li>
</ol>

        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/10/08/Linux-swapping机制详解/">Linux swapping机制详解</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-10-08
        </span>
        
          <span class="post-category">
            
              <a href="/categories/内存管理/">内存管理</a>
            
          </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <h2 id="swapping"><a href="#swapping" class="headerlink" title="swapping"></a>swapping</h2><p>说明：本文中介绍的内核版本为<a href="http://elixir.free-electrons.com/linux/v2.6.11/source" target="_blank" rel="noopener">2.6.11</a></p>
<p>名词汇总：</p>
<ol>
<li>交换区(swap area)</li>
<li>页槽(page slot)</li>
<li>swap in (换入)：是指页面从交换分区转移到内存之中</li>
<li>swap out (换出)：是指页面从内存转移到交换分区中</li>
<li>PFRA(page frame reclaiming algorithm)</li>
<li>交换子区(swap extent)</li>
</ol>
<p>swapping子系统的主要功能总结如下:</p>
<ul>
<li>在磁盘上建立交换区(swap area)，用于存放没有磁盘映像的页</li>
<li>管理交换区空间。当需求发生时，分配与释放页槽(page slot)</li>
<li>提供函数用于从RAM中把页换出(swap out)到交换区或从交换区换入(swap in)到RAM中</li>
<li>利用页表项中的换出页标识符跟踪数据在交换区中的位置</li>
</ul>
<h3 id="交换区"><a href="#交换区" class="headerlink" title="交换区"></a>交换区</h3><p>从内存中换出的页存放在交换区(swap area)中，交换区的实现可以使用磁盘分区，也可以使用包含在大型分区中的文件。可以定义多个交换区，最大个数由<code>MAX_SWAPFILES</code>宏(通常被设置为32)确定。</p>
<p>每个交换区都由一组页槽(page slot)组成，也就是说，由一组4096字节大小的块组成，每块中包含一个换出的页。交换区的第一个页槽用来永久存放有关交换区的信息。</p>
<h4 id="创建与激活交换区"><a href="#创建与激活交换区" class="headerlink" title="创建与激活交换区"></a>创建与激活交换区</h4><p>通常，系统管理员在创建Linux系统中的其他分区时都创建一个交换分区，然后使用<code>mkswap</code>命令把这个磁盘区设置成一个新的交换区。该命令对刚才介绍的第一个页槽中的字段进行初始化。由于磁盘中可能会有一些坏块，这个程序还可以对其他所有的页槽进行检查从而确定有缺陷页槽的位置。但是执行<code>mkswap</code>命令会把交换区设置为非激活状态。每个交换区都可以在系统启动时在脚本文件中被激活，也可以在系统执行之后动态激活。<br>每个交换区都由一个或者多个交换子区(swap extent)组成，每个交换子区由一个<br><code>swap_extent</code>描述符表示，每个子区对应一组页槽，它们在磁盘上是物理相邻的。当激活交换区自身的同时，组成交换区的有序子区链表也被创建。存放在磁盘分区中的交换区只有一个子区；但是存放在普通文件中的交换区则可能有多个子区，这是因为文件系统有可能没把该文件全部分配在磁盘的一组连续块中。</p>
<h4 id="如何在交换区中分布页"><a href="#如何在交换区中分布页" class="headerlink" title="如何在交换区中分布页"></a>如何在交换区中分布页</h4><p>当换出时，内核尽力把换出的页存放在相邻的页槽中，从而减少在访问交换区时磁盘的寻道时间，这是高效交换算法的一个重要因素。</p>
<h3 id="交换区描述符"><a href="#交换区描述符" class="headerlink" title="交换区描述符"></a>交换区描述符</h3><p>每个活动的交换区在内存中都有自己的<a href="http://elixir.free-electrons.com/linux/v2.6.11/source/include/linux/swap.h#L121" target="_blank" rel="noopener">swap_info_struct</a>描述符，其结构如下所示：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The in-memory structure used to track swap areas.</span></span><br><span class="line"><span class="comment"> * extent_list.prev points at the lowest-index extent.  That list is</span></span><br><span class="line"><span class="comment"> * sorted.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">swap_info_struct</span> &#123;</span></span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">int</span> flags; <span class="comment">//交换区标志</span></span><br><span class="line">	<span class="keyword">spinlock_t</span> sdev_lock;<span class="comment">//保护交换区的自旋锁</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">swap_file</span>;</span><span class="comment">//指针，指向存放交换区的普通文件或者设备文件的文件对象</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">block_device</span> *<span class="title">bdev</span>;</span><span class="comment">//存放交换区的块设备描述符</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">extent_list</span>;</span><span class="comment">//组成交换区的子区链表的头部</span></span><br><span class="line">	<span class="keyword">int</span> nr_extents;<span class="comment">//组成交换区的子区数量</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">swap_extent</span> *<span class="title">curr_swap_extent</span>;</span></span><br><span class="line">	<span class="keyword">unsigned</span> old_block_size;</span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">short</span> * swap_map;<span class="comment">//指向计数器数组的指针，交换区的每个页槽对应一个数组元素</span></span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">int</span> lowest_bit;</span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">int</span> highest_bit;</span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">int</span> cluster_next;</span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">int</span> cluster_nr;</span><br><span class="line">	<span class="keyword">int</span> prio;<span class="comment">// 交换区优先级</span></span><br><span class="line">	<span class="keyword">int</span> pages;<span class="comment">//可用页槽的个数</span></span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">long</span> max;<span class="comment">//交换区的大小，以页为单位</span></span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">long</span> inuse_pages;<span class="comment">//交换区内已用页槽数</span></span><br><span class="line">	<span class="keyword">int</span> next;<span class="comment">// 指向下一个交换区描述符的指针</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p><code>swap_map</code>字段指向一个计数器数组，交换区的每个页槽对应一个元素。如果计数器值等于０，那么这个页槽就是空闲的；如果计数器为正数，那么换出页就填充了这个页槽，实际上，页槽计数器的值就表示共享换出页的进程数；如果计数器的值是<br>SWAP_MAP_BAD(等于32768)，那么就认为这个页槽是有缺陷的，也就是不可用的。<br><code>swap_info</code>数组包括<code>MAX_SWAPFILES</code>个交换区描述符。</p>
<p>下图说明了<code>swap_info</code>数组、一个交换区和相应的计数器数组的情况。</p>
<p><img src="/images/2017/10/1.png" alt=""></p>
<h3 id="换出页标识符"><a href="#换出页标识符" class="headerlink" title="换出页标识符"></a>换出页标识符</h3><p>可以很简单地而又唯一地标志一个换出页，这是通过<code>swap_info</code>数组中指定交换区的索引和在交换区内指定页槽的索引实现的。由于交换区的第一个页(索引为0)用来存放有关交换区的信息，第一个可用页槽的索引就为1。换出页标识符的格式如下图所示:<br><img src="/images/2017/10/2.png" alt=""></p>
<p>当页被换出时，其换出标识符就作为page entry插入页表中，这样在需要时就可以再找到这个页。要注意这中标志符的最低位与<code>Present</code>标志对应，通常被清除来说明该页目前不在RAM中。但是，剩余31位中至少有一个被置位，因为没有页存放在交换区0的页槽0中。这样就可以从一个页表项中区分三种不同的情况:</p>
<ul>
<li>空项:该页相应的页框还没有分配给进程</li>
<li>前31个最高位不全等于0，最后一位等于0:该页现在被换出</li>
<li>最低位等于１:该页包含在RAM中</li>
</ul>
<h3 id="激活和禁用交换区"><a href="#激活和禁用交换区" class="headerlink" title="激活和禁用交换区"></a>激活和禁用交换区</h3><p>一旦交换区被初始化，超级用户就可以分别使用<em>swapon</em>  和<em>swapoff</em> 程序激活和禁用交换区，这两个程序分别使用了<code>swapon()</code>和<code>swapoff()</code>系统调用。</p>
<h3 id="分配和释放页槽"><a href="#分配和释放页槽" class="headerlink" title="分配和释放页槽"></a>分配和释放页槽</h3><p>在释放内存时，内核要在很短的时间内把很多页都交换出去。因此尽力把这些页存放在相邻的页槽中非常重要，这样就可以减少在访问交换区时磁盘的寻道时间。</p>
<h3 id="swap-cache"><a href="#swap-cache" class="headerlink" title="swap cache"></a>swap cache</h3><p>向交换区来回传送页会引发很多竞争，具体来说，交换子系统必须仔细处理下面的情形:</p>
<ul>
<li>多重换入：两个进程可能同时要换入同一个共享匿名页</li>
<li>同时换入换出:一个进程可能换入正由PFRA换出的页</li>
</ul>
<p>swap cache的引入就是为了解决这类同步问题。关键的原则是，没有检查swap cache是否已包括了所涉及的页，就不能进行换入或者换出操作。有了swap cache,涉及同一页的并发交换操作总是作用于同一个页框的。因此，内核可以安全地依赖页描述符的<code>PG_locked</code>标志，以避免任何竞争。</p>
<p>考虑一下共享同一换出页的两个进程这种情形。当第一个进程试图访问页时，内核开始换入页操作，第一步就是检查页框是否在swap cache中，我们假定页框不在swap cache中，那么内核就分配一个新页框并把它插入到swap cache，然后开始I/O操作，从交换区读入页的数据；同时，第二个进程访问该共享匿名页，与上面相同，内核开始换入操作，检查涉及的页框是否在swap cache中。现在页框是在swap cache，因此内核只是访问页框描述符，在PG_locked标志清0之前（即I/O数据传输完毕之前），让当前进程睡眠。</p>
<p>当换入换出操作同时出现时，swap cache起着至关重要的作用。<code>shrink_list()</code>函数要开始换出一个匿名页，就必须当<code>try_to_unmap()</code>从进程（所有拥有该页的进程）的用户态页表中成功删除了该页后才可以。但是当换出的页写操作还在执行的时候，这些进程中可能有某个进程要访问该页，而产生换入操作。<br>在写入磁盘前，待换出的页由<code>shrink_list()</code>存放在swap cache。考虑页由两个进程（A和B）共享的情况，如下图(a)所示。最初，两个进程的页表项都引用该页框，该页有两个拥有者。当PFRA选择回收页时，<code>shrink_list()</code>把页框插入swap cache，如下图(b)所示。然后PFRA调用<code>try_to_unmap()</code>从这两个进程的页表项中删除对该页框的引用。一旦这个函数结束，该页框就只有swap cache引用它，而引用页槽的有这两个进程和swap cache，如下图(c)所示。假如正当页中的数据写入磁盘时，进程B又访问该页，即它要用该页内部的线性地址访问它，那么缺页异常处理程序会发现页框正在swap cache中，并把物理地址放回进程B的页表项，如下图(d)所示。如果上面并发的换入操作没发生，换出操作结束，则<code>shrink_list()</code>会从swap cache删除该页框并把它释放到伙伴系统，如下图(e)所示。<br><img src="/images/2017/10/3.png" alt=""></p>
<p>可以认为swap cache是一个临时区域，该区域存有正在被换入或换出的匿名页描述符。当换入或换出结束时（对于共享匿名页，换入换出操作必须对共享该页的所有进程进行），匿名页描述符就可以从swap cache删除。</p>
<h3 id="换出页"><a href="#换出页" class="headerlink" title="换出页"></a>换出页</h3><ol>
<li>向swap cache插入页框</li>
<li>更新页表项</li>
<li>将页写入交换区</li>
<li>从swap cache中删除页框</li>
</ol>
<h3 id="换入页"><a href="#换入页" class="headerlink" title="换入页"></a>换入页</h3><p>当进程试图对一个已被换出的页进行寻址时，必然会发生页的换入。在以下条件全满足时，缺页异常处理程序会触发一个换入操作:</p>
<ul>
<li>引起异常的地址所在的页是一个有效的页，也就是说，它属于当前进程的一个线性区</li>
<li>页不在内存中，也就是页表项的Present标志被清除</li>
<li>与页有关的页表项不为空，但是<code>PG_dirty</code>位被清0，意味着页表项包含一个换出页标识符</li>
</ul>
<p>如果上面的所有条件满足，则<code>handle_pte_fault()</code>调用<code>do_swap_page()</code>函数换入所需的页。</p>
<hr>
<p>参考资料：</p>
<ol>
<li>《深入理解LINUX内核》第十七章第４节</li>
</ol>

        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/09/28/Linux内核中的页面回收算法/">Linux内核中的页面回收算法</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-09-28
        </span>
        
          <span class="post-category">
            
              <a href="/categories/内存管理/">内存管理</a>
            
          </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <h2 id="Linux内核中的页面回收算法"><a href="#Linux内核中的页面回收算法" class="headerlink" title="Linux内核中的页面回收算法"></a>Linux内核中的页面回收算法</h2><p>本文将基于 2.6.18.1 版本的内核来探讨 Linux 中的页面回收机制。</p>
<h3 id="为什么要进行页面回收"><a href="#为什么要进行页面回收" class="headerlink" title="为什么要进行页面回收"></a>为什么要进行页面回收</h3><p>操作系统管理内存中的物理页面，同时也担任着内存分配的职责。应用程序可以通过内存分配函数向操作系统申请物理页面；在使用完这些物理页面之后，应用程序可以通过相应的内存释放函数释放这些物理页面。但是，对于内存中的某些物理页面，页面的使用者并不会主动释放它们，如果这些物理页面一直被占用而得不到释放，那么无论计算机上可用的物理内存有多少，物理内存迟早都有被用完的时候。所以，对于无法被主动释放的物理页面，操作系统就需要提供相应的功能去释放它们，Linux 中提供页面回收机制进行页面回收。</p>
<p>一般来说，page cache无法被页面的使用者主动释放，因为系统不知道这些页面何时应该被释放。Linux 中page cache存在的最大好处就是可以让程序从缓存中快速获取数据，从而提升系统的性能。在系统负载不重的情况下，Linux 操作系统会分配较多的物理页面用于页缓存，从而提高程序的运行效率；但是在系统负载较重的情况下，Linux 操作系统就可能会适当回收用于缓存的页面，并减少用于缓存的页面的分配，从而满足系统中优先级更高的内存分配请求。对于用户进程来说，Linux 操作系统可以在它需要的时候为它分配物理内存，但是当用户进程不再需要这些物理页面的时候，如果用户进程不主动释放占用的页面，Linux 操作系统也不会强制用户进程去释放这些物理页面。基于上述这些情况，当内存中可用的物理页面越来越少，并最终导致内存的使用捉襟见肘的时候，为了保证系统的顺利运行，Linux 操作系统就会根据一定的算法去回收那些长期被占用并且没有得到有效使用的物理页面。</p>
<p>由操作系统内核本身使用的物理页面不在 Linux 操作系统进行页面回收的考虑范围之内，这是因为与用户进程相比，内核不需要占用非常多的内存，回收内核占用的物理页面会显著增加内核代码的复杂性，潜在收益非常低。</p>
<h3 id="页面回收机制背景"><a href="#页面回收机制背景" class="headerlink" title="页面回收机制背景"></a>页面回收机制背景</h3><h4 id="哪些页面可以被回收"><a href="#哪些页面可以被回收" class="headerlink" title="哪些页面可以被回收"></a>哪些页面可以被回收</h4><p>内存中并非所有物理页面都是可以进行回收的，总的来说，以下这些种物理页面可以被 Linux 操作系统回收：</p>
<ul>
<li>文件读写操作过程中用于缓冲数据的页面</li>
<li>用户地址空间中用于文件内存映射的页面</li>
<li>匿名页面：进程用户模式下的堆栈或者是使用 mmap 匿名映射的内存区</li>
<li>特殊的用于 slab 分配器的缓存，比如用于缓存文件目录结构 dentry 的 cache，以及用于缓存索引节点 inode 的 cache</li>
</ul>
<p>在页面被操作系统回收之前，所有与之关联的进程页表项必须要断开与该页面之间的映射关系。对于匿名页面来说，在页面被回收之前，匿名页面中的内容首先需要先被交换到交换区中去；对于page cache来说，如果要回收的页面是“脏”页面，那么该页面在被回收之前需要先将页面中的数据写回磁盘。<br>除此之外，其他的页面要么不可以被回收，要么根本不必进行回收。比如，内核占用的页面不会被回收；映射到内核空间中的页面也不会被回收；内核在执行的过程中动态生成的页面需要永驻内存；被锁住的页面不能被回收；而没有被占用的物理页面则根本不需要被回收。</p>
<h3 id="进行页面回收的时机"><a href="#进行页面回收的时机" class="headerlink" title="进行页面回收的时机"></a>进行页面回收的时机</h3><p>Linux 操作系统使用如下这两种机制检查系统内存的使用情况，从而确定可用的内存是否太少从而需要进行页面回收。</p>
<ul>
<li>周期性的检查：这是由后台运行的守护进程 kswapd 完成的。该进程定期检查当前系统的内存使用情况，当发现系统内空闲的物理页面数目少于特定的阈值时，该进程就会发起页面回收的操作。</li>
<li>“内存严重不足”事件的触发：在某些情况下，比如，操作系统忽然需要通过伙伴系统为用户进程分配一大块内存，或者需要创建一个很大的缓冲区，而当时系统中的内存没有办法提供足够多的物理内存以满足这种内存请求，这时候，操作系统就必须尽快进行页面回收操作，以便释放出一些内存空间从而满足上述的内存请求。这种页面回收方式也被称作“直接页面回收”。</li>
</ul>
<p>如果操作系统在进行了内存回收操作之后仍然无法回收到足够多的页面以满足上述内存要求，那么操作系统只有最后一个选择，那就是使用 OOM( out of memory )killer，它从系统中挑选一个最合适的进程杀死它，并释放该进程所占用的所有页面。<br>上面介绍的内存回收机制主要依赖于三个字段：pages_min，pages_low 以及 pages_high。每个内存区域（ <a href="http://elixir.free-electrons.com/linux/v2.6.18.1/source/include/linux/mmzone.h#L139" target="_blank" rel="noopener">zone</a> ）都在其区域描述符中定义了这样三个字段，这三个字段的具体含义如下表 1 所示。</p>
<p><strong>表 1. 字段含义</strong></p>
<table>
<thead>
<tr>
<th>名称</th>
<th>字段描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>pages_min</td>
<td>区域的预留页面数目，如果空闲物理页面的数目低于 pages_min，那么系统的压力会比较大，此时，内存区域中急需空闲的物理页面，页面回收的需求非常紧迫。</td>
</tr>
<tr>
<td>pages_low</td>
<td>控制进行页面回收的最小阈值，如果空闲物理页面的数目低于 pages_low，那么操作系统内核会开始进行页面回收。</td>
</tr>
<tr>
<td>pages_high</td>
<td>控制进行页面回收的最大阈值，如果空闲物理页面的数目多于 pages_high，则内存区域的状态是理想的。</td>
</tr>
</tbody>
</table>
<h3 id="页面回收算法"><a href="#页面回收算法" class="headerlink" title="页面回收算法"></a>页面回收算法</h3><p>Linux 中的页面回收是基于 LRU(least recently used，最近最少使用 ) 算法的。LRU 算法基于这样一个事实，过去一段时间内频繁使用的页面，在不久的将来很可能会被再次访问到。反过来说，已经很久没有访问过的页面在未来较短的时间内也不会被频繁访问到。因此，在物理内存不够用的情况下，这样的页面成为被换出的最佳候选者。<br>LRU 算法的基本原理很简单，为每个物理页面绑定一个计数器，用以标识该页面的访问频度。操作系统内核进行页面回收的时候就可以根据页面的计数器的值来确定要回收哪些页面。然而，在硬件上提供这种支持的体系结构很少，Linux 操作系统没有办法依靠这样一种页计数器去跟踪每个页面的访问情况，所以，Linux 在页表项中增加了一个 Accessed 位，当页面被访问到的时候，该位就会被硬件自动置位。该位被置位表示该页面还很年轻，不能被换出去。此后，在系统的运行过程中，该页面的年龄会被操作系统更改。在 Linux 中，相关的操作主要是基于两个 LRU 链表以及两个标识页面状态的标志符，下文会逐一介绍这些相应的数据结构以及 Linux 如何使用这些数据结构进行页面回收。</p>
<h4 id="LRU-链表"><a href="#LRU-链表" class="headerlink" title="LRU 链表"></a>LRU 链表</h4><p>在 Linux 中，操作系统对 LRU 的实现主要是基于一对双向链表：active 链表和 inactive 链表，这两个链表是 Linux 操作系统进行页面回收所依赖的关键数据结构，每个内存区域都存在一对这样的链表。顾名思义，那些经常被访问的处于活跃状态的页面会被放在 active 链表上，而那些虽然可能关联到一个或者多个进程，但是并不经常使用的页面则会被放到 inactive 链表上。页面会在这两个双向链表中移动，操作系统会根据页面的活跃程度来判断应该把页面放到哪个链表上。页面可能会从 active 链表上被转移到 inactive 链表上，也可能从 inactive 链表上被转移到 active 链表上，但是，这种转移并不是每次页面访问都会发生，页面的这种转移发生的间隔有可能比较长。那些最近最少使用的页面会被逐个放到 inactive 链表的尾部。进行页面回收的时候，Linux 操作系统会从 inactive 链表的尾部开始进行回收。</p>
<p>用于描述内存区域的 <a href="http://elixir.free-electrons.com/linux/v2.6.18.1/source/include/linux/mmzone.h#L139" target="_blank" rel="noopener">struct zone()</a> 中关于这两个链表以及相关的关键字段的定义如下所示：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">zone</span> &#123;</span> </span><br><span class="line">   ……</span><br><span class="line"> <span class="keyword">spinlock_t</span> 		    lru_lock; 	</span><br><span class="line"> <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>  	 <span class="title">active_list</span>;</span> </span><br><span class="line"> <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> 	 <span class="title">inactive_list</span>;</span> </span><br><span class="line"> <span class="keyword">unsigned</span> <span class="keyword">long</span> 		 nr_active; </span><br><span class="line"> <span class="keyword">unsigned</span> <span class="keyword">long</span> 		 nr_inactive; </span><br><span class="line">   ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>各字段含义如下所示：</p>
<ul>
<li>lru_lock：active_list 和 inactive_list 使用的自旋锁</li>
<li>active_list：管理内存区域中处于活跃状态的页面</li>
<li>inactive_list：管理内存区域中处于不活跃状态的页面</li>
<li>nr_active：active_list 链表上的页面数目</li>
<li>nr_inactive：inactive_list 链表上的页面数目</li>
</ul>
<h4 id="如何在两个-LRU-链表之间移动页面"><a href="#如何在两个-LRU-链表之间移动页面" class="headerlink" title="如何在两个 LRU 链表之间移动页面"></a>如何在两个 LRU 链表之间移动页面</h4><p>Linux 引入了两个页面标志符 PG_active 和 PG_referenced 用于标识页面的活跃程度，从而决定如何在两个链表之间移动页面。PG_active 用于表示页面当前是否是活跃的，如果该位被置位，则表示该页面是活跃的。PG_referenced 用于表示页面最近是否被访问过，每次页面被访问，该位都会被置位。Linux 必须同时使用这两个标志符来判断页面的活跃程度。</p>
<p>Linux 2.6 中这两个标志符密切合作，其核心思想如下所示：</p>
<ul>
<li>如果页面被认为是活跃的，则将该页的 PG_active 置位；否则，不置位。</li>
<li>当页面被访问时，检查该页的 PG_referenced 位，若未被置位，则将它置位；若发现该页的 PG_referenced 已经被置位了，则意味着该页经常被访问，这时，若该页在 inactive 链表上，则置位其 PG_active ，将其移动到 active 链表上去，并清除其 PG_referenced 位；如果页面的 PG_referenced 位被置位了一段时间后，该页面没有被再次访问，那么 Linux 操作系统会清除该页面的 PG_referenced 位，因为这意味着这个页面最近这段时间都没有被访问。</li>
<li>PG_referenced 位同样也可以用于页面从 active 链表移动到 inactive 链表。对于某个在 active 链表上的页面来说，其 PG_active 位被置位，如果 PG_referenced 位未被置位，给定一段时间之后，该页面如果还是没有被访问，那么该页面会被清除其 PG_active 位，挪到 inactive 链表上去。</li>
</ul>
<p><em>注：PG_referenced利用的是Accessed位，Accessed由硬件置为1，软件置为0。</em></p>
<p>Linux 中实现在 LRU 链表之间移动页面的关键函数如下所示（本文涉及的源代码均是基于 Linux 2.6.18.1 版本的）：</p>
<ul>
<li><a href="http://elixir.free-electrons.com/linux/v2.6.18.1/source/mm/swap.c#L142" target="_blank" rel="noopener">mark_page_accessed()</a>：当一个页面被访问时，则调用该函数相应地修改 PG_active 和 PG_referenced。</li>
<li><a href="http://elixir.free-electrons.com/linux/v2.6.18.1/source/mm/rmap.c#L411" target="_blank" rel="noopener">page_referenced()</a>：当操作系统进行页面回收时，每扫描到一个页面，就会调用该函数设置页面的 PG_referenced 位。如果一个页面的 PG_referenced 位被置位，但是在一定时间内该页面没有被再次访问，那么该页面的 PG_referenced 位会被清除。</li>
<li><a href="http://elixir.free-electrons.com/linux/v2.6.18.1/source/mm/swap.c#L121" target="_blank" rel="noopener">activate_page()</a>：该函数将页面放到 active 链表上去。</li>
<li><a href="http://elixir.free-electrons.com/linux/v2.6.18.1/source/mm/vmscan.c#L715" target="_blank" rel="noopener">shrink_active_list()</a>：该函数将页面移动到 inactive 链表上去。</li>
</ul>
<h4 id="LRU-缓存"><a href="#LRU-缓存" class="headerlink" title="LRU 缓存"></a>LRU 缓存</h4><p>前边提到，页面根据其活跃程度会在 active 链表和 inactive 链表之间来回移动，如果要将某个页面插入到这两个链表中去，必须要通过自旋锁以保证对链表的并发访问操作不会出错。为了降低锁的竞争，Linux 提供了一种特殊的缓存：LRU 缓存，用以批量地向 LRU 链表中快速地添加页面。有了 LRU 缓存之后，新页不会被马上添加到相应的链表上去，而是先被放到一个缓冲区中去，当该缓冲区缓存了足够多的页面之后，缓冲区中的页面才会被一次性地全部添加到相应的 LRU 链表中去。Linux 采用这种方法降低了锁的竞争，极大地提升了系统的性能。<br>LRU 缓存用到了 pagevec 结构，如下所示 :<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pagevec</span> &#123;</span> </span><br><span class="line"> <span class="keyword">unsigned</span> <span class="keyword">long</span> nr; </span><br><span class="line"> <span class="keyword">unsigned</span> <span class="keyword">long</span> cold; </span><br><span class="line"> <span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">pages</span>[<span class="title">PAGEVEC_SIZE</span>];</span> </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>pagevec 这个结构就是用来管理 LRU 缓存中的这些页面的。该结构定义了一个数组，这个数组中的项是指向 page 结构的指针。一个 pagevec 结构最多可以存在 14 个这样的项（PAGEVEC_SIZE 的默认值是 14）。当一个 pagevec 的结构满了，那么该 pagevec 中的所有页面会一次性地被移动到相应的 LRU 链表上去。<br>用来实现 LRU 缓存的两个关键函数是 <a href="http://elixir.free-electrons.com/linux/v2.6.18.1/source/mm/swap.c#L161" target="_blank" rel="noopener">lru_cache_add()</a> 和 <a href="http://elixir.free-electrons.com/linux/v2.6.18.1/source/mm/swap.c#L171" target="_blank" rel="noopener">lru_cache_add_active()</a>。前者用于延迟将页面添加到 inactive 链表上去，后者用于延迟将页面添加到 active 链表上去。这两个函数都会将要移动的页面先放到页向量 pagevec 中，当 pagevec 满了（已经装了 14 个页面的描述符指针），pagevec 结构中的所有页面才会被一次性地移动到相应的链表上去。<br>下图概括总结了上文介绍的如何在两个链表之间移动页面，以及 LRU 缓存在其中起到的作用：</p>
<p><strong>图 1. 页面在 LRU 链表之间移动示意图</strong><br><img src="/images/2017/9/12.png" alt=""><br>其中，1 表示函数 mark_page_accessed()，2 表示函数 page_referenced()，3 表示函数 activate_page()，4 表示函数 shrink_active_list()。</p>
<h3 id="页面回收的实现"><a href="#页面回收的实现" class="headerlink" title="页面回收的实现"></a>页面回收的实现</h3><p>Linux 操作系统进行页面回收需要考虑的方面很多，下图列出了 Linux 操作系统进行页面回收的关键代码流程图，该图给出了实现页面回收的关键代码函数名，并说明它们之间是如何彼此链接的。<br><strong>图 2. 页面回收关键代码流程图</strong><br><img src="/images/2017/9/13.jpg" alt=""></p>
<p>上文提到 Linux 中页面回收主要是通过两种方式触发的，一种是由“内存严重不足”事件触发的；一种是由后台进程 kswapd 触发的，该进程周期性地运行，一旦检测到内存不足，就会触发页面回收操作。对于第一种情况，系统会调用函数 try_to_free_pages() 去检查当前内存区域中的页面，回收那些最不常用的页面。对于第二种情况，函数 balance_pgdat() 是入口函数。<br>当 NUMA 上的某个节点的低内存区域调用函数 try_to_free_pages() 的时候，该函数会反复调用 shrink_zones() 以及 shrink_slab() 释放一定数目的页面，默认值是 32 个页面。如果在特定的循环次数内没有能够成功释放 32 个页面，那么页面回收会调用 OOM killer 选择并杀死一个进程，然后释放它占用的所有页面。函数 shrink_zones() 会对内存区域列表中的所有区域分别调用 shrink_zone() 函数，后者是从内存回收最近最少使用页面的入口函数。<br>对于定期页面检查并进行回收的入口函数 balance_pgdat() 来说，它主要调用的函数是 shrink_zone() 和 shrink_slab()。从上图中我们也可以看出，进行页面回收的两条代码路径最终汇合到函数 shrink_zone() 和函数 shrink_slab() 上。</p>
<h4 id="函数-shrink-zone"><a href="#函数-shrink-zone" class="headerlink" title="函数 shrink_zone()"></a>函数 shrink_zone()</h4><p>其中，shrink_zone() 函数是 Linux 操作系统实现页面回收的最核心的函数之一，它实现了对一个内存区域的页面进行回收的功能，该函数主要做了两件事情：</p>
<ul>
<li>将某些页面从 active 链表移到 inactive 链表，这是由函数 shrink_active_list() 实现的。</li>
<li>从 inactive 链表中选定一定数目的页面，将其放到一个临时链表中，这由函数 shrink_inactive_list() 完成。该函数最终会调用 shrink_page_list() 去回收这些页面。</li>
</ul>
<p>函数 shrink_page_list() 返回的是回收成功的页面数目。概括来说，对于可进行回收的页面，该函数主要做了这样几件事情，其代码流程图如下所示：</p>
<p><img src="/images/2017/9/15.jpg" alt=""></p>
<ul>
<li>对于匿名页面来说，在回收此类页面时，需要将其数据写入到交换区。如果尚未为该页面分配交换区槽位，则先分配一个槽位，并将该页面添加到交换缓存。同时，将相关的 page 实例加入到交换区，这样，对该页面的处理就可以跟其他已经建立映射的页面一样；</li>
<li>如果该页面已经被映射到一个或者多个进程的页表项中，那么必须找到所有引用该页面的进程，并更新页表中与这些进程相关的所有页表项。</li>
<li>如果该页面中的数据是脏的，那么数据必须要被回写；</li>
<li>释放Page cache中的干净页面。</li>
</ul>
<h4 id="函数-shrink-slab"><a href="#函数-shrink-slab" class="headerlink" title="函数 shrink_slab()"></a>函数 shrink_slab()</h4><p>函数 shrink_slab() 是用来回收磁盘缓存所占用的页面的。Linux 操作系统并不清楚这类页面是如何使用的，所以如果希望操作系统回收磁盘缓存所占用的页面，那么必须要向操作系统内核注册 shrinker 函数，shrinker 函数会在内存较少的时候主动释放一些该磁盘缓存占用的空间。函数 shrink_slab() 会遍历 shrinker 链表，从而对所有注册了 shrinker 函数的磁盘缓存进行处理。<br>从实现上来看，shrinker 函数和 slab 分配器并没有固定的联系，只是当前主要是 slab 缓存使用 shrinker 函数最多。<br>注册 shrinker 是通过函数 set_shrinker() 实现的，解除 shrinker 注册是通过函数 remove_shrinker() 实现的。当前，Linux 操作系统中主要的 shrinker 函数有如下几种：</p>
<ul>
<li>shrink_dcache_memory()：该 shrinker 函数负责 dentry 缓存。</li>
<li>shrink_icache_memory()：该 shrinker 函数负责 inode 缓存。</li>
<li>mb_cache_shrink_fn()：该 shrinker 函数负责用于文件系统元数据的缓存。</li>
</ul>
<hr>
<p>参考资料：</p>
<ol>
<li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-pagerecycle/index.html" target="_blank" rel="noopener">Linux 2.6 中的页面回收与反向映射</a></li>
<li>《深入理解LINUX内核》</li>
<li><a href="http://blog.chinaunix.net/uid-28236237-id-3370664.html" target="_blank" rel="noopener">shrink_page_list 函数分析 </a></li>
</ol>

        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/09/19/C程序员该知道的内存知识/">Ｃ程序员该知道的内存知识</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-09-19
        </span>
        
          <span class="post-category">
            
              <a href="/categories/操作系统/">操作系统</a>
            
          </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <p>本文翻译至<a href="http://marek.vavrusa.com/c/memory/2015/02/20/memory/" target="_blank" rel="noopener">What a C programmer should know about memory</a></p>
<h1 id="C程序员该知道的内存知识"><a href="#C程序员该知道的内存知识" class="headerlink" title="Ｃ程序员该知道的内存知识"></a>Ｃ程序员该知道的内存知识</h1><p>2007年，Ulrich Drepper写了<a href="http://www.akkadia.org/drepper/cpumemory.pdf" target="_blank" rel="noopener">What every programmer should know about memory</a>这篇大作，本文是在这篇文章的基础上提炼而成的。</p>
<h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><p>除非你处理某些嵌入式系统或内核空间代码，否则你将在保护模式下工作。在保护模式下，进程拥有自己的虚拟地址空间。为了使用这个空间，你必须要求操作系统用真实的介质来支持虚拟地址空间，这就是映射（mapping）。 支持的介质可以是物理内存（不一定是RAM）或持久化存储介质(如磁盘)。</p>
<p>虚拟内存分配器(virtual memory allocator VMA)可能并没有给你分配真实的物理内存，VMA徒劳地希望你不会使用这些内存,这就叫做<a href="https://www.kernel.org/doc/Documentation/vm/overcommit-accounting" target="_blank" rel="noopener">overcommiting</a>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> *block = <span class="built_in">malloc</span>(<span class="number">1024</span> * <span class="keyword">sizeof</span>(<span class="keyword">char</span>));</span><br><span class="line"><span class="keyword">if</span> (block == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> -ENOMEM; <span class="comment">/* Sad :( */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>检查<code>NULL</code>返回值是一个很好的做法，但并不像以前一样强大。 由于overcommit，操作系统可能会给你的内存分配器一个有效的内存指针，但如果你要访问它，就会发生异常。 在这种情况下，通常是一个<a href="http://www.win.tue.nl/~aeb/linux/lk/lk-9.html#ss9.6" target="_blank" rel="noopener">OOM killer</a> 杀死你的进程。</p>
<h3 id="进程地址空间布局"><a href="#进程地址空间布局" class="headerlink" title="进程地址空间布局"></a>进程地址空间布局</h3><p><a href="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory/" target="_blank" rel="noopener">Anatomy of a Program in Memory</a>这篇文章很好地说明了进程地址空间的布局。这里有些瑕疵，其中一个是它只涵盖x86-32架构的地址空间布局，但幸运的是x86-64架构的地址空间布局没有发生大的变化。与 x86-32架构相比，x86-64架构的进程可以使用更大的地址空间 (在Linux上最高达48位)。<br><img src="/images/2017/9/11.png" alt=""></p>
<h2 id="stack-allocation"><a href="#stack-allocation" class="headerlink" title="stack allocation"></a>stack allocation</h2><p>实用程序：</p>
<ul>
<li><code>alloca()</code> - <a href="http://linux.die.net/man/3/alloca" target="_blank" rel="noopener">allocate memory in the stack frame of the caller</a></li>
<li><code>getrlimit()</code> - <a href="http://linux.die.net/man/2/getrlimit" target="_blank" rel="noopener">get/set resource limits</a></li>
<li><code>sigaltstack()</code> - <a href="http://linux.die.net/man/2/sigaltstack" target="_blank" rel="noopener">set and/or get signal stack context</a></li>
</ul>
<p>栈很容易理解，每个人都知道如何在栈上创建变量。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> stairway = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> heaven[] = &#123; <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span> &#125;;</span><br></pre></td></tr></table></figure></p>
<p>变量的有效性受范围限制,在C语言中，这意味着：{}。 所以每当一个}来了，一个变量就失效了。<code>alloca（）</code>在当前stack frame中动态分配内存,stack frame和物理页面不是一样的，它只是一组被压到栈上的数据（函数，参数，变量…）。</p>
<p>variable-length arrays (VLA)与<code>alloca（）</code>有一个不同点:VLA的有效性受范围限制；在当前函数返回之前，alloca分配的内存将保持有效。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">laugh</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">unsigned</span> i = <span class="number">0</span>; i &lt; megatron; ++i) &#123;</span><br><span class="line">        <span class="keyword">char</span> *res = alloca(<span class="number">2</span>);</span><br><span class="line">        <span class="built_in">memcpy</span>(res, <span class="string">"ha"</span>, <span class="number">2</span>);</span><br><span class="line">        <span class="keyword">char</span> vla[<span class="number">2</span>] = &#123;<span class="string">'h'</span>,<span class="string">'a'</span>&#125;</span><br><span class="line">    &#125; <span class="comment">/* vla dies, res lives */</span></span><br><span class="line">&#125; <span class="comment">/* all allocas die */</span></span><br></pre></td></tr></table></figure></p>
<p>无论是VLA还是alloca，在分配大量内存时，都有些问题，因为你几乎无法控制可用的栈内存，而如果待分配的内存超过了栈的空间限制，这就会导致stack overflow 问题。针对stack overflow问题，有两个解决方法，但是这两者都不实用。</p>
<p>第一个方法是使用<a href="http://linux.die.net/man/2/sigaltstack" target="_blank" rel="noopener">sigaltstack()</a>来捕获和处理<code>SIGSEGV</code>。 但这只是捕获stack overflow这个异常。</p>
<p>另一个方法是使用<em>split-stacks</em>进行编译， 它被称为这样，因为它真正地将完整的栈分解成一个称为<em>stacklets</em>的小栈链表。 据我所知，<a href="https://gcc.gnu.org/wiki/SplitStacks" target="_blank" rel="noopener">GCC</a>和<a href="http://llvm.org/releases/3.0/docs/SegmentedStacks.html" target="_blank" rel="noopener">clang</a>使用<code>-fsplit-stack</code>选项支持它。 在理论上，这也可以改善内存消耗，并降低创建线程的成本 －因为栈开始可以很小，并且随着需求而增加。</p>
<h2 id="heap-allocation"><a href="#heap-allocation" class="headerlink" title="heap allocation"></a>heap allocation</h2><p>实用程序：</p>
<ul>
<li><code>brk()</code>, <code>sbrk()</code> - <a href="http://linux.die.net/man/2/sbrk" target="_blank" rel="noopener">manipulate the data segment size</a></li>
<li><code>malloc()</code> family - <a href="http://linux.die.net/man/3/malloc" target="_blank" rel="noopener">portable libc memory allocator</a></li>
</ul>
<p>堆分配可以简单地移动<a href="http://linux.die.net/man/2/sbrk" target="_blank" rel="noopener">program break </a>，并且在旧位置和新位置之间分配内存。 到目前为止，堆分配与栈分配一样快。但是如果使用这个方法的话有些问题需要注意：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> *block = sbrk(<span class="number">1024</span> * <span class="keyword">sizeof</span>(<span class="keyword">char</span>));</span><br></pre></td></tr></table></figure></p>
<ol>
<li>我们无法回收未使用的内存块</li>
<li>不是线程安全的，因为堆在线程之间是共享的</li>
<li>接口几乎不可移植，libraries不得触及break<blockquote>
<p> man 3 sbrk — Various systems use various types for the argument of sbrk(). Common are int, ssizet, ptrdifft, intptr_t.</p>
</blockquote>
</li>
</ol>
<p>由于这些原因，libc实现了用于内存分配的统一接口。 <a href="http://en.wikibooks.org/wiki/C_Programming/C_Reference/stdlib.h/malloc#Implementations" target="_blank" rel="noopener">实现方式各不相同</a>，但它为你提供了任何大小、线程安全的堆内存分配方式。 这样的成本是延迟，因为现在涉及到了锁机制，有关使用/空闲块信息的数据结构和额外的内存开销。</p>
<p>堆从<code>start_brk</code>到<code>brk</code>是连续的，考虑下面的情况：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> *truck = <span class="built_in">malloc</span>(<span class="number">1024</span> * <span class="number">1024</span> * <span class="keyword">sizeof</span>(<span class="keyword">char</span>));</span><br><span class="line"><span class="keyword">char</span> *bike  = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">char</span>));</span><br><span class="line"><span class="built_in">free</span>(truck);</span><br></pre></td></tr></table></figure></p>
<p>堆分配器移动brk为<code>truck</code>分配空间。 <code>bike</code>同样如此。 但是在<code>truck</code>被free之后，brk不能向下移动，因为brk指向<code>bike</code>,而<code>bike</code>此刻占据着最高地址。 这样的结果是进程可以重新使用前一个<code>truck</code>的内存，但在<code>bike</code>被free之前，这部分地址空间不能返回给系统。 </p>
<p>请注意，<code>free()</code>并不总是尝试缩小数据段，因为这是一个潜在的昂贵的操作。对于长时间运行的程序（如守护程序）来说，这是一个问题。 存在一个名为<a href="https://linux.die.net/man/3/malloc_trim" target="_blank" rel="noopener">malloc_trim()</a>的GNU扩展，它用于从堆顶部释放内存，但可能会使进程运行的很慢。 在很多应用场景中，这个问题很严重，所以应该谨慎使用<code>malloc_trim()</code>。</p>
<h3 id="何时使用自定义分配器"><a href="#何时使用自定义分配器" class="headerlink" title="何时使用自定义分配器"></a>何时使用自定义分配器</h3><p>这里将上文提到的分配器称为GP分配器，有一些GP分配器不足的实际用例。例如分配大量固定大小的小块， 这可能看起来不像一个典型的模式，但它是非常频繁发生的。 例如，查找数据结构（如树和tries）通常需要节点来构建层次结构， 在这种情况下，不仅碎片是问题，还有数据的局部性。 缓存高效的数据结构将keys放在一起（最好在同一页面上），而不是将其与数据混合。 默认分配器不保证局部性。更糟糕的是，小块的分配将导致空间开销。  针对上述问题，这里有解决方案！</p>
<h4 id="Slab-allocator"><a href="#Slab-allocator" class="headerlink" title="Slab allocator"></a>Slab allocator</h4><p>实用程序：</p>
<ul>
<li><code>posix_memalign()</code>- <a href="http://linux.die.net/man/3/posix_memalign" target="_blank" rel="noopener">allocate aligned memory</a></li>
</ul>
<p><a href="https://www.usenix.org/legacy/publications/library/proceedings/bos94/full_papers/bonwick.a" target="_blank" rel="noopener">Bonwick</a>为内核对象缓存描述了slab allocator的原理，但slab allocator也适用于用户空间。allocator分配slab内存，即一个整页，并将其切成许多固定大小的块。 假设每个块至少可以保存一个指针或整数，你可以将它们链接到list中，其中list head指向第一个空闲元素。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Super-simple slab. */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">slab</span> &#123;</span></span><br><span class="line">    <span class="keyword">void</span> **head;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">/* Create page-aligned slab */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">slab</span> *<span class="title">slab</span> = <span class="title">NULL</span>;</span></span><br><span class="line">posix_memalign(&amp;slab, page_size, page_size);</span><br><span class="line">slab-&gt;head = (<span class="keyword">void</span> **)((<span class="keyword">char</span>*)slab + <span class="keyword">sizeof</span>(struct slab));</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Create a NULL-terminated slab freelist */</span></span><br><span class="line"><span class="keyword">char</span>* item = (<span class="keyword">char</span>*)slab-&gt;head;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">unsigned</span> i = <span class="number">0</span>; i &lt; item_count; ++i) &#123;</span><br><span class="line">    *((<span class="keyword">void</span>**)item) = item + item_size;</span><br><span class="line">    item += item_size;</span><br><span class="line">&#125;</span><br><span class="line">*((<span class="keyword">void</span>**)item) = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure></p>
<p>allocation相当于pop list head，Freeing相当于push新的list head。 如果slab与page_size边界对齐，则可以使用<a href="http://stackoverflow.com/a/2601527/4591872" target="_blank" rel="noopener">rounding down</a>技巧。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Free an element */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">slab</span> *<span class="title">slab</span> = (<span class="title">void</span> *)((<span class="title">size_t</span>)<span class="title">ptr</span> &amp; <span class="title">PAGESIZE_BITS</span>);</span></span><br><span class="line">*((<span class="keyword">void</span>**)ptr) = (<span class="keyword">void</span>*)slab-&gt;head;</span><br><span class="line">slab-&gt;head = (<span class="keyword">void</span>**)ptr;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Allocate an element */</span></span><br><span class="line"><span class="keyword">if</span>((item = slab-&gt;head)) &#123;</span><br><span class="line">    slab-&gt;head = (<span class="keyword">void</span>**)*item;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">/* No elements left. */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>要想利用层级结构及缓存局部性的相关特性，我们可以使用现成的库，例如，<strong>gasp</strong> ，glib实现有一个<a href="https://developer.gnome.org/glib/stable/glib-Memory-Slices.html" target="_blank" rel="noopener">整洁的文档</a>，并称之为“memory slices”。</p>
<h4 id="Memory-pools"><a href="#Memory-pools" class="headerlink" title="Memory pools"></a>Memory pools</h4><p>实用程序：</p>
<ul>
<li><code>obstack_alloc()</code>- <a href="http://www.gnu.org/software/libc/manual/html_node/Obstacks.html" target="_blank" rel="noopener">allocate memory from object stack</a></li>
</ul>
<p>Slab allocator一旦分配就分配一个slab，当free的时候，slab中的内存块会被全部释放掉；<code>obstack_alloc()</code>则提供了一个内存块的栈，你可以pop与push内存块，这样在free的时候就不需要释放全部的内存块，而且内存块还可以添加到栈中。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Define block allocator. */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> obstack_chunk_alloc malloc</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> obstack_chunk_free free</span></span><br><span class="line"><span class="comment">/* Initialize obstack and allocate a bunch of animals. */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">obstack</span> <span class="title">animal_stack</span>;</span></span><br><span class="line">obstack_init (&amp;animal_stack);</span><br><span class="line"><span class="keyword">char</span> *bob = obstack_alloc(&amp;animal_stack, <span class="keyword">sizeof</span>(animal));</span><br><span class="line"><span class="keyword">char</span> *fred = obstack_alloc(&amp;animal_stack, <span class="keyword">sizeof</span>(animal));</span><br><span class="line"><span class="keyword">char</span> *roger = obstack_alloc(&amp;animal_stack, <span class="keyword">sizeof</span>(animal));</span><br><span class="line"><span class="comment">/* Free everything after fred (i.e. fred and roger). */</span></span><br><span class="line">obstack_free(&amp;animal_stack, fred);</span><br><span class="line"><span class="comment">/* Free everything. */</span></span><br><span class="line">obstack_free(&amp;animal_stack, <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* This is wrong, I better cancel it. */</span></span><br><span class="line">obstack_grow(&amp;animal_stack, <span class="string">"long"</span>, <span class="number">4</span>);</span><br><span class="line">obstack_grow(&amp;animal_stack, <span class="string">"fred"</span>, <span class="number">5</span>);</span><br><span class="line">obstack_free (&amp;animal_stack, obstack_finish(&amp;animal_stack));</span><br><span class="line"></span><br><span class="line"><span class="comment">/* This time for real. */</span></span><br><span class="line">obstack_grow(&amp;animal_stack, <span class="string">"long"</span>, <span class="number">4</span>);</span><br><span class="line">obstack_grow(&amp;animal_stack, <span class="string">"bob"</span>, <span class="number">4</span>);</span><br><span class="line"><span class="keyword">char</span> *result = obstack_finish(&amp;animal_stack);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%s\n"</span>, result); <span class="comment">/* "longbob" */</span></span><br></pre></td></tr></table></figure>
<h4 id="Demand-paging"><a href="#Demand-paging" class="headerlink" title="Demand paging"></a>Demand paging</h4><p>实用程序：</p>
<ul>
<li><code>mlock()</code>- <a href="http://linux.die.net/man/2/mlock" target="_blank" rel="noopener">lock/unlock memory</a></li>
<li><code>madvise()</code>- <a href="http://linux.die.net/man/2/madvise" target="_blank" rel="noopener">give advice about use of memory</a></li>
</ul>
<p>GP内存分配器不会立即将内存返回给系统的原因之一是成本高昂。如果要将内存立刻返回给系统， 系统必须做两件事情：(1)建立虚拟页面到真实页面的映射；(2)给你一个空白的真实页面。而overcommit的做法是： 虚拟内存分配器仅完成第一件事情，虚拟地址指向的页面不是指向一个真实的页面，而是指向一个特殊的页面0。</p>
<p>每次尝试访问特殊页面时，都会发生page fault，这意味着：内核会暂停进程的执行并获取一个真实的页面，然后更新页面表，之后进程恢复执行。 <em>demand paging</em>也被称为<em>lazy loading</em>，<a href="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/" target="_blank" rel="noopener">这里</a>有更详细的解释。</p>
<p>内存管理器对你如何访问内存做出非常保守的预测。你可以<a href="http://linux.die.net/man/2/mlock" target="_blank" rel="noopener">lock</a>物理内存中的连续内存块以避免页面被swap出去而发生page fault：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> *block = <span class="built_in">malloc</span>(<span class="number">1024</span> * <span class="keyword">sizeof</span>(<span class="keyword">char</span>));</span><br><span class="line">mlock(block, <span class="number">1024</span> * <span class="keyword">sizeof</span>(<span class="keyword">char</span>));</span><br></pre></td></tr></table></figure>
<p>你还可以提供内存使用模式的<a href="http://linux.die.net/man/2/madvise" target="_blank" rel="noopener">advise</a>：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> *block = <span class="built_in">malloc</span>(<span class="number">1024</span> * <span class="keyword">sizeof</span>(block));</span><br><span class="line">madvise(block, <span class="number">1024</span> * <span class="keyword">sizeof</span>(block), MADV_SEQUENTIAL);</span><br></pre></td></tr></table></figure></p>
<p>实际建议的解释是平台特定的，系统甚至可以选择忽略它。 并不是所有的建议都得到很好的支持，有些甚至会改变语义，但MADV_SEQUENTIAL，MADV_WILLNEED和MADV_DONTNEED这三个是最常用的。</p>
<h2 id="memory-mapping"><a href="#memory-mapping" class="headerlink" title="memory mapping"></a>memory mapping</h2><p>实用程序：</p>
<ul>
<li><code>sysconf()</code>- <a href="http://linux.die.net/man/3/sysconf" target="_blank" rel="noopener">get configuration information at run time</a></li>
<li><code>mmap()</code>- <a href="https://linux.die.net/man/2/mmap" target="_blank" rel="noopener">map virtual memory</a></li>
<li><code>mincore()</code>- <a href="http://linux.die.net/man/2/mincore" target="_blank" rel="noopener">determine whether pages are resident in memory</a></li>
<li><code>shmat()</code>- <a href="http://linux.die.net/man/2/shmat" target="_blank" rel="noopener">shared memory operations</a></li>
</ul>
<p>一个页面通常是一个4KB的块，但你不应该依赖它，应该使用<code>sysconf()</code>来获取页面大小。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> page_size = sysconf(_SC_PAGESIZE); <span class="comment">/* Slice and dice. */</span></span><br></pre></td></tr></table></figure></p>
<p>即使平台统一页面大小，系统中所有页面的大小也未必相同。 例如，Linux有一个<a href="http://lwn.net/Articles/423584/" target="_blank" rel="noopener">透明大页面</a>（THP）机制，THP对你是透明的，但是Linux的<code>mmap</code>选项<a href="https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt" target="_blank" rel="noopener">MAP_HUGETLB</a>允许你明确地使用它。</p>
<h3 id="Fixed-memory-mappings"><a href="#Fixed-memory-mappings" class="headerlink" title="Fixed memory mappings"></a>Fixed memory mappings</h3><p>在 x86-64架构下，大约2/3<code>TASK_SIZE</code>（用户进程的最高可用地址）的地址是一个安全的选择。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TASK_SIZE 0x800000000000</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SHARED_BLOCK (void *)(2 * TASK_SIZE / 3)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> *shared_cats = shmat(shm_key, SHARED_BLOCK, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span>(shared_cats == (<span class="keyword">void</span> *)<span class="number">-1</span>) &#123;</span><br><span class="line">    perror(<span class="string">"shmat"</span>); <span class="comment">/* Sad :( */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这不是一个可移植的例子，但点明了要点。 映射固定地址范围通常被认为是不安全的，因为它不会检查这段地址空间是否已经被映射过。 <code>mincore()</code>函数可以告诉你页面是否被映射到物理内存中，但是在多线程环境下这个方法是行不通的。</p>
<p>然而，固定地址映射不仅对未使用的地址范围有用，对于使用过的地址范围也是有用的。 内存分配器使用<code>mmap()</code>来获取更大的内存块，由于on-demand paging，这使得有效的稀疏阵列成为可能。 假设你创建了一个稀疏阵列，现在你要释放一些数据，那么该如何做呢？ 你不能完全free它，因此不能使用<code>munmap()</code>。 你可以使用<code>madvise()</code> <a href="http://lwn.net/Articles/591214/" target="_blank" rel="noopener">MADV_FREE</a> / MADV_DONTNEED来标记待free的页面，这是最佳的解决方案。</p>
<p>下面是一个可移植的例子：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> *<span class="built_in">array</span> = mmap(<span class="literal">NULL</span>, length, PROT_READ|PROT_WRITE,</span><br><span class="line">                   MAP_ANONYMOUS, <span class="number">-1</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* ... some magic gone awry ... */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Let's clear some pages. */</span></span><br><span class="line">mmap(<span class="built_in">array</span> + offset, length, MAP_FIXED|MAP_ANONYMOUS, <span class="number">-1</span>, <span class="number">0</span>);</span><br></pre></td></tr></table></figure></p>
<p>这相当于unmap旧页面并再次map特殊页面，这样该进程仍然使用相同数量的虚拟内存，但驻留在物理内存中的数据量会降低。</p>
<h3 id="File-backed-memory-maps"><a href="#File-backed-memory-maps" class="headerlink" title="File-backed memory maps"></a>File-backed memory maps</h3><p>实用程序：</p>
<ul>
<li><code>msync()</code>- <a href="http://linux.die.net/man/2/msync" target="_blank" rel="noopener">synchronize a file with memory map</a></li>
<li><code>ftruncate()</code>- <a href="http://linux.die.net/man/2/ftruncate" target="_blank" rel="noopener">truncate a file to a specified length</a></li>
<li><code>vmsplice()</code>- <a href="http://linux.die.net/man/2/vmsplice" target="_blank" rel="noopener">splice user pages into a pipe</a></li>
</ul>
<p>到目前为止，我们介绍的一直都是匿名内存，接下来将介绍 File-backed的内存映射，它提供了缓存，同步和 copy-on-write机制。</p>
<p>File-backed的共享内存映射添加了新的模式<code>MAP_SHARED</code>，这意味着你对页面所做的更改将被写回文件，因此这个文件在进程间是共享的。 内存管理器决定什么时候同步，但幸运的是有<code>msync()</code>函数强制页面与backing store进行同步。<code>msync()</code>对数据库是非常好的，因为它保证了写数据的持久性。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Map the contents of a file into memory (shared). */</span></span><br><span class="line"><span class="keyword">int</span> fd = open(...);</span><br><span class="line"><span class="keyword">void</span> *db = mmap(<span class="literal">NULL</span>, file_size, PROT_READ|PROT_WRITE,</span><br><span class="line">                MAP_SHARED, fd, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span> (db == (<span class="keyword">void</span> *)<span class="number">-1</span>) &#123;</span><br><span class="line">    <span class="comment">/* Mapping failed */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Write to a page */</span></span><br><span class="line"><span class="keyword">char</span> *page = (<span class="keyword">char</span> *)db;</span><br><span class="line"><span class="built_in">strcpy</span>(page, <span class="string">"bob"</span>);</span><br><span class="line"><span class="comment">/* This is going to be a durable page. */</span></span><br><span class="line">msync(page, <span class="number">4</span>, MS_SYNC);</span><br><span class="line"><span class="comment">/* This is going to be a less durable page. */</span></span><br><span class="line">page = page + PAGE_SIZE;</span><br><span class="line"><span class="built_in">strcpy</span>(page, <span class="string">"fred"</span>);</span><br><span class="line">msync(page, <span class="number">5</span>, MS_ASYNC);</span><br></pre></td></tr></table></figure></p>
<p>请注意，你不能映射比实文件size更多的数据，因此你无法增长或缩小。 然而，你可以使用<code>ftruncate()</code>提前创建（或增长）稀疏文件。 缺点是，它使内存压缩(compaction)更加困难。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Resize the file. */</span></span><br><span class="line"><span class="keyword">int</span> fd = open(...);</span><br><span class="line">ftruncate(fd, expected_length);</span><br></pre></td></tr></table></figure></p>
<h4 id="Copy-on-write"><a href="#Copy-on-write" class="headerlink" title="Copy-on-write"></a>Copy-on-write</h4><p>到目前为止，这是关于共享内存映射。 但是你可以使用另一种方式的内存映射－ 映射文件的共享副本，并且在修改后无需修改backing store。 请注意，页面不会被立即copy，这是没有意义的，但在你修改页面的那一刻，立刻发生copy操作。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> fd = open(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Copy-on-write mapping */</span></span><br><span class="line"><span class="keyword">void</span> *db = mmap(<span class="literal">NULL</span>, file_size, PROT_READ|PROT_WRITE,</span><br><span class="line">                    MAP_PRIVATE, fd, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span> (db == (<span class="keyword">void</span> *)<span class="number">-1</span>) &#123;</span><br><span class="line">    <span class="comment">/* Mapping failed */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* This page will be copied as soon as we write to it */</span></span><br><span class="line"><span class="keyword">char</span> *page = (<span class="keyword">char</span> *)db;</span><br><span class="line"><span class="built_in">strcpy</span>(page, <span class="string">"bob"</span>);</span><br></pre></td></tr></table></figure></p>
<h4 id="Zero-copy-streaming"><a href="#Zero-copy-streaming" class="headerlink" title="Zero-copy streaming"></a>Zero-copy streaming</h4><p>由于文件本质上是内存，你可以将其流式传输到管道（包括套接字）中，这样就无需发生copy操作。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sock = get_client();</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">iovec</span> <span class="title">iov</span> = &#123;</span> .iov_base = cat_db, .iov_len = PAGE_SIZE &#125;;</span><br><span class="line"><span class="keyword">int</span> ret = vmsplice(sock, &amp;iov, <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span> (ret != <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">/* No streaming :( */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="mmap-的问题"><a href="#mmap-的问题" class="headerlink" title="mmap()的问题"></a>mmap()的问题</h4><p>在有些情下况，与通常的read()/write()文件相比，mmap文件会大大降低系统性能。 处理 page fault会比简单地读取文件慢，因为mmap必须读取文件并做更多的事情。 实际上，mmapped I/ O可能会更快，因为它避免了数据的多重缓存，并且在后台可以预读。 但有时候这种做法将会损害系统的性能， 一个这样的例子是：当文件的大小超过可用内存空间，而我们只随机读取文件中的一小部分。 在这种情况下，系统会读取可能不被使用的块，并且每次内存访问都会发生page fault，从而导致TLB thrashing问题。 你可以用<code>madvise()</code>来减少系统损失。</p>
<h2 id="memory-consumption"><a href="#memory-consumption" class="headerlink" title="memory consumption"></a>memory consumption</h2><p>实用程序：</p>
<ul>
<li><code>vmtouch</code>- <a href="http://hoytech.com/vmtouch/" target="_blank" rel="noopener">portable virtual memory toucher</a></li>
</ul>
<h3 id="Terms"><a href="#Terms" class="headerlink" title="Terms"></a>Terms</h3><ul>
<li><strong>VSS</strong>- Virtual Set Size 进程虚拟使用内存（包含共享库占用的内存）</li>
<li><strong>RSS</strong>- Resident Set Size 进程实际使用物理内存（包含共享库占用的内存）</li>
<li><strong>PSS</strong>- Proportional Set Size 进程实际使用的物理内存（比例分配共享库占用的内存）</li>
<li><strong>USS</strong>- Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）</li>
</ul>
<p>一般来说内存占用大小有如下规律：VSS &gt;= RSS &gt;= PSS &gt;= USS</p>
<hr>
<p>资料整理:</p>
<ol>
<li><a href="https://www.win.tue.nl/~aeb/" target="_blank" rel="noopener">Andries E. Brouwer</a></li>
<li><a href="http://duartes.org/gustavo/blog/" target="_blank" rel="noopener">Gustavo Duarte blog</a></li>
<li><a href="http://agis.io/" target="_blank" rel="noopener">Agis Anastasopoulos</a></li>
<li><a href="http://landley.net/" target="_blank" rel="noopener">landley.net</a></li>
</ol>

        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/09/19/How-can-one-really-learn-Linux-Kernel-Memory-Management/">How can one really learn Linux Kernel Memory Management</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-09-19
        </span>
        
          <span class="post-category">
            
              <a href="/categories/经验/">经验</a>
            
          </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <p>Linux kernel memory management part is the 2nd most complicated part to understand in the Linux kernel but it is that much interesting as well. Best approach to learn it would be to read the code. But obviously one can’t start reading the code randomly without knowing the terms and what exactly is happening in the current mm part. So, just to start from, I would go like this:</p>
<ul>
<li><p>Read the current LSF/MM notes: <a href="http://lwn.net/Articles/684252/" target="_blank" rel="noopener">The 2016 Linux Storage, Filesystem, and Memory-Management Summit </a>. LSF/MM is the annual Linux Storage, Filesystem and Memory Management Summit. It is an invite only event and people usually discusses about their plans and projects for the next year. One can go for reading about past years’ LWN summit reports as well. Some kernel developers writes separate blogs on this summit as well.</p>
</li>
<li><p>Now, while going through these notes, one will surely have many questions. And those can be found on these sites. Usually google search definitely helps. But I am just listing some standard sites for the reference:</p>
<ol>
<li><a href="http://linux-mm.org/" target="_blank" rel="noopener">LinuxMM - linux-mm.org Wiki</a></li>
<li><a href="https://www.kernel.org/doc/gorman/pdf/understand.pdf" target="_blank" rel="noopener">Understanding the Linux Virtual Memory Manager</a>(Nice book but somehow old. Looking at code while reading can definitely help to understand how things are changed over the years.)</li>
<li>Blogs of the kernel developers who are working in the mm part of the kernel: <a href="http://surriel.com/blog/1" target="_blank" rel="noopener">Rik van Riel’s home page</a>and  <a href="http://techsingularity.net/blog/" target="_blank" rel="noopener">Mel Gorman</a></li>
<li><a href="https://lwn.net/Kernel/" target="_blank" rel="noopener">Kernel coverage at LWN.net </a>(I found these articles very useful. They are the best documentation I have ever come across. On most of the topics I have seen that articles are written over the years which are helpful to understand how things are changing in the kernel).</li>
<li>Kernel documentation</li>
</ol>
</li>
<li>Along with reading, make sure that you look at the code and try to understand how it works. There is an IRC channel #mm on OFTC server. You can ask questions related to memory management part of the kernel.</li>
<li>Usually while reading the code, if I don’t understand anything I use <code>git blame</code>. Specifically in the mm part, developers are used to write detailed commit log (with the test cases/programs)so that they and others can refer it in the future. Most of the time I have found them useful for understanding any mm code.</li>
<li>And last but not least, play with the code. Try to experiment with it and testing it by changing the code. The more you play, more you will understand.</li>
</ul>
<hr>
<p>转载至:<a href="https://www.quora.com/How-can-one-really-learn-Linux-Kernel-Memory-Management" target="_blank" rel="noopener">quora</a></p>

        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/09/11/Large-Pages-May-Be-Harmful-on-NUMA-Systems/">Large Pages May Be Harmful on NUMA Systems</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-09-11
        </span>
        
          <span class="post-category">
            
              <a href="/categories/内存管理/">内存管理</a>
            
          </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <h2 id="Large-Pages-May-Be-Harmful-on-NUMA-Systems"><a href="#Large-Pages-May-Be-Harmful-on-NUMA-Systems" class="headerlink" title="Large Pages May Be Harmful on NUMA Systems"></a>Large Pages May Be Harmful on NUMA Systems</h2><p>此论文是ATC’14上的一篇文章，今天特意总结一下，希望对读者会有所帮助。</p>
<h3 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h3><ul>
<li><a href="https://www.usenix.org/conference/atc14/technical-sessions/presentation/gaud" target="_blank" rel="noopener">Large Pages May Be Harmful on NUMA Systems</a><br>这里可以下载到paper与slides，同时还有音频资料。</li>
<li>作者</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">姓名</th>
<th style="text-align:center">主页</th>
<th style="text-align:right">谷歌学术</th>
<th style="text-align:right">dblp</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Fabien Gaud</td>
<td style="text-align:center"><a href="http://www.fabiengaud.net/" target="_blank" rel="noopener">Fabien Gaud</a></td>
<td style="text-align:right"><a href="https://scholar.google.com.hk/citations?user=jTXbed0AAAAJ&amp;hl=zh-CN&amp;newwindow=1&amp;oi=sra" target="_blank" rel="noopener">Fabien Gaud</a></td>
<td style="text-align:right"><a href="http://dblp.uni-trier.de/pers/hd/g/Gaud:Fabien" target="_blank" rel="noopener">Fabien Gaud</a></td>
</tr>
<tr>
<td style="text-align:left">Baptiste Lepers</td>
<td style="text-align:center"><a href="https://www.linkedin.com/in/baptiste-lepers-b1535434/" target="_blank" rel="noopener">Baptiste Lepers</a></td>
<td style="text-align:right"><a href="https://scholar.google.com/citations?user=6dsH-1oAAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener">Baptiste Lepers</a></td>
<td style="text-align:right"><a href="http://dblp.uni-trier.de/pers/hd/l/Lepers:Baptiste" target="_blank" rel="noopener">Baptiste Lepers</a></td>
</tr>
<tr>
<td style="text-align:left">Jeremie Decouchant</td>
<td style="text-align:center"><a href="https://wwwen.uni.lu/snt/people/jeremie_decouchant" target="_blank" rel="noopener">Jeremie Decouchant</a></td>
<td style="text-align:right"><a href="https://scholar.google.com/citations?user=ieSod0sAAAAJ&amp;hl=en" target="_blank" rel="noopener">Jeremie Decouchant</a></td>
<td style="text-align:right"><a href="http://dblp.uni-trier.de/pers/hd/d/Decouchant:Jeremie" target="_blank" rel="noopener">Jeremie Decouchant</a></td>
</tr>
<tr>
<td style="text-align:left">Justin Funston</td>
<td style="text-align:center"><a href="http://www.ece.ubc.ca/~jfunston/" target="_blank" rel="noopener">Justin Funston</a></td>
<td style="text-align:right"></td>
<td style="text-align:right"><a href="http://dblp.uni-trier.de/pers/hd/f/Funston:Justin_R=" target="_blank" rel="noopener">Justin Funston</a></td>
</tr>
<tr>
<td style="text-align:left">Alexandra Fedorova</td>
<td style="text-align:center"><a href="https://www.ece.ubc.ca/~sasha/" target="_blank" rel="noopener">Alexandra Fedorova</a></td>
<td style="text-align:right"><a href="https://scholar.google.com.hk/citations?user=orMwSjoAAAAJ&amp;hl=zh-CN&amp;newwindow=1&amp;oi=sra" target="_blank" rel="noopener">Alexandra Fedorova</a></td>
<td style="text-align:right"><a href="http://dblp.uni-trier.de/pers/hd/f/Fedorova:Alexandra" target="_blank" rel="noopener">Alexandra Fedorova</a></td>
</tr>
<tr>
<td style="text-align:left">Vivien Quema</td>
<td style="text-align:center"><a href="http://lig-membres.imag.fr/quema/" target="_blank" rel="noopener">Vivien Quema</a></td>
<td style="text-align:right"><a href="https://scholar.google.com/citations?user=siaBkcQAAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener">Vivien Quema</a></td>
<td style="text-align:right"><a href="http://dblp.uni-trier.de/pers/hd/q/Qu=eacute=ma:Vivien" target="_blank" rel="noopener">Vivien Quema</a></td>
</tr>
</tbody>
</table>
<ul>
<li><a href="https://scholar.google.com.hk/scholar?hl=zh-CN&amp;newwindow=1&amp;as_sdt=0,5&amp;sciodt=0,5&amp;cites=10083559362640818120&amp;scipsc=" target="_blank" rel="noopener">最新动态</a></li>
</ul>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>在<a href="https://cenalulu.github.io/linux/numa/" target="_blank" rel="noopener">NUMA系统</a>上，内存分布在多个物理节点上，大页损害了NUMA系统的性能。</p>
<p>大页可能加剧有害的NUMA效应，如局部性差和不平衡，这两者均会增加内存访问延迟。</p>
<h4 id="hot-page-effect-amp-amp-page-level-false-sharing"><a href="#hot-page-effect-amp-amp-page-level-false-sharing" class="headerlink" title="hot page effect&amp;&amp;page-level false sharing"></a><em>hot page effect</em>&amp;&amp;<em>page-level false sharing</em></h4><p>大页的应用使内存管理单元更粗糙， 因此，许多频繁访问的内存地址更可能映射到相同的物理页面上，并且使得拥有该页的存储器节点重载(overload) - 这就是所谓的<em>hot page effect</em>。 hot page effect不能通过页面迁移和平衡来解决; 在重新平衡内存之前必须拆分页面。<br><img src="/images/2017/9/8.png" alt=""></p>
<p><img src="/images/2017/9/9.png" alt=""></p>
<p>大页导致线程之间的<em>page-level false sharing</em>(线程访问同一页面上的不同数据)更频繁。 page-level false sharing局部性差，仅通过页面迁移不能解决问题。</p>
<h4 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h4><ul>
<li><p>量化在NUMA系统上大页引起的性能下降。 我们发现它影响到我们benchmark集中25％至30％的应用程序，并导致5％至43％的性能下降。</p>
</li>
<li><p>证明这些性能损失是由于NUMA因素，如局部性差和不平衡。</p>
</li>
<li><p>表明可以使用旧技术和新技术的组合来解决问题。</p>
</li>
</ul>
<h3 id="衡量指标"><a href="#衡量指标" class="headerlink" title="衡量指标"></a>衡量指标</h3><h4 id="衡量大页优势的指标"><a href="#衡量大页优势的指标" class="headerlink" title="衡量大页优势的指标"></a>衡量大页优势的指标</h4><p>由page table walks引起的L2 cache miss的数量（可从硬件性能计数器获得），以及任何核在page fault handler中花费的最长时间。当我们使用大页时，我们预计由于page table walks而导致的L2 cache miss将降低。 类似地，大页将减少页面page fault的数量，从而减少page fault handler花费的时间。</p>
<h4 id="衡量NUMA效应的指标"><a href="#衡量NUMA效应的指标" class="headerlink" title="衡量NUMA效应的指标"></a>衡量NUMA效应的指标</h4><p> local access ratio (LAR)，即访问本地内存的百分比以及内存控制器的流量不平衡。</p>
<p> 对于内存密集型应用程序，低LAR和高不平衡意味着NUMA问题。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>我们的解决方案包括两个组件：现有的NUMA-aware页面放置算法Carrefour，以及基于Carrefour的大页面扩展－Carrefour-LP。 对于一些受影响的应用程序，仅使用Carrefour就能够恢复失去的性能，但在其他情况下，由于hot page effect和page-level false sharing，Carrefour无效。 因此，我们实现了Carrefour-LP，根据需要动态拆分大页来解决hot page effect和page-level false sharing这两个问题。</p>
<p>Carrefour-LP由两部分组成：reactive component和conservative component。</p>
<ul>
<li>reactive component连续监视NUMA效应的指标，如果存在问题，则应用Carrefour的页面平衡技术，如果Carrefour无效，则拆分大页。 </li>
<li>conservative component持续监视大页优势的指标，如果大页能够提供收益，则重新启用以前被禁用的大页。</li>
</ul>
<p>算法见下图。其中4-9行对应于conservative component，其余部分对应于reactive component。<br><img src="/images/2017/9/10.png" alt=""><br>说明：Interleave就将内存page随机分布到各个CPU Core上，使得每个CPU的负载和Remote Access的频率都均匀分布。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>使用大页可能会造成或者加剧NUMA问题，例如减少局部性或不平衡。 在某些情况下，这些问题可以通过使用NUMA-aware页面放置算法来解决，但后者遇到了两个问题：hot page effect和page-level false sharing，这些问题不能通过页面迁移来解决。 为了解决这些问题，我们实现了Carrefour-LP。 实验结果显示，Carrefour-LP恢复了由于大页而损失的性能。</p>
<p>当大型页面（1GB）被广泛使用时，像Carrefour-LP这样的解决方案在未来将会更加重要。</p>

        
      
    </div>

    

    

  </article>

      
      
  <nav class="pagination">
    
      <a class="prev" href="/page/3/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text">上一页</span>
      </a>
    
    
      <a class="next" href="/page/5/">
        <span class="next-text">下一页</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


    
  </section>

          </div>
          

        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:liujunming1163@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/liujunming" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2016 - 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">liujunming</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    


    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script>

  </body>
</html>
